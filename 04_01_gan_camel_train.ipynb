{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.GAN import GAN\n",
    "from utils.loaders import load_safari\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'gan'\n",
    "RUN_ID = '0001'\n",
    "DATA_NAME = 'camel'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train) = load_safari(DATA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5684324c88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[200,:,:,0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/haesun/github/GDL_code/env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/haesun/github/GDL_code/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "gan = GAN(input_dim = (28,28,1)\n",
    "        , discriminator_conv_filters = [64,64,128,128]\n",
    "        , discriminator_conv_kernel_size = [5,5,5,5]\n",
    "        , discriminator_conv_strides = [2,2,2,1]\n",
    "        , discriminator_batch_norm_momentum = None\n",
    "        , discriminator_activation = 'relu'\n",
    "        , discriminator_dropout_rate = 0.4\n",
    "        , discriminator_learning_rate = 0.0008\n",
    "        , generator_initial_dense_layer_size = (7, 7, 64)\n",
    "        , generator_upsample = [2,2, 1, 1]\n",
    "        , generator_conv_filters = [128,64, 64,1]\n",
    "        , generator_conv_kernel_size = [5,5,5,5]\n",
    "        , generator_conv_strides = [1,1, 1, 1]\n",
    "        , generator_batch_norm_momentum = 0.9\n",
    "        , generator_activation = 'relu'\n",
    "        , generator_dropout_rate = None\n",
    "        , generator_learning_rate = 0.0004\n",
    "        , optimiser = 'rmsprop'\n",
    "        , z_dim = 100\n",
    "        )\n",
    "\n",
    "if mode == 'build':\n",
    "    gan.save(RUN_FOLDER)\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_input (InputLa (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_0 (Conv2D (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_1 (Conv2D (None, 7, 7, 64)          102464    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_2 (Conv2D (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_3 (Conv2D (None, 4, 4, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 720,833\n",
      "Trainable params: 720,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_0 (Conv2D)    (None, 14, 14, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "generator_conv_1 (Conv2D)    (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_2 (Conv2DTran (None, 28, 28, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_3 (Conv2DTran (None, 28, 28, 1)         1601      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 844,161\n",
      "Trainable params: 837,377\n",
      "Non-trainable params: 6,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*에포크마다 생성된 샘플 이미지가 `run/gan/0001_camel/images` 폴더에 저장됩니다.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 6000\n",
    "PRINT_EVERY_N_BATCHES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/haesun/github/GDL_code/env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haesun/github/GDL_code/env/lib/python3.7/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: (0.717)(R 0.698, F 0.735)] [D acc: (0.172)(0.344, 0.000)] [G loss: 0.685] [G acc: 1.000]\n",
      "1 [D loss: (0.839)(R 0.640, F 1.039)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.674] [G acc: 1.000]\n",
      "2 [D loss: (1.021)(R 0.634, F 1.408)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.686] [G acc: 1.000]\n",
      "3 [D loss: (0.696)(R 0.686, F 0.707)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.686] [G acc: 1.000]\n",
      "4 [D loss: (0.695)(R 0.687, F 0.703)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.687] [G acc: 1.000]\n",
      "5 [D loss: (0.694)(R 0.688, F 0.701)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.688] [G acc: 1.000]\n",
      "6 [D loss: (0.693)(R 0.688, F 0.699)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.687] [G acc: 1.000]\n",
      "7 [D loss: (0.694)(R 0.687, F 0.700)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.688] [G acc: 1.000]\n",
      "8 [D loss: (0.694)(R 0.687, F 0.701)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.688] [G acc: 1.000]\n",
      "9 [D loss: (0.694)(R 0.688, F 0.701)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.689] [G acc: 1.000]\n",
      "10 [D loss: (0.694)(R 0.689, F 0.699)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.689] [G acc: 1.000]\n",
      "11 [D loss: (0.694)(R 0.689, F 0.699)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.690] [G acc: 0.984]\n",
      "12 [D loss: (0.694)(R 0.689, F 0.699)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.690] [G acc: 0.984]\n",
      "13 [D loss: (0.694)(R 0.689, F 0.699)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.690] [G acc: 0.984]\n",
      "14 [D loss: (0.694)(R 0.690, F 0.698)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.691] [G acc: 0.984]\n",
      "15 [D loss: (0.694)(R 0.691, F 0.698)] [D acc: (0.477)(0.953, 0.000)] [G loss: 0.691] [G acc: 0.969]\n",
      "16 [D loss: (0.694)(R 0.691, F 0.697)] [D acc: (0.492)(0.984, 0.000)] [G loss: 0.692] [G acc: 0.906]\n",
      "17 [D loss: (0.694)(R 0.691, F 0.697)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.692] [G acc: 0.953]\n",
      "18 [D loss: (0.694)(R 0.691, F 0.696)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.692] [G acc: 0.953]\n",
      "19 [D loss: (0.694)(R 0.691, F 0.696)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.692] [G acc: 0.859]\n",
      "20 [D loss: (0.694)(R 0.691, F 0.696)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.692] [G acc: 0.922]\n",
      "21 [D loss: (0.694)(R 0.692, F 0.696)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.692] [G acc: 0.891]\n",
      "22 [D loss: (0.694)(R 0.692, F 0.695)] [D acc: (0.477)(0.953, 0.000)] [G loss: 0.693] [G acc: 0.844]\n",
      "23 [D loss: (0.694)(R 0.692, F 0.695)] [D acc: (0.477)(0.953, 0.000)] [G loss: 0.693] [G acc: 0.781]\n",
      "24 [D loss: (0.694)(R 0.692, F 0.695)] [D acc: (0.438)(0.875, 0.000)] [G loss: 0.693] [G acc: 0.844]\n",
      "25 [D loss: (0.693)(R 0.692, F 0.695)] [D acc: (0.453)(0.906, 0.000)] [G loss: 0.693] [G acc: 0.828]\n",
      "26 [D loss: (0.693)(R 0.692, F 0.695)] [D acc: (0.492)(0.953, 0.031)] [G loss: 0.693] [G acc: 0.609]\n",
      "27 [D loss: (0.694)(R 0.692, F 0.695)] [D acc: (0.430)(0.844, 0.016)] [G loss: 0.693] [G acc: 0.484]\n",
      "28 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.477)(0.859, 0.094)] [G loss: 0.693] [G acc: 0.328]\n",
      "29 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.422)(0.781, 0.062)] [G loss: 0.693] [G acc: 0.359]\n",
      "30 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.398)(0.797, 0.000)] [G loss: 0.693] [G acc: 0.312]\n",
      "31 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.320)(0.625, 0.016)] [G loss: 0.693] [G acc: 0.359]\n",
      "32 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.406)(0.750, 0.062)] [G loss: 0.693] [G acc: 0.531]\n",
      "33 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.414)(0.781, 0.047)] [G loss: 0.693] [G acc: 0.344]\n",
      "34 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.352)(0.641, 0.062)] [G loss: 0.693] [G acc: 0.516]\n",
      "35 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.453)(0.797, 0.109)] [G loss: 0.693] [G acc: 0.422]\n",
      "36 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.352)(0.672, 0.031)] [G loss: 0.693] [G acc: 0.406]\n",
      "37 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.445)(0.734, 0.156)] [G loss: 0.694] [G acc: 0.141]\n",
      "38 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.359)(0.578, 0.141)] [G loss: 0.694] [G acc: 0.359]\n",
      "39 [D loss: (0.694)(R 0.693, F 0.694)] [D acc: (0.320)(0.516, 0.125)] [G loss: 0.693] [G acc: 0.391]\n",
      "40 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.422)(0.797, 0.047)] [G loss: 0.693] [G acc: 0.531]\n",
      "41 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.344)(0.672, 0.016)] [G loss: 0.693] [G acc: 0.484]\n",
      "42 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.414)(0.766, 0.062)] [G loss: 0.693] [G acc: 0.344]\n",
      "43 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.188)(0.344, 0.031)] [G loss: 0.693] [G acc: 0.438]\n",
      "44 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.406)(0.750, 0.062)] [G loss: 0.693] [G acc: 0.391]\n",
      "45 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.693] [G acc: 0.203]\n",
      "46 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.266)(0.484, 0.047)] [G loss: 0.693] [G acc: 0.172]\n",
      "47 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.289)(0.516, 0.062)] [G loss: 0.693] [G acc: 0.281]\n",
      "48 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.430)(0.688, 0.172)] [G loss: 0.694] [G acc: 0.125]\n",
      "49 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.188)(0.344, 0.031)] [G loss: 0.693] [G acc: 0.438]\n",
      "50 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.461)(0.766, 0.156)] [G loss: 0.694] [G acc: 0.219]\n",
      "51 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.367)(0.672, 0.062)] [G loss: 0.694] [G acc: 0.172]\n",
      "52 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.516)(0.750, 0.281)] [G loss: 0.694] [G acc: 0.188]\n",
      "53 [D loss: (0.693)(R 0.693, F 0.693)] [D acc: (0.539)(0.578, 0.500)] [G loss: 0.697] [G acc: 0.016]\n",
      "54 [D loss: (0.696)(R 0.692, F 0.700)] [D acc: (0.414)(0.719, 0.109)] [G loss: 0.694] [G acc: 0.078]\n",
      "55 [D loss: (0.694)(R 0.693, F 0.694)] [D acc: (0.242)(0.406, 0.078)] [G loss: 0.693] [G acc: 0.438]\n",
      "56 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.367)(0.641, 0.094)] [G loss: 0.693] [G acc: 0.500]\n",
      "57 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.547)(0.828, 0.266)] [G loss: 0.693] [G acc: 0.406]\n",
      "58 [D loss: (0.694)(R 0.692, F 0.695)] [D acc: (0.430)(0.750, 0.109)] [G loss: 0.693] [G acc: 0.453]\n",
      "59 [D loss: (0.693)(R 0.692, F 0.694)] [D acc: (0.469)(0.812, 0.125)] [G loss: 0.694] [G acc: 0.219]\n",
      "60 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.391)(0.656, 0.125)] [G loss: 0.693] [G acc: 0.219]\n",
      "61 [D loss: (0.693)(R 0.692, F 0.694)] [D acc: (0.484)(0.781, 0.188)] [G loss: 0.694] [G acc: 0.172]\n",
      "62 [D loss: (0.694)(R 0.692, F 0.696)] [D acc: (0.367)(0.703, 0.031)] [G loss: 0.694] [G acc: 0.078]\n",
      "63 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.383)(0.609, 0.156)] [G loss: 0.694] [G acc: 0.250]\n",
      "64 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.500)(0.797, 0.203)] [G loss: 0.694] [G acc: 0.203]\n",
      "65 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.414)(0.750, 0.078)] [G loss: 0.693] [G acc: 0.344]\n",
      "66 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.406)(0.688, 0.125)] [G loss: 0.693] [G acc: 0.328]\n",
      "67 [D loss: (0.693)(R 0.692, F 0.695)] [D acc: (0.477)(0.906, 0.047)] [G loss: 0.694] [G acc: 0.219]\n",
      "68 [D loss: (0.693)(R 0.693, F 0.694)] [D acc: (0.406)(0.734, 0.078)] [G loss: 0.693] [G acc: 0.375]\n",
      "69 [D loss: (0.693)(R 0.691, F 0.696)] [D acc: (0.477)(0.891, 0.062)] [G loss: 0.694] [G acc: 0.141]\n",
      "70 [D loss: (0.693)(R 0.692, F 0.694)] [D acc: (0.539)(0.703, 0.375)] [G loss: 0.694] [G acc: 0.156]\n",
      "71 [D loss: (0.693)(R 0.692, F 0.695)] [D acc: (0.484)(0.844, 0.125)] [G loss: 0.694] [G acc: 0.219]\n",
      "72 [D loss: (0.693)(R 0.692, F 0.695)] [D acc: (0.422)(0.781, 0.062)] [G loss: 0.694] [G acc: 0.203]\n",
      "73 [D loss: (0.692)(R 0.691, F 0.694)] [D acc: (0.617)(0.938, 0.297)] [G loss: 0.694] [G acc: 0.172]\n",
      "74 [D loss: (0.700)(R 0.689, F 0.712)] [D acc: (0.414)(0.812, 0.016)] [G loss: 0.695] [G acc: 0.047]\n",
      "75 [D loss: (0.692)(R 0.692, F 0.693)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.697] [G acc: 0.062]\n",
      "76 [D loss: (0.693)(R 0.690, F 0.696)] [D acc: (0.523)(0.781, 0.266)] [G loss: 0.695] [G acc: 0.219]\n",
      "77 [D loss: (0.691)(R 0.688, F 0.694)] [D acc: (0.648)(0.812, 0.484)] [G loss: 0.698] [G acc: 0.062]\n",
      "78 [D loss: (0.695)(R 0.687, F 0.703)] [D acc: (0.438)(0.781, 0.094)] [G loss: 0.699] [G acc: 0.031]\n",
      "79 [D loss: (0.692)(R 0.688, F 0.697)] [D acc: (0.539)(0.797, 0.281)] [G loss: 0.694] [G acc: 0.344]\n",
      "80 [D loss: (0.694)(R 0.686, F 0.703)] [D acc: (0.445)(0.844, 0.047)] [G loss: 0.694] [G acc: 0.328]\n",
      "81 [D loss: (0.692)(R 0.686, F 0.698)] [D acc: (0.578)(0.922, 0.234)] [G loss: 0.696] [G acc: 0.250]\n",
      "82 [D loss: (0.692)(R 0.688, F 0.697)] [D acc: (0.555)(0.781, 0.328)] [G loss: 0.695] [G acc: 0.266]\n",
      "83 [D loss: (0.695)(R 0.683, F 0.708)] [D acc: (0.492)(0.875, 0.109)] [G loss: 0.695] [G acc: 0.234]\n",
      "84 [D loss: (0.692)(R 0.686, F 0.697)] [D acc: (0.539)(0.844, 0.234)] [G loss: 0.697] [G acc: 0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 [D loss: (0.690)(R 0.684, F 0.697)] [D acc: (0.609)(0.891, 0.328)] [G loss: 0.704] [G acc: 0.109]\n",
      "86 [D loss: (0.688)(R 0.680, F 0.696)] [D acc: (0.609)(0.766, 0.453)] [G loss: 0.710] [G acc: 0.000]\n",
      "87 [D loss: (0.699)(R 0.675, F 0.723)] [D acc: (0.500)(0.828, 0.172)] [G loss: 0.699] [G acc: 0.297]\n",
      "88 [D loss: (0.683)(R 0.680, F 0.686)] [D acc: (0.758)(0.734, 0.781)] [G loss: 0.714] [G acc: 0.125]\n",
      "89 [D loss: (0.700)(R 0.663, F 0.738)] [D acc: (0.492)(0.875, 0.109)] [G loss: 0.718] [G acc: 0.047]\n",
      "90 [D loss: (0.692)(R 0.678, F 0.706)] [D acc: (0.484)(0.688, 0.281)] [G loss: 0.704] [G acc: 0.188]\n",
      "91 [D loss: (0.689)(R 0.674, F 0.705)] [D acc: (0.609)(0.828, 0.391)] [G loss: 0.703] [G acc: 0.344]\n",
      "92 [D loss: (0.690)(R 0.672, F 0.709)] [D acc: (0.523)(0.781, 0.266)] [G loss: 0.711] [G acc: 0.078]\n",
      "93 [D loss: (0.699)(R 0.680, F 0.717)] [D acc: (0.461)(0.766, 0.156)] [G loss: 0.698] [G acc: 0.328]\n",
      "94 [D loss: (0.696)(R 0.677, F 0.715)] [D acc: (0.422)(0.766, 0.078)] [G loss: 0.695] [G acc: 0.359]\n",
      "95 [D loss: (0.697)(R 0.680, F 0.713)] [D acc: (0.461)(0.750, 0.172)] [G loss: 0.694] [G acc: 0.516]\n",
      "96 [D loss: (0.695)(R 0.685, F 0.706)] [D acc: (0.414)(0.688, 0.141)] [G loss: 0.692] [G acc: 0.516]\n",
      "97 [D loss: (0.693)(R 0.679, F 0.706)] [D acc: (0.438)(0.797, 0.078)] [G loss: 0.693] [G acc: 0.469]\n",
      "98 [D loss: (0.693)(R 0.683, F 0.703)] [D acc: (0.430)(0.703, 0.156)] [G loss: 0.693] [G acc: 0.500]\n",
      "99 [D loss: (0.692)(R 0.683, F 0.701)] [D acc: (0.492)(0.766, 0.219)] [G loss: 0.696] [G acc: 0.312]\n",
      "100 [D loss: (0.694)(R 0.681, F 0.708)] [D acc: (0.484)(0.781, 0.188)] [G loss: 0.695] [G acc: 0.297]\n",
      "101 [D loss: (0.693)(R 0.679, F 0.707)] [D acc: (0.492)(0.766, 0.219)] [G loss: 0.694] [G acc: 0.328]\n",
      "102 [D loss: (0.699)(R 0.682, F 0.716)] [D acc: (0.547)(0.766, 0.328)] [G loss: 0.697] [G acc: 0.281]\n",
      "103 [D loss: (0.694)(R 0.683, F 0.705)] [D acc: (0.555)(0.781, 0.328)] [G loss: 0.696] [G acc: 0.406]\n",
      "104 [D loss: (0.691)(R 0.682, F 0.701)] [D acc: (0.594)(0.781, 0.406)] [G loss: 0.699] [G acc: 0.219]\n",
      "105 [D loss: (0.686)(R 0.678, F 0.694)] [D acc: (0.680)(0.859, 0.500)] [G loss: 0.708] [G acc: 0.156]\n",
      "106 [D loss: (0.695)(R 0.682, F 0.709)] [D acc: (0.445)(0.625, 0.266)] [G loss: 0.709] [G acc: 0.125]\n",
      "107 [D loss: (0.693)(R 0.673, F 0.713)] [D acc: (0.594)(0.891, 0.297)] [G loss: 0.691] [G acc: 0.531]\n",
      "108 [D loss: (0.692)(R 0.677, F 0.708)] [D acc: (0.500)(0.672, 0.328)] [G loss: 0.700] [G acc: 0.281]\n",
      "109 [D loss: (0.692)(R 0.675, F 0.709)] [D acc: (0.547)(0.797, 0.297)] [G loss: 0.696] [G acc: 0.391]\n",
      "110 [D loss: (0.694)(R 0.678, F 0.709)] [D acc: (0.492)(0.750, 0.234)] [G loss: 0.698] [G acc: 0.312]\n",
      "111 [D loss: (0.697)(R 0.682, F 0.712)] [D acc: (0.414)(0.656, 0.172)] [G loss: 0.693] [G acc: 0.406]\n",
      "112 [D loss: (0.693)(R 0.679, F 0.707)] [D acc: (0.469)(0.734, 0.203)] [G loss: 0.698] [G acc: 0.281]\n",
      "113 [D loss: (0.692)(R 0.679, F 0.705)] [D acc: (0.516)(0.750, 0.281)] [G loss: 0.693] [G acc: 0.469]\n",
      "114 [D loss: (0.697)(R 0.678, F 0.716)] [D acc: (0.492)(0.828, 0.156)] [G loss: 0.698] [G acc: 0.219]\n",
      "115 [D loss: (0.691)(R 0.683, F 0.700)] [D acc: (0.523)(0.734, 0.312)] [G loss: 0.699] [G acc: 0.266]\n",
      "116 [D loss: (0.694)(R 0.683, F 0.705)] [D acc: (0.461)(0.672, 0.250)] [G loss: 0.697] [G acc: 0.281]\n",
      "117 [D loss: (0.693)(R 0.680, F 0.705)] [D acc: (0.562)(0.781, 0.344)] [G loss: 0.696] [G acc: 0.312]\n",
      "118 [D loss: (0.693)(R 0.686, F 0.699)] [D acc: (0.469)(0.609, 0.328)] [G loss: 0.693] [G acc: 0.359]\n",
      "119 [D loss: (0.695)(R 0.685, F 0.705)] [D acc: (0.445)(0.625, 0.266)] [G loss: 0.695] [G acc: 0.375]\n",
      "120 [D loss: (0.692)(R 0.685, F 0.699)] [D acc: (0.531)(0.703, 0.359)] [G loss: 0.696] [G acc: 0.266]\n",
      "121 [D loss: (0.694)(R 0.684, F 0.705)] [D acc: (0.453)(0.719, 0.188)] [G loss: 0.695] [G acc: 0.375]\n",
      "122 [D loss: (0.693)(R 0.686, F 0.699)] [D acc: (0.445)(0.641, 0.250)] [G loss: 0.695] [G acc: 0.344]\n",
      "123 [D loss: (0.693)(R 0.686, F 0.699)] [D acc: (0.523)(0.719, 0.328)] [G loss: 0.697] [G acc: 0.234]\n",
      "124 [D loss: (0.694)(R 0.685, F 0.702)] [D acc: (0.492)(0.734, 0.250)] [G loss: 0.692] [G acc: 0.531]\n",
      "125 [D loss: (0.694)(R 0.686, F 0.701)] [D acc: (0.508)(0.734, 0.281)] [G loss: 0.694] [G acc: 0.406]\n",
      "126 [D loss: (0.693)(R 0.685, F 0.700)] [D acc: (0.555)(0.828, 0.281)] [G loss: 0.694] [G acc: 0.344]\n",
      "127 [D loss: (0.696)(R 0.686, F 0.705)] [D acc: (0.398)(0.531, 0.266)] [G loss: 0.695] [G acc: 0.344]\n",
      "128 [D loss: (0.693)(R 0.686, F 0.699)] [D acc: (0.547)(0.812, 0.281)] [G loss: 0.694] [G acc: 0.406]\n",
      "129 [D loss: (0.693)(R 0.686, F 0.699)] [D acc: (0.523)(0.734, 0.312)] [G loss: 0.693] [G acc: 0.469]\n",
      "130 [D loss: (0.694)(R 0.687, F 0.701)] [D acc: (0.484)(0.641, 0.328)] [G loss: 0.692] [G acc: 0.500]\n",
      "131 [D loss: (0.693)(R 0.688, F 0.698)] [D acc: (0.492)(0.625, 0.359)] [G loss: 0.692] [G acc: 0.484]\n",
      "132 [D loss: (0.695)(R 0.685, F 0.704)] [D acc: (0.461)(0.719, 0.203)] [G loss: 0.693] [G acc: 0.453]\n",
      "133 [D loss: (0.692)(R 0.686, F 0.699)] [D acc: (0.492)(0.734, 0.250)] [G loss: 0.692] [G acc: 0.500]\n",
      "134 [D loss: (0.693)(R 0.683, F 0.702)] [D acc: (0.523)(0.812, 0.234)] [G loss: 0.693] [G acc: 0.500]\n",
      "135 [D loss: (0.694)(R 0.685, F 0.703)] [D acc: (0.461)(0.703, 0.219)] [G loss: 0.692] [G acc: 0.516]\n",
      "136 [D loss: (0.693)(R 0.684, F 0.702)] [D acc: (0.477)(0.688, 0.266)] [G loss: 0.692] [G acc: 0.531]\n",
      "137 [D loss: (0.696)(R 0.683, F 0.710)] [D acc: (0.531)(0.859, 0.203)] [G loss: 0.693] [G acc: 0.438]\n",
      "138 [D loss: (0.694)(R 0.685, F 0.702)] [D acc: (0.508)(0.719, 0.297)] [G loss: 0.693] [G acc: 0.453]\n",
      "139 [D loss: (0.694)(R 0.685, F 0.702)] [D acc: (0.508)(0.750, 0.266)] [G loss: 0.692] [G acc: 0.516]\n",
      "140 [D loss: (0.692)(R 0.687, F 0.698)] [D acc: (0.469)(0.641, 0.297)] [G loss: 0.693] [G acc: 0.391]\n",
      "141 [D loss: (0.694)(R 0.684, F 0.704)] [D acc: (0.492)(0.734, 0.250)] [G loss: 0.693] [G acc: 0.438]\n",
      "142 [D loss: (0.694)(R 0.687, F 0.701)] [D acc: (0.469)(0.656, 0.281)] [G loss: 0.693] [G acc: 0.453]\n",
      "143 [D loss: (0.693)(R 0.688, F 0.699)] [D acc: (0.453)(0.688, 0.219)] [G loss: 0.693] [G acc: 0.469]\n",
      "144 [D loss: (0.694)(R 0.688, F 0.700)] [D acc: (0.492)(0.719, 0.266)] [G loss: 0.693] [G acc: 0.438]\n",
      "145 [D loss: (0.693)(R 0.687, F 0.698)] [D acc: (0.430)(0.656, 0.203)] [G loss: 0.692] [G acc: 0.562]\n",
      "146 [D loss: (0.695)(R 0.686, F 0.704)] [D acc: (0.375)(0.578, 0.172)] [G loss: 0.693] [G acc: 0.484]\n",
      "147 [D loss: (0.694)(R 0.688, F 0.699)] [D acc: (0.508)(0.734, 0.281)] [G loss: 0.693] [G acc: 0.469]\n",
      "148 [D loss: (0.692)(R 0.687, F 0.698)] [D acc: (0.516)(0.719, 0.312)] [G loss: 0.694] [G acc: 0.406]\n",
      "149 [D loss: (0.691)(R 0.686, F 0.696)] [D acc: (0.570)(0.781, 0.359)] [G loss: 0.695] [G acc: 0.328]\n",
      "150 [D loss: (0.693)(R 0.688, F 0.697)] [D acc: (0.445)(0.578, 0.312)] [G loss: 0.692] [G acc: 0.500]\n",
      "151 [D loss: (0.691)(R 0.682, F 0.699)] [D acc: (0.562)(0.828, 0.297)] [G loss: 0.692] [G acc: 0.516]\n",
      "152 [D loss: (0.701)(R 0.684, F 0.719)] [D acc: (0.359)(0.609, 0.109)] [G loss: 0.694] [G acc: 0.469]\n",
      "153 [D loss: (0.692)(R 0.687, F 0.697)] [D acc: (0.492)(0.672, 0.312)] [G loss: 0.693] [G acc: 0.438]\n",
      "154 [D loss: (0.694)(R 0.687, F 0.701)] [D acc: (0.508)(0.766, 0.250)] [G loss: 0.696] [G acc: 0.266]\n",
      "155 [D loss: (0.693)(R 0.689, F 0.697)] [D acc: (0.492)(0.641, 0.344)] [G loss: 0.693] [G acc: 0.484]\n",
      "156 [D loss: (0.693)(R 0.687, F 0.699)] [D acc: (0.539)(0.797, 0.281)] [G loss: 0.695] [G acc: 0.297]\n",
      "157 [D loss: (0.692)(R 0.687, F 0.696)] [D acc: (0.555)(0.703, 0.406)] [G loss: 0.694] [G acc: 0.453]\n",
      "158 [D loss: (0.694)(R 0.685, F 0.702)] [D acc: (0.539)(0.750, 0.328)] [G loss: 0.697] [G acc: 0.203]\n",
      "159 [D loss: (0.694)(R 0.687, F 0.701)] [D acc: (0.484)(0.641, 0.328)] [G loss: 0.692] [G acc: 0.516]\n",
      "160 [D loss: (0.691)(R 0.686, F 0.696)] [D acc: (0.594)(0.703, 0.484)] [G loss: 0.694] [G acc: 0.359]\n",
      "161 [D loss: (0.697)(R 0.684, F 0.710)] [D acc: (0.430)(0.688, 0.172)] [G loss: 0.694] [G acc: 0.453]\n",
      "162 [D loss: (0.692)(R 0.685, F 0.700)] [D acc: (0.539)(0.812, 0.266)] [G loss: 0.694] [G acc: 0.453]\n",
      "163 [D loss: (0.690)(R 0.685, F 0.696)] [D acc: (0.586)(0.766, 0.406)] [G loss: 0.695] [G acc: 0.422]\n",
      "164 [D loss: (0.693)(R 0.687, F 0.699)] [D acc: (0.438)(0.656, 0.219)] [G loss: 0.693] [G acc: 0.406]\n",
      "165 [D loss: (0.693)(R 0.684, F 0.703)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.693] [G acc: 0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 [D loss: (0.692)(R 0.682, F 0.701)] [D acc: (0.547)(0.781, 0.312)] [G loss: 0.693] [G acc: 0.484]\n",
      "167 [D loss: (0.692)(R 0.682, F 0.702)] [D acc: (0.508)(0.766, 0.250)] [G loss: 0.694] [G acc: 0.391]\n",
      "168 [D loss: (0.693)(R 0.681, F 0.705)] [D acc: (0.508)(0.797, 0.219)] [G loss: 0.690] [G acc: 0.594]\n",
      "169 [D loss: (0.694)(R 0.682, F 0.705)] [D acc: (0.562)(0.859, 0.266)] [G loss: 0.695] [G acc: 0.344]\n",
      "170 [D loss: (0.696)(R 0.689, F 0.703)] [D acc: (0.398)(0.609, 0.188)] [G loss: 0.692] [G acc: 0.594]\n",
      "171 [D loss: (0.694)(R 0.681, F 0.706)] [D acc: (0.516)(0.812, 0.219)] [G loss: 0.693] [G acc: 0.422]\n",
      "172 [D loss: (0.689)(R 0.683, F 0.696)] [D acc: (0.578)(0.797, 0.359)] [G loss: 0.696] [G acc: 0.359]\n",
      "173 [D loss: (0.691)(R 0.682, F 0.699)] [D acc: (0.492)(0.672, 0.312)] [G loss: 0.695] [G acc: 0.438]\n",
      "174 [D loss: (0.690)(R 0.681, F 0.698)] [D acc: (0.562)(0.781, 0.344)] [G loss: 0.700] [G acc: 0.250]\n",
      "175 [D loss: (0.690)(R 0.679, F 0.702)] [D acc: (0.461)(0.625, 0.297)] [G loss: 0.707] [G acc: 0.156]\n",
      "176 [D loss: (0.691)(R 0.669, F 0.713)] [D acc: (0.547)(0.797, 0.297)] [G loss: 0.695] [G acc: 0.438]\n",
      "177 [D loss: (0.693)(R 0.677, F 0.710)] [D acc: (0.453)(0.719, 0.188)] [G loss: 0.689] [G acc: 0.547]\n",
      "178 [D loss: (0.692)(R 0.661, F 0.723)] [D acc: (0.570)(0.906, 0.234)] [G loss: 0.693] [G acc: 0.438]\n",
      "179 [D loss: (0.690)(R 0.672, F 0.708)] [D acc: (0.516)(0.734, 0.297)] [G loss: 0.693] [G acc: 0.500]\n",
      "180 [D loss: (0.696)(R 0.671, F 0.722)] [D acc: (0.484)(0.750, 0.219)] [G loss: 0.697] [G acc: 0.406]\n",
      "181 [D loss: (0.691)(R 0.674, F 0.708)] [D acc: (0.523)(0.750, 0.297)] [G loss: 0.692] [G acc: 0.469]\n",
      "182 [D loss: (0.694)(R 0.674, F 0.714)] [D acc: (0.500)(0.781, 0.219)] [G loss: 0.690] [G acc: 0.469]\n",
      "183 [D loss: (0.695)(R 0.675, F 0.716)] [D acc: (0.484)(0.812, 0.156)] [G loss: 0.695] [G acc: 0.312]\n",
      "184 [D loss: (0.690)(R 0.674, F 0.706)] [D acc: (0.531)(0.766, 0.297)] [G loss: 0.697] [G acc: 0.375]\n",
      "185 [D loss: (0.694)(R 0.677, F 0.710)] [D acc: (0.492)(0.734, 0.250)] [G loss: 0.696] [G acc: 0.359]\n",
      "186 [D loss: (0.689)(R 0.669, F 0.708)] [D acc: (0.570)(0.797, 0.344)] [G loss: 0.698] [G acc: 0.266]\n",
      "187 [D loss: (0.690)(R 0.676, F 0.703)] [D acc: (0.555)(0.797, 0.312)] [G loss: 0.689] [G acc: 0.516]\n",
      "188 [D loss: (0.689)(R 0.672, F 0.705)] [D acc: (0.633)(0.781, 0.484)] [G loss: 0.695] [G acc: 0.391]\n",
      "189 [D loss: (0.687)(R 0.662, F 0.712)] [D acc: (0.586)(0.828, 0.344)] [G loss: 0.713] [G acc: 0.219]\n",
      "190 [D loss: (0.692)(R 0.679, F 0.705)] [D acc: (0.594)(0.641, 0.547)] [G loss: 0.717] [G acc: 0.266]\n",
      "191 [D loss: (0.690)(R 0.674, F 0.707)] [D acc: (0.523)(0.688, 0.359)] [G loss: 0.695] [G acc: 0.359]\n",
      "192 [D loss: (0.696)(R 0.660, F 0.731)] [D acc: (0.445)(0.766, 0.125)] [G loss: 0.693] [G acc: 0.484]\n",
      "193 [D loss: (0.693)(R 0.669, F 0.717)] [D acc: (0.469)(0.688, 0.250)] [G loss: 0.695] [G acc: 0.453]\n",
      "194 [D loss: (0.684)(R 0.663, F 0.704)] [D acc: (0.586)(0.750, 0.422)] [G loss: 0.702] [G acc: 0.406]\n",
      "195 [D loss: (0.692)(R 0.675, F 0.709)] [D acc: (0.445)(0.641, 0.250)] [G loss: 0.695] [G acc: 0.406]\n",
      "196 [D loss: (0.690)(R 0.665, F 0.716)] [D acc: (0.539)(0.766, 0.312)] [G loss: 0.702] [G acc: 0.375]\n",
      "197 [D loss: (0.684)(R 0.669, F 0.699)] [D acc: (0.609)(0.688, 0.531)] [G loss: 0.698] [G acc: 0.328]\n",
      "198 [D loss: (0.691)(R 0.653, F 0.729)] [D acc: (0.469)(0.781, 0.156)] [G loss: 0.691] [G acc: 0.469]\n",
      "199 [D loss: (0.691)(R 0.663, F 0.718)] [D acc: (0.531)(0.781, 0.281)] [G loss: 0.696] [G acc: 0.422]\n",
      "200 [D loss: (0.691)(R 0.659, F 0.722)] [D acc: (0.547)(0.797, 0.297)] [G loss: 0.690] [G acc: 0.516]\n",
      "201 [D loss: (0.694)(R 0.662, F 0.725)] [D acc: (0.492)(0.781, 0.203)] [G loss: 0.702] [G acc: 0.344]\n",
      "202 [D loss: (0.687)(R 0.670, F 0.704)] [D acc: (0.570)(0.766, 0.375)] [G loss: 0.703] [G acc: 0.406]\n",
      "203 [D loss: (0.694)(R 0.676, F 0.711)] [D acc: (0.484)(0.625, 0.344)] [G loss: 0.697] [G acc: 0.406]\n",
      "204 [D loss: (0.692)(R 0.660, F 0.724)] [D acc: (0.477)(0.734, 0.219)] [G loss: 0.697] [G acc: 0.500]\n",
      "205 [D loss: (0.691)(R 0.666, F 0.716)] [D acc: (0.469)(0.703, 0.234)] [G loss: 0.703] [G acc: 0.344]\n",
      "206 [D loss: (0.684)(R 0.664, F 0.705)] [D acc: (0.539)(0.750, 0.328)] [G loss: 0.700] [G acc: 0.359]\n",
      "207 [D loss: (0.691)(R 0.661, F 0.720)] [D acc: (0.516)(0.688, 0.344)] [G loss: 0.690] [G acc: 0.438]\n",
      "208 [D loss: (0.682)(R 0.656, F 0.708)] [D acc: (0.625)(0.828, 0.422)] [G loss: 0.697] [G acc: 0.406]\n",
      "209 [D loss: (0.690)(R 0.663, F 0.718)] [D acc: (0.570)(0.750, 0.391)] [G loss: 0.697] [G acc: 0.484]\n",
      "210 [D loss: (0.687)(R 0.663, F 0.710)] [D acc: (0.523)(0.719, 0.328)] [G loss: 0.692] [G acc: 0.391]\n",
      "211 [D loss: (0.690)(R 0.656, F 0.724)] [D acc: (0.516)(0.750, 0.281)] [G loss: 0.705] [G acc: 0.344]\n",
      "212 [D loss: (0.686)(R 0.659, F 0.713)] [D acc: (0.562)(0.719, 0.406)] [G loss: 0.712] [G acc: 0.328]\n",
      "213 [D loss: (0.683)(R 0.645, F 0.722)] [D acc: (0.531)(0.703, 0.359)] [G loss: 0.695] [G acc: 0.469]\n",
      "214 [D loss: (0.683)(R 0.633, F 0.732)] [D acc: (0.555)(0.734, 0.375)] [G loss: 0.708] [G acc: 0.234]\n",
      "215 [D loss: (0.680)(R 0.653, F 0.706)] [D acc: (0.602)(0.719, 0.484)] [G loss: 0.727] [G acc: 0.328]\n",
      "216 [D loss: (0.687)(R 0.636, F 0.739)] [D acc: (0.492)(0.719, 0.266)] [G loss: 0.700] [G acc: 0.375]\n",
      "217 [D loss: (0.696)(R 0.638, F 0.754)] [D acc: (0.500)(0.734, 0.266)] [G loss: 0.691] [G acc: 0.484]\n",
      "218 [D loss: (0.691)(R 0.636, F 0.747)] [D acc: (0.500)(0.812, 0.188)] [G loss: 0.684] [G acc: 0.547]\n",
      "219 [D loss: (0.688)(R 0.639, F 0.737)] [D acc: (0.586)(0.844, 0.328)] [G loss: 0.694] [G acc: 0.484]\n",
      "220 [D loss: (0.677)(R 0.637, F 0.717)] [D acc: (0.578)(0.797, 0.359)] [G loss: 0.707] [G acc: 0.266]\n",
      "221 [D loss: (0.688)(R 0.631, F 0.744)] [D acc: (0.531)(0.844, 0.219)] [G loss: 0.697] [G acc: 0.438]\n",
      "222 [D loss: (0.691)(R 0.636, F 0.747)] [D acc: (0.555)(0.750, 0.359)] [G loss: 0.678] [G acc: 0.594]\n",
      "223 [D loss: (0.690)(R 0.649, F 0.731)] [D acc: (0.508)(0.719, 0.297)] [G loss: 0.696] [G acc: 0.438]\n",
      "224 [D loss: (0.683)(R 0.640, F 0.726)] [D acc: (0.531)(0.734, 0.328)] [G loss: 0.702] [G acc: 0.391]\n",
      "225 [D loss: (0.681)(R 0.634, F 0.727)] [D acc: (0.547)(0.734, 0.359)] [G loss: 0.682] [G acc: 0.578]\n",
      "226 [D loss: (0.686)(R 0.623, F 0.748)] [D acc: (0.570)(0.797, 0.344)] [G loss: 0.694] [G acc: 0.484]\n",
      "227 [D loss: (0.687)(R 0.634, F 0.739)] [D acc: (0.500)(0.766, 0.234)] [G loss: 0.690] [G acc: 0.453]\n",
      "228 [D loss: (0.690)(R 0.630, F 0.750)] [D acc: (0.492)(0.688, 0.297)] [G loss: 0.698] [G acc: 0.453]\n",
      "229 [D loss: (0.686)(R 0.651, F 0.721)] [D acc: (0.555)(0.734, 0.375)] [G loss: 0.685] [G acc: 0.547]\n",
      "230 [D loss: (0.683)(R 0.630, F 0.735)] [D acc: (0.586)(0.781, 0.391)] [G loss: 0.695] [G acc: 0.422]\n",
      "231 [D loss: (0.687)(R 0.632, F 0.742)] [D acc: (0.523)(0.797, 0.250)] [G loss: 0.702] [G acc: 0.391]\n",
      "232 [D loss: (0.682)(R 0.632, F 0.731)] [D acc: (0.516)(0.766, 0.266)] [G loss: 0.707] [G acc: 0.359]\n",
      "233 [D loss: (0.696)(R 0.630, F 0.762)] [D acc: (0.508)(0.703, 0.312)] [G loss: 0.697] [G acc: 0.500]\n",
      "234 [D loss: (0.688)(R 0.638, F 0.738)] [D acc: (0.461)(0.641, 0.281)] [G loss: 0.685] [G acc: 0.578]\n",
      "235 [D loss: (0.682)(R 0.618, F 0.746)] [D acc: (0.578)(0.781, 0.375)] [G loss: 0.682] [G acc: 0.625]\n",
      "236 [D loss: (0.693)(R 0.625, F 0.761)] [D acc: (0.523)(0.797, 0.250)] [G loss: 0.695] [G acc: 0.438]\n",
      "237 [D loss: (0.693)(R 0.633, F 0.753)] [D acc: (0.484)(0.750, 0.219)] [G loss: 0.685] [G acc: 0.547]\n",
      "238 [D loss: (0.679)(R 0.629, F 0.729)] [D acc: (0.570)(0.797, 0.344)] [G loss: 0.689] [G acc: 0.422]\n",
      "239 [D loss: (0.691)(R 0.626, F 0.757)] [D acc: (0.516)(0.781, 0.250)] [G loss: 0.691] [G acc: 0.375]\n",
      "240 [D loss: (0.682)(R 0.629, F 0.736)] [D acc: (0.586)(0.781, 0.391)] [G loss: 0.707] [G acc: 0.328]\n",
      "241 [D loss: (0.692)(R 0.652, F 0.732)] [D acc: (0.508)(0.734, 0.281)] [G loss: 0.697] [G acc: 0.406]\n",
      "242 [D loss: (0.685)(R 0.640, F 0.730)] [D acc: (0.523)(0.719, 0.328)] [G loss: 0.703] [G acc: 0.391]\n",
      "243 [D loss: (0.668)(R 0.631, F 0.705)] [D acc: (0.633)(0.766, 0.500)] [G loss: 0.709] [G acc: 0.281]\n",
      "244 [D loss: (0.684)(R 0.631, F 0.737)] [D acc: (0.539)(0.719, 0.359)] [G loss: 0.729] [G acc: 0.297]\n",
      "245 [D loss: (0.691)(R 0.635, F 0.746)] [D acc: (0.516)(0.766, 0.266)] [G loss: 0.706] [G acc: 0.406]\n",
      "246 [D loss: (0.674)(R 0.632, F 0.717)] [D acc: (0.586)(0.766, 0.406)] [G loss: 0.698] [G acc: 0.453]\n",
      "247 [D loss: (0.690)(R 0.643, F 0.738)] [D acc: (0.555)(0.688, 0.422)] [G loss: 0.697] [G acc: 0.516]\n",
      "248 [D loss: (0.687)(R 0.626, F 0.748)] [D acc: (0.539)(0.828, 0.250)] [G loss: 0.701] [G acc: 0.422]\n",
      "249 [D loss: (0.678)(R 0.641, F 0.714)] [D acc: (0.594)(0.766, 0.422)] [G loss: 0.699] [G acc: 0.469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 [D loss: (0.683)(R 0.630, F 0.735)] [D acc: (0.508)(0.719, 0.297)] [G loss: 0.699] [G acc: 0.406]\n",
      "251 [D loss: (0.678)(R 0.640, F 0.716)] [D acc: (0.539)(0.672, 0.406)] [G loss: 0.690] [G acc: 0.469]\n",
      "252 [D loss: (0.687)(R 0.611, F 0.763)] [D acc: (0.578)(0.844, 0.312)] [G loss: 0.704] [G acc: 0.406]\n",
      "253 [D loss: (0.687)(R 0.619, F 0.755)] [D acc: (0.500)(0.781, 0.219)] [G loss: 0.709] [G acc: 0.406]\n",
      "254 [D loss: (0.693)(R 0.645, F 0.742)] [D acc: (0.500)(0.703, 0.297)] [G loss: 0.695] [G acc: 0.422]\n",
      "255 [D loss: (0.684)(R 0.627, F 0.742)] [D acc: (0.594)(0.812, 0.375)] [G loss: 0.711] [G acc: 0.328]\n",
      "256 [D loss: (0.681)(R 0.633, F 0.728)] [D acc: (0.500)(0.656, 0.344)] [G loss: 0.704] [G acc: 0.391]\n",
      "257 [D loss: (0.677)(R 0.632, F 0.722)] [D acc: (0.570)(0.750, 0.391)] [G loss: 0.680] [G acc: 0.609]\n",
      "258 [D loss: (0.677)(R 0.613, F 0.742)] [D acc: (0.586)(0.797, 0.375)] [G loss: 0.709] [G acc: 0.391]\n",
      "259 [D loss: (0.673)(R 0.624, F 0.723)] [D acc: (0.531)(0.703, 0.359)] [G loss: 0.702] [G acc: 0.438]\n",
      "260 [D loss: (0.682)(R 0.616, F 0.748)] [D acc: (0.562)(0.750, 0.375)] [G loss: 0.690] [G acc: 0.406]\n",
      "261 [D loss: (0.687)(R 0.635, F 0.739)] [D acc: (0.555)(0.750, 0.359)] [G loss: 0.703] [G acc: 0.406]\n",
      "262 [D loss: (0.690)(R 0.606, F 0.773)] [D acc: (0.570)(0.812, 0.328)] [G loss: 0.702] [G acc: 0.391]\n",
      "263 [D loss: (0.689)(R 0.623, F 0.756)] [D acc: (0.492)(0.766, 0.219)] [G loss: 0.703] [G acc: 0.422]\n",
      "264 [D loss: (0.676)(R 0.631, F 0.720)] [D acc: (0.594)(0.781, 0.406)] [G loss: 0.700] [G acc: 0.438]\n",
      "265 [D loss: (0.690)(R 0.639, F 0.742)] [D acc: (0.531)(0.750, 0.312)] [G loss: 0.700] [G acc: 0.406]\n",
      "266 [D loss: (0.678)(R 0.629, F 0.727)] [D acc: (0.609)(0.797, 0.422)] [G loss: 0.713] [G acc: 0.328]\n",
      "267 [D loss: (0.668)(R 0.603, F 0.734)] [D acc: (0.625)(0.891, 0.359)] [G loss: 0.705] [G acc: 0.438]\n",
      "268 [D loss: (0.670)(R 0.606, F 0.735)] [D acc: (0.562)(0.703, 0.422)] [G loss: 0.689] [G acc: 0.516]\n",
      "269 [D loss: (0.678)(R 0.623, F 0.734)] [D acc: (0.531)(0.672, 0.391)] [G loss: 0.705] [G acc: 0.375]\n",
      "270 [D loss: (0.694)(R 0.625, F 0.763)] [D acc: (0.469)(0.703, 0.234)] [G loss: 0.706] [G acc: 0.438]\n",
      "271 [D loss: (0.702)(R 0.644, F 0.759)] [D acc: (0.477)(0.688, 0.266)] [G loss: 0.722] [G acc: 0.281]\n",
      "272 [D loss: (0.669)(R 0.643, F 0.695)] [D acc: (0.664)(0.719, 0.609)] [G loss: 0.709] [G acc: 0.359]\n",
      "273 [D loss: (0.691)(R 0.613, F 0.768)] [D acc: (0.547)(0.766, 0.328)] [G loss: 0.733] [G acc: 0.250]\n",
      "274 [D loss: (0.683)(R 0.651, F 0.716)] [D acc: (0.531)(0.672, 0.391)] [G loss: 0.717] [G acc: 0.344]\n",
      "275 [D loss: (0.665)(R 0.605, F 0.724)] [D acc: (0.594)(0.797, 0.391)] [G loss: 0.692] [G acc: 0.500]\n",
      "276 [D loss: (0.682)(R 0.612, F 0.753)] [D acc: (0.594)(0.797, 0.391)] [G loss: 0.697] [G acc: 0.500]\n",
      "277 [D loss: (0.703)(R 0.594, F 0.812)] [D acc: (0.500)(0.781, 0.219)] [G loss: 0.718] [G acc: 0.312]\n",
      "278 [D loss: (0.635)(R 0.580, F 0.691)] [D acc: (0.695)(0.844, 0.547)] [G loss: 0.716] [G acc: 0.391]\n",
      "279 [D loss: (0.695)(R 0.629, F 0.762)] [D acc: (0.500)(0.719, 0.281)] [G loss: 0.723] [G acc: 0.312]\n",
      "280 [D loss: (0.651)(R 0.603, F 0.699)] [D acc: (0.617)(0.797, 0.438)] [G loss: 0.704] [G acc: 0.406]\n",
      "281 [D loss: (0.704)(R 0.622, F 0.786)] [D acc: (0.461)(0.656, 0.266)] [G loss: 0.712] [G acc: 0.375]\n",
      "282 [D loss: (0.685)(R 0.620, F 0.749)] [D acc: (0.586)(0.781, 0.391)] [G loss: 0.724] [G acc: 0.312]\n",
      "283 [D loss: (0.682)(R 0.621, F 0.742)] [D acc: (0.539)(0.688, 0.391)] [G loss: 0.710] [G acc: 0.359]\n",
      "284 [D loss: (0.669)(R 0.638, F 0.700)] [D acc: (0.570)(0.609, 0.531)] [G loss: 0.738] [G acc: 0.203]\n",
      "285 [D loss: (0.698)(R 0.653, F 0.743)] [D acc: (0.500)(0.609, 0.391)] [G loss: 0.704] [G acc: 0.406]\n",
      "286 [D loss: (0.681)(R 0.643, F 0.720)] [D acc: (0.617)(0.719, 0.516)] [G loss: 0.706] [G acc: 0.453]\n",
      "287 [D loss: (0.672)(R 0.622, F 0.723)] [D acc: (0.578)(0.781, 0.375)] [G loss: 0.706] [G acc: 0.359]\n",
      "288 [D loss: (0.693)(R 0.617, F 0.768)] [D acc: (0.570)(0.797, 0.344)] [G loss: 0.722] [G acc: 0.344]\n",
      "289 [D loss: (0.663)(R 0.616, F 0.711)] [D acc: (0.617)(0.734, 0.500)] [G loss: 0.704] [G acc: 0.406]\n",
      "290 [D loss: (0.679)(R 0.612, F 0.746)] [D acc: (0.562)(0.734, 0.391)] [G loss: 0.737] [G acc: 0.266]\n",
      "291 [D loss: (0.674)(R 0.616, F 0.731)] [D acc: (0.562)(0.703, 0.422)] [G loss: 0.721] [G acc: 0.375]\n",
      "292 [D loss: (0.666)(R 0.618, F 0.714)] [D acc: (0.656)(0.734, 0.578)] [G loss: 0.729] [G acc: 0.359]\n",
      "293 [D loss: (0.675)(R 0.604, F 0.746)] [D acc: (0.578)(0.703, 0.453)] [G loss: 0.760] [G acc: 0.266]\n",
      "294 [D loss: (0.670)(R 0.606, F 0.734)] [D acc: (0.555)(0.719, 0.391)] [G loss: 0.708] [G acc: 0.375]\n",
      "295 [D loss: (0.657)(R 0.611, F 0.703)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.729] [G acc: 0.266]\n",
      "296 [D loss: (0.697)(R 0.600, F 0.794)] [D acc: (0.445)(0.672, 0.219)] [G loss: 0.721] [G acc: 0.391]\n",
      "297 [D loss: (0.671)(R 0.589, F 0.753)] [D acc: (0.609)(0.781, 0.438)] [G loss: 0.729] [G acc: 0.312]\n",
      "298 [D loss: (0.660)(R 0.585, F 0.735)] [D acc: (0.633)(0.750, 0.516)] [G loss: 0.703] [G acc: 0.484]\n",
      "299 [D loss: (0.688)(R 0.618, F 0.757)] [D acc: (0.562)(0.734, 0.391)] [G loss: 0.733] [G acc: 0.312]\n",
      "300 [D loss: (0.697)(R 0.634, F 0.760)] [D acc: (0.500)(0.641, 0.359)] [G loss: 0.723] [G acc: 0.312]\n",
      "301 [D loss: (0.673)(R 0.643, F 0.703)] [D acc: (0.570)(0.641, 0.500)] [G loss: 0.747] [G acc: 0.234]\n",
      "302 [D loss: (0.664)(R 0.627, F 0.702)] [D acc: (0.594)(0.672, 0.516)] [G loss: 0.739] [G acc: 0.297]\n",
      "303 [D loss: (0.656)(R 0.573, F 0.738)] [D acc: (0.625)(0.797, 0.453)] [G loss: 0.705] [G acc: 0.422]\n",
      "304 [D loss: (0.678)(R 0.618, F 0.739)] [D acc: (0.625)(0.797, 0.453)] [G loss: 0.723] [G acc: 0.328]\n",
      "305 [D loss: (0.677)(R 0.586, F 0.768)] [D acc: (0.633)(0.797, 0.469)] [G loss: 0.778] [G acc: 0.188]\n",
      "306 [D loss: (0.665)(R 0.618, F 0.713)] [D acc: (0.617)(0.734, 0.500)] [G loss: 0.710] [G acc: 0.438]\n",
      "307 [D loss: (0.656)(R 0.595, F 0.717)] [D acc: (0.586)(0.719, 0.453)] [G loss: 0.749] [G acc: 0.297]\n",
      "308 [D loss: (0.642)(R 0.564, F 0.719)] [D acc: (0.656)(0.719, 0.594)] [G loss: 0.794] [G acc: 0.172]\n",
      "309 [D loss: (0.660)(R 0.583, F 0.737)] [D acc: (0.570)(0.703, 0.438)] [G loss: 0.745] [G acc: 0.328]\n",
      "310 [D loss: (0.694)(R 0.645, F 0.744)] [D acc: (0.492)(0.578, 0.406)] [G loss: 0.725] [G acc: 0.312]\n",
      "311 [D loss: (0.680)(R 0.632, F 0.729)] [D acc: (0.570)(0.688, 0.453)] [G loss: 0.711] [G acc: 0.391]\n",
      "312 [D loss: (0.668)(R 0.576, F 0.761)] [D acc: (0.625)(0.781, 0.469)] [G loss: 0.712] [G acc: 0.391]\n",
      "313 [D loss: (0.678)(R 0.625, F 0.732)] [D acc: (0.602)(0.750, 0.453)] [G loss: 0.723] [G acc: 0.391]\n",
      "314 [D loss: (0.660)(R 0.607, F 0.712)] [D acc: (0.555)(0.641, 0.469)] [G loss: 0.729] [G acc: 0.297]\n",
      "315 [D loss: (0.632)(R 0.550, F 0.714)] [D acc: (0.703)(0.844, 0.562)] [G loss: 0.746] [G acc: 0.312]\n",
      "316 [D loss: (0.668)(R 0.565, F 0.770)] [D acc: (0.570)(0.766, 0.375)] [G loss: 0.732] [G acc: 0.375]\n",
      "317 [D loss: (0.690)(R 0.601, F 0.779)] [D acc: (0.516)(0.703, 0.328)] [G loss: 0.718] [G acc: 0.422]\n",
      "318 [D loss: (0.643)(R 0.590, F 0.695)] [D acc: (0.680)(0.766, 0.594)] [G loss: 0.784] [G acc: 0.188]\n",
      "319 [D loss: (0.691)(R 0.552, F 0.829)] [D acc: (0.562)(0.719, 0.406)] [G loss: 0.747] [G acc: 0.281]\n",
      "320 [D loss: (0.641)(R 0.563, F 0.718)] [D acc: (0.625)(0.766, 0.484)] [G loss: 0.749] [G acc: 0.328]\n",
      "321 [D loss: (0.652)(R 0.570, F 0.734)] [D acc: (0.594)(0.734, 0.453)] [G loss: 0.759] [G acc: 0.281]\n",
      "322 [D loss: (0.675)(R 0.606, F 0.744)] [D acc: (0.586)(0.719, 0.453)] [G loss: 0.729] [G acc: 0.344]\n",
      "323 [D loss: (0.679)(R 0.601, F 0.757)] [D acc: (0.539)(0.688, 0.391)] [G loss: 0.759] [G acc: 0.250]\n",
      "324 [D loss: (0.672)(R 0.584, F 0.760)] [D acc: (0.547)(0.766, 0.328)] [G loss: 0.741] [G acc: 0.297]\n",
      "325 [D loss: (0.678)(R 0.610, F 0.746)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.760] [G acc: 0.266]\n",
      "326 [D loss: (0.652)(R 0.570, F 0.733)] [D acc: (0.672)(0.828, 0.516)] [G loss: 0.723] [G acc: 0.359]\n",
      "327 [D loss: (0.652)(R 0.575, F 0.728)] [D acc: (0.609)(0.781, 0.438)] [G loss: 0.776] [G acc: 0.234]\n",
      "328 [D loss: (0.662)(R 0.545, F 0.779)] [D acc: (0.609)(0.812, 0.406)] [G loss: 0.750] [G acc: 0.375]\n",
      "329 [D loss: (0.670)(R 0.611, F 0.729)] [D acc: (0.562)(0.672, 0.453)] [G loss: 0.751] [G acc: 0.344]\n",
      "330 [D loss: (0.679)(R 0.576, F 0.783)] [D acc: (0.547)(0.734, 0.359)] [G loss: 0.742] [G acc: 0.391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331 [D loss: (0.672)(R 0.631, F 0.714)] [D acc: (0.594)(0.656, 0.531)] [G loss: 0.760] [G acc: 0.234]\n",
      "332 [D loss: (0.666)(R 0.584, F 0.748)] [D acc: (0.602)(0.797, 0.406)] [G loss: 0.740] [G acc: 0.344]\n",
      "333 [D loss: (0.642)(R 0.580, F 0.705)] [D acc: (0.641)(0.672, 0.609)] [G loss: 0.754] [G acc: 0.250]\n",
      "334 [D loss: (0.683)(R 0.585, F 0.782)] [D acc: (0.547)(0.672, 0.422)] [G loss: 0.747] [G acc: 0.266]\n",
      "335 [D loss: (0.691)(R 0.602, F 0.779)] [D acc: (0.508)(0.688, 0.328)] [G loss: 0.734] [G acc: 0.406]\n",
      "336 [D loss: (0.655)(R 0.590, F 0.720)] [D acc: (0.609)(0.656, 0.562)] [G loss: 0.746] [G acc: 0.312]\n",
      "337 [D loss: (0.661)(R 0.614, F 0.708)] [D acc: (0.602)(0.672, 0.531)] [G loss: 0.752] [G acc: 0.344]\n",
      "338 [D loss: (0.661)(R 0.590, F 0.732)] [D acc: (0.609)(0.734, 0.484)] [G loss: 0.781] [G acc: 0.219]\n",
      "339 [D loss: (0.677)(R 0.607, F 0.747)] [D acc: (0.570)(0.688, 0.453)] [G loss: 0.752] [G acc: 0.234]\n",
      "340 [D loss: (0.650)(R 0.587, F 0.713)] [D acc: (0.648)(0.750, 0.547)] [G loss: 0.776] [G acc: 0.172]\n",
      "341 [D loss: (0.664)(R 0.605, F 0.724)] [D acc: (0.586)(0.672, 0.500)] [G loss: 0.752] [G acc: 0.297]\n",
      "342 [D loss: (0.630)(R 0.560, F 0.700)] [D acc: (0.648)(0.688, 0.609)] [G loss: 0.757] [G acc: 0.312]\n",
      "343 [D loss: (0.673)(R 0.598, F 0.749)] [D acc: (0.547)(0.672, 0.422)] [G loss: 0.769] [G acc: 0.250]\n",
      "344 [D loss: (0.674)(R 0.582, F 0.767)] [D acc: (0.539)(0.672, 0.406)] [G loss: 0.777] [G acc: 0.219]\n",
      "345 [D loss: (0.685)(R 0.628, F 0.742)] [D acc: (0.508)(0.594, 0.422)] [G loss: 0.767] [G acc: 0.203]\n",
      "346 [D loss: (0.659)(R 0.593, F 0.724)] [D acc: (0.578)(0.719, 0.438)] [G loss: 0.751] [G acc: 0.234]\n",
      "347 [D loss: (0.648)(R 0.584, F 0.711)] [D acc: (0.609)(0.703, 0.516)] [G loss: 0.769] [G acc: 0.250]\n",
      "348 [D loss: (0.638)(R 0.544, F 0.731)] [D acc: (0.641)(0.844, 0.438)] [G loss: 0.765] [G acc: 0.250]\n",
      "349 [D loss: (0.633)(R 0.538, F 0.728)] [D acc: (0.633)(0.734, 0.531)] [G loss: 0.775] [G acc: 0.234]\n",
      "350 [D loss: (0.729)(R 0.597, F 0.861)] [D acc: (0.570)(0.734, 0.406)] [G loss: 0.780] [G acc: 0.203]\n",
      "351 [D loss: (0.664)(R 0.652, F 0.677)] [D acc: (0.578)(0.531, 0.625)] [G loss: 0.757] [G acc: 0.234]\n",
      "352 [D loss: (0.671)(R 0.590, F 0.752)] [D acc: (0.594)(0.750, 0.438)] [G loss: 0.737] [G acc: 0.391]\n",
      "353 [D loss: (0.680)(R 0.622, F 0.738)] [D acc: (0.539)(0.547, 0.531)] [G loss: 0.792] [G acc: 0.172]\n",
      "354 [D loss: (0.649)(R 0.613, F 0.684)] [D acc: (0.625)(0.688, 0.562)] [G loss: 0.761] [G acc: 0.219]\n",
      "355 [D loss: (0.664)(R 0.624, F 0.704)] [D acc: (0.570)(0.625, 0.516)] [G loss: 0.804] [G acc: 0.203]\n",
      "356 [D loss: (0.674)(R 0.631, F 0.718)] [D acc: (0.562)(0.625, 0.500)] [G loss: 0.814] [G acc: 0.188]\n",
      "357 [D loss: (0.616)(R 0.561, F 0.672)] [D acc: (0.719)(0.766, 0.672)] [G loss: 0.807] [G acc: 0.250]\n",
      "358 [D loss: (0.651)(R 0.544, F 0.757)] [D acc: (0.633)(0.750, 0.516)] [G loss: 0.760] [G acc: 0.328]\n",
      "359 [D loss: (0.672)(R 0.555, F 0.789)] [D acc: (0.570)(0.750, 0.391)] [G loss: 0.801] [G acc: 0.172]\n",
      "360 [D loss: (0.683)(R 0.570, F 0.796)] [D acc: (0.523)(0.641, 0.406)] [G loss: 0.770] [G acc: 0.312]\n",
      "361 [D loss: (0.665)(R 0.618, F 0.713)] [D acc: (0.555)(0.641, 0.469)] [G loss: 0.765] [G acc: 0.266]\n",
      "362 [D loss: (0.675)(R 0.598, F 0.753)] [D acc: (0.555)(0.688, 0.422)] [G loss: 0.805] [G acc: 0.188]\n",
      "363 [D loss: (0.666)(R 0.627, F 0.705)] [D acc: (0.578)(0.656, 0.500)] [G loss: 0.764] [G acc: 0.297]\n",
      "364 [D loss: (0.666)(R 0.617, F 0.714)] [D acc: (0.570)(0.625, 0.516)] [G loss: 0.788] [G acc: 0.188]\n",
      "365 [D loss: (0.663)(R 0.622, F 0.703)] [D acc: (0.570)(0.641, 0.500)] [G loss: 0.802] [G acc: 0.172]\n",
      "366 [D loss: (0.673)(R 0.607, F 0.740)] [D acc: (0.570)(0.656, 0.484)] [G loss: 0.717] [G acc: 0.453]\n",
      "367 [D loss: (0.667)(R 0.587, F 0.747)] [D acc: (0.562)(0.688, 0.438)] [G loss: 0.777] [G acc: 0.234]\n",
      "368 [D loss: (0.687)(R 0.599, F 0.774)] [D acc: (0.555)(0.703, 0.406)] [G loss: 0.766] [G acc: 0.312]\n",
      "369 [D loss: (0.655)(R 0.598, F 0.713)] [D acc: (0.617)(0.766, 0.469)] [G loss: 0.789] [G acc: 0.234]\n",
      "370 [D loss: (0.662)(R 0.657, F 0.667)] [D acc: (0.562)(0.516, 0.609)] [G loss: 0.795] [G acc: 0.234]\n",
      "371 [D loss: (0.645)(R 0.592, F 0.697)] [D acc: (0.742)(0.797, 0.688)] [G loss: 0.791] [G acc: 0.219]\n",
      "372 [D loss: (0.654)(R 0.620, F 0.689)] [D acc: (0.617)(0.656, 0.578)] [G loss: 0.777] [G acc: 0.281]\n",
      "373 [D loss: (0.671)(R 0.603, F 0.739)] [D acc: (0.562)(0.672, 0.453)] [G loss: 0.815] [G acc: 0.156]\n",
      "374 [D loss: (0.683)(R 0.600, F 0.765)] [D acc: (0.539)(0.641, 0.438)] [G loss: 0.804] [G acc: 0.172]\n",
      "375 [D loss: (0.650)(R 0.590, F 0.711)] [D acc: (0.531)(0.594, 0.469)] [G loss: 0.761] [G acc: 0.250]\n",
      "376 [D loss: (0.644)(R 0.564, F 0.725)] [D acc: (0.656)(0.719, 0.594)] [G loss: 0.775] [G acc: 0.328]\n",
      "377 [D loss: (0.667)(R 0.569, F 0.765)] [D acc: (0.555)(0.703, 0.406)] [G loss: 0.755] [G acc: 0.297]\n",
      "378 [D loss: (0.646)(R 0.581, F 0.710)] [D acc: (0.648)(0.766, 0.531)] [G loss: 0.771] [G acc: 0.219]\n",
      "379 [D loss: (0.685)(R 0.649, F 0.721)] [D acc: (0.539)(0.547, 0.531)] [G loss: 0.782] [G acc: 0.234]\n",
      "380 [D loss: (0.651)(R 0.575, F 0.726)] [D acc: (0.648)(0.781, 0.516)] [G loss: 0.778] [G acc: 0.281]\n",
      "381 [D loss: (0.674)(R 0.617, F 0.731)] [D acc: (0.578)(0.672, 0.484)] [G loss: 0.781] [G acc: 0.203]\n",
      "382 [D loss: (0.638)(R 0.563, F 0.713)] [D acc: (0.617)(0.688, 0.547)] [G loss: 0.811] [G acc: 0.125]\n",
      "383 [D loss: (0.660)(R 0.627, F 0.692)] [D acc: (0.594)(0.641, 0.547)] [G loss: 0.795] [G acc: 0.250]\n",
      "384 [D loss: (0.646)(R 0.536, F 0.755)] [D acc: (0.648)(0.750, 0.547)] [G loss: 0.817] [G acc: 0.219]\n",
      "385 [D loss: (0.675)(R 0.611, F 0.739)] [D acc: (0.602)(0.641, 0.562)] [G loss: 0.798] [G acc: 0.234]\n",
      "386 [D loss: (0.652)(R 0.620, F 0.684)] [D acc: (0.672)(0.672, 0.672)] [G loss: 0.785] [G acc: 0.266]\n",
      "387 [D loss: (0.673)(R 0.625, F 0.722)] [D acc: (0.547)(0.625, 0.469)] [G loss: 0.819] [G acc: 0.188]\n",
      "388 [D loss: (0.654)(R 0.595, F 0.714)] [D acc: (0.688)(0.734, 0.641)] [G loss: 0.815] [G acc: 0.156]\n",
      "389 [D loss: (0.667)(R 0.604, F 0.731)] [D acc: (0.609)(0.719, 0.500)] [G loss: 0.762] [G acc: 0.266]\n",
      "390 [D loss: (0.619)(R 0.517, F 0.720)] [D acc: (0.656)(0.766, 0.547)] [G loss: 0.801] [G acc: 0.219]\n",
      "391 [D loss: (0.625)(R 0.522, F 0.728)] [D acc: (0.703)(0.812, 0.594)] [G loss: 0.826] [G acc: 0.156]\n",
      "392 [D loss: (0.674)(R 0.608, F 0.739)] [D acc: (0.570)(0.672, 0.469)] [G loss: 0.820] [G acc: 0.234]\n",
      "393 [D loss: (0.637)(R 0.573, F 0.701)] [D acc: (0.664)(0.688, 0.641)] [G loss: 0.778] [G acc: 0.297]\n",
      "394 [D loss: (0.648)(R 0.568, F 0.728)] [D acc: (0.602)(0.719, 0.484)] [G loss: 0.861] [G acc: 0.141]\n",
      "395 [D loss: (0.656)(R 0.574, F 0.738)] [D acc: (0.578)(0.656, 0.500)] [G loss: 0.845] [G acc: 0.250]\n",
      "396 [D loss: (0.676)(R 0.614, F 0.738)] [D acc: (0.586)(0.625, 0.547)] [G loss: 0.793] [G acc: 0.219]\n",
      "397 [D loss: (0.642)(R 0.570, F 0.714)] [D acc: (0.672)(0.703, 0.641)] [G loss: 0.811] [G acc: 0.219]\n",
      "398 [D loss: (0.642)(R 0.574, F 0.710)] [D acc: (0.648)(0.688, 0.609)] [G loss: 0.834] [G acc: 0.203]\n",
      "399 [D loss: (0.634)(R 0.574, F 0.694)] [D acc: (0.680)(0.781, 0.578)] [G loss: 0.798] [G acc: 0.234]\n",
      "400 [D loss: (0.601)(R 0.563, F 0.638)] [D acc: (0.695)(0.750, 0.641)] [G loss: 0.797] [G acc: 0.344]\n",
      "401 [D loss: (0.676)(R 0.598, F 0.753)] [D acc: (0.547)(0.609, 0.484)] [G loss: 0.829] [G acc: 0.266]\n",
      "402 [D loss: (0.641)(R 0.564, F 0.717)] [D acc: (0.594)(0.719, 0.469)] [G loss: 0.822] [G acc: 0.203]\n",
      "403 [D loss: (0.680)(R 0.570, F 0.789)] [D acc: (0.578)(0.688, 0.469)] [G loss: 0.812] [G acc: 0.234]\n",
      "404 [D loss: (0.650)(R 0.551, F 0.748)] [D acc: (0.648)(0.750, 0.547)] [G loss: 0.807] [G acc: 0.234]\n",
      "405 [D loss: (0.634)(R 0.567, F 0.702)] [D acc: (0.594)(0.656, 0.531)] [G loss: 0.868] [G acc: 0.141]\n",
      "406 [D loss: (0.638)(R 0.625, F 0.652)] [D acc: (0.617)(0.625, 0.609)] [G loss: 0.799] [G acc: 0.234]\n",
      "407 [D loss: (0.661)(R 0.598, F 0.723)] [D acc: (0.602)(0.609, 0.594)] [G loss: 0.811] [G acc: 0.219]\n",
      "408 [D loss: (0.670)(R 0.622, F 0.718)] [D acc: (0.586)(0.641, 0.531)] [G loss: 0.809] [G acc: 0.250]\n",
      "409 [D loss: (0.650)(R 0.579, F 0.721)] [D acc: (0.609)(0.703, 0.516)] [G loss: 0.828] [G acc: 0.219]\n",
      "410 [D loss: (0.656)(R 0.588, F 0.723)] [D acc: (0.648)(0.750, 0.547)] [G loss: 0.842] [G acc: 0.266]\n",
      "411 [D loss: (0.615)(R 0.559, F 0.671)] [D acc: (0.688)(0.750, 0.625)] [G loss: 0.866] [G acc: 0.156]\n",
      "412 [D loss: (0.636)(R 0.567, F 0.706)] [D acc: (0.656)(0.672, 0.641)] [G loss: 0.870] [G acc: 0.172]\n",
      "413 [D loss: (0.625)(R 0.528, F 0.722)] [D acc: (0.648)(0.719, 0.578)] [G loss: 0.906] [G acc: 0.188]\n",
      "414 [D loss: (0.678)(R 0.614, F 0.742)] [D acc: (0.594)(0.609, 0.578)] [G loss: 0.793] [G acc: 0.344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415 [D loss: (0.638)(R 0.608, F 0.669)] [D acc: (0.633)(0.672, 0.594)] [G loss: 0.845] [G acc: 0.219]\n",
      "416 [D loss: (0.667)(R 0.603, F 0.732)] [D acc: (0.594)(0.641, 0.547)] [G loss: 0.868] [G acc: 0.203]\n",
      "417 [D loss: (0.626)(R 0.615, F 0.636)] [D acc: (0.664)(0.609, 0.719)] [G loss: 0.804] [G acc: 0.328]\n",
      "418 [D loss: (0.652)(R 0.545, F 0.760)] [D acc: (0.625)(0.719, 0.531)] [G loss: 0.859] [G acc: 0.188]\n",
      "419 [D loss: (0.679)(R 0.634, F 0.724)] [D acc: (0.586)(0.609, 0.562)] [G loss: 0.851] [G acc: 0.172]\n",
      "420 [D loss: (0.645)(R 0.634, F 0.656)] [D acc: (0.602)(0.578, 0.625)] [G loss: 0.786] [G acc: 0.266]\n",
      "421 [D loss: (0.650)(R 0.576, F 0.724)] [D acc: (0.609)(0.656, 0.562)] [G loss: 0.784] [G acc: 0.281]\n",
      "422 [D loss: (0.617)(R 0.559, F 0.674)] [D acc: (0.688)(0.734, 0.641)] [G loss: 0.850] [G acc: 0.125]\n",
      "423 [D loss: (0.649)(R 0.562, F 0.736)] [D acc: (0.625)(0.719, 0.531)] [G loss: 0.866] [G acc: 0.172]\n",
      "424 [D loss: (0.657)(R 0.599, F 0.716)] [D acc: (0.555)(0.594, 0.516)] [G loss: 0.803] [G acc: 0.266]\n",
      "425 [D loss: (0.651)(R 0.569, F 0.734)] [D acc: (0.617)(0.734, 0.500)] [G loss: 0.802] [G acc: 0.203]\n",
      "426 [D loss: (0.628)(R 0.583, F 0.673)] [D acc: (0.703)(0.734, 0.672)] [G loss: 0.834] [G acc: 0.266]\n",
      "427 [D loss: (0.645)(R 0.530, F 0.760)] [D acc: (0.602)(0.766, 0.438)] [G loss: 0.825] [G acc: 0.234]\n",
      "428 [D loss: (0.683)(R 0.593, F 0.773)] [D acc: (0.539)(0.578, 0.500)] [G loss: 0.837] [G acc: 0.203]\n",
      "429 [D loss: (0.673)(R 0.661, F 0.685)] [D acc: (0.562)(0.547, 0.578)] [G loss: 0.780] [G acc: 0.297]\n",
      "430 [D loss: (0.683)(R 0.607, F 0.759)] [D acc: (0.555)(0.625, 0.484)] [G loss: 0.858] [G acc: 0.125]\n",
      "431 [D loss: (0.661)(R 0.620, F 0.702)] [D acc: (0.602)(0.656, 0.547)] [G loss: 0.823] [G acc: 0.156]\n",
      "432 [D loss: (0.646)(R 0.608, F 0.685)] [D acc: (0.617)(0.672, 0.562)] [G loss: 0.844] [G acc: 0.172]\n",
      "433 [D loss: (0.656)(R 0.614, F 0.699)] [D acc: (0.586)(0.625, 0.547)] [G loss: 0.835] [G acc: 0.172]\n",
      "434 [D loss: (0.643)(R 0.622, F 0.664)] [D acc: (0.688)(0.641, 0.734)] [G loss: 0.845] [G acc: 0.250]\n",
      "435 [D loss: (0.673)(R 0.638, F 0.708)] [D acc: (0.531)(0.547, 0.516)] [G loss: 0.852] [G acc: 0.219]\n",
      "436 [D loss: (0.658)(R 0.608, F 0.709)] [D acc: (0.578)(0.625, 0.531)] [G loss: 0.857] [G acc: 0.094]\n",
      "437 [D loss: (0.618)(R 0.586, F 0.651)] [D acc: (0.656)(0.641, 0.672)] [G loss: 0.840] [G acc: 0.219]\n",
      "438 [D loss: (0.664)(R 0.613, F 0.715)] [D acc: (0.555)(0.609, 0.500)] [G loss: 0.850] [G acc: 0.141]\n",
      "439 [D loss: (0.655)(R 0.602, F 0.707)] [D acc: (0.578)(0.609, 0.547)] [G loss: 0.854] [G acc: 0.156]\n",
      "440 [D loss: (0.676)(R 0.658, F 0.693)] [D acc: (0.594)(0.609, 0.578)] [G loss: 0.889] [G acc: 0.062]\n",
      "441 [D loss: (0.669)(R 0.646, F 0.692)] [D acc: (0.648)(0.641, 0.656)] [G loss: 0.845] [G acc: 0.219]\n",
      "442 [D loss: (0.658)(R 0.628, F 0.688)] [D acc: (0.625)(0.641, 0.609)] [G loss: 0.832] [G acc: 0.141]\n",
      "443 [D loss: (0.625)(R 0.570, F 0.681)] [D acc: (0.617)(0.641, 0.594)] [G loss: 0.827] [G acc: 0.219]\n",
      "444 [D loss: (0.634)(R 0.591, F 0.677)] [D acc: (0.617)(0.703, 0.531)] [G loss: 0.859] [G acc: 0.125]\n",
      "445 [D loss: (0.645)(R 0.571, F 0.718)] [D acc: (0.633)(0.719, 0.547)] [G loss: 0.890] [G acc: 0.125]\n",
      "446 [D loss: (0.611)(R 0.567, F 0.655)] [D acc: (0.703)(0.719, 0.688)] [G loss: 0.834] [G acc: 0.156]\n",
      "447 [D loss: (0.643)(R 0.587, F 0.699)] [D acc: (0.602)(0.594, 0.609)] [G loss: 0.848] [G acc: 0.281]\n",
      "448 [D loss: (0.690)(R 0.629, F 0.751)] [D acc: (0.539)(0.578, 0.500)] [G loss: 0.838] [G acc: 0.203]\n",
      "449 [D loss: (0.652)(R 0.618, F 0.687)] [D acc: (0.625)(0.609, 0.641)] [G loss: 0.830] [G acc: 0.250]\n",
      "450 [D loss: (0.630)(R 0.605, F 0.655)] [D acc: (0.633)(0.625, 0.641)] [G loss: 0.876] [G acc: 0.141]\n",
      "451 [D loss: (0.708)(R 0.610, F 0.807)] [D acc: (0.562)(0.609, 0.516)] [G loss: 0.843] [G acc: 0.141]\n",
      "452 [D loss: (0.665)(R 0.656, F 0.674)] [D acc: (0.578)(0.500, 0.656)] [G loss: 0.810] [G acc: 0.266]\n",
      "453 [D loss: (0.673)(R 0.649, F 0.697)] [D acc: (0.555)(0.562, 0.547)] [G loss: 0.817] [G acc: 0.250]\n",
      "454 [D loss: (0.635)(R 0.592, F 0.678)] [D acc: (0.680)(0.703, 0.656)] [G loss: 0.826] [G acc: 0.188]\n",
      "455 [D loss: (0.629)(R 0.559, F 0.699)] [D acc: (0.633)(0.672, 0.594)] [G loss: 0.818] [G acc: 0.281]\n",
      "456 [D loss: (0.642)(R 0.589, F 0.695)] [D acc: (0.633)(0.672, 0.594)] [G loss: 0.880] [G acc: 0.156]\n",
      "457 [D loss: (0.686)(R 0.667, F 0.704)] [D acc: (0.594)(0.594, 0.594)] [G loss: 0.870] [G acc: 0.172]\n",
      "458 [D loss: (0.652)(R 0.595, F 0.710)] [D acc: (0.609)(0.625, 0.594)] [G loss: 0.820] [G acc: 0.188]\n",
      "459 [D loss: (0.655)(R 0.627, F 0.684)] [D acc: (0.586)(0.562, 0.609)] [G loss: 0.816] [G acc: 0.234]\n",
      "460 [D loss: (0.653)(R 0.584, F 0.722)] [D acc: (0.617)(0.672, 0.562)] [G loss: 0.827] [G acc: 0.234]\n",
      "461 [D loss: (0.669)(R 0.648, F 0.689)] [D acc: (0.523)(0.516, 0.531)] [G loss: 0.855] [G acc: 0.203]\n",
      "462 [D loss: (0.628)(R 0.535, F 0.721)] [D acc: (0.641)(0.766, 0.516)] [G loss: 0.883] [G acc: 0.125]\n",
      "463 [D loss: (0.608)(R 0.570, F 0.646)] [D acc: (0.656)(0.641, 0.672)] [G loss: 0.909] [G acc: 0.156]\n",
      "464 [D loss: (0.693)(R 0.670, F 0.716)] [D acc: (0.523)(0.500, 0.547)] [G loss: 0.835] [G acc: 0.234]\n",
      "465 [D loss: (0.703)(R 0.625, F 0.782)] [D acc: (0.562)(0.562, 0.562)] [G loss: 0.855] [G acc: 0.125]\n",
      "466 [D loss: (0.671)(R 0.643, F 0.698)] [D acc: (0.617)(0.609, 0.625)] [G loss: 0.852] [G acc: 0.125]\n",
      "467 [D loss: (0.618)(R 0.590, F 0.647)] [D acc: (0.641)(0.609, 0.672)] [G loss: 0.859] [G acc: 0.172]\n",
      "468 [D loss: (0.637)(R 0.558, F 0.716)] [D acc: (0.641)(0.672, 0.609)] [G loss: 0.830] [G acc: 0.203]\n",
      "469 [D loss: (0.660)(R 0.619, F 0.702)] [D acc: (0.625)(0.578, 0.672)] [G loss: 0.855] [G acc: 0.188]\n",
      "470 [D loss: (0.648)(R 0.582, F 0.714)] [D acc: (0.602)(0.625, 0.578)] [G loss: 0.892] [G acc: 0.188]\n",
      "471 [D loss: (0.652)(R 0.663, F 0.642)] [D acc: (0.680)(0.547, 0.812)] [G loss: 0.858] [G acc: 0.203]\n",
      "472 [D loss: (0.667)(R 0.584, F 0.751)] [D acc: (0.633)(0.719, 0.547)] [G loss: 0.901] [G acc: 0.188]\n",
      "473 [D loss: (0.657)(R 0.653, F 0.661)] [D acc: (0.602)(0.578, 0.625)] [G loss: 0.863] [G acc: 0.141]\n",
      "474 [D loss: (0.619)(R 0.609, F 0.629)] [D acc: (0.727)(0.688, 0.766)] [G loss: 0.853] [G acc: 0.266]\n",
      "475 [D loss: (0.604)(R 0.580, F 0.629)] [D acc: (0.727)(0.719, 0.734)] [G loss: 0.859] [G acc: 0.250]\n",
      "476 [D loss: (0.629)(R 0.557, F 0.702)] [D acc: (0.617)(0.703, 0.531)] [G loss: 0.902] [G acc: 0.172]\n",
      "477 [D loss: (0.606)(R 0.506, F 0.707)] [D acc: (0.664)(0.766, 0.562)] [G loss: 0.944] [G acc: 0.188]\n",
      "478 [D loss: (0.669)(R 0.660, F 0.678)] [D acc: (0.617)(0.578, 0.656)] [G loss: 0.852] [G acc: 0.219]\n",
      "479 [D loss: (0.643)(R 0.533, F 0.753)] [D acc: (0.625)(0.734, 0.516)] [G loss: 0.884] [G acc: 0.156]\n",
      "480 [D loss: (0.639)(R 0.558, F 0.719)] [D acc: (0.617)(0.656, 0.578)] [G loss: 0.839] [G acc: 0.234]\n",
      "481 [D loss: (0.626)(R 0.588, F 0.664)] [D acc: (0.633)(0.594, 0.672)] [G loss: 0.880] [G acc: 0.219]\n",
      "482 [D loss: (0.629)(R 0.574, F 0.684)] [D acc: (0.680)(0.703, 0.656)] [G loss: 0.956] [G acc: 0.125]\n",
      "483 [D loss: (0.641)(R 0.607, F 0.675)] [D acc: (0.680)(0.641, 0.719)] [G loss: 0.896] [G acc: 0.219]\n",
      "484 [D loss: (0.656)(R 0.626, F 0.685)] [D acc: (0.578)(0.594, 0.562)] [G loss: 0.858] [G acc: 0.234]\n",
      "485 [D loss: (0.649)(R 0.605, F 0.694)] [D acc: (0.641)(0.672, 0.609)] [G loss: 0.874] [G acc: 0.219]\n",
      "486 [D loss: (0.630)(R 0.573, F 0.687)] [D acc: (0.680)(0.719, 0.641)] [G loss: 0.890] [G acc: 0.203]\n",
      "487 [D loss: (0.653)(R 0.565, F 0.740)] [D acc: (0.578)(0.656, 0.500)] [G loss: 0.832] [G acc: 0.234]\n",
      "488 [D loss: (0.655)(R 0.542, F 0.768)] [D acc: (0.609)(0.719, 0.500)] [G loss: 0.948] [G acc: 0.094]\n",
      "489 [D loss: (0.645)(R 0.584, F 0.706)] [D acc: (0.641)(0.703, 0.578)] [G loss: 0.942] [G acc: 0.125]\n",
      "490 [D loss: (0.620)(R 0.619, F 0.621)] [D acc: (0.641)(0.578, 0.703)] [G loss: 0.877] [G acc: 0.188]\n",
      "491 [D loss: (0.688)(R 0.597, F 0.779)] [D acc: (0.531)(0.562, 0.500)] [G loss: 0.897] [G acc: 0.156]\n",
      "492 [D loss: (0.626)(R 0.612, F 0.639)] [D acc: (0.648)(0.625, 0.672)] [G loss: 0.897] [G acc: 0.188]\n",
      "493 [D loss: (0.603)(R 0.575, F 0.632)] [D acc: (0.695)(0.656, 0.734)] [G loss: 0.954] [G acc: 0.125]\n",
      "494 [D loss: (0.645)(R 0.617, F 0.674)] [D acc: (0.594)(0.578, 0.609)] [G loss: 0.882] [G acc: 0.266]\n",
      "495 [D loss: (0.649)(R 0.601, F 0.698)] [D acc: (0.641)(0.625, 0.656)] [G loss: 0.879] [G acc: 0.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496 [D loss: (0.610)(R 0.604, F 0.615)] [D acc: (0.680)(0.641, 0.719)] [G loss: 0.930] [G acc: 0.188]\n",
      "497 [D loss: (0.633)(R 0.521, F 0.744)] [D acc: (0.680)(0.734, 0.625)] [G loss: 1.004] [G acc: 0.094]\n",
      "498 [D loss: (0.607)(R 0.608, F 0.605)] [D acc: (0.664)(0.609, 0.719)] [G loss: 0.967] [G acc: 0.188]\n",
      "499 [D loss: (0.590)(R 0.579, F 0.601)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.051] [G acc: 0.062]\n",
      "500 [D loss: (0.631)(R 0.591, F 0.671)] [D acc: (0.656)(0.641, 0.672)] [G loss: 0.919] [G acc: 0.188]\n",
      "501 [D loss: (0.627)(R 0.539, F 0.715)] [D acc: (0.633)(0.688, 0.578)] [G loss: 0.932] [G acc: 0.141]\n",
      "502 [D loss: (0.677)(R 0.658, F 0.697)] [D acc: (0.578)(0.578, 0.578)] [G loss: 0.893] [G acc: 0.156]\n",
      "503 [D loss: (0.665)(R 0.593, F 0.737)] [D acc: (0.664)(0.719, 0.609)] [G loss: 0.910] [G acc: 0.156]\n",
      "504 [D loss: (0.605)(R 0.590, F 0.619)] [D acc: (0.672)(0.625, 0.719)] [G loss: 0.901] [G acc: 0.172]\n",
      "505 [D loss: (0.639)(R 0.629, F 0.649)] [D acc: (0.602)(0.594, 0.609)] [G loss: 0.868] [G acc: 0.297]\n",
      "506 [D loss: (0.634)(R 0.582, F 0.686)] [D acc: (0.617)(0.641, 0.594)] [G loss: 0.886] [G acc: 0.219]\n",
      "507 [D loss: (0.645)(R 0.624, F 0.666)] [D acc: (0.602)(0.562, 0.641)] [G loss: 0.922] [G acc: 0.094]\n",
      "508 [D loss: (0.657)(R 0.603, F 0.710)] [D acc: (0.641)(0.688, 0.594)] [G loss: 0.889] [G acc: 0.250]\n",
      "509 [D loss: (0.616)(R 0.510, F 0.722)] [D acc: (0.641)(0.734, 0.547)] [G loss: 0.925] [G acc: 0.141]\n",
      "510 [D loss: (0.639)(R 0.568, F 0.711)] [D acc: (0.672)(0.734, 0.609)] [G loss: 0.953] [G acc: 0.156]\n",
      "511 [D loss: (0.624)(R 0.595, F 0.653)] [D acc: (0.617)(0.641, 0.594)] [G loss: 0.981] [G acc: 0.094]\n",
      "512 [D loss: (0.616)(R 0.577, F 0.655)] [D acc: (0.672)(0.734, 0.609)] [G loss: 0.955] [G acc: 0.141]\n",
      "513 [D loss: (0.641)(R 0.590, F 0.692)] [D acc: (0.617)(0.625, 0.609)] [G loss: 0.881] [G acc: 0.297]\n",
      "514 [D loss: (0.637)(R 0.588, F 0.686)] [D acc: (0.656)(0.625, 0.688)] [G loss: 0.922] [G acc: 0.281]\n",
      "515 [D loss: (0.724)(R 0.635, F 0.813)] [D acc: (0.492)(0.562, 0.422)] [G loss: 0.939] [G acc: 0.094]\n",
      "516 [D loss: (0.624)(R 0.598, F 0.649)] [D acc: (0.609)(0.594, 0.625)] [G loss: 0.963] [G acc: 0.141]\n",
      "517 [D loss: (0.650)(R 0.621, F 0.679)] [D acc: (0.633)(0.594, 0.672)] [G loss: 0.962] [G acc: 0.109]\n",
      "518 [D loss: (0.591)(R 0.577, F 0.605)] [D acc: (0.688)(0.656, 0.719)] [G loss: 0.946] [G acc: 0.203]\n",
      "519 [D loss: (0.634)(R 0.567, F 0.700)] [D acc: (0.594)(0.609, 0.578)] [G loss: 0.960] [G acc: 0.141]\n",
      "520 [D loss: (0.650)(R 0.621, F 0.678)] [D acc: (0.586)(0.594, 0.578)] [G loss: 0.899] [G acc: 0.234]\n",
      "521 [D loss: (0.626)(R 0.555, F 0.698)] [D acc: (0.617)(0.656, 0.578)] [G loss: 0.944] [G acc: 0.172]\n",
      "522 [D loss: (0.605)(R 0.539, F 0.671)] [D acc: (0.695)(0.734, 0.656)] [G loss: 0.948] [G acc: 0.188]\n",
      "523 [D loss: (0.610)(R 0.559, F 0.660)] [D acc: (0.648)(0.688, 0.609)] [G loss: 0.983] [G acc: 0.141]\n",
      "524 [D loss: (0.648)(R 0.611, F 0.685)] [D acc: (0.602)(0.547, 0.656)] [G loss: 0.965] [G acc: 0.156]\n",
      "525 [D loss: (0.627)(R 0.613, F 0.642)] [D acc: (0.633)(0.672, 0.594)] [G loss: 0.950] [G acc: 0.203]\n",
      "526 [D loss: (0.663)(R 0.669, F 0.656)] [D acc: (0.594)(0.547, 0.641)] [G loss: 0.952] [G acc: 0.141]\n",
      "527 [D loss: (0.584)(R 0.534, F 0.635)] [D acc: (0.672)(0.734, 0.609)] [G loss: 0.994] [G acc: 0.125]\n",
      "528 [D loss: (0.672)(R 0.652, F 0.693)] [D acc: (0.547)(0.531, 0.562)] [G loss: 0.972] [G acc: 0.094]\n",
      "529 [D loss: (0.625)(R 0.499, F 0.752)] [D acc: (0.664)(0.766, 0.562)] [G loss: 1.006] [G acc: 0.141]\n",
      "530 [D loss: (0.610)(R 0.652, F 0.568)] [D acc: (0.664)(0.562, 0.766)] [G loss: 0.945] [G acc: 0.203]\n",
      "531 [D loss: (0.644)(R 0.637, F 0.651)] [D acc: (0.602)(0.531, 0.672)] [G loss: 0.906] [G acc: 0.219]\n",
      "532 [D loss: (0.597)(R 0.569, F 0.625)] [D acc: (0.688)(0.672, 0.703)] [G loss: 0.901] [G acc: 0.172]\n",
      "533 [D loss: (0.568)(R 0.484, F 0.651)] [D acc: (0.727)(0.781, 0.672)] [G loss: 0.956] [G acc: 0.188]\n",
      "534 [D loss: (0.641)(R 0.573, F 0.710)] [D acc: (0.641)(0.688, 0.594)] [G loss: 0.945] [G acc: 0.156]\n",
      "535 [D loss: (0.630)(R 0.563, F 0.698)] [D acc: (0.617)(0.672, 0.562)] [G loss: 1.021] [G acc: 0.109]\n",
      "536 [D loss: (0.587)(R 0.531, F 0.643)] [D acc: (0.695)(0.734, 0.656)] [G loss: 1.006] [G acc: 0.125]\n",
      "537 [D loss: (0.655)(R 0.556, F 0.753)] [D acc: (0.672)(0.734, 0.609)] [G loss: 0.958] [G acc: 0.203]\n",
      "538 [D loss: (0.590)(R 0.585, F 0.595)] [D acc: (0.727)(0.688, 0.766)] [G loss: 0.968] [G acc: 0.172]\n",
      "539 [D loss: (0.628)(R 0.584, F 0.672)] [D acc: (0.633)(0.672, 0.594)] [G loss: 0.977] [G acc: 0.172]\n",
      "540 [D loss: (0.614)(R 0.542, F 0.685)] [D acc: (0.633)(0.688, 0.578)] [G loss: 0.968] [G acc: 0.203]\n",
      "541 [D loss: (0.622)(R 0.580, F 0.663)] [D acc: (0.641)(0.672, 0.609)] [G loss: 1.016] [G acc: 0.125]\n",
      "542 [D loss: (0.669)(R 0.624, F 0.714)] [D acc: (0.609)(0.609, 0.609)] [G loss: 0.916] [G acc: 0.188]\n",
      "543 [D loss: (0.636)(R 0.552, F 0.721)] [D acc: (0.648)(0.688, 0.609)] [G loss: 0.990] [G acc: 0.062]\n",
      "544 [D loss: (0.576)(R 0.533, F 0.619)] [D acc: (0.711)(0.703, 0.719)] [G loss: 0.932] [G acc: 0.234]\n",
      "545 [D loss: (0.629)(R 0.532, F 0.725)] [D acc: (0.711)(0.703, 0.719)] [G loss: 0.958] [G acc: 0.172]\n",
      "546 [D loss: (0.656)(R 0.620, F 0.692)] [D acc: (0.648)(0.609, 0.688)] [G loss: 0.940] [G acc: 0.156]\n",
      "547 [D loss: (0.664)(R 0.680, F 0.648)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.963] [G acc: 0.156]\n",
      "548 [D loss: (0.668)(R 0.617, F 0.720)] [D acc: (0.555)(0.531, 0.578)] [G loss: 0.939] [G acc: 0.188]\n",
      "549 [D loss: (0.643)(R 0.674, F 0.613)] [D acc: (0.602)(0.500, 0.703)] [G loss: 0.968] [G acc: 0.141]\n",
      "550 [D loss: (0.660)(R 0.604, F 0.717)] [D acc: (0.633)(0.609, 0.656)] [G loss: 0.891] [G acc: 0.219]\n",
      "551 [D loss: (0.616)(R 0.584, F 0.648)] [D acc: (0.680)(0.672, 0.688)] [G loss: 0.949] [G acc: 0.125]\n",
      "552 [D loss: (0.629)(R 0.657, F 0.601)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.032] [G acc: 0.094]\n",
      "553 [D loss: (0.676)(R 0.639, F 0.714)] [D acc: (0.602)(0.578, 0.625)] [G loss: 0.946] [G acc: 0.094]\n",
      "554 [D loss: (0.629)(R 0.537, F 0.722)] [D acc: (0.680)(0.703, 0.656)] [G loss: 0.941] [G acc: 0.156]\n",
      "555 [D loss: (0.631)(R 0.593, F 0.670)] [D acc: (0.648)(0.625, 0.672)] [G loss: 0.932] [G acc: 0.219]\n",
      "556 [D loss: (0.646)(R 0.678, F 0.614)] [D acc: (0.633)(0.547, 0.719)] [G loss: 0.894] [G acc: 0.188]\n",
      "557 [D loss: (0.658)(R 0.591, F 0.726)] [D acc: (0.617)(0.656, 0.578)] [G loss: 0.948] [G acc: 0.141]\n",
      "558 [D loss: (0.678)(R 0.619, F 0.737)] [D acc: (0.625)(0.609, 0.641)] [G loss: 0.907] [G acc: 0.172]\n",
      "559 [D loss: (0.624)(R 0.638, F 0.610)] [D acc: (0.633)(0.562, 0.703)] [G loss: 0.935] [G acc: 0.172]\n",
      "560 [D loss: (0.599)(R 0.571, F 0.626)] [D acc: (0.688)(0.688, 0.688)] [G loss: 0.914] [G acc: 0.219]\n",
      "561 [D loss: (0.658)(R 0.577, F 0.739)] [D acc: (0.625)(0.656, 0.594)] [G loss: 0.927] [G acc: 0.203]\n",
      "562 [D loss: (0.581)(R 0.516, F 0.645)] [D acc: (0.703)(0.750, 0.656)] [G loss: 0.970] [G acc: 0.250]\n",
      "563 [D loss: (0.650)(R 0.569, F 0.731)] [D acc: (0.641)(0.703, 0.578)] [G loss: 0.973] [G acc: 0.125]\n",
      "564 [D loss: (0.600)(R 0.612, F 0.588)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.016] [G acc: 0.109]\n",
      "565 [D loss: (0.646)(R 0.599, F 0.694)] [D acc: (0.656)(0.656, 0.656)] [G loss: 0.963] [G acc: 0.156]\n",
      "566 [D loss: (0.635)(R 0.510, F 0.761)] [D acc: (0.625)(0.719, 0.531)] [G loss: 0.952] [G acc: 0.188]\n",
      "567 [D loss: (0.663)(R 0.680, F 0.647)] [D acc: (0.586)(0.516, 0.656)] [G loss: 0.985] [G acc: 0.141]\n",
      "568 [D loss: (0.651)(R 0.625, F 0.677)] [D acc: (0.578)(0.594, 0.562)] [G loss: 0.925] [G acc: 0.234]\n",
      "569 [D loss: (0.634)(R 0.618, F 0.651)] [D acc: (0.680)(0.672, 0.688)] [G loss: 0.989] [G acc: 0.094]\n",
      "570 [D loss: (0.652)(R 0.613, F 0.691)] [D acc: (0.633)(0.625, 0.641)] [G loss: 0.932] [G acc: 0.219]\n",
      "571 [D loss: (0.631)(R 0.653, F 0.609)] [D acc: (0.648)(0.562, 0.734)] [G loss: 0.933] [G acc: 0.156]\n",
      "572 [D loss: (0.627)(R 0.585, F 0.669)] [D acc: (0.617)(0.578, 0.656)] [G loss: 0.944] [G acc: 0.141]\n",
      "573 [D loss: (0.646)(R 0.637, F 0.656)] [D acc: (0.609)(0.562, 0.656)] [G loss: 0.971] [G acc: 0.125]\n",
      "574 [D loss: (0.647)(R 0.597, F 0.696)] [D acc: (0.625)(0.578, 0.672)] [G loss: 0.944] [G acc: 0.219]\n",
      "575 [D loss: (0.610)(R 0.553, F 0.666)] [D acc: (0.664)(0.656, 0.672)] [G loss: 0.902] [G acc: 0.188]\n",
      "576 [D loss: (0.593)(R 0.557, F 0.628)] [D acc: (0.672)(0.703, 0.641)] [G loss: 0.963] [G acc: 0.109]\n",
      "577 [D loss: (0.647)(R 0.637, F 0.658)] [D acc: (0.617)(0.547, 0.688)] [G loss: 1.013] [G acc: 0.078]\n",
      "578 [D loss: (0.623)(R 0.590, F 0.655)] [D acc: (0.656)(0.609, 0.703)] [G loss: 0.896] [G acc: 0.219]\n",
      "579 [D loss: (0.671)(R 0.688, F 0.654)] [D acc: (0.594)(0.484, 0.703)] [G loss: 0.997] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580 [D loss: (0.638)(R 0.606, F 0.670)] [D acc: (0.695)(0.656, 0.734)] [G loss: 0.983] [G acc: 0.062]\n",
      "581 [D loss: (0.670)(R 0.666, F 0.674)] [D acc: (0.539)(0.516, 0.562)] [G loss: 0.935] [G acc: 0.203]\n",
      "582 [D loss: (0.621)(R 0.593, F 0.649)] [D acc: (0.648)(0.609, 0.688)] [G loss: 0.927] [G acc: 0.156]\n",
      "583 [D loss: (0.618)(R 0.589, F 0.646)] [D acc: (0.680)(0.656, 0.703)] [G loss: 0.922] [G acc: 0.172]\n",
      "584 [D loss: (0.587)(R 0.509, F 0.665)] [D acc: (0.695)(0.703, 0.688)] [G loss: 0.929] [G acc: 0.219]\n",
      "585 [D loss: (0.627)(R 0.602, F 0.652)] [D acc: (0.625)(0.609, 0.641)] [G loss: 0.921] [G acc: 0.234]\n",
      "586 [D loss: (0.650)(R 0.627, F 0.673)] [D acc: (0.617)(0.594, 0.641)] [G loss: 0.936] [G acc: 0.141]\n",
      "587 [D loss: (0.606)(R 0.543, F 0.669)] [D acc: (0.672)(0.719, 0.625)] [G loss: 1.024] [G acc: 0.094]\n",
      "588 [D loss: (0.627)(R 0.650, F 0.603)] [D acc: (0.641)(0.547, 0.734)] [G loss: 0.950] [G acc: 0.188]\n",
      "589 [D loss: (0.623)(R 0.588, F 0.658)] [D acc: (0.688)(0.641, 0.734)] [G loss: 0.984] [G acc: 0.141]\n",
      "590 [D loss: (0.656)(R 0.653, F 0.658)] [D acc: (0.609)(0.531, 0.688)] [G loss: 0.931] [G acc: 0.141]\n",
      "591 [D loss: (0.602)(R 0.553, F 0.651)] [D acc: (0.672)(0.656, 0.688)] [G loss: 0.994] [G acc: 0.188]\n",
      "592 [D loss: (0.656)(R 0.571, F 0.741)] [D acc: (0.594)(0.672, 0.516)] [G loss: 1.025] [G acc: 0.094]\n",
      "593 [D loss: (0.596)(R 0.594, F 0.599)] [D acc: (0.703)(0.656, 0.750)] [G loss: 0.961] [G acc: 0.172]\n",
      "594 [D loss: (0.617)(R 0.602, F 0.632)] [D acc: (0.680)(0.688, 0.672)] [G loss: 0.947] [G acc: 0.188]\n",
      "595 [D loss: (0.604)(R 0.553, F 0.655)] [D acc: (0.688)(0.750, 0.625)] [G loss: 1.051] [G acc: 0.078]\n",
      "596 [D loss: (0.661)(R 0.652, F 0.669)] [D acc: (0.562)(0.500, 0.625)] [G loss: 0.983] [G acc: 0.141]\n",
      "597 [D loss: (0.627)(R 0.608, F 0.647)] [D acc: (0.602)(0.562, 0.641)] [G loss: 0.973] [G acc: 0.156]\n",
      "598 [D loss: (0.584)(R 0.529, F 0.639)] [D acc: (0.734)(0.766, 0.703)] [G loss: 0.990] [G acc: 0.141]\n",
      "599 [D loss: (0.656)(R 0.607, F 0.705)] [D acc: (0.602)(0.625, 0.578)] [G loss: 1.008] [G acc: 0.156]\n",
      "600 [D loss: (0.625)(R 0.563, F 0.686)] [D acc: (0.648)(0.656, 0.641)] [G loss: 0.957] [G acc: 0.172]\n",
      "601 [D loss: (0.598)(R 0.553, F 0.643)] [D acc: (0.695)(0.672, 0.719)] [G loss: 0.959] [G acc: 0.172]\n",
      "602 [D loss: (0.639)(R 0.621, F 0.657)] [D acc: (0.617)(0.562, 0.672)] [G loss: 1.003] [G acc: 0.125]\n",
      "603 [D loss: (0.582)(R 0.559, F 0.605)] [D acc: (0.688)(0.656, 0.719)] [G loss: 0.995] [G acc: 0.219]\n",
      "604 [D loss: (0.619)(R 0.556, F 0.681)] [D acc: (0.656)(0.641, 0.672)] [G loss: 0.955] [G acc: 0.203]\n",
      "605 [D loss: (0.598)(R 0.543, F 0.652)] [D acc: (0.664)(0.672, 0.656)] [G loss: 1.043] [G acc: 0.109]\n",
      "606 [D loss: (0.623)(R 0.623, F 0.624)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.039] [G acc: 0.078]\n",
      "607 [D loss: (0.604)(R 0.525, F 0.684)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.010] [G acc: 0.109]\n",
      "608 [D loss: (0.591)(R 0.588, F 0.594)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.042] [G acc: 0.109]\n",
      "609 [D loss: (0.576)(R 0.562, F 0.590)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.073] [G acc: 0.172]\n",
      "610 [D loss: (0.642)(R 0.598, F 0.687)] [D acc: (0.664)(0.703, 0.625)] [G loss: 1.023] [G acc: 0.109]\n",
      "611 [D loss: (0.614)(R 0.591, F 0.637)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.142] [G acc: 0.094]\n",
      "612 [D loss: (0.595)(R 0.605, F 0.585)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.038] [G acc: 0.125]\n",
      "613 [D loss: (0.613)(R 0.606, F 0.620)] [D acc: (0.625)(0.609, 0.641)] [G loss: 1.064] [G acc: 0.094]\n",
      "614 [D loss: (0.590)(R 0.584, F 0.596)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.010] [G acc: 0.156]\n",
      "615 [D loss: (0.619)(R 0.599, F 0.638)] [D acc: (0.641)(0.609, 0.672)] [G loss: 0.979] [G acc: 0.125]\n",
      "616 [D loss: (0.576)(R 0.511, F 0.640)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.012] [G acc: 0.141]\n",
      "617 [D loss: (0.611)(R 0.582, F 0.641)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.041] [G acc: 0.141]\n",
      "618 [D loss: (0.608)(R 0.598, F 0.618)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.064] [G acc: 0.078]\n",
      "619 [D loss: (0.674)(R 0.685, F 0.662)] [D acc: (0.586)(0.484, 0.688)] [G loss: 0.997] [G acc: 0.062]\n",
      "620 [D loss: (0.601)(R 0.615, F 0.587)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.025] [G acc: 0.156]\n",
      "621 [D loss: (0.632)(R 0.599, F 0.665)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.064] [G acc: 0.109]\n",
      "622 [D loss: (0.618)(R 0.650, F 0.586)] [D acc: (0.648)(0.516, 0.781)] [G loss: 1.002] [G acc: 0.141]\n",
      "623 [D loss: (0.584)(R 0.506, F 0.661)] [D acc: (0.727)(0.734, 0.719)] [G loss: 0.964] [G acc: 0.219]\n",
      "624 [D loss: (0.638)(R 0.588, F 0.688)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.027] [G acc: 0.109]\n",
      "625 [D loss: (0.598)(R 0.599, F 0.598)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.043] [G acc: 0.109]\n",
      "626 [D loss: (0.655)(R 0.632, F 0.677)] [D acc: (0.625)(0.609, 0.641)] [G loss: 1.039] [G acc: 0.141]\n",
      "627 [D loss: (0.669)(R 0.681, F 0.656)] [D acc: (0.578)(0.516, 0.641)] [G loss: 1.038] [G acc: 0.125]\n",
      "628 [D loss: (0.612)(R 0.580, F 0.643)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.034] [G acc: 0.078]\n",
      "629 [D loss: (0.619)(R 0.640, F 0.598)] [D acc: (0.672)(0.594, 0.750)] [G loss: 0.954] [G acc: 0.188]\n",
      "630 [D loss: (0.614)(R 0.524, F 0.704)] [D acc: (0.594)(0.672, 0.516)] [G loss: 1.017] [G acc: 0.109]\n",
      "631 [D loss: (0.614)(R 0.549, F 0.680)] [D acc: (0.641)(0.641, 0.641)] [G loss: 1.027] [G acc: 0.156]\n",
      "632 [D loss: (0.632)(R 0.622, F 0.641)] [D acc: (0.602)(0.547, 0.656)] [G loss: 0.933] [G acc: 0.172]\n",
      "633 [D loss: (0.633)(R 0.640, F 0.626)] [D acc: (0.641)(0.578, 0.703)] [G loss: 0.995] [G acc: 0.172]\n",
      "634 [D loss: (0.532)(R 0.557, F 0.507)] [D acc: (0.797)(0.719, 0.875)] [G loss: 0.978] [G acc: 0.234]\n",
      "635 [D loss: (0.558)(R 0.520, F 0.595)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.000] [G acc: 0.203]\n",
      "636 [D loss: (0.602)(R 0.585, F 0.620)] [D acc: (0.633)(0.609, 0.656)] [G loss: 0.980] [G acc: 0.250]\n",
      "637 [D loss: (0.640)(R 0.543, F 0.737)] [D acc: (0.609)(0.625, 0.594)] [G loss: 1.007] [G acc: 0.109]\n",
      "638 [D loss: (0.584)(R 0.532, F 0.637)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.044] [G acc: 0.188]\n",
      "639 [D loss: (0.580)(R 0.549, F 0.610)] [D acc: (0.641)(0.656, 0.625)] [G loss: 1.029] [G acc: 0.141]\n",
      "640 [D loss: (0.604)(R 0.523, F 0.685)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.068] [G acc: 0.141]\n",
      "641 [D loss: (0.617)(R 0.530, F 0.703)] [D acc: (0.641)(0.656, 0.625)] [G loss: 1.070] [G acc: 0.125]\n",
      "642 [D loss: (0.572)(R 0.559, F 0.584)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.094] [G acc: 0.172]\n",
      "643 [D loss: (0.562)(R 0.571, F 0.554)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.103] [G acc: 0.062]\n",
      "644 [D loss: (0.589)(R 0.457, F 0.721)] [D acc: (0.656)(0.734, 0.578)] [G loss: 1.028] [G acc: 0.172]\n",
      "645 [D loss: (0.593)(R 0.608, F 0.579)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.021] [G acc: 0.203]\n",
      "646 [D loss: (0.575)(R 0.525, F 0.624)] [D acc: (0.734)(0.766, 0.703)] [G loss: 1.082] [G acc: 0.156]\n",
      "647 [D loss: (0.656)(R 0.625, F 0.686)] [D acc: (0.586)(0.547, 0.625)] [G loss: 1.033] [G acc: 0.188]\n",
      "648 [D loss: (0.651)(R 0.659, F 0.643)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.077] [G acc: 0.109]\n",
      "649 [D loss: (0.615)(R 0.566, F 0.664)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.058] [G acc: 0.047]\n",
      "650 [D loss: (0.671)(R 0.637, F 0.704)] [D acc: (0.609)(0.594, 0.625)] [G loss: 1.005] [G acc: 0.047]\n",
      "651 [D loss: (0.626)(R 0.642, F 0.611)] [D acc: (0.672)(0.594, 0.750)] [G loss: 0.951] [G acc: 0.203]\n",
      "652 [D loss: (0.607)(R 0.599, F 0.615)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.031] [G acc: 0.078]\n",
      "653 [D loss: (0.548)(R 0.484, F 0.611)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.023] [G acc: 0.109]\n",
      "654 [D loss: (0.694)(R 0.649, F 0.739)] [D acc: (0.594)(0.516, 0.672)] [G loss: 1.002] [G acc: 0.125]\n",
      "655 [D loss: (0.591)(R 0.515, F 0.666)] [D acc: (0.664)(0.672, 0.656)] [G loss: 1.050] [G acc: 0.094]\n",
      "656 [D loss: (0.614)(R 0.647, F 0.581)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.003] [G acc: 0.141]\n",
      "657 [D loss: (0.610)(R 0.591, F 0.630)] [D acc: (0.602)(0.547, 0.656)] [G loss: 0.973] [G acc: 0.219]\n",
      "658 [D loss: (0.550)(R 0.506, F 0.593)] [D acc: (0.648)(0.656, 0.641)] [G loss: 1.009] [G acc: 0.109]\n",
      "659 [D loss: (0.580)(R 0.491, F 0.669)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.066] [G acc: 0.109]\n",
      "660 [D loss: (0.656)(R 0.640, F 0.672)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.081] [G acc: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661 [D loss: (0.623)(R 0.578, F 0.669)] [D acc: (0.633)(0.625, 0.641)] [G loss: 1.111] [G acc: 0.125]\n",
      "662 [D loss: (0.627)(R 0.628, F 0.625)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.027] [G acc: 0.094]\n",
      "663 [D loss: (0.599)(R 0.644, F 0.554)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.048] [G acc: 0.125]\n",
      "664 [D loss: (0.595)(R 0.581, F 0.610)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.087] [G acc: 0.109]\n",
      "665 [D loss: (0.632)(R 0.566, F 0.699)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.026] [G acc: 0.109]\n",
      "666 [D loss: (0.658)(R 0.660, F 0.656)] [D acc: (0.625)(0.578, 0.672)] [G loss: 1.013] [G acc: 0.141]\n",
      "667 [D loss: (0.608)(R 0.606, F 0.610)] [D acc: (0.727)(0.688, 0.766)] [G loss: 0.984] [G acc: 0.203]\n",
      "668 [D loss: (0.607)(R 0.597, F 0.616)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.083] [G acc: 0.109]\n",
      "669 [D loss: (0.608)(R 0.627, F 0.589)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.010] [G acc: 0.219]\n",
      "670 [D loss: (0.586)(R 0.561, F 0.611)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.008] [G acc: 0.141]\n",
      "671 [D loss: (0.564)(R 0.524, F 0.605)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.088] [G acc: 0.109]\n",
      "672 [D loss: (0.626)(R 0.647, F 0.605)] [D acc: (0.648)(0.531, 0.766)] [G loss: 0.986] [G acc: 0.141]\n",
      "673 [D loss: (0.653)(R 0.603, F 0.704)] [D acc: (0.641)(0.656, 0.625)] [G loss: 1.079] [G acc: 0.109]\n",
      "674 [D loss: (0.637)(R 0.572, F 0.703)] [D acc: (0.625)(0.688, 0.562)] [G loss: 1.098] [G acc: 0.125]\n",
      "675 [D loss: (0.653)(R 0.716, F 0.589)] [D acc: (0.562)(0.469, 0.656)] [G loss: 1.038] [G acc: 0.078]\n",
      "676 [D loss: (0.666)(R 0.647, F 0.684)] [D acc: (0.609)(0.531, 0.688)] [G loss: 1.039] [G acc: 0.156]\n",
      "677 [D loss: (0.598)(R 0.577, F 0.620)] [D acc: (0.672)(0.609, 0.734)] [G loss: 0.993] [G acc: 0.141]\n",
      "678 [D loss: (0.659)(R 0.583, F 0.736)] [D acc: (0.609)(0.594, 0.625)] [G loss: 1.034] [G acc: 0.094]\n",
      "679 [D loss: (0.594)(R 0.545, F 0.643)] [D acc: (0.672)(0.688, 0.656)] [G loss: 1.013] [G acc: 0.078]\n",
      "680 [D loss: (0.627)(R 0.610, F 0.643)] [D acc: (0.633)(0.625, 0.641)] [G loss: 0.991] [G acc: 0.203]\n",
      "681 [D loss: (0.617)(R 0.624, F 0.610)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.023] [G acc: 0.094]\n",
      "682 [D loss: (0.673)(R 0.592, F 0.754)] [D acc: (0.648)(0.641, 0.656)] [G loss: 1.005] [G acc: 0.141]\n",
      "683 [D loss: (0.575)(R 0.597, F 0.553)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.017] [G acc: 0.094]\n",
      "684 [D loss: (0.601)(R 0.645, F 0.557)] [D acc: (0.680)(0.562, 0.797)] [G loss: 0.968] [G acc: 0.156]\n",
      "685 [D loss: (0.566)(R 0.491, F 0.641)] [D acc: (0.688)(0.719, 0.656)] [G loss: 0.943] [G acc: 0.188]\n",
      "686 [D loss: (0.595)(R 0.522, F 0.669)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.051] [G acc: 0.125]\n",
      "687 [D loss: (0.629)(R 0.604, F 0.655)] [D acc: (0.602)(0.594, 0.609)] [G loss: 0.979] [G acc: 0.141]\n",
      "688 [D loss: (0.607)(R 0.578, F 0.635)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.045] [G acc: 0.078]\n",
      "689 [D loss: (0.618)(R 0.624, F 0.612)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.005] [G acc: 0.125]\n",
      "690 [D loss: (0.580)(R 0.561, F 0.599)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.021] [G acc: 0.172]\n",
      "691 [D loss: (0.641)(R 0.531, F 0.751)] [D acc: (0.609)(0.703, 0.516)] [G loss: 1.026] [G acc: 0.094]\n",
      "692 [D loss: (0.579)(R 0.545, F 0.612)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.049] [G acc: 0.109]\n",
      "693 [D loss: (0.651)(R 0.615, F 0.688)] [D acc: (0.609)(0.547, 0.672)] [G loss: 1.058] [G acc: 0.141]\n",
      "694 [D loss: (0.607)(R 0.576, F 0.638)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.032] [G acc: 0.094]\n",
      "695 [D loss: (0.588)(R 0.578, F 0.599)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.082] [G acc: 0.109]\n",
      "696 [D loss: (0.593)(R 0.561, F 0.625)] [D acc: (0.656)(0.672, 0.641)] [G loss: 1.059] [G acc: 0.062]\n",
      "697 [D loss: (0.623)(R 0.537, F 0.709)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.061] [G acc: 0.047]\n",
      "698 [D loss: (0.583)(R 0.558, F 0.608)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.029] [G acc: 0.125]\n",
      "699 [D loss: (0.595)(R 0.549, F 0.641)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.086] [G acc: 0.109]\n",
      "700 [D loss: (0.611)(R 0.593, F 0.629)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.019] [G acc: 0.156]\n",
      "701 [D loss: (0.696)(R 0.684, F 0.707)] [D acc: (0.578)(0.547, 0.609)] [G loss: 1.018] [G acc: 0.094]\n",
      "702 [D loss: (0.564)(R 0.523, F 0.604)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.044] [G acc: 0.047]\n",
      "703 [D loss: (0.651)(R 0.581, F 0.721)] [D acc: (0.617)(0.656, 0.578)] [G loss: 0.984] [G acc: 0.109]\n",
      "704 [D loss: (0.581)(R 0.582, F 0.580)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.058] [G acc: 0.109]\n",
      "705 [D loss: (0.688)(R 0.652, F 0.723)] [D acc: (0.594)(0.562, 0.625)] [G loss: 0.978] [G acc: 0.125]\n",
      "706 [D loss: (0.601)(R 0.598, F 0.605)] [D acc: (0.633)(0.609, 0.656)] [G loss: 0.970] [G acc: 0.234]\n",
      "707 [D loss: (0.617)(R 0.596, F 0.637)] [D acc: (0.648)(0.641, 0.656)] [G loss: 0.954] [G acc: 0.234]\n",
      "708 [D loss: (0.565)(R 0.570, F 0.561)] [D acc: (0.734)(0.672, 0.797)] [G loss: 0.969] [G acc: 0.234]\n",
      "709 [D loss: (0.658)(R 0.644, F 0.672)] [D acc: (0.625)(0.578, 0.672)] [G loss: 1.083] [G acc: 0.078]\n",
      "710 [D loss: (0.571)(R 0.523, F 0.618)] [D acc: (0.680)(0.703, 0.656)] [G loss: 1.013] [G acc: 0.141]\n",
      "711 [D loss: (0.662)(R 0.639, F 0.685)] [D acc: (0.633)(0.609, 0.656)] [G loss: 1.026] [G acc: 0.125]\n",
      "712 [D loss: (0.584)(R 0.599, F 0.568)] [D acc: (0.672)(0.562, 0.781)] [G loss: 0.988] [G acc: 0.125]\n",
      "713 [D loss: (0.646)(R 0.630, F 0.662)] [D acc: (0.609)(0.578, 0.641)] [G loss: 1.057] [G acc: 0.141]\n",
      "714 [D loss: (0.597)(R 0.631, F 0.563)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.028] [G acc: 0.141]\n",
      "715 [D loss: (0.640)(R 0.576, F 0.703)] [D acc: (0.680)(0.719, 0.641)] [G loss: 0.965] [G acc: 0.234]\n",
      "716 [D loss: (0.723)(R 0.567, F 0.879)] [D acc: (0.531)(0.547, 0.516)] [G loss: 1.012] [G acc: 0.109]\n",
      "717 [D loss: (0.621)(R 0.650, F 0.592)] [D acc: (0.656)(0.562, 0.750)] [G loss: 0.982] [G acc: 0.125]\n",
      "718 [D loss: (0.578)(R 0.580, F 0.575)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.060] [G acc: 0.078]\n",
      "719 [D loss: (0.556)(R 0.543, F 0.570)] [D acc: (0.734)(0.672, 0.797)] [G loss: 0.934] [G acc: 0.219]\n",
      "720 [D loss: (0.630)(R 0.651, F 0.609)] [D acc: (0.617)(0.531, 0.703)] [G loss: 1.004] [G acc: 0.203]\n",
      "721 [D loss: (0.593)(R 0.566, F 0.620)] [D acc: (0.656)(0.609, 0.703)] [G loss: 0.989] [G acc: 0.141]\n",
      "722 [D loss: (0.636)(R 0.605, F 0.667)] [D acc: (0.641)(0.625, 0.656)] [G loss: 1.033] [G acc: 0.188]\n",
      "723 [D loss: (0.615)(R 0.599, F 0.631)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.016] [G acc: 0.141]\n",
      "724 [D loss: (0.575)(R 0.621, F 0.528)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.058] [G acc: 0.125]\n",
      "725 [D loss: (0.575)(R 0.497, F 0.652)] [D acc: (0.711)(0.750, 0.672)] [G loss: 1.027] [G acc: 0.141]\n",
      "726 [D loss: (0.612)(R 0.563, F 0.662)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.113] [G acc: 0.109]\n",
      "727 [D loss: (0.686)(R 0.713, F 0.658)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.082] [G acc: 0.094]\n",
      "728 [D loss: (0.601)(R 0.623, F 0.578)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.005] [G acc: 0.109]\n",
      "729 [D loss: (0.633)(R 0.672, F 0.595)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.047] [G acc: 0.094]\n",
      "730 [D loss: (0.595)(R 0.569, F 0.621)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.028] [G acc: 0.141]\n",
      "731 [D loss: (0.626)(R 0.608, F 0.643)] [D acc: (0.664)(0.609, 0.719)] [G loss: 0.956] [G acc: 0.156]\n",
      "732 [D loss: (0.566)(R 0.581, F 0.550)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.100] [G acc: 0.094]\n",
      "733 [D loss: (0.613)(R 0.575, F 0.650)] [D acc: (0.648)(0.656, 0.641)] [G loss: 0.997] [G acc: 0.188]\n",
      "734 [D loss: (0.609)(R 0.543, F 0.676)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.067] [G acc: 0.156]\n",
      "735 [D loss: (0.574)(R 0.588, F 0.560)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.001] [G acc: 0.156]\n",
      "736 [D loss: (0.601)(R 0.523, F 0.679)] [D acc: (0.625)(0.641, 0.609)] [G loss: 1.018] [G acc: 0.156]\n",
      "737 [D loss: (0.661)(R 0.606, F 0.717)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.019] [G acc: 0.125]\n",
      "738 [D loss: (0.578)(R 0.563, F 0.592)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.059] [G acc: 0.125]\n",
      "739 [D loss: (0.566)(R 0.520, F 0.612)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.022] [G acc: 0.141]\n",
      "740 [D loss: (0.597)(R 0.566, F 0.628)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.076] [G acc: 0.172]\n",
      "741 [D loss: (0.647)(R 0.570, F 0.725)] [D acc: (0.594)(0.594, 0.594)] [G loss: 0.983] [G acc: 0.156]\n",
      "742 [D loss: (0.586)(R 0.576, F 0.595)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.075] [G acc: 0.109]\n",
      "743 [D loss: (0.622)(R 0.536, F 0.708)] [D acc: (0.656)(0.672, 0.641)] [G loss: 1.065] [G acc: 0.078]\n",
      "744 [D loss: (0.564)(R 0.526, F 0.601)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.029] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745 [D loss: (0.569)(R 0.569, F 0.568)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.021] [G acc: 0.125]\n",
      "746 [D loss: (0.638)(R 0.606, F 0.669)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.061] [G acc: 0.141]\n",
      "747 [D loss: (0.573)(R 0.614, F 0.532)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.060] [G acc: 0.125]\n",
      "748 [D loss: (0.647)(R 0.542, F 0.753)] [D acc: (0.633)(0.688, 0.578)] [G loss: 1.128] [G acc: 0.062]\n",
      "749 [D loss: (0.607)(R 0.553, F 0.662)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.046] [G acc: 0.203]\n",
      "750 [D loss: (0.644)(R 0.583, F 0.705)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.122] [G acc: 0.094]\n",
      "751 [D loss: (0.602)(R 0.657, F 0.547)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.031] [G acc: 0.172]\n",
      "752 [D loss: (0.676)(R 0.660, F 0.693)] [D acc: (0.609)(0.547, 0.672)] [G loss: 0.996] [G acc: 0.203]\n",
      "753 [D loss: (0.593)(R 0.573, F 0.612)] [D acc: (0.648)(0.656, 0.641)] [G loss: 1.000] [G acc: 0.172]\n",
      "754 [D loss: (0.613)(R 0.593, F 0.632)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.039] [G acc: 0.188]\n",
      "755 [D loss: (0.646)(R 0.582, F 0.710)] [D acc: (0.609)(0.656, 0.562)] [G loss: 1.107] [G acc: 0.109]\n",
      "756 [D loss: (0.594)(R 0.537, F 0.652)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.043] [G acc: 0.109]\n",
      "757 [D loss: (0.580)(R 0.568, F 0.591)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.056] [G acc: 0.141]\n",
      "758 [D loss: (0.669)(R 0.677, F 0.661)] [D acc: (0.633)(0.547, 0.719)] [G loss: 1.106] [G acc: 0.094]\n",
      "759 [D loss: (0.599)(R 0.582, F 0.615)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.016] [G acc: 0.156]\n",
      "760 [D loss: (0.650)(R 0.738, F 0.562)] [D acc: (0.625)(0.406, 0.844)] [G loss: 0.997] [G acc: 0.156]\n",
      "761 [D loss: (0.588)(R 0.588, F 0.588)] [D acc: (0.641)(0.547, 0.734)] [G loss: 0.978] [G acc: 0.156]\n",
      "762 [D loss: (0.626)(R 0.584, F 0.668)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.106] [G acc: 0.109]\n",
      "763 [D loss: (0.543)(R 0.516, F 0.570)] [D acc: (0.727)(0.688, 0.766)] [G loss: 0.998] [G acc: 0.219]\n",
      "764 [D loss: (0.555)(R 0.485, F 0.624)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.028] [G acc: 0.109]\n",
      "765 [D loss: (0.608)(R 0.586, F 0.630)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.055] [G acc: 0.125]\n",
      "766 [D loss: (0.620)(R 0.574, F 0.666)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.042] [G acc: 0.109]\n",
      "767 [D loss: (0.533)(R 0.492, F 0.574)] [D acc: (0.797)(0.781, 0.812)] [G loss: 1.118] [G acc: 0.062]\n",
      "768 [D loss: (0.626)(R 0.503, F 0.750)] [D acc: (0.672)(0.688, 0.656)] [G loss: 1.142] [G acc: 0.062]\n",
      "769 [D loss: (0.628)(R 0.661, F 0.595)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.129] [G acc: 0.125]\n",
      "770 [D loss: (0.605)(R 0.643, F 0.566)] [D acc: (0.664)(0.516, 0.812)] [G loss: 1.040] [G acc: 0.094]\n",
      "771 [D loss: (0.564)(R 0.499, F 0.629)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.110] [G acc: 0.125]\n",
      "772 [D loss: (0.666)(R 0.595, F 0.737)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.073] [G acc: 0.047]\n",
      "773 [D loss: (0.591)(R 0.572, F 0.609)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.093] [G acc: 0.094]\n",
      "774 [D loss: (0.611)(R 0.645, F 0.577)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.080] [G acc: 0.062]\n",
      "775 [D loss: (0.546)(R 0.526, F 0.567)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.127] [G acc: 0.125]\n",
      "776 [D loss: (0.570)(R 0.586, F 0.554)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.106] [G acc: 0.156]\n",
      "777 [D loss: (0.550)(R 0.489, F 0.610)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.111] [G acc: 0.094]\n",
      "778 [D loss: (0.643)(R 0.586, F 0.700)] [D acc: (0.594)(0.609, 0.578)] [G loss: 1.068] [G acc: 0.203]\n",
      "779 [D loss: (0.579)(R 0.571, F 0.586)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.076] [G acc: 0.156]\n",
      "780 [D loss: (0.632)(R 0.554, F 0.710)] [D acc: (0.633)(0.672, 0.594)] [G loss: 1.148] [G acc: 0.094]\n",
      "781 [D loss: (0.620)(R 0.617, F 0.623)] [D acc: (0.648)(0.609, 0.688)] [G loss: 0.979] [G acc: 0.141]\n",
      "782 [D loss: (0.530)(R 0.475, F 0.586)] [D acc: (0.758)(0.781, 0.734)] [G loss: 1.132] [G acc: 0.109]\n",
      "783 [D loss: (0.727)(R 0.647, F 0.806)] [D acc: (0.578)(0.562, 0.594)] [G loss: 1.092] [G acc: 0.094]\n",
      "784 [D loss: (0.620)(R 0.670, F 0.570)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.117] [G acc: 0.109]\n",
      "785 [D loss: (0.581)(R 0.608, F 0.553)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.042] [G acc: 0.141]\n",
      "786 [D loss: (0.604)(R 0.540, F 0.667)] [D acc: (0.641)(0.656, 0.625)] [G loss: 1.082] [G acc: 0.109]\n",
      "787 [D loss: (0.623)(R 0.656, F 0.589)] [D acc: (0.641)(0.562, 0.719)] [G loss: 0.983] [G acc: 0.156]\n",
      "788 [D loss: (0.619)(R 0.575, F 0.662)] [D acc: (0.625)(0.578, 0.672)] [G loss: 1.046] [G acc: 0.125]\n",
      "789 [D loss: (0.610)(R 0.606, F 0.615)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.070] [G acc: 0.078]\n",
      "790 [D loss: (0.619)(R 0.614, F 0.625)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.027] [G acc: 0.172]\n",
      "791 [D loss: (0.602)(R 0.532, F 0.672)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.068] [G acc: 0.141]\n",
      "792 [D loss: (0.607)(R 0.645, F 0.569)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.033] [G acc: 0.078]\n",
      "793 [D loss: (0.625)(R 0.689, F 0.561)] [D acc: (0.633)(0.516, 0.750)] [G loss: 1.102] [G acc: 0.078]\n",
      "794 [D loss: (0.567)(R 0.533, F 0.601)] [D acc: (0.734)(0.750, 0.719)] [G loss: 1.008] [G acc: 0.125]\n",
      "795 [D loss: (0.581)(R 0.567, F 0.595)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.062] [G acc: 0.156]\n",
      "796 [D loss: (0.630)(R 0.528, F 0.732)] [D acc: (0.625)(0.656, 0.594)] [G loss: 1.032] [G acc: 0.109]\n",
      "797 [D loss: (0.538)(R 0.558, F 0.519)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.124] [G acc: 0.156]\n",
      "798 [D loss: (0.593)(R 0.545, F 0.641)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.015] [G acc: 0.156]\n",
      "799 [D loss: (0.680)(R 0.654, F 0.705)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.000] [G acc: 0.141]\n",
      "800 [D loss: (0.589)(R 0.600, F 0.578)] [D acc: (0.750)(0.672, 0.828)] [G loss: 0.996] [G acc: 0.109]\n",
      "801 [D loss: (0.613)(R 0.531, F 0.695)] [D acc: (0.641)(0.672, 0.609)] [G loss: 1.096] [G acc: 0.141]\n",
      "802 [D loss: (0.591)(R 0.530, F 0.652)] [D acc: (0.680)(0.672, 0.688)] [G loss: 0.999] [G acc: 0.172]\n",
      "803 [D loss: (0.583)(R 0.590, F 0.577)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.067] [G acc: 0.125]\n",
      "804 [D loss: (0.634)(R 0.626, F 0.642)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.070] [G acc: 0.109]\n",
      "805 [D loss: (0.663)(R 0.689, F 0.637)] [D acc: (0.578)(0.484, 0.672)] [G loss: 1.062] [G acc: 0.094]\n",
      "806 [D loss: (0.605)(R 0.669, F 0.542)] [D acc: (0.641)(0.469, 0.812)] [G loss: 1.025] [G acc: 0.219]\n",
      "807 [D loss: (0.627)(R 0.656, F 0.598)] [D acc: (0.641)(0.516, 0.766)] [G loss: 1.011] [G acc: 0.156]\n",
      "808 [D loss: (0.618)(R 0.661, F 0.576)] [D acc: (0.703)(0.625, 0.781)] [G loss: 0.989] [G acc: 0.203]\n",
      "809 [D loss: (0.686)(R 0.644, F 0.727)] [D acc: (0.641)(0.578, 0.703)] [G loss: 0.994] [G acc: 0.156]\n",
      "810 [D loss: (0.603)(R 0.628, F 0.578)] [D acc: (0.688)(0.578, 0.797)] [G loss: 0.982] [G acc: 0.141]\n",
      "811 [D loss: (0.615)(R 0.495, F 0.734)] [D acc: (0.680)(0.719, 0.641)] [G loss: 0.986] [G acc: 0.156]\n",
      "812 [D loss: (0.612)(R 0.605, F 0.620)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.003] [G acc: 0.078]\n",
      "813 [D loss: (0.622)(R 0.597, F 0.647)] [D acc: (0.633)(0.531, 0.734)] [G loss: 0.985] [G acc: 0.172]\n",
      "814 [D loss: (0.636)(R 0.664, F 0.607)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.003] [G acc: 0.094]\n",
      "815 [D loss: (0.611)(R 0.545, F 0.676)] [D acc: (0.734)(0.750, 0.719)] [G loss: 0.964] [G acc: 0.188]\n",
      "816 [D loss: (0.604)(R 0.576, F 0.632)] [D acc: (0.680)(0.641, 0.719)] [G loss: 0.998] [G acc: 0.125]\n",
      "817 [D loss: (0.620)(R 0.644, F 0.595)] [D acc: (0.586)(0.484, 0.688)] [G loss: 1.002] [G acc: 0.141]\n",
      "818 [D loss: (0.622)(R 0.676, F 0.567)] [D acc: (0.641)(0.516, 0.766)] [G loss: 1.032] [G acc: 0.094]\n",
      "819 [D loss: (0.583)(R 0.595, F 0.571)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.026] [G acc: 0.172]\n",
      "820 [D loss: (0.653)(R 0.629, F 0.676)] [D acc: (0.594)(0.531, 0.656)] [G loss: 0.987] [G acc: 0.156]\n",
      "821 [D loss: (0.600)(R 0.466, F 0.733)] [D acc: (0.680)(0.781, 0.578)] [G loss: 1.086] [G acc: 0.078]\n",
      "822 [D loss: (0.593)(R 0.591, F 0.595)] [D acc: (0.648)(0.547, 0.750)] [G loss: 0.979] [G acc: 0.109]\n",
      "823 [D loss: (0.599)(R 0.673, F 0.525)] [D acc: (0.734)(0.562, 0.906)] [G loss: 1.010] [G acc: 0.188]\n",
      "824 [D loss: (0.587)(R 0.498, F 0.675)] [D acc: (0.672)(0.719, 0.625)] [G loss: 1.123] [G acc: 0.109]\n",
      "825 [D loss: (0.627)(R 0.614, F 0.640)] [D acc: (0.602)(0.516, 0.688)] [G loss: 1.022] [G acc: 0.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826 [D loss: (0.600)(R 0.548, F 0.652)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.038] [G acc: 0.172]\n",
      "827 [D loss: (0.546)(R 0.509, F 0.583)] [D acc: (0.727)(0.688, 0.766)] [G loss: 0.962] [G acc: 0.188]\n",
      "828 [D loss: (0.573)(R 0.482, F 0.664)] [D acc: (0.664)(0.688, 0.641)] [G loss: 1.019] [G acc: 0.188]\n",
      "829 [D loss: (0.600)(R 0.544, F 0.656)] [D acc: (0.672)(0.703, 0.641)] [G loss: 1.039] [G acc: 0.141]\n",
      "830 [D loss: (0.622)(R 0.581, F 0.662)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.081] [G acc: 0.094]\n",
      "831 [D loss: (0.621)(R 0.627, F 0.615)] [D acc: (0.633)(0.547, 0.719)] [G loss: 1.073] [G acc: 0.094]\n",
      "832 [D loss: (0.573)(R 0.591, F 0.555)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.083] [G acc: 0.062]\n",
      "833 [D loss: (0.604)(R 0.542, F 0.665)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.056] [G acc: 0.141]\n",
      "834 [D loss: (0.657)(R 0.666, F 0.648)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.083] [G acc: 0.047]\n",
      "835 [D loss: (0.608)(R 0.568, F 0.648)] [D acc: (0.672)(0.688, 0.656)] [G loss: 1.062] [G acc: 0.109]\n",
      "836 [D loss: (0.615)(R 0.661, F 0.569)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.083] [G acc: 0.078]\n",
      "837 [D loss: (0.586)(R 0.569, F 0.603)] [D acc: (0.656)(0.656, 0.656)] [G loss: 1.096] [G acc: 0.141]\n",
      "838 [D loss: (0.639)(R 0.559, F 0.720)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.124] [G acc: 0.062]\n",
      "839 [D loss: (0.616)(R 0.591, F 0.641)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.058] [G acc: 0.094]\n",
      "840 [D loss: (0.565)(R 0.539, F 0.590)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.054] [G acc: 0.141]\n",
      "841 [D loss: (0.626)(R 0.614, F 0.637)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.098] [G acc: 0.109]\n",
      "842 [D loss: (0.564)(R 0.550, F 0.578)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.039] [G acc: 0.141]\n",
      "843 [D loss: (0.647)(R 0.620, F 0.674)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.038] [G acc: 0.141]\n",
      "844 [D loss: (0.615)(R 0.557, F 0.673)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.074] [G acc: 0.141]\n",
      "845 [D loss: (0.627)(R 0.605, F 0.649)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.109] [G acc: 0.109]\n",
      "846 [D loss: (0.565)(R 0.591, F 0.539)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.040] [G acc: 0.203]\n",
      "847 [D loss: (0.599)(R 0.620, F 0.578)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.008] [G acc: 0.125]\n",
      "848 [D loss: (0.589)(R 0.507, F 0.672)] [D acc: (0.672)(0.703, 0.641)] [G loss: 1.031] [G acc: 0.172]\n",
      "849 [D loss: (0.616)(R 0.559, F 0.674)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.074] [G acc: 0.203]\n",
      "850 [D loss: (0.635)(R 0.656, F 0.615)] [D acc: (0.609)(0.516, 0.703)] [G loss: 0.994] [G acc: 0.219]\n",
      "851 [D loss: (0.657)(R 0.607, F 0.707)] [D acc: (0.625)(0.609, 0.641)] [G loss: 1.101] [G acc: 0.078]\n",
      "852 [D loss: (0.652)(R 0.672, F 0.631)] [D acc: (0.602)(0.516, 0.688)] [G loss: 1.019] [G acc: 0.141]\n",
      "853 [D loss: (0.613)(R 0.687, F 0.539)] [D acc: (0.656)(0.516, 0.797)] [G loss: 1.000] [G acc: 0.141]\n",
      "854 [D loss: (0.600)(R 0.585, F 0.614)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.096] [G acc: 0.062]\n",
      "855 [D loss: (0.622)(R 0.546, F 0.698)] [D acc: (0.641)(0.641, 0.641)] [G loss: 1.085] [G acc: 0.125]\n",
      "856 [D loss: (0.563)(R 0.590, F 0.535)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.087] [G acc: 0.109]\n",
      "857 [D loss: (0.586)(R 0.468, F 0.704)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.153] [G acc: 0.078]\n",
      "858 [D loss: (0.608)(R 0.609, F 0.607)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.111] [G acc: 0.141]\n",
      "859 [D loss: (0.632)(R 0.670, F 0.594)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.031] [G acc: 0.141]\n",
      "860 [D loss: (0.621)(R 0.577, F 0.665)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.080] [G acc: 0.094]\n",
      "861 [D loss: (0.596)(R 0.521, F 0.671)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.076] [G acc: 0.062]\n",
      "862 [D loss: (0.574)(R 0.551, F 0.597)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.036] [G acc: 0.219]\n",
      "863 [D loss: (0.602)(R 0.606, F 0.598)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.137] [G acc: 0.125]\n",
      "864 [D loss: (0.594)(R 0.641, F 0.547)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.060] [G acc: 0.141]\n",
      "865 [D loss: (0.646)(R 0.584, F 0.708)] [D acc: (0.625)(0.656, 0.594)] [G loss: 1.085] [G acc: 0.141]\n",
      "866 [D loss: (0.566)(R 0.567, F 0.565)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.045] [G acc: 0.156]\n",
      "867 [D loss: (0.589)(R 0.559, F 0.619)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.129] [G acc: 0.125]\n",
      "868 [D loss: (0.648)(R 0.644, F 0.652)] [D acc: (0.594)(0.484, 0.703)] [G loss: 1.025] [G acc: 0.203]\n",
      "869 [D loss: (0.581)(R 0.580, F 0.582)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.135] [G acc: 0.078]\n",
      "870 [D loss: (0.578)(R 0.533, F 0.623)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.107] [G acc: 0.062]\n",
      "871 [D loss: (0.605)(R 0.568, F 0.642)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.141] [G acc: 0.047]\n",
      "872 [D loss: (0.626)(R 0.623, F 0.629)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.115] [G acc: 0.062]\n",
      "873 [D loss: (0.551)(R 0.507, F 0.595)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.136] [G acc: 0.094]\n",
      "874 [D loss: (0.605)(R 0.596, F 0.613)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.127] [G acc: 0.031]\n",
      "875 [D loss: (0.591)(R 0.621, F 0.560)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.069] [G acc: 0.125]\n",
      "876 [D loss: (0.566)(R 0.548, F 0.583)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.135] [G acc: 0.094]\n",
      "877 [D loss: (0.601)(R 0.584, F 0.619)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.021] [G acc: 0.156]\n",
      "878 [D loss: (0.639)(R 0.593, F 0.685)] [D acc: (0.641)(0.562, 0.719)] [G loss: 1.159] [G acc: 0.094]\n",
      "879 [D loss: (0.569)(R 0.660, F 0.478)] [D acc: (0.727)(0.547, 0.906)] [G loss: 0.997] [G acc: 0.172]\n",
      "880 [D loss: (0.678)(R 0.610, F 0.746)] [D acc: (0.609)(0.594, 0.625)] [G loss: 1.054] [G acc: 0.062]\n",
      "881 [D loss: (0.602)(R 0.647, F 0.557)] [D acc: (0.672)(0.516, 0.828)] [G loss: 1.056] [G acc: 0.109]\n",
      "882 [D loss: (0.590)(R 0.517, F 0.662)] [D acc: (0.656)(0.719, 0.594)] [G loss: 1.090] [G acc: 0.078]\n",
      "883 [D loss: (0.571)(R 0.524, F 0.618)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.124] [G acc: 0.094]\n",
      "884 [D loss: (0.544)(R 0.495, F 0.593)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.094] [G acc: 0.094]\n",
      "885 [D loss: (0.603)(R 0.558, F 0.648)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.105] [G acc: 0.125]\n",
      "886 [D loss: (0.599)(R 0.584, F 0.613)] [D acc: (0.609)(0.562, 0.656)] [G loss: 1.075] [G acc: 0.125]\n",
      "887 [D loss: (0.538)(R 0.520, F 0.556)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.111] [G acc: 0.125]\n",
      "888 [D loss: (0.687)(R 0.632, F 0.742)] [D acc: (0.594)(0.562, 0.625)] [G loss: 1.035] [G acc: 0.109]\n",
      "889 [D loss: (0.620)(R 0.684, F 0.555)] [D acc: (0.648)(0.562, 0.734)] [G loss: 0.976] [G acc: 0.234]\n",
      "890 [D loss: (0.607)(R 0.647, F 0.566)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.023] [G acc: 0.203]\n",
      "891 [D loss: (0.574)(R 0.499, F 0.649)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.068] [G acc: 0.094]\n",
      "892 [D loss: (0.620)(R 0.576, F 0.664)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.000] [G acc: 0.234]\n",
      "893 [D loss: (0.612)(R 0.574, F 0.651)] [D acc: (0.617)(0.609, 0.625)] [G loss: 0.995] [G acc: 0.188]\n",
      "894 [D loss: (0.619)(R 0.568, F 0.669)] [D acc: (0.617)(0.578, 0.656)] [G loss: 1.075] [G acc: 0.141]\n",
      "895 [D loss: (0.558)(R 0.547, F 0.569)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.019] [G acc: 0.250]\n",
      "896 [D loss: (0.595)(R 0.552, F 0.638)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.023] [G acc: 0.172]\n",
      "897 [D loss: (0.601)(R 0.559, F 0.643)] [D acc: (0.625)(0.578, 0.672)] [G loss: 1.082] [G acc: 0.109]\n",
      "898 [D loss: (0.572)(R 0.605, F 0.538)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.140] [G acc: 0.094]\n",
      "899 [D loss: (0.567)(R 0.512, F 0.623)] [D acc: (0.773)(0.797, 0.750)] [G loss: 1.215] [G acc: 0.062]\n",
      "900 [D loss: (0.642)(R 0.584, F 0.699)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.126] [G acc: 0.062]\n",
      "901 [D loss: (0.574)(R 0.593, F 0.556)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.140] [G acc: 0.094]\n",
      "902 [D loss: (0.616)(R 0.540, F 0.692)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.173] [G acc: 0.109]\n",
      "903 [D loss: (0.595)(R 0.662, F 0.528)] [D acc: (0.656)(0.484, 0.828)] [G loss: 1.113] [G acc: 0.188]\n",
      "904 [D loss: (0.595)(R 0.570, F 0.621)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.040] [G acc: 0.219]\n",
      "905 [D loss: (0.636)(R 0.578, F 0.695)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.105] [G acc: 0.062]\n",
      "906 [D loss: (0.596)(R 0.579, F 0.612)] [D acc: (0.625)(0.562, 0.688)] [G loss: 1.004] [G acc: 0.125]\n",
      "907 [D loss: (0.640)(R 0.582, F 0.698)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.170] [G acc: 0.109]\n",
      "908 [D loss: (0.649)(R 0.731, F 0.568)] [D acc: (0.609)(0.422, 0.797)] [G loss: 1.005] [G acc: 0.156]\n",
      "909 [D loss: (0.598)(R 0.616, F 0.580)] [D acc: (0.703)(0.625, 0.781)] [G loss: 0.996] [G acc: 0.156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910 [D loss: (0.580)(R 0.562, F 0.598)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.037] [G acc: 0.250]\n",
      "911 [D loss: (0.577)(R 0.556, F 0.598)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.136] [G acc: 0.078]\n",
      "912 [D loss: (0.584)(R 0.473, F 0.695)] [D acc: (0.656)(0.688, 0.625)] [G loss: 1.099] [G acc: 0.125]\n",
      "913 [D loss: (0.636)(R 0.643, F 0.629)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.105] [G acc: 0.078]\n",
      "914 [D loss: (0.631)(R 0.532, F 0.730)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.094] [G acc: 0.172]\n",
      "915 [D loss: (0.626)(R 0.663, F 0.588)] [D acc: (0.641)(0.500, 0.781)] [G loss: 1.187] [G acc: 0.047]\n",
      "916 [D loss: (0.626)(R 0.673, F 0.579)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.141] [G acc: 0.109]\n",
      "917 [D loss: (0.597)(R 0.597, F 0.598)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.043] [G acc: 0.188]\n",
      "918 [D loss: (0.640)(R 0.534, F 0.746)] [D acc: (0.656)(0.656, 0.656)] [G loss: 1.059] [G acc: 0.141]\n",
      "919 [D loss: (0.587)(R 0.639, F 0.534)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.128] [G acc: 0.109]\n",
      "920 [D loss: (0.561)(R 0.616, F 0.506)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.076] [G acc: 0.188]\n",
      "921 [D loss: (0.633)(R 0.534, F 0.732)] [D acc: (0.641)(0.656, 0.625)] [G loss: 1.172] [G acc: 0.062]\n",
      "922 [D loss: (0.652)(R 0.693, F 0.612)] [D acc: (0.586)(0.484, 0.688)] [G loss: 1.063] [G acc: 0.125]\n",
      "923 [D loss: (0.618)(R 0.610, F 0.626)] [D acc: (0.625)(0.594, 0.656)] [G loss: 1.041] [G acc: 0.172]\n",
      "924 [D loss: (0.596)(R 0.615, F 0.578)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.081] [G acc: 0.203]\n",
      "925 [D loss: (0.634)(R 0.621, F 0.647)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.049] [G acc: 0.172]\n",
      "926 [D loss: (0.596)(R 0.593, F 0.599)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.171] [G acc: 0.109]\n",
      "927 [D loss: (0.590)(R 0.605, F 0.575)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.073] [G acc: 0.125]\n",
      "928 [D loss: (0.568)(R 0.621, F 0.515)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.147] [G acc: 0.156]\n",
      "929 [D loss: (0.543)(R 0.523, F 0.563)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.162] [G acc: 0.109]\n",
      "930 [D loss: (0.586)(R 0.527, F 0.644)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.086] [G acc: 0.141]\n",
      "931 [D loss: (0.574)(R 0.528, F 0.619)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.179] [G acc: 0.078]\n",
      "932 [D loss: (0.646)(R 0.674, F 0.618)] [D acc: (0.609)(0.531, 0.688)] [G loss: 1.237] [G acc: 0.094]\n",
      "933 [D loss: (0.578)(R 0.580, F 0.575)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.216] [G acc: 0.062]\n",
      "934 [D loss: (0.505)(R 0.559, F 0.452)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.347] [G acc: 0.031]\n",
      "935 [D loss: (0.571)(R 0.474, F 0.668)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.158] [G acc: 0.078]\n",
      "936 [D loss: (0.561)(R 0.572, F 0.551)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.197] [G acc: 0.078]\n",
      "937 [D loss: (0.581)(R 0.553, F 0.608)] [D acc: (0.633)(0.594, 0.672)] [G loss: 1.194] [G acc: 0.062]\n",
      "938 [D loss: (0.563)(R 0.547, F 0.580)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.144] [G acc: 0.141]\n",
      "939 [D loss: (0.563)(R 0.520, F 0.606)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.238] [G acc: 0.094]\n",
      "940 [D loss: (0.607)(R 0.593, F 0.621)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.090] [G acc: 0.094]\n",
      "941 [D loss: (0.640)(R 0.585, F 0.694)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.029] [G acc: 0.188]\n",
      "942 [D loss: (0.570)(R 0.535, F 0.604)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.197] [G acc: 0.094]\n",
      "943 [D loss: (0.550)(R 0.492, F 0.608)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.272] [G acc: 0.094]\n",
      "944 [D loss: (0.550)(R 0.557, F 0.543)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.257] [G acc: 0.078]\n",
      "945 [D loss: (0.551)(R 0.520, F 0.583)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.069] [G acc: 0.234]\n",
      "946 [D loss: (0.601)(R 0.601, F 0.601)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.247] [G acc: 0.078]\n",
      "947 [D loss: (0.607)(R 0.650, F 0.565)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.206] [G acc: 0.109]\n",
      "948 [D loss: (0.611)(R 0.573, F 0.648)] [D acc: (0.672)(0.703, 0.641)] [G loss: 1.158] [G acc: 0.078]\n",
      "949 [D loss: (0.659)(R 0.613, F 0.705)] [D acc: (0.617)(0.609, 0.625)] [G loss: 1.089] [G acc: 0.125]\n",
      "950 [D loss: (0.535)(R 0.595, F 0.475)] [D acc: (0.789)(0.672, 0.906)] [G loss: 1.174] [G acc: 0.125]\n",
      "951 [D loss: (0.541)(R 0.545, F 0.538)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.099] [G acc: 0.125]\n",
      "952 [D loss: (0.511)(R 0.473, F 0.550)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.113] [G acc: 0.141]\n",
      "953 [D loss: (0.595)(R 0.534, F 0.656)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.010] [G acc: 0.219]\n",
      "954 [D loss: (0.500)(R 0.446, F 0.554)] [D acc: (0.742)(0.781, 0.703)] [G loss: 1.094] [G acc: 0.219]\n",
      "955 [D loss: (0.635)(R 0.609, F 0.660)] [D acc: (0.633)(0.594, 0.672)] [G loss: 1.139] [G acc: 0.156]\n",
      "956 [D loss: (0.592)(R 0.585, F 0.599)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.166] [G acc: 0.094]\n",
      "957 [D loss: (0.557)(R 0.557, F 0.558)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.174] [G acc: 0.125]\n",
      "958 [D loss: (0.620)(R 0.536, F 0.705)] [D acc: (0.641)(0.656, 0.625)] [G loss: 1.113] [G acc: 0.172]\n",
      "959 [D loss: (0.536)(R 0.411, F 0.661)] [D acc: (0.750)(0.797, 0.703)] [G loss: 1.208] [G acc: 0.078]\n",
      "960 [D loss: (0.542)(R 0.489, F 0.594)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.195] [G acc: 0.109]\n",
      "961 [D loss: (0.571)(R 0.571, F 0.570)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.275] [G acc: 0.062]\n",
      "962 [D loss: (0.551)(R 0.607, F 0.495)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.123] [G acc: 0.125]\n",
      "963 [D loss: (0.670)(R 0.633, F 0.707)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.156] [G acc: 0.172]\n",
      "964 [D loss: (0.566)(R 0.566, F 0.565)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.238] [G acc: 0.047]\n",
      "965 [D loss: (0.581)(R 0.629, F 0.532)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.105] [G acc: 0.172]\n",
      "966 [D loss: (0.591)(R 0.561, F 0.621)] [D acc: (0.648)(0.641, 0.656)] [G loss: 1.146] [G acc: 0.141]\n",
      "967 [D loss: (0.466)(R 0.445, F 0.486)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.190] [G acc: 0.172]\n",
      "968 [D loss: (0.604)(R 0.518, F 0.690)] [D acc: (0.648)(0.656, 0.641)] [G loss: 1.196] [G acc: 0.109]\n",
      "969 [D loss: (0.627)(R 0.658, F 0.597)] [D acc: (0.664)(0.516, 0.812)] [G loss: 1.147] [G acc: 0.141]\n",
      "970 [D loss: (0.588)(R 0.596, F 0.580)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.097] [G acc: 0.125]\n",
      "971 [D loss: (0.543)(R 0.506, F 0.580)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.054] [G acc: 0.172]\n",
      "972 [D loss: (0.649)(R 0.584, F 0.714)] [D acc: (0.641)(0.672, 0.609)] [G loss: 1.185] [G acc: 0.078]\n",
      "973 [D loss: (0.578)(R 0.633, F 0.523)] [D acc: (0.672)(0.531, 0.812)] [G loss: 1.116] [G acc: 0.094]\n",
      "974 [D loss: (0.505)(R 0.485, F 0.525)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.194] [G acc: 0.125]\n",
      "975 [D loss: (0.594)(R 0.530, F 0.657)] [D acc: (0.641)(0.672, 0.609)] [G loss: 1.166] [G acc: 0.047]\n",
      "976 [D loss: (0.599)(R 0.572, F 0.627)] [D acc: (0.656)(0.656, 0.656)] [G loss: 1.099] [G acc: 0.188]\n",
      "977 [D loss: (0.629)(R 0.640, F 0.617)] [D acc: (0.633)(0.562, 0.703)] [G loss: 1.233] [G acc: 0.062]\n",
      "978 [D loss: (0.587)(R 0.621, F 0.554)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.155] [G acc: 0.094]\n",
      "979 [D loss: (0.610)(R 0.605, F 0.614)] [D acc: (0.641)(0.562, 0.719)] [G loss: 1.081] [G acc: 0.188]\n",
      "980 [D loss: (0.663)(R 0.592, F 0.733)] [D acc: (0.617)(0.609, 0.625)] [G loss: 1.156] [G acc: 0.062]\n",
      "981 [D loss: (0.559)(R 0.635, F 0.484)] [D acc: (0.758)(0.609, 0.906)] [G loss: 1.107] [G acc: 0.094]\n",
      "982 [D loss: (0.581)(R 0.548, F 0.614)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.065] [G acc: 0.141]\n",
      "983 [D loss: (0.595)(R 0.596, F 0.593)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.135] [G acc: 0.141]\n",
      "984 [D loss: (0.583)(R 0.584, F 0.582)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.064] [G acc: 0.156]\n",
      "985 [D loss: (0.550)(R 0.564, F 0.536)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.181] [G acc: 0.062]\n",
      "986 [D loss: (0.610)(R 0.580, F 0.639)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.141] [G acc: 0.078]\n",
      "987 [D loss: (0.586)(R 0.557, F 0.614)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.096] [G acc: 0.062]\n",
      "988 [D loss: (0.600)(R 0.565, F 0.636)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.176] [G acc: 0.078]\n",
      "989 [D loss: (0.542)(R 0.612, F 0.472)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.204] [G acc: 0.109]\n",
      "990 [D loss: (0.595)(R 0.518, F 0.673)] [D acc: (0.672)(0.688, 0.656)] [G loss: 1.208] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "991 [D loss: (0.566)(R 0.613, F 0.519)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.145] [G acc: 0.125]\n",
      "992 [D loss: (0.666)(R 0.646, F 0.685)] [D acc: (0.625)(0.578, 0.672)] [G loss: 1.099] [G acc: 0.141]\n",
      "993 [D loss: (0.638)(R 0.656, F 0.621)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.116] [G acc: 0.141]\n",
      "994 [D loss: (0.617)(R 0.569, F 0.665)] [D acc: (0.609)(0.609, 0.609)] [G loss: 1.207] [G acc: 0.078]\n",
      "995 [D loss: (0.646)(R 0.657, F 0.636)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.182] [G acc: 0.078]\n",
      "996 [D loss: (0.624)(R 0.703, F 0.545)] [D acc: (0.648)(0.516, 0.781)] [G loss: 1.094] [G acc: 0.047]\n",
      "997 [D loss: (0.573)(R 0.502, F 0.645)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.194] [G acc: 0.047]\n",
      "998 [D loss: (0.651)(R 0.680, F 0.621)] [D acc: (0.648)(0.531, 0.766)] [G loss: 1.217] [G acc: 0.047]\n",
      "999 [D loss: (0.600)(R 0.665, F 0.536)] [D acc: (0.633)(0.500, 0.766)] [G loss: 1.104] [G acc: 0.094]\n",
      "1000 [D loss: (0.565)(R 0.502, F 0.628)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.094] [G acc: 0.156]\n",
      "1001 [D loss: (0.627)(R 0.584, F 0.670)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.028] [G acc: 0.156]\n",
      "1002 [D loss: (0.552)(R 0.565, F 0.540)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.118] [G acc: 0.094]\n",
      "1003 [D loss: (0.620)(R 0.623, F 0.616)] [D acc: (0.664)(0.547, 0.781)] [G loss: 1.136] [G acc: 0.109]\n",
      "1004 [D loss: (0.533)(R 0.553, F 0.512)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.082] [G acc: 0.141]\n",
      "1005 [D loss: (0.580)(R 0.466, F 0.695)] [D acc: (0.695)(0.719, 0.672)] [G loss: 1.088] [G acc: 0.109]\n",
      "1006 [D loss: (0.623)(R 0.651, F 0.596)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.064] [G acc: 0.062]\n",
      "1007 [D loss: (0.637)(R 0.681, F 0.592)] [D acc: (0.594)(0.500, 0.688)] [G loss: 1.104] [G acc: 0.125]\n",
      "1008 [D loss: (0.560)(R 0.522, F 0.599)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.124] [G acc: 0.125]\n",
      "1009 [D loss: (0.539)(R 0.520, F 0.557)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.078] [G acc: 0.156]\n",
      "1010 [D loss: (0.630)(R 0.547, F 0.713)] [D acc: (0.672)(0.719, 0.625)] [G loss: 1.096] [G acc: 0.078]\n",
      "1011 [D loss: (0.555)(R 0.602, F 0.509)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.199] [G acc: 0.109]\n",
      "1012 [D loss: (0.574)(R 0.497, F 0.652)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.122] [G acc: 0.172]\n",
      "1013 [D loss: (0.574)(R 0.560, F 0.589)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.191] [G acc: 0.078]\n",
      "1014 [D loss: (0.636)(R 0.635, F 0.637)] [D acc: (0.617)(0.547, 0.688)] [G loss: 1.182] [G acc: 0.094]\n",
      "1015 [D loss: (0.618)(R 0.613, F 0.622)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.099] [G acc: 0.141]\n",
      "1016 [D loss: (0.547)(R 0.564, F 0.530)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.095] [G acc: 0.094]\n",
      "1017 [D loss: (0.530)(R 0.517, F 0.543)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.228] [G acc: 0.094]\n",
      "1018 [D loss: (0.618)(R 0.626, F 0.611)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.122] [G acc: 0.156]\n",
      "1019 [D loss: (0.505)(R 0.507, F 0.503)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.167] [G acc: 0.109]\n",
      "1020 [D loss: (0.537)(R 0.495, F 0.579)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.147] [G acc: 0.219]\n",
      "1021 [D loss: (0.632)(R 0.596, F 0.668)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.155] [G acc: 0.141]\n",
      "1022 [D loss: (0.593)(R 0.586, F 0.599)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.055] [G acc: 0.125]\n",
      "1023 [D loss: (0.638)(R 0.567, F 0.708)] [D acc: (0.555)(0.578, 0.531)] [G loss: 1.067] [G acc: 0.125]\n",
      "1024 [D loss: (0.550)(R 0.594, F 0.505)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.210] [G acc: 0.156]\n",
      "1025 [D loss: (0.554)(R 0.575, F 0.533)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.204] [G acc: 0.141]\n",
      "1026 [D loss: (0.677)(R 0.619, F 0.735)] [D acc: (0.594)(0.609, 0.578)] [G loss: 1.108] [G acc: 0.125]\n",
      "1027 [D loss: (0.585)(R 0.602, F 0.568)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.149] [G acc: 0.109]\n",
      "1028 [D loss: (0.566)(R 0.597, F 0.535)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.184] [G acc: 0.172]\n",
      "1029 [D loss: (0.573)(R 0.639, F 0.506)] [D acc: (0.656)(0.469, 0.844)] [G loss: 1.132] [G acc: 0.172]\n",
      "1030 [D loss: (0.534)(R 0.464, F 0.604)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.155] [G acc: 0.109]\n",
      "1031 [D loss: (0.545)(R 0.560, F 0.531)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.165] [G acc: 0.172]\n",
      "1032 [D loss: (0.640)(R 0.566, F 0.715)] [D acc: (0.648)(0.625, 0.672)] [G loss: 1.179] [G acc: 0.094]\n",
      "1033 [D loss: (0.577)(R 0.596, F 0.558)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.120] [G acc: 0.094]\n",
      "1034 [D loss: (0.603)(R 0.563, F 0.643)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.213] [G acc: 0.047]\n",
      "1035 [D loss: (0.556)(R 0.558, F 0.554)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.175] [G acc: 0.125]\n",
      "1036 [D loss: (0.601)(R 0.537, F 0.664)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.285] [G acc: 0.016]\n",
      "1037 [D loss: (0.631)(R 0.591, F 0.672)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.100] [G acc: 0.094]\n",
      "1038 [D loss: (0.612)(R 0.609, F 0.615)] [D acc: (0.617)(0.578, 0.656)] [G loss: 1.050] [G acc: 0.125]\n",
      "1039 [D loss: (0.588)(R 0.618, F 0.558)] [D acc: (0.648)(0.531, 0.766)] [G loss: 1.092] [G acc: 0.094]\n",
      "1040 [D loss: (0.579)(R 0.600, F 0.559)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.109] [G acc: 0.125]\n",
      "1041 [D loss: (0.547)(R 0.469, F 0.625)] [D acc: (0.750)(0.797, 0.703)] [G loss: 1.246] [G acc: 0.172]\n",
      "1042 [D loss: (0.696)(R 0.699, F 0.693)] [D acc: (0.617)(0.578, 0.656)] [G loss: 1.071] [G acc: 0.188]\n",
      "1043 [D loss: (0.585)(R 0.577, F 0.593)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.111] [G acc: 0.141]\n",
      "1044 [D loss: (0.551)(R 0.515, F 0.587)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.143] [G acc: 0.172]\n",
      "1045 [D loss: (0.548)(R 0.492, F 0.604)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.173] [G acc: 0.062]\n",
      "1046 [D loss: (0.590)(R 0.568, F 0.613)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.177] [G acc: 0.078]\n",
      "1047 [D loss: (0.542)(R 0.609, F 0.475)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.215] [G acc: 0.094]\n",
      "1048 [D loss: (0.528)(R 0.537, F 0.518)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.156] [G acc: 0.141]\n",
      "1049 [D loss: (0.604)(R 0.620, F 0.588)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.171] [G acc: 0.094]\n",
      "1050 [D loss: (0.585)(R 0.543, F 0.627)] [D acc: (0.633)(0.562, 0.703)] [G loss: 1.140] [G acc: 0.156]\n",
      "1051 [D loss: (0.593)(R 0.642, F 0.545)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.137] [G acc: 0.125]\n",
      "1052 [D loss: (0.565)(R 0.576, F 0.554)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.151] [G acc: 0.125]\n",
      "1053 [D loss: (0.639)(R 0.612, F 0.665)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.132] [G acc: 0.109]\n",
      "1054 [D loss: (0.547)(R 0.576, F 0.517)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.296] [G acc: 0.062]\n",
      "1055 [D loss: (0.649)(R 0.607, F 0.690)] [D acc: (0.625)(0.578, 0.672)] [G loss: 1.120] [G acc: 0.109]\n",
      "1056 [D loss: (0.602)(R 0.677, F 0.527)] [D acc: (0.664)(0.547, 0.781)] [G loss: 1.203] [G acc: 0.125]\n",
      "1057 [D loss: (0.582)(R 0.627, F 0.537)] [D acc: (0.648)(0.531, 0.766)] [G loss: 1.192] [G acc: 0.062]\n",
      "1058 [D loss: (0.587)(R 0.568, F 0.607)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.277] [G acc: 0.078]\n",
      "1059 [D loss: (0.588)(R 0.546, F 0.631)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.203] [G acc: 0.078]\n",
      "1060 [D loss: (0.466)(R 0.436, F 0.496)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.178] [G acc: 0.125]\n",
      "1061 [D loss: (0.584)(R 0.522, F 0.646)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.326] [G acc: 0.094]\n",
      "1062 [D loss: (0.550)(R 0.585, F 0.516)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.199] [G acc: 0.062]\n",
      "1063 [D loss: (0.645)(R 0.562, F 0.728)] [D acc: (0.617)(0.609, 0.625)] [G loss: 1.113] [G acc: 0.094]\n",
      "1064 [D loss: (0.553)(R 0.577, F 0.530)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.201] [G acc: 0.109]\n",
      "1065 [D loss: (0.525)(R 0.470, F 0.580)] [D acc: (0.742)(0.766, 0.719)] [G loss: 1.223] [G acc: 0.125]\n",
      "1066 [D loss: (0.590)(R 0.595, F 0.585)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.146] [G acc: 0.188]\n",
      "1067 [D loss: (0.576)(R 0.575, F 0.578)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.180] [G acc: 0.078]\n",
      "1068 [D loss: (0.595)(R 0.615, F 0.575)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.158] [G acc: 0.156]\n",
      "1069 [D loss: (0.666)(R 0.569, F 0.763)] [D acc: (0.625)(0.672, 0.578)] [G loss: 1.153] [G acc: 0.094]\n",
      "1070 [D loss: (0.561)(R 0.556, F 0.566)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.130] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1071 [D loss: (0.581)(R 0.567, F 0.594)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.303] [G acc: 0.109]\n",
      "1072 [D loss: (0.544)(R 0.524, F 0.564)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.114] [G acc: 0.172]\n",
      "1073 [D loss: (0.576)(R 0.520, F 0.632)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.098] [G acc: 0.172]\n",
      "1074 [D loss: (0.480)(R 0.507, F 0.453)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.139] [G acc: 0.109]\n",
      "1075 [D loss: (0.538)(R 0.452, F 0.625)] [D acc: (0.727)(0.766, 0.688)] [G loss: 1.245] [G acc: 0.109]\n",
      "1076 [D loss: (0.592)(R 0.566, F 0.619)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.269] [G acc: 0.109]\n",
      "1077 [D loss: (0.516)(R 0.472, F 0.560)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.301] [G acc: 0.062]\n",
      "1078 [D loss: (0.608)(R 0.595, F 0.620)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.272] [G acc: 0.203]\n",
      "1079 [D loss: (0.588)(R 0.595, F 0.581)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.219] [G acc: 0.172]\n",
      "1080 [D loss: (0.589)(R 0.564, F 0.614)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.222] [G acc: 0.172]\n",
      "1081 [D loss: (0.547)(R 0.583, F 0.511)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.225] [G acc: 0.141]\n",
      "1082 [D loss: (0.557)(R 0.544, F 0.570)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.352] [G acc: 0.078]\n",
      "1083 [D loss: (0.581)(R 0.589, F 0.572)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.134] [G acc: 0.141]\n",
      "1084 [D loss: (0.554)(R 0.505, F 0.604)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.235] [G acc: 0.125]\n",
      "1085 [D loss: (0.607)(R 0.535, F 0.679)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.220] [G acc: 0.109]\n",
      "1086 [D loss: (0.613)(R 0.519, F 0.708)] [D acc: (0.680)(0.688, 0.672)] [G loss: 1.296] [G acc: 0.078]\n",
      "1087 [D loss: (0.544)(R 0.616, F 0.472)] [D acc: (0.750)(0.594, 0.906)] [G loss: 1.182] [G acc: 0.062]\n",
      "1088 [D loss: (0.526)(R 0.530, F 0.522)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.069] [G acc: 0.234]\n",
      "1089 [D loss: (0.509)(R 0.437, F 0.581)] [D acc: (0.750)(0.797, 0.703)] [G loss: 1.186] [G acc: 0.141]\n",
      "1090 [D loss: (0.606)(R 0.667, F 0.545)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.123] [G acc: 0.141]\n",
      "1091 [D loss: (0.581)(R 0.545, F 0.618)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.242] [G acc: 0.125]\n",
      "1092 [D loss: (0.530)(R 0.538, F 0.521)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.277] [G acc: 0.109]\n",
      "1093 [D loss: (0.602)(R 0.557, F 0.646)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.217] [G acc: 0.172]\n",
      "1094 [D loss: (0.563)(R 0.540, F 0.586)] [D acc: (0.695)(0.719, 0.672)] [G loss: 1.248] [G acc: 0.125]\n",
      "1095 [D loss: (0.591)(R 0.578, F 0.605)] [D acc: (0.641)(0.625, 0.656)] [G loss: 1.209] [G acc: 0.109]\n",
      "1096 [D loss: (0.574)(R 0.630, F 0.519)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.222] [G acc: 0.094]\n",
      "1097 [D loss: (0.580)(R 0.584, F 0.576)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.160] [G acc: 0.172]\n",
      "1098 [D loss: (0.563)(R 0.576, F 0.550)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.186] [G acc: 0.094]\n",
      "1099 [D loss: (0.504)(R 0.466, F 0.542)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.271] [G acc: 0.109]\n",
      "1100 [D loss: (0.556)(R 0.614, F 0.498)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.276] [G acc: 0.078]\n",
      "1101 [D loss: (0.624)(R 0.599, F 0.650)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.196] [G acc: 0.109]\n",
      "1102 [D loss: (0.579)(R 0.575, F 0.583)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.241] [G acc: 0.125]\n",
      "1103 [D loss: (0.560)(R 0.559, F 0.561)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.143] [G acc: 0.156]\n",
      "1104 [D loss: (0.580)(R 0.574, F 0.586)] [D acc: (0.648)(0.625, 0.672)] [G loss: 1.260] [G acc: 0.062]\n",
      "1105 [D loss: (0.498)(R 0.473, F 0.523)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.285] [G acc: 0.141]\n",
      "1106 [D loss: (0.566)(R 0.604, F 0.528)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.191] [G acc: 0.109]\n",
      "1107 [D loss: (0.539)(R 0.483, F 0.595)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.211] [G acc: 0.156]\n",
      "1108 [D loss: (0.616)(R 0.660, F 0.571)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.039] [G acc: 0.234]\n",
      "1109 [D loss: (0.569)(R 0.561, F 0.578)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.027] [G acc: 0.172]\n",
      "1110 [D loss: (0.589)(R 0.602, F 0.576)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.131] [G acc: 0.172]\n",
      "1111 [D loss: (0.551)(R 0.541, F 0.561)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.189] [G acc: 0.094]\n",
      "1112 [D loss: (0.646)(R 0.643, F 0.649)] [D acc: (0.570)(0.500, 0.641)] [G loss: 1.132] [G acc: 0.109]\n",
      "1113 [D loss: (0.651)(R 0.719, F 0.584)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.047] [G acc: 0.188]\n",
      "1114 [D loss: (0.509)(R 0.513, F 0.505)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.104] [G acc: 0.156]\n",
      "1115 [D loss: (0.603)(R 0.553, F 0.654)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.175] [G acc: 0.125]\n",
      "1116 [D loss: (0.535)(R 0.539, F 0.531)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.099] [G acc: 0.234]\n",
      "1117 [D loss: (0.632)(R 0.625, F 0.639)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.104] [G acc: 0.172]\n",
      "1118 [D loss: (0.542)(R 0.475, F 0.608)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.076] [G acc: 0.156]\n",
      "1119 [D loss: (0.570)(R 0.529, F 0.612)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.194] [G acc: 0.109]\n",
      "1120 [D loss: (0.601)(R 0.566, F 0.637)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.183] [G acc: 0.125]\n",
      "1121 [D loss: (0.629)(R 0.653, F 0.604)] [D acc: (0.633)(0.531, 0.734)] [G loss: 1.256] [G acc: 0.031]\n",
      "1122 [D loss: (0.569)(R 0.626, F 0.512)] [D acc: (0.711)(0.531, 0.891)] [G loss: 1.141] [G acc: 0.141]\n",
      "1123 [D loss: (0.524)(R 0.543, F 0.506)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.117] [G acc: 0.141]\n",
      "1124 [D loss: (0.695)(R 0.585, F 0.805)] [D acc: (0.609)(0.594, 0.625)] [G loss: 1.161] [G acc: 0.062]\n",
      "1125 [D loss: (0.562)(R 0.653, F 0.472)] [D acc: (0.719)(0.516, 0.922)] [G loss: 1.130] [G acc: 0.125]\n",
      "1126 [D loss: (0.541)(R 0.586, F 0.495)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.056] [G acc: 0.172]\n",
      "1127 [D loss: (0.590)(R 0.541, F 0.638)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.082] [G acc: 0.141]\n",
      "1128 [D loss: (0.584)(R 0.570, F 0.597)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.268] [G acc: 0.047]\n",
      "1129 [D loss: (0.582)(R 0.599, F 0.564)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.135] [G acc: 0.094]\n",
      "1130 [D loss: (0.569)(R 0.587, F 0.550)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.177] [G acc: 0.078]\n",
      "1131 [D loss: (0.567)(R 0.455, F 0.678)] [D acc: (0.797)(0.812, 0.781)] [G loss: 1.271] [G acc: 0.062]\n",
      "1132 [D loss: (0.558)(R 0.569, F 0.548)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.219] [G acc: 0.109]\n",
      "1133 [D loss: (0.524)(R 0.483, F 0.564)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.223] [G acc: 0.109]\n",
      "1134 [D loss: (0.562)(R 0.506, F 0.617)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.198] [G acc: 0.125]\n",
      "1135 [D loss: (0.567)(R 0.557, F 0.578)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.059] [G acc: 0.219]\n",
      "1136 [D loss: (0.596)(R 0.514, F 0.679)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.230] [G acc: 0.094]\n",
      "1137 [D loss: (0.599)(R 0.624, F 0.573)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.146] [G acc: 0.156]\n",
      "1138 [D loss: (0.584)(R 0.607, F 0.561)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.056] [G acc: 0.125]\n",
      "1139 [D loss: (0.507)(R 0.472, F 0.542)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.179] [G acc: 0.125]\n",
      "1140 [D loss: (0.558)(R 0.487, F 0.629)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.168] [G acc: 0.141]\n",
      "1141 [D loss: (0.618)(R 0.634, F 0.602)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.247] [G acc: 0.047]\n",
      "1142 [D loss: (0.632)(R 0.707, F 0.557)] [D acc: (0.633)(0.484, 0.781)] [G loss: 1.149] [G acc: 0.141]\n",
      "1143 [D loss: (0.576)(R 0.546, F 0.607)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.161] [G acc: 0.062]\n",
      "1144 [D loss: (0.557)(R 0.602, F 0.512)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.181] [G acc: 0.062]\n",
      "1145 [D loss: (0.565)(R 0.544, F 0.587)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.257] [G acc: 0.062]\n",
      "1146 [D loss: (0.529)(R 0.585, F 0.472)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.174] [G acc: 0.109]\n",
      "1147 [D loss: (0.525)(R 0.515, F 0.535)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.168] [G acc: 0.125]\n",
      "1148 [D loss: (0.587)(R 0.573, F 0.602)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.180] [G acc: 0.125]\n",
      "1149 [D loss: (0.539)(R 0.474, F 0.605)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.326] [G acc: 0.062]\n",
      "1150 [D loss: (0.628)(R 0.650, F 0.606)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.326] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151 [D loss: (0.586)(R 0.647, F 0.524)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.243] [G acc: 0.109]\n",
      "1152 [D loss: (0.560)(R 0.570, F 0.550)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.219] [G acc: 0.062]\n",
      "1153 [D loss: (0.600)(R 0.614, F 0.586)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.208] [G acc: 0.125]\n",
      "1154 [D loss: (0.589)(R 0.662, F 0.515)] [D acc: (0.703)(0.516, 0.891)] [G loss: 1.214] [G acc: 0.109]\n",
      "1155 [D loss: (0.567)(R 0.462, F 0.672)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.222] [G acc: 0.016]\n",
      "1156 [D loss: (0.627)(R 0.631, F 0.622)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.231] [G acc: 0.094]\n",
      "1157 [D loss: (0.615)(R 0.653, F 0.576)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.161] [G acc: 0.047]\n",
      "1158 [D loss: (0.519)(R 0.518, F 0.521)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.181] [G acc: 0.125]\n",
      "1159 [D loss: (0.631)(R 0.689, F 0.574)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.059] [G acc: 0.172]\n",
      "1160 [D loss: (0.554)(R 0.543, F 0.565)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.190] [G acc: 0.109]\n",
      "1161 [D loss: (0.546)(R 0.532, F 0.560)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.199] [G acc: 0.078]\n",
      "1162 [D loss: (0.537)(R 0.455, F 0.618)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.260] [G acc: 0.062]\n",
      "1163 [D loss: (0.580)(R 0.594, F 0.566)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.181] [G acc: 0.125]\n",
      "1164 [D loss: (0.583)(R 0.602, F 0.564)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.209] [G acc: 0.078]\n",
      "1165 [D loss: (0.521)(R 0.495, F 0.548)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.281] [G acc: 0.078]\n",
      "1166 [D loss: (0.552)(R 0.561, F 0.542)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.172] [G acc: 0.141]\n",
      "1167 [D loss: (0.554)(R 0.479, F 0.630)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.180] [G acc: 0.062]\n",
      "1168 [D loss: (0.599)(R 0.592, F 0.606)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.162] [G acc: 0.109]\n",
      "1169 [D loss: (0.584)(R 0.589, F 0.579)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.146] [G acc: 0.094]\n",
      "1170 [D loss: (0.572)(R 0.609, F 0.535)] [D acc: (0.664)(0.547, 0.781)] [G loss: 1.279] [G acc: 0.078]\n",
      "1171 [D loss: (0.528)(R 0.525, F 0.530)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.205] [G acc: 0.109]\n",
      "1172 [D loss: (0.571)(R 0.529, F 0.613)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.205] [G acc: 0.125]\n",
      "1173 [D loss: (0.570)(R 0.599, F 0.542)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.173] [G acc: 0.109]\n",
      "1174 [D loss: (0.646)(R 0.636, F 0.656)] [D acc: (0.633)(0.594, 0.672)] [G loss: 1.228] [G acc: 0.109]\n",
      "1175 [D loss: (0.469)(R 0.486, F 0.451)] [D acc: (0.797)(0.703, 0.891)] [G loss: 1.250] [G acc: 0.109]\n",
      "1176 [D loss: (0.717)(R 0.639, F 0.795)] [D acc: (0.609)(0.594, 0.625)] [G loss: 1.083] [G acc: 0.125]\n",
      "1177 [D loss: (0.546)(R 0.519, F 0.573)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.187] [G acc: 0.125]\n",
      "1178 [D loss: (0.569)(R 0.534, F 0.604)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.112] [G acc: 0.188]\n",
      "1179 [D loss: (0.602)(R 0.669, F 0.534)] [D acc: (0.648)(0.500, 0.797)] [G loss: 1.171] [G acc: 0.078]\n",
      "1180 [D loss: (0.553)(R 0.585, F 0.521)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.145] [G acc: 0.094]\n",
      "1181 [D loss: (0.615)(R 0.656, F 0.574)] [D acc: (0.641)(0.469, 0.812)] [G loss: 1.187] [G acc: 0.078]\n",
      "1182 [D loss: (0.577)(R 0.644, F 0.510)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.192] [G acc: 0.094]\n",
      "1183 [D loss: (0.507)(R 0.439, F 0.575)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.229] [G acc: 0.078]\n",
      "1184 [D loss: (0.591)(R 0.524, F 0.657)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.294] [G acc: 0.094]\n",
      "1185 [D loss: (0.614)(R 0.608, F 0.621)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.184] [G acc: 0.094]\n",
      "1186 [D loss: (0.523)(R 0.492, F 0.555)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.233] [G acc: 0.109]\n",
      "1187 [D loss: (0.569)(R 0.539, F 0.598)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.171] [G acc: 0.094]\n",
      "1188 [D loss: (0.517)(R 0.501, F 0.533)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.157] [G acc: 0.141]\n",
      "1189 [D loss: (0.524)(R 0.500, F 0.548)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.288] [G acc: 0.047]\n",
      "1190 [D loss: (0.587)(R 0.477, F 0.696)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.231] [G acc: 0.094]\n",
      "1191 [D loss: (0.460)(R 0.506, F 0.414)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.211] [G acc: 0.141]\n",
      "1192 [D loss: (0.623)(R 0.545, F 0.702)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.317] [G acc: 0.141]\n",
      "1193 [D loss: (0.589)(R 0.536, F 0.643)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.283] [G acc: 0.094]\n",
      "1194 [D loss: (0.548)(R 0.516, F 0.581)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.303] [G acc: 0.078]\n",
      "1195 [D loss: (0.576)(R 0.563, F 0.590)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.260] [G acc: 0.078]\n",
      "1196 [D loss: (0.527)(R 0.619, F 0.435)] [D acc: (0.734)(0.531, 0.938)] [G loss: 1.300] [G acc: 0.078]\n",
      "1197 [D loss: (0.560)(R 0.480, F 0.641)] [D acc: (0.680)(0.703, 0.656)] [G loss: 1.324] [G acc: 0.047]\n",
      "1198 [D loss: (0.578)(R 0.645, F 0.511)] [D acc: (0.664)(0.516, 0.812)] [G loss: 1.243] [G acc: 0.094]\n",
      "1199 [D loss: (0.587)(R 0.657, F 0.517)] [D acc: (0.664)(0.484, 0.844)] [G loss: 1.257] [G acc: 0.125]\n",
      "1200 [D loss: (0.686)(R 0.677, F 0.696)] [D acc: (0.609)(0.516, 0.703)] [G loss: 1.209] [G acc: 0.078]\n",
      "1201 [D loss: (0.566)(R 0.643, F 0.489)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.208] [G acc: 0.094]\n",
      "1202 [D loss: (0.514)(R 0.556, F 0.471)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.104] [G acc: 0.156]\n",
      "1203 [D loss: (0.601)(R 0.491, F 0.711)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.242] [G acc: 0.062]\n",
      "1204 [D loss: (0.544)(R 0.605, F 0.483)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.239] [G acc: 0.094]\n",
      "1205 [D loss: (0.541)(R 0.518, F 0.565)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.162] [G acc: 0.172]\n",
      "1206 [D loss: (0.567)(R 0.548, F 0.586)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.170] [G acc: 0.109]\n",
      "1207 [D loss: (0.553)(R 0.550, F 0.556)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.205] [G acc: 0.125]\n",
      "1208 [D loss: (0.539)(R 0.476, F 0.603)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.193] [G acc: 0.062]\n",
      "1209 [D loss: (0.610)(R 0.590, F 0.629)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.277] [G acc: 0.094]\n",
      "1210 [D loss: (0.675)(R 0.714, F 0.636)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.222] [G acc: 0.109]\n",
      "1211 [D loss: (0.537)(R 0.596, F 0.478)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.246] [G acc: 0.062]\n",
      "1212 [D loss: (0.545)(R 0.519, F 0.571)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.153] [G acc: 0.141]\n",
      "1213 [D loss: (0.590)(R 0.601, F 0.579)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.172] [G acc: 0.125]\n",
      "1214 [D loss: (0.524)(R 0.570, F 0.477)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.305] [G acc: 0.109]\n",
      "1215 [D loss: (0.585)(R 0.545, F 0.626)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.188] [G acc: 0.078]\n",
      "1216 [D loss: (0.576)(R 0.553, F 0.600)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.249] [G acc: 0.125]\n",
      "1217 [D loss: (0.614)(R 0.687, F 0.540)] [D acc: (0.656)(0.516, 0.797)] [G loss: 1.108] [G acc: 0.125]\n",
      "1218 [D loss: (0.638)(R 0.616, F 0.659)] [D acc: (0.625)(0.594, 0.656)] [G loss: 1.201] [G acc: 0.125]\n",
      "1219 [D loss: (0.561)(R 0.576, F 0.547)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.225] [G acc: 0.078]\n",
      "1220 [D loss: (0.630)(R 0.629, F 0.632)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.181] [G acc: 0.109]\n",
      "1221 [D loss: (0.599)(R 0.618, F 0.581)] [D acc: (0.648)(0.547, 0.750)] [G loss: 1.159] [G acc: 0.125]\n",
      "1222 [D loss: (0.589)(R 0.614, F 0.564)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.146] [G acc: 0.094]\n",
      "1223 [D loss: (0.573)(R 0.608, F 0.537)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.211] [G acc: 0.078]\n",
      "1224 [D loss: (0.516)(R 0.552, F 0.480)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.055] [G acc: 0.234]\n",
      "1225 [D loss: (0.587)(R 0.519, F 0.655)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.162] [G acc: 0.172]\n",
      "1226 [D loss: (0.659)(R 0.682, F 0.635)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.025] [G acc: 0.172]\n",
      "1227 [D loss: (0.624)(R 0.659, F 0.590)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.139] [G acc: 0.125]\n",
      "1228 [D loss: (0.559)(R 0.562, F 0.555)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.131] [G acc: 0.125]\n",
      "1229 [D loss: (0.621)(R 0.546, F 0.695)] [D acc: (0.672)(0.688, 0.656)] [G loss: 1.178] [G acc: 0.078]\n",
      "1230 [D loss: (0.567)(R 0.538, F 0.596)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.196] [G acc: 0.047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1231 [D loss: (0.603)(R 0.622, F 0.585)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.165] [G acc: 0.109]\n",
      "1232 [D loss: (0.574)(R 0.534, F 0.614)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.134] [G acc: 0.141]\n",
      "1233 [D loss: (0.567)(R 0.578, F 0.556)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.219] [G acc: 0.016]\n",
      "1234 [D loss: (0.635)(R 0.652, F 0.618)] [D acc: (0.633)(0.547, 0.719)] [G loss: 1.188] [G acc: 0.016]\n",
      "1235 [D loss: (0.523)(R 0.520, F 0.526)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.158] [G acc: 0.078]\n",
      "1236 [D loss: (0.579)(R 0.531, F 0.626)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.287] [G acc: 0.109]\n",
      "1237 [D loss: (0.546)(R 0.493, F 0.600)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.250] [G acc: 0.125]\n",
      "1238 [D loss: (0.663)(R 0.652, F 0.674)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.214] [G acc: 0.109]\n",
      "1239 [D loss: (0.567)(R 0.624, F 0.509)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.188] [G acc: 0.047]\n",
      "1240 [D loss: (0.559)(R 0.558, F 0.560)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.354] [G acc: 0.047]\n",
      "1241 [D loss: (0.632)(R 0.574, F 0.690)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.240] [G acc: 0.078]\n",
      "1242 [D loss: (0.489)(R 0.494, F 0.484)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.295] [G acc: 0.031]\n",
      "1243 [D loss: (0.639)(R 0.603, F 0.674)] [D acc: (0.617)(0.609, 0.625)] [G loss: 1.289] [G acc: 0.031]\n",
      "1244 [D loss: (0.565)(R 0.621, F 0.508)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.159] [G acc: 0.125]\n",
      "1245 [D loss: (0.541)(R 0.539, F 0.542)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.083] [G acc: 0.125]\n",
      "1246 [D loss: (0.639)(R 0.450, F 0.827)] [D acc: (0.680)(0.750, 0.609)] [G loss: 1.221] [G acc: 0.141]\n",
      "1247 [D loss: (0.603)(R 0.681, F 0.526)] [D acc: (0.664)(0.516, 0.812)] [G loss: 1.093] [G acc: 0.172]\n",
      "1248 [D loss: (0.570)(R 0.569, F 0.571)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.204] [G acc: 0.062]\n",
      "1249 [D loss: (0.488)(R 0.477, F 0.499)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.215] [G acc: 0.094]\n",
      "1250 [D loss: (0.542)(R 0.544, F 0.540)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.196] [G acc: 0.125]\n",
      "1251 [D loss: (0.523)(R 0.531, F 0.516)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.318] [G acc: 0.078]\n",
      "1252 [D loss: (0.567)(R 0.575, F 0.558)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.268] [G acc: 0.141]\n",
      "1253 [D loss: (0.554)(R 0.570, F 0.537)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.252] [G acc: 0.094]\n",
      "1254 [D loss: (0.533)(R 0.534, F 0.532)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.191] [G acc: 0.109]\n",
      "1255 [D loss: (0.527)(R 0.519, F 0.535)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.194] [G acc: 0.109]\n",
      "1256 [D loss: (0.590)(R 0.631, F 0.549)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.266] [G acc: 0.094]\n",
      "1257 [D loss: (0.595)(R 0.564, F 0.625)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.160] [G acc: 0.094]\n",
      "1258 [D loss: (0.548)(R 0.462, F 0.634)] [D acc: (0.797)(0.797, 0.797)] [G loss: 1.258] [G acc: 0.109]\n",
      "1259 [D loss: (0.520)(R 0.501, F 0.539)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.388] [G acc: 0.062]\n",
      "1260 [D loss: (0.561)(R 0.568, F 0.554)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.278] [G acc: 0.016]\n",
      "1261 [D loss: (0.479)(R 0.464, F 0.495)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.300] [G acc: 0.094]\n",
      "1262 [D loss: (0.572)(R 0.575, F 0.569)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.296] [G acc: 0.094]\n",
      "1263 [D loss: (0.608)(R 0.691, F 0.524)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.258] [G acc: 0.125]\n",
      "1264 [D loss: (0.565)(R 0.556, F 0.573)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.304] [G acc: 0.109]\n",
      "1265 [D loss: (0.539)(R 0.511, F 0.566)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.194] [G acc: 0.188]\n",
      "1266 [D loss: (0.598)(R 0.613, F 0.584)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.311] [G acc: 0.031]\n",
      "1267 [D loss: (0.499)(R 0.516, F 0.483)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.268] [G acc: 0.062]\n",
      "1268 [D loss: (0.517)(R 0.456, F 0.578)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.340] [G acc: 0.078]\n",
      "1269 [D loss: (0.539)(R 0.577, F 0.501)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.350] [G acc: 0.094]\n",
      "1270 [D loss: (0.537)(R 0.508, F 0.565)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.374] [G acc: 0.078]\n",
      "1271 [D loss: (0.580)(R 0.528, F 0.632)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.479] [G acc: 0.062]\n",
      "1272 [D loss: (0.587)(R 0.618, F 0.556)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.258] [G acc: 0.203]\n",
      "1273 [D loss: (0.498)(R 0.473, F 0.523)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.353] [G acc: 0.125]\n",
      "1274 [D loss: (0.482)(R 0.468, F 0.496)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.392] [G acc: 0.078]\n",
      "1275 [D loss: (0.543)(R 0.523, F 0.564)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.279] [G acc: 0.109]\n",
      "1276 [D loss: (0.487)(R 0.493, F 0.482)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.306] [G acc: 0.109]\n",
      "1277 [D loss: (0.641)(R 0.593, F 0.690)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.460] [G acc: 0.062]\n",
      "1278 [D loss: (0.624)(R 0.707, F 0.542)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.276] [G acc: 0.062]\n",
      "1279 [D loss: (0.535)(R 0.537, F 0.533)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.333] [G acc: 0.078]\n",
      "1280 [D loss: (0.576)(R 0.636, F 0.517)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.354] [G acc: 0.062]\n",
      "1281 [D loss: (0.526)(R 0.521, F 0.532)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.268] [G acc: 0.156]\n",
      "1282 [D loss: (0.569)(R 0.681, F 0.458)] [D acc: (0.742)(0.578, 0.906)] [G loss: 1.187] [G acc: 0.156]\n",
      "1283 [D loss: (0.566)(R 0.604, F 0.529)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.152] [G acc: 0.141]\n",
      "1284 [D loss: (0.549)(R 0.515, F 0.583)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.203] [G acc: 0.141]\n",
      "1285 [D loss: (0.556)(R 0.554, F 0.558)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.237] [G acc: 0.094]\n",
      "1286 [D loss: (0.629)(R 0.485, F 0.773)] [D acc: (0.680)(0.703, 0.656)] [G loss: 1.243] [G acc: 0.062]\n",
      "1287 [D loss: (0.533)(R 0.574, F 0.492)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.215] [G acc: 0.078]\n",
      "1288 [D loss: (0.684)(R 0.700, F 0.668)] [D acc: (0.594)(0.469, 0.719)] [G loss: 1.140] [G acc: 0.109]\n",
      "1289 [D loss: (0.596)(R 0.665, F 0.527)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.123] [G acc: 0.141]\n",
      "1290 [D loss: (0.539)(R 0.479, F 0.599)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.141] [G acc: 0.188]\n",
      "1291 [D loss: (0.594)(R 0.529, F 0.659)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.250] [G acc: 0.094]\n",
      "1292 [D loss: (0.583)(R 0.594, F 0.572)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.145] [G acc: 0.141]\n",
      "1293 [D loss: (0.568)(R 0.678, F 0.458)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.236] [G acc: 0.078]\n",
      "1294 [D loss: (0.602)(R 0.497, F 0.707)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.184] [G acc: 0.094]\n",
      "1295 [D loss: (0.635)(R 0.736, F 0.533)] [D acc: (0.617)(0.469, 0.766)] [G loss: 1.171] [G acc: 0.109]\n",
      "1296 [D loss: (0.572)(R 0.574, F 0.570)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.170] [G acc: 0.109]\n",
      "1297 [D loss: (0.564)(R 0.547, F 0.581)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.225] [G acc: 0.109]\n",
      "1298 [D loss: (0.563)(R 0.563, F 0.563)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.345] [G acc: 0.047]\n",
      "1299 [D loss: (0.554)(R 0.585, F 0.524)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.280] [G acc: 0.062]\n",
      "1300 [D loss: (0.533)(R 0.481, F 0.585)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.229] [G acc: 0.094]\n",
      "1301 [D loss: (0.524)(R 0.565, F 0.484)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.229] [G acc: 0.156]\n",
      "1302 [D loss: (0.604)(R 0.619, F 0.589)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.147] [G acc: 0.156]\n",
      "1303 [D loss: (0.539)(R 0.568, F 0.510)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.059] [G acc: 0.219]\n",
      "1304 [D loss: (0.661)(R 0.562, F 0.761)] [D acc: (0.648)(0.641, 0.656)] [G loss: 1.299] [G acc: 0.109]\n",
      "1305 [D loss: (0.603)(R 0.664, F 0.541)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.214] [G acc: 0.078]\n",
      "1306 [D loss: (0.511)(R 0.514, F 0.508)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.254] [G acc: 0.141]\n",
      "1307 [D loss: (0.579)(R 0.478, F 0.680)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.269] [G acc: 0.109]\n",
      "1308 [D loss: (0.576)(R 0.638, F 0.514)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.258] [G acc: 0.094]\n",
      "1309 [D loss: (0.554)(R 0.597, F 0.511)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.208] [G acc: 0.109]\n",
      "1310 [D loss: (0.491)(R 0.448, F 0.534)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.261] [G acc: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311 [D loss: (0.465)(R 0.429, F 0.502)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.432] [G acc: 0.062]\n",
      "1312 [D loss: (0.596)(R 0.555, F 0.637)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.334] [G acc: 0.125]\n",
      "1313 [D loss: (0.573)(R 0.592, F 0.555)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.217] [G acc: 0.062]\n",
      "1314 [D loss: (0.538)(R 0.577, F 0.500)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.324] [G acc: 0.062]\n",
      "1315 [D loss: (0.480)(R 0.489, F 0.470)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.337] [G acc: 0.109]\n",
      "1316 [D loss: (0.496)(R 0.525, F 0.468)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.269] [G acc: 0.125]\n",
      "1317 [D loss: (0.709)(R 0.571, F 0.847)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.238] [G acc: 0.078]\n",
      "1318 [D loss: (0.514)(R 0.546, F 0.482)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.213] [G acc: 0.141]\n",
      "1319 [D loss: (0.553)(R 0.527, F 0.578)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.149] [G acc: 0.172]\n",
      "1320 [D loss: (0.732)(R 0.539, F 0.924)] [D acc: (0.617)(0.641, 0.594)] [G loss: 1.233] [G acc: 0.094]\n",
      "1321 [D loss: (0.536)(R 0.567, F 0.505)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.173] [G acc: 0.125]\n",
      "1322 [D loss: (0.587)(R 0.541, F 0.633)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.311] [G acc: 0.062]\n",
      "1323 [D loss: (0.497)(R 0.478, F 0.516)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.195] [G acc: 0.188]\n",
      "1324 [D loss: (0.533)(R 0.464, F 0.601)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.308] [G acc: 0.141]\n",
      "1325 [D loss: (0.623)(R 0.568, F 0.677)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.290] [G acc: 0.125]\n",
      "1326 [D loss: (0.623)(R 0.681, F 0.566)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.214] [G acc: 0.125]\n",
      "1327 [D loss: (0.559)(R 0.599, F 0.519)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.282] [G acc: 0.078]\n",
      "1328 [D loss: (0.552)(R 0.559, F 0.545)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.301] [G acc: 0.109]\n",
      "1329 [D loss: (0.491)(R 0.505, F 0.477)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.412] [G acc: 0.062]\n",
      "1330 [D loss: (0.515)(R 0.551, F 0.480)] [D acc: (0.789)(0.672, 0.906)] [G loss: 1.360] [G acc: 0.078]\n",
      "1331 [D loss: (0.503)(R 0.401, F 0.605)] [D acc: (0.719)(0.797, 0.641)] [G loss: 1.352] [G acc: 0.109]\n",
      "1332 [D loss: (0.555)(R 0.634, F 0.476)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.206] [G acc: 0.141]\n",
      "1333 [D loss: (0.585)(R 0.542, F 0.627)] [D acc: (0.648)(0.672, 0.625)] [G loss: 1.400] [G acc: 0.062]\n",
      "1334 [D loss: (0.537)(R 0.554, F 0.519)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.369] [G acc: 0.062]\n",
      "1335 [D loss: (0.575)(R 0.589, F 0.562)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.226] [G acc: 0.172]\n",
      "1336 [D loss: (0.555)(R 0.480, F 0.629)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.311] [G acc: 0.141]\n",
      "1337 [D loss: (0.592)(R 0.701, F 0.483)] [D acc: (0.695)(0.547, 0.844)] [G loss: 1.208] [G acc: 0.094]\n",
      "1338 [D loss: (0.574)(R 0.459, F 0.688)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.185] [G acc: 0.172]\n",
      "1339 [D loss: (0.541)(R 0.535, F 0.547)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.211] [G acc: 0.156]\n",
      "1340 [D loss: (0.577)(R 0.557, F 0.597)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.264] [G acc: 0.094]\n",
      "1341 [D loss: (0.568)(R 0.621, F 0.515)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.221] [G acc: 0.188]\n",
      "1342 [D loss: (0.565)(R 0.525, F 0.606)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.375] [G acc: 0.047]\n",
      "1343 [D loss: (0.504)(R 0.506, F 0.503)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.319] [G acc: 0.078]\n",
      "1344 [D loss: (0.587)(R 0.582, F 0.593)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.253] [G acc: 0.047]\n",
      "1345 [D loss: (0.610)(R 0.692, F 0.527)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.193] [G acc: 0.125]\n",
      "1346 [D loss: (0.555)(R 0.487, F 0.624)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.180] [G acc: 0.188]\n",
      "1347 [D loss: (0.618)(R 0.586, F 0.650)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.235] [G acc: 0.109]\n",
      "1348 [D loss: (0.558)(R 0.573, F 0.543)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.253] [G acc: 0.109]\n",
      "1349 [D loss: (0.579)(R 0.634, F 0.525)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.202] [G acc: 0.062]\n",
      "1350 [D loss: (0.466)(R 0.504, F 0.428)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.383] [G acc: 0.109]\n",
      "1351 [D loss: (0.547)(R 0.565, F 0.528)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.269] [G acc: 0.141]\n",
      "1352 [D loss: (0.498)(R 0.505, F 0.491)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.340] [G acc: 0.062]\n",
      "1353 [D loss: (0.678)(R 0.579, F 0.777)] [D acc: (0.648)(0.656, 0.641)] [G loss: 1.297] [G acc: 0.109]\n",
      "1354 [D loss: (0.542)(R 0.564, F 0.520)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.232] [G acc: 0.156]\n",
      "1355 [D loss: (0.537)(R 0.548, F 0.525)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.308] [G acc: 0.109]\n",
      "1356 [D loss: (0.588)(R 0.640, F 0.537)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.233] [G acc: 0.094]\n",
      "1357 [D loss: (0.585)(R 0.499, F 0.671)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.311] [G acc: 0.062]\n",
      "1358 [D loss: (0.549)(R 0.623, F 0.475)] [D acc: (0.695)(0.531, 0.859)] [G loss: 1.267] [G acc: 0.078]\n",
      "1359 [D loss: (0.569)(R 0.498, F 0.639)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.251] [G acc: 0.172]\n",
      "1360 [D loss: (0.589)(R 0.530, F 0.647)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.190] [G acc: 0.156]\n",
      "1361 [D loss: (0.537)(R 0.537, F 0.536)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.230] [G acc: 0.109]\n",
      "1362 [D loss: (0.487)(R 0.437, F 0.537)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.429] [G acc: 0.141]\n",
      "1363 [D loss: (0.569)(R 0.581, F 0.557)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.229] [G acc: 0.078]\n",
      "1364 [D loss: (0.590)(R 0.593, F 0.586)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.252] [G acc: 0.156]\n",
      "1365 [D loss: (0.535)(R 0.533, F 0.538)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.310] [G acc: 0.109]\n",
      "1366 [D loss: (0.469)(R 0.472, F 0.466)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.223] [G acc: 0.188]\n",
      "1367 [D loss: (0.500)(R 0.457, F 0.543)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.441] [G acc: 0.062]\n",
      "1368 [D loss: (0.555)(R 0.467, F 0.644)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.325] [G acc: 0.109]\n",
      "1369 [D loss: (0.577)(R 0.622, F 0.532)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.307] [G acc: 0.188]\n",
      "1370 [D loss: (0.554)(R 0.536, F 0.571)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.229] [G acc: 0.094]\n",
      "1371 [D loss: (0.631)(R 0.685, F 0.577)] [D acc: (0.641)(0.516, 0.766)] [G loss: 1.316] [G acc: 0.062]\n",
      "1372 [D loss: (0.503)(R 0.402, F 0.604)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.440] [G acc: 0.031]\n",
      "1373 [D loss: (0.513)(R 0.562, F 0.465)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.413] [G acc: 0.031]\n",
      "1374 [D loss: (0.492)(R 0.480, F 0.504)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.398] [G acc: 0.094]\n",
      "1375 [D loss: (0.504)(R 0.496, F 0.511)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.285] [G acc: 0.156]\n",
      "1376 [D loss: (0.520)(R 0.478, F 0.562)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.340] [G acc: 0.078]\n",
      "1377 [D loss: (0.614)(R 0.400, F 0.828)] [D acc: (0.680)(0.781, 0.578)] [G loss: 1.553] [G acc: 0.062]\n",
      "1378 [D loss: (0.638)(R 0.718, F 0.559)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.390] [G acc: 0.078]\n",
      "1379 [D loss: (0.501)(R 0.539, F 0.462)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.334] [G acc: 0.094]\n",
      "1380 [D loss: (0.440)(R 0.298, F 0.581)] [D acc: (0.789)(0.875, 0.703)] [G loss: 1.377] [G acc: 0.094]\n",
      "1381 [D loss: (0.582)(R 0.618, F 0.545)] [D acc: (0.641)(0.562, 0.719)] [G loss: 1.394] [G acc: 0.078]\n",
      "1382 [D loss: (0.545)(R 0.550, F 0.540)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.353] [G acc: 0.062]\n",
      "1383 [D loss: (0.547)(R 0.672, F 0.422)] [D acc: (0.750)(0.578, 0.922)] [G loss: 1.266] [G acc: 0.156]\n",
      "1384 [D loss: (0.648)(R 0.550, F 0.747)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.353] [G acc: 0.078]\n",
      "1385 [D loss: (0.587)(R 0.643, F 0.530)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.301] [G acc: 0.078]\n",
      "1386 [D loss: (0.601)(R 0.678, F 0.524)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.216] [G acc: 0.125]\n",
      "1387 [D loss: (0.510)(R 0.517, F 0.504)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.236] [G acc: 0.078]\n",
      "1388 [D loss: (0.554)(R 0.628, F 0.480)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.180] [G acc: 0.172]\n",
      "1389 [D loss: (0.554)(R 0.529, F 0.579)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.263] [G acc: 0.094]\n",
      "1390 [D loss: (0.542)(R 0.575, F 0.509)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.252] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1391 [D loss: (0.578)(R 0.621, F 0.535)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.289] [G acc: 0.078]\n",
      "1392 [D loss: (0.550)(R 0.491, F 0.609)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.227] [G acc: 0.109]\n",
      "1393 [D loss: (0.588)(R 0.563, F 0.613)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.280] [G acc: 0.062]\n",
      "1394 [D loss: (0.547)(R 0.496, F 0.598)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.340] [G acc: 0.109]\n",
      "1395 [D loss: (0.559)(R 0.653, F 0.465)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.148] [G acc: 0.141]\n",
      "1396 [D loss: (0.520)(R 0.514, F 0.526)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.304] [G acc: 0.078]\n",
      "1397 [D loss: (0.598)(R 0.662, F 0.535)] [D acc: (0.648)(0.516, 0.781)] [G loss: 1.303] [G acc: 0.062]\n",
      "1398 [D loss: (0.488)(R 0.478, F 0.498)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.328] [G acc: 0.141]\n",
      "1399 [D loss: (0.588)(R 0.499, F 0.678)] [D acc: (0.680)(0.719, 0.641)] [G loss: 1.382] [G acc: 0.062]\n",
      "1400 [D loss: (0.573)(R 0.558, F 0.587)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.274] [G acc: 0.094]\n",
      "1401 [D loss: (0.514)(R 0.545, F 0.483)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.258] [G acc: 0.078]\n",
      "1402 [D loss: (0.596)(R 0.610, F 0.582)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.266] [G acc: 0.109]\n",
      "1403 [D loss: (0.560)(R 0.467, F 0.654)] [D acc: (0.734)(0.750, 0.719)] [G loss: 1.304] [G acc: 0.109]\n",
      "1404 [D loss: (0.510)(R 0.598, F 0.422)] [D acc: (0.789)(0.656, 0.922)] [G loss: 1.387] [G acc: 0.047]\n",
      "1405 [D loss: (0.605)(R 0.562, F 0.648)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.279] [G acc: 0.094]\n",
      "1406 [D loss: (0.518)(R 0.587, F 0.449)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.414] [G acc: 0.047]\n",
      "1407 [D loss: (0.550)(R 0.583, F 0.517)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.292] [G acc: 0.078]\n",
      "1408 [D loss: (0.521)(R 0.536, F 0.507)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.329] [G acc: 0.094]\n",
      "1409 [D loss: (0.611)(R 0.640, F 0.583)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.269] [G acc: 0.109]\n",
      "1410 [D loss: (0.592)(R 0.634, F 0.551)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.243] [G acc: 0.109]\n",
      "1411 [D loss: (0.525)(R 0.568, F 0.482)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.328] [G acc: 0.109]\n",
      "1412 [D loss: (0.586)(R 0.550, F 0.621)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.236] [G acc: 0.094]\n",
      "1413 [D loss: (0.527)(R 0.559, F 0.494)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.267] [G acc: 0.109]\n",
      "1414 [D loss: (0.509)(R 0.507, F 0.511)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.288] [G acc: 0.094]\n",
      "1415 [D loss: (0.608)(R 0.505, F 0.711)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.290] [G acc: 0.031]\n",
      "1416 [D loss: (0.575)(R 0.668, F 0.482)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.167] [G acc: 0.062]\n",
      "1417 [D loss: (0.564)(R 0.564, F 0.564)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.285] [G acc: 0.062]\n",
      "1418 [D loss: (0.542)(R 0.580, F 0.503)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.348] [G acc: 0.062]\n",
      "1419 [D loss: (0.487)(R 0.462, F 0.513)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.330] [G acc: 0.109]\n",
      "1420 [D loss: (0.527)(R 0.523, F 0.532)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.293] [G acc: 0.094]\n",
      "1421 [D loss: (0.604)(R 0.654, F 0.553)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.172] [G acc: 0.109]\n",
      "1422 [D loss: (0.634)(R 0.586, F 0.682)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.329] [G acc: 0.062]\n",
      "1423 [D loss: (0.639)(R 0.737, F 0.542)] [D acc: (0.617)(0.469, 0.766)] [G loss: 1.164] [G acc: 0.125]\n",
      "1424 [D loss: (0.603)(R 0.685, F 0.520)] [D acc: (0.688)(0.516, 0.859)] [G loss: 1.147] [G acc: 0.062]\n",
      "1425 [D loss: (0.530)(R 0.624, F 0.437)] [D acc: (0.664)(0.547, 0.781)] [G loss: 1.242] [G acc: 0.094]\n",
      "1426 [D loss: (0.524)(R 0.497, F 0.551)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.242] [G acc: 0.094]\n",
      "1427 [D loss: (0.529)(R 0.486, F 0.572)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.324] [G acc: 0.031]\n",
      "1428 [D loss: (0.568)(R 0.601, F 0.535)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.321] [G acc: 0.016]\n",
      "1429 [D loss: (0.497)(R 0.537, F 0.457)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.352] [G acc: 0.125]\n",
      "1430 [D loss: (0.532)(R 0.497, F 0.566)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.290] [G acc: 0.078]\n",
      "1431 [D loss: (0.614)(R 0.593, F 0.635)] [D acc: (0.648)(0.609, 0.688)] [G loss: 1.191] [G acc: 0.141]\n",
      "1432 [D loss: (0.572)(R 0.574, F 0.570)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.267] [G acc: 0.109]\n",
      "1433 [D loss: (0.528)(R 0.527, F 0.530)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.245] [G acc: 0.062]\n",
      "1434 [D loss: (0.480)(R 0.496, F 0.463)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.239] [G acc: 0.125]\n",
      "1435 [D loss: (0.590)(R 0.424, F 0.755)] [D acc: (0.719)(0.766, 0.672)] [G loss: 1.273] [G acc: 0.094]\n",
      "1436 [D loss: (0.469)(R 0.561, F 0.377)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.352] [G acc: 0.094]\n",
      "1437 [D loss: (0.499)(R 0.535, F 0.463)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.358] [G acc: 0.125]\n",
      "1438 [D loss: (0.663)(R 0.605, F 0.721)] [D acc: (0.633)(0.562, 0.703)] [G loss: 1.331] [G acc: 0.094]\n",
      "1439 [D loss: (0.513)(R 0.514, F 0.512)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.356] [G acc: 0.125]\n",
      "1440 [D loss: (0.667)(R 0.725, F 0.608)] [D acc: (0.586)(0.500, 0.672)] [G loss: 1.294] [G acc: 0.141]\n",
      "1441 [D loss: (0.526)(R 0.586, F 0.467)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.230] [G acc: 0.078]\n",
      "1442 [D loss: (0.565)(R 0.520, F 0.611)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.275] [G acc: 0.109]\n",
      "1443 [D loss: (0.664)(R 0.648, F 0.680)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.211] [G acc: 0.078]\n",
      "1444 [D loss: (0.552)(R 0.655, F 0.448)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.197] [G acc: 0.109]\n",
      "1445 [D loss: (0.581)(R 0.548, F 0.614)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.316] [G acc: 0.109]\n",
      "1446 [D loss: (0.630)(R 0.621, F 0.638)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.242] [G acc: 0.125]\n",
      "1447 [D loss: (0.584)(R 0.562, F 0.605)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.114] [G acc: 0.172]\n",
      "1448 [D loss: (0.598)(R 0.634, F 0.563)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.173] [G acc: 0.141]\n",
      "1449 [D loss: (0.565)(R 0.500, F 0.631)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.275] [G acc: 0.078]\n",
      "1450 [D loss: (0.526)(R 0.539, F 0.513)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.290] [G acc: 0.062]\n",
      "1451 [D loss: (0.533)(R 0.585, F 0.482)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.225] [G acc: 0.172]\n",
      "1452 [D loss: (0.584)(R 0.582, F 0.585)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.243] [G acc: 0.156]\n",
      "1453 [D loss: (0.509)(R 0.566, F 0.453)] [D acc: (0.734)(0.562, 0.906)] [G loss: 1.214] [G acc: 0.141]\n",
      "1454 [D loss: (0.524)(R 0.474, F 0.573)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.315] [G acc: 0.047]\n",
      "1455 [D loss: (0.555)(R 0.572, F 0.538)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.255] [G acc: 0.094]\n",
      "1456 [D loss: (0.620)(R 0.619, F 0.621)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.193] [G acc: 0.125]\n",
      "1457 [D loss: (0.597)(R 0.585, F 0.609)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.171] [G acc: 0.141]\n",
      "1458 [D loss: (0.490)(R 0.482, F 0.497)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.142] [G acc: 0.156]\n",
      "1459 [D loss: (0.556)(R 0.574, F 0.538)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.061] [G acc: 0.219]\n",
      "1460 [D loss: (0.549)(R 0.482, F 0.617)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.218] [G acc: 0.156]\n",
      "1461 [D loss: (0.709)(R 0.495, F 0.922)] [D acc: (0.672)(0.750, 0.594)] [G loss: 1.278] [G acc: 0.047]\n",
      "1462 [D loss: (0.548)(R 0.612, F 0.485)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.213] [G acc: 0.125]\n",
      "1463 [D loss: (0.512)(R 0.486, F 0.537)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.211] [G acc: 0.109]\n",
      "1464 [D loss: (0.512)(R 0.495, F 0.529)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.175] [G acc: 0.109]\n",
      "1465 [D loss: (0.560)(R 0.558, F 0.563)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.195] [G acc: 0.172]\n",
      "1466 [D loss: (0.494)(R 0.478, F 0.510)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.236] [G acc: 0.078]\n",
      "1467 [D loss: (0.544)(R 0.548, F 0.539)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.280] [G acc: 0.125]\n",
      "1468 [D loss: (0.599)(R 0.665, F 0.533)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.278] [G acc: 0.109]\n",
      "1469 [D loss: (0.594)(R 0.615, F 0.572)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.354] [G acc: 0.062]\n",
      "1470 [D loss: (0.597)(R 0.626, F 0.567)] [D acc: (0.648)(0.547, 0.750)] [G loss: 1.310] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1471 [D loss: (0.516)(R 0.463, F 0.568)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.471] [G acc: 0.094]\n",
      "1472 [D loss: (0.622)(R 0.603, F 0.641)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.375] [G acc: 0.109]\n",
      "1473 [D loss: (0.596)(R 0.649, F 0.544)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.275] [G acc: 0.125]\n",
      "1474 [D loss: (0.581)(R 0.606, F 0.556)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.186] [G acc: 0.156]\n",
      "1475 [D loss: (0.512)(R 0.448, F 0.575)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.371] [G acc: 0.125]\n",
      "1476 [D loss: (0.590)(R 0.623, F 0.558)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.161] [G acc: 0.188]\n",
      "1477 [D loss: (0.536)(R 0.538, F 0.533)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.279] [G acc: 0.062]\n",
      "1478 [D loss: (0.615)(R 0.628, F 0.601)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.187] [G acc: 0.094]\n",
      "1479 [D loss: (0.623)(R 0.682, F 0.564)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.283] [G acc: 0.125]\n",
      "1480 [D loss: (0.587)(R 0.602, F 0.572)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.260] [G acc: 0.094]\n",
      "1481 [D loss: (0.594)(R 0.608, F 0.580)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.196] [G acc: 0.172]\n",
      "1482 [D loss: (0.606)(R 0.574, F 0.637)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.090] [G acc: 0.156]\n",
      "1483 [D loss: (0.568)(R 0.565, F 0.572)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.130] [G acc: 0.219]\n",
      "1484 [D loss: (0.551)(R 0.592, F 0.510)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.208] [G acc: 0.125]\n",
      "1485 [D loss: (0.597)(R 0.533, F 0.660)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.150] [G acc: 0.125]\n",
      "1486 [D loss: (0.612)(R 0.628, F 0.595)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.099] [G acc: 0.141]\n",
      "1487 [D loss: (0.578)(R 0.583, F 0.573)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.107] [G acc: 0.141]\n",
      "1488 [D loss: (0.535)(R 0.503, F 0.568)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.137] [G acc: 0.141]\n",
      "1489 [D loss: (0.478)(R 0.484, F 0.471)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.233] [G acc: 0.172]\n",
      "1490 [D loss: (0.503)(R 0.488, F 0.517)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.337] [G acc: 0.109]\n",
      "1491 [D loss: (0.528)(R 0.473, F 0.583)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.357] [G acc: 0.109]\n",
      "1492 [D loss: (0.558)(R 0.582, F 0.534)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.207] [G acc: 0.078]\n",
      "1493 [D loss: (0.550)(R 0.489, F 0.610)] [D acc: (0.727)(0.750, 0.703)] [G loss: 1.309] [G acc: 0.078]\n",
      "1494 [D loss: (0.613)(R 0.585, F 0.641)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.332] [G acc: 0.062]\n",
      "1495 [D loss: (0.600)(R 0.674, F 0.526)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.194] [G acc: 0.062]\n",
      "1496 [D loss: (0.565)(R 0.572, F 0.558)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.252] [G acc: 0.109]\n",
      "1497 [D loss: (0.490)(R 0.494, F 0.485)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.298] [G acc: 0.109]\n",
      "1498 [D loss: (0.577)(R 0.574, F 0.581)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.341] [G acc: 0.078]\n",
      "1499 [D loss: (0.547)(R 0.516, F 0.577)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.253] [G acc: 0.047]\n",
      "1500 [D loss: (0.511)(R 0.543, F 0.480)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.303] [G acc: 0.094]\n",
      "1501 [D loss: (0.569)(R 0.537, F 0.601)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.234] [G acc: 0.062]\n",
      "1502 [D loss: (0.470)(R 0.436, F 0.504)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.245] [G acc: 0.156]\n",
      "1503 [D loss: (0.532)(R 0.478, F 0.586)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.501] [G acc: 0.062]\n",
      "1504 [D loss: (0.584)(R 0.599, F 0.569)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.268] [G acc: 0.188]\n",
      "1505 [D loss: (0.515)(R 0.539, F 0.491)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.353] [G acc: 0.109]\n",
      "1506 [D loss: (0.505)(R 0.511, F 0.499)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.441] [G acc: 0.078]\n",
      "1507 [D loss: (0.428)(R 0.416, F 0.439)] [D acc: (0.820)(0.797, 0.844)] [G loss: 1.546] [G acc: 0.156]\n",
      "1508 [D loss: (0.627)(R 0.447, F 0.806)] [D acc: (0.672)(0.734, 0.609)] [G loss: 1.409] [G acc: 0.141]\n",
      "1509 [D loss: (0.631)(R 0.742, F 0.519)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.322] [G acc: 0.125]\n",
      "1510 [D loss: (0.551)(R 0.605, F 0.498)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.227] [G acc: 0.125]\n",
      "1511 [D loss: (0.514)(R 0.473, F 0.555)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.266] [G acc: 0.125]\n",
      "1512 [D loss: (0.585)(R 0.618, F 0.553)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.338] [G acc: 0.141]\n",
      "1513 [D loss: (0.539)(R 0.578, F 0.501)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.418] [G acc: 0.031]\n",
      "1514 [D loss: (0.541)(R 0.540, F 0.542)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.382] [G acc: 0.094]\n",
      "1515 [D loss: (0.534)(R 0.610, F 0.459)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.281] [G acc: 0.125]\n",
      "1516 [D loss: (0.579)(R 0.508, F 0.649)] [D acc: (0.703)(0.734, 0.672)] [G loss: 1.189] [G acc: 0.203]\n",
      "1517 [D loss: (0.480)(R 0.501, F 0.458)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.249] [G acc: 0.125]\n",
      "1518 [D loss: (0.496)(R 0.467, F 0.526)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.357] [G acc: 0.141]\n",
      "1519 [D loss: (0.538)(R 0.550, F 0.525)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.316] [G acc: 0.125]\n",
      "1520 [D loss: (0.623)(R 0.478, F 0.769)] [D acc: (0.664)(0.719, 0.609)] [G loss: 1.418] [G acc: 0.078]\n",
      "1521 [D loss: (0.639)(R 0.750, F 0.527)] [D acc: (0.625)(0.453, 0.797)] [G loss: 1.188] [G acc: 0.125]\n",
      "1522 [D loss: (0.552)(R 0.614, F 0.491)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.415] [G acc: 0.094]\n",
      "1523 [D loss: (0.566)(R 0.580, F 0.551)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.190] [G acc: 0.172]\n",
      "1524 [D loss: (0.535)(R 0.510, F 0.561)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.275] [G acc: 0.062]\n",
      "1525 [D loss: (0.625)(R 0.622, F 0.628)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.190] [G acc: 0.141]\n",
      "1526 [D loss: (0.600)(R 0.640, F 0.560)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.268] [G acc: 0.062]\n",
      "1527 [D loss: (0.595)(R 0.601, F 0.590)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.165] [G acc: 0.156]\n",
      "1528 [D loss: (0.502)(R 0.513, F 0.491)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.284] [G acc: 0.125]\n",
      "1529 [D loss: (0.552)(R 0.475, F 0.630)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.243] [G acc: 0.094]\n",
      "1530 [D loss: (0.544)(R 0.566, F 0.521)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.150] [G acc: 0.156]\n",
      "1531 [D loss: (0.682)(R 0.661, F 0.702)] [D acc: (0.602)(0.562, 0.641)] [G loss: 1.224] [G acc: 0.125]\n",
      "1532 [D loss: (0.560)(R 0.560, F 0.561)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.246] [G acc: 0.109]\n",
      "1533 [D loss: (0.629)(R 0.589, F 0.669)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.362] [G acc: 0.031]\n",
      "1534 [D loss: (0.518)(R 0.539, F 0.498)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.255] [G acc: 0.094]\n",
      "1535 [D loss: (0.579)(R 0.598, F 0.561)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.239] [G acc: 0.031]\n",
      "1536 [D loss: (0.522)(R 0.524, F 0.519)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.198] [G acc: 0.172]\n",
      "1537 [D loss: (0.509)(R 0.467, F 0.550)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.275] [G acc: 0.109]\n",
      "1538 [D loss: (0.568)(R 0.547, F 0.589)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.167] [G acc: 0.141]\n",
      "1539 [D loss: (0.540)(R 0.592, F 0.488)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.273] [G acc: 0.156]\n",
      "1540 [D loss: (0.516)(R 0.498, F 0.535)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.322] [G acc: 0.125]\n",
      "1541 [D loss: (0.519)(R 0.587, F 0.452)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.304] [G acc: 0.109]\n",
      "1542 [D loss: (0.570)(R 0.588, F 0.552)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.206] [G acc: 0.203]\n",
      "1543 [D loss: (0.599)(R 0.631, F 0.567)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.275] [G acc: 0.125]\n",
      "1544 [D loss: (0.604)(R 0.636, F 0.571)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.164] [G acc: 0.125]\n",
      "1545 [D loss: (0.557)(R 0.516, F 0.598)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.198] [G acc: 0.141]\n",
      "1546 [D loss: (0.577)(R 0.595, F 0.559)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.327] [G acc: 0.094]\n",
      "1547 [D loss: (0.540)(R 0.541, F 0.538)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.341] [G acc: 0.156]\n",
      "1548 [D loss: (0.586)(R 0.634, F 0.539)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.268] [G acc: 0.078]\n",
      "1549 [D loss: (0.516)(R 0.596, F 0.436)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.194] [G acc: 0.125]\n",
      "1550 [D loss: (0.514)(R 0.452, F 0.575)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.307] [G acc: 0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1551 [D loss: (0.620)(R 0.636, F 0.604)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.142] [G acc: 0.125]\n",
      "1552 [D loss: (0.527)(R 0.496, F 0.557)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.288] [G acc: 0.078]\n",
      "1553 [D loss: (0.520)(R 0.463, F 0.577)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.294] [G acc: 0.094]\n",
      "1554 [D loss: (0.570)(R 0.581, F 0.558)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.274] [G acc: 0.109]\n",
      "1555 [D loss: (0.622)(R 0.643, F 0.600)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.213] [G acc: 0.125]\n",
      "1556 [D loss: (0.557)(R 0.570, F 0.544)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.233] [G acc: 0.141]\n",
      "1557 [D loss: (0.583)(R 0.585, F 0.581)] [D acc: (0.648)(0.625, 0.672)] [G loss: 1.148] [G acc: 0.125]\n",
      "1558 [D loss: (0.551)(R 0.465, F 0.637)] [D acc: (0.648)(0.703, 0.594)] [G loss: 1.251] [G acc: 0.156]\n",
      "1559 [D loss: (0.504)(R 0.528, F 0.480)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.277] [G acc: 0.094]\n",
      "1560 [D loss: (0.628)(R 0.509, F 0.748)] [D acc: (0.656)(0.703, 0.609)] [G loss: 1.238] [G acc: 0.078]\n",
      "1561 [D loss: (0.609)(R 0.635, F 0.582)] [D acc: (0.641)(0.516, 0.766)] [G loss: 1.275] [G acc: 0.062]\n",
      "1562 [D loss: (0.543)(R 0.588, F 0.497)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.272] [G acc: 0.109]\n",
      "1563 [D loss: (0.502)(R 0.509, F 0.495)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.274] [G acc: 0.125]\n",
      "1564 [D loss: (0.518)(R 0.503, F 0.533)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.224] [G acc: 0.109]\n",
      "1565 [D loss: (0.569)(R 0.577, F 0.560)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.244] [G acc: 0.109]\n",
      "1566 [D loss: (0.454)(R 0.405, F 0.502)] [D acc: (0.773)(0.781, 0.766)] [G loss: 1.367] [G acc: 0.109]\n",
      "1567 [D loss: (0.605)(R 0.593, F 0.617)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.256] [G acc: 0.125]\n",
      "1568 [D loss: (0.484)(R 0.493, F 0.475)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.241] [G acc: 0.156]\n",
      "1569 [D loss: (0.633)(R 0.560, F 0.706)] [D acc: (0.633)(0.609, 0.656)] [G loss: 1.188] [G acc: 0.141]\n",
      "1570 [D loss: (0.659)(R 0.722, F 0.595)] [D acc: (0.648)(0.500, 0.797)] [G loss: 1.237] [G acc: 0.109]\n",
      "1571 [D loss: (0.531)(R 0.611, F 0.451)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.227] [G acc: 0.125]\n",
      "1572 [D loss: (0.535)(R 0.548, F 0.521)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.261] [G acc: 0.031]\n",
      "1573 [D loss: (0.596)(R 0.558, F 0.634)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.244] [G acc: 0.078]\n",
      "1574 [D loss: (0.618)(R 0.667, F 0.569)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.198] [G acc: 0.188]\n",
      "1575 [D loss: (0.600)(R 0.535, F 0.666)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.163] [G acc: 0.188]\n",
      "1576 [D loss: (0.571)(R 0.599, F 0.542)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.308] [G acc: 0.094]\n",
      "1577 [D loss: (0.612)(R 0.634, F 0.591)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.261] [G acc: 0.094]\n",
      "1578 [D loss: (0.556)(R 0.566, F 0.546)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.265] [G acc: 0.109]\n",
      "1579 [D loss: (0.573)(R 0.642, F 0.504)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.328] [G acc: 0.172]\n",
      "1580 [D loss: (0.594)(R 0.567, F 0.622)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.262] [G acc: 0.094]\n",
      "1581 [D loss: (0.513)(R 0.502, F 0.523)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.336] [G acc: 0.078]\n",
      "1582 [D loss: (0.570)(R 0.559, F 0.580)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.224] [G acc: 0.078]\n",
      "1583 [D loss: (0.669)(R 0.688, F 0.649)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.071] [G acc: 0.156]\n",
      "1584 [D loss: (0.635)(R 0.627, F 0.642)] [D acc: (0.633)(0.641, 0.625)] [G loss: 1.205] [G acc: 0.109]\n",
      "1585 [D loss: (0.490)(R 0.495, F 0.484)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.185] [G acc: 0.125]\n",
      "1586 [D loss: (0.570)(R 0.601, F 0.538)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.189] [G acc: 0.188]\n",
      "1587 [D loss: (0.520)(R 0.494, F 0.547)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.155] [G acc: 0.141]\n",
      "1588 [D loss: (0.603)(R 0.398, F 0.807)] [D acc: (0.727)(0.781, 0.672)] [G loss: 1.136] [G acc: 0.172]\n",
      "1589 [D loss: (0.574)(R 0.641, F 0.508)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.231] [G acc: 0.141]\n",
      "1590 [D loss: (0.605)(R 0.528, F 0.682)] [D acc: (0.625)(0.641, 0.609)] [G loss: 1.301] [G acc: 0.109]\n",
      "1591 [D loss: (0.535)(R 0.575, F 0.495)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.201] [G acc: 0.047]\n",
      "1592 [D loss: (0.525)(R 0.561, F 0.490)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.174] [G acc: 0.125]\n",
      "1593 [D loss: (0.566)(R 0.603, F 0.528)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.240] [G acc: 0.094]\n",
      "1594 [D loss: (0.610)(R 0.583, F 0.638)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.400] [G acc: 0.062]\n",
      "1595 [D loss: (0.519)(R 0.555, F 0.484)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.319] [G acc: 0.078]\n",
      "1596 [D loss: (0.581)(R 0.606, F 0.557)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.218] [G acc: 0.078]\n",
      "1597 [D loss: (0.562)(R 0.576, F 0.548)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.150] [G acc: 0.141]\n",
      "1598 [D loss: (0.578)(R 0.633, F 0.524)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.190] [G acc: 0.078]\n",
      "1599 [D loss: (0.561)(R 0.478, F 0.644)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.260] [G acc: 0.062]\n",
      "1600 [D loss: (0.597)(R 0.639, F 0.555)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.271] [G acc: 0.078]\n",
      "1601 [D loss: (0.530)(R 0.505, F 0.556)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.262] [G acc: 0.125]\n",
      "1602 [D loss: (0.597)(R 0.568, F 0.627)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.363] [G acc: 0.078]\n",
      "1603 [D loss: (0.567)(R 0.537, F 0.597)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.180] [G acc: 0.109]\n",
      "1604 [D loss: (0.612)(R 0.670, F 0.554)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.277] [G acc: 0.109]\n",
      "1605 [D loss: (0.559)(R 0.579, F 0.539)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.266] [G acc: 0.078]\n",
      "1606 [D loss: (0.538)(R 0.582, F 0.494)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.252] [G acc: 0.062]\n",
      "1607 [D loss: (0.609)(R 0.591, F 0.628)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.405] [G acc: 0.109]\n",
      "1608 [D loss: (0.560)(R 0.673, F 0.448)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.371] [G acc: 0.047]\n",
      "1609 [D loss: (0.620)(R 0.565, F 0.675)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.194] [G acc: 0.141]\n",
      "1610 [D loss: (0.568)(R 0.631, F 0.505)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.266] [G acc: 0.078]\n",
      "1611 [D loss: (0.565)(R 0.591, F 0.538)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.108] [G acc: 0.094]\n",
      "1612 [D loss: (0.576)(R 0.521, F 0.632)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.204] [G acc: 0.125]\n",
      "1613 [D loss: (0.555)(R 0.596, F 0.515)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.280] [G acc: 0.062]\n",
      "1614 [D loss: (0.522)(R 0.509, F 0.535)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.225] [G acc: 0.078]\n",
      "1615 [D loss: (0.560)(R 0.527, F 0.593)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.371] [G acc: 0.078]\n",
      "1616 [D loss: (0.586)(R 0.552, F 0.620)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.186] [G acc: 0.125]\n",
      "1617 [D loss: (0.560)(R 0.551, F 0.570)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.283] [G acc: 0.141]\n",
      "1618 [D loss: (0.546)(R 0.587, F 0.506)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.391] [G acc: 0.109]\n",
      "1619 [D loss: (0.606)(R 0.532, F 0.680)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.253] [G acc: 0.094]\n",
      "1620 [D loss: (0.529)(R 0.574, F 0.484)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.204] [G acc: 0.172]\n",
      "1621 [D loss: (0.550)(R 0.532, F 0.568)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.305] [G acc: 0.109]\n",
      "1622 [D loss: (0.593)(R 0.585, F 0.600)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.172] [G acc: 0.156]\n",
      "1623 [D loss: (0.547)(R 0.504, F 0.590)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.229] [G acc: 0.125]\n",
      "1624 [D loss: (0.581)(R 0.604, F 0.559)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.195] [G acc: 0.141]\n",
      "1625 [D loss: (0.561)(R 0.598, F 0.524)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.263] [G acc: 0.094]\n",
      "1626 [D loss: (0.558)(R 0.620, F 0.495)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.267] [G acc: 0.109]\n",
      "1627 [D loss: (0.597)(R 0.576, F 0.618)] [D acc: (0.648)(0.641, 0.656)] [G loss: 1.324] [G acc: 0.078]\n",
      "1628 [D loss: (0.520)(R 0.525, F 0.516)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.257] [G acc: 0.078]\n",
      "1629 [D loss: (0.474)(R 0.476, F 0.471)] [D acc: (0.805)(0.703, 0.906)] [G loss: 1.333] [G acc: 0.109]\n",
      "1630 [D loss: (0.554)(R 0.526, F 0.583)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.283] [G acc: 0.156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1631 [D loss: (0.564)(R 0.556, F 0.573)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.267] [G acc: 0.109]\n",
      "1632 [D loss: (0.574)(R 0.503, F 0.645)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.298] [G acc: 0.156]\n",
      "1633 [D loss: (0.606)(R 0.579, F 0.633)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.337] [G acc: 0.109]\n",
      "1634 [D loss: (0.609)(R 0.653, F 0.564)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.310] [G acc: 0.062]\n",
      "1635 [D loss: (0.586)(R 0.610, F 0.562)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.284] [G acc: 0.094]\n",
      "1636 [D loss: (0.536)(R 0.547, F 0.525)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.379] [G acc: 0.062]\n",
      "1637 [D loss: (0.571)(R 0.632, F 0.510)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.260] [G acc: 0.141]\n",
      "1638 [D loss: (0.514)(R 0.535, F 0.493)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.338] [G acc: 0.125]\n",
      "1639 [D loss: (0.538)(R 0.490, F 0.586)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.251] [G acc: 0.141]\n",
      "1640 [D loss: (0.521)(R 0.569, F 0.474)] [D acc: (0.789)(0.672, 0.906)] [G loss: 1.267] [G acc: 0.172]\n",
      "1641 [D loss: (0.591)(R 0.503, F 0.679)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.212] [G acc: 0.141]\n",
      "1642 [D loss: (0.548)(R 0.590, F 0.507)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.295] [G acc: 0.094]\n",
      "1643 [D loss: (0.705)(R 0.577, F 0.832)] [D acc: (0.648)(0.625, 0.672)] [G loss: 1.408] [G acc: 0.094]\n",
      "1644 [D loss: (0.593)(R 0.671, F 0.514)] [D acc: (0.680)(0.516, 0.844)] [G loss: 1.300] [G acc: 0.125]\n",
      "1645 [D loss: (0.604)(R 0.631, F 0.576)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.305] [G acc: 0.125]\n",
      "1646 [D loss: (0.569)(R 0.588, F 0.550)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.270] [G acc: 0.094]\n",
      "1647 [D loss: (0.583)(R 0.645, F 0.520)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.292] [G acc: 0.109]\n",
      "1648 [D loss: (0.577)(R 0.504, F 0.650)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.218] [G acc: 0.172]\n",
      "1649 [D loss: (0.608)(R 0.649, F 0.567)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.244] [G acc: 0.109]\n",
      "1650 [D loss: (0.557)(R 0.591, F 0.522)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.268] [G acc: 0.094]\n",
      "1651 [D loss: (0.574)(R 0.509, F 0.639)] [D acc: (0.672)(0.688, 0.656)] [G loss: 1.171] [G acc: 0.125]\n",
      "1652 [D loss: (0.509)(R 0.488, F 0.531)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.397] [G acc: 0.109]\n",
      "1653 [D loss: (0.533)(R 0.581, F 0.485)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.303] [G acc: 0.109]\n",
      "1654 [D loss: (0.541)(R 0.522, F 0.561)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.326] [G acc: 0.109]\n",
      "1655 [D loss: (0.494)(R 0.557, F 0.431)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.220] [G acc: 0.188]\n",
      "1656 [D loss: (0.543)(R 0.495, F 0.590)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.288] [G acc: 0.109]\n",
      "1657 [D loss: (0.602)(R 0.606, F 0.598)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.335] [G acc: 0.031]\n",
      "1658 [D loss: (0.542)(R 0.542, F 0.542)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.450] [G acc: 0.141]\n",
      "1659 [D loss: (0.658)(R 0.678, F 0.637)] [D acc: (0.594)(0.531, 0.656)] [G loss: 1.309] [G acc: 0.078]\n",
      "1660 [D loss: (0.589)(R 0.616, F 0.562)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.332] [G acc: 0.078]\n",
      "1661 [D loss: (0.575)(R 0.633, F 0.517)] [D acc: (0.664)(0.547, 0.781)] [G loss: 1.209] [G acc: 0.094]\n",
      "1662 [D loss: (0.547)(R 0.490, F 0.605)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.159] [G acc: 0.172]\n",
      "1663 [D loss: (0.574)(R 0.550, F 0.597)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.167] [G acc: 0.172]\n",
      "1664 [D loss: (0.579)(R 0.609, F 0.549)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.066] [G acc: 0.219]\n",
      "1665 [D loss: (0.639)(R 0.630, F 0.647)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.099] [G acc: 0.219]\n",
      "1666 [D loss: (0.607)(R 0.611, F 0.602)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.094] [G acc: 0.156]\n",
      "1667 [D loss: (0.514)(R 0.515, F 0.513)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.258] [G acc: 0.125]\n",
      "1668 [D loss: (0.665)(R 0.716, F 0.614)] [D acc: (0.609)(0.453, 0.766)] [G loss: 1.166] [G acc: 0.031]\n",
      "1669 [D loss: (0.572)(R 0.562, F 0.583)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.160] [G acc: 0.125]\n",
      "1670 [D loss: (0.582)(R 0.592, F 0.573)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.010] [G acc: 0.297]\n",
      "1671 [D loss: (0.599)(R 0.565, F 0.634)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.162] [G acc: 0.172]\n",
      "1672 [D loss: (0.487)(R 0.454, F 0.520)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.074] [G acc: 0.203]\n",
      "1673 [D loss: (0.591)(R 0.556, F 0.625)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.172] [G acc: 0.172]\n",
      "1674 [D loss: (0.527)(R 0.463, F 0.590)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.220] [G acc: 0.141]\n",
      "1675 [D loss: (0.560)(R 0.512, F 0.609)] [D acc: (0.664)(0.672, 0.656)] [G loss: 1.170] [G acc: 0.141]\n",
      "1676 [D loss: (0.603)(R 0.590, F 0.616)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.313] [G acc: 0.047]\n",
      "1677 [D loss: (0.589)(R 0.628, F 0.550)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.234] [G acc: 0.125]\n",
      "1678 [D loss: (0.552)(R 0.502, F 0.602)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.322] [G acc: 0.094]\n",
      "1679 [D loss: (0.544)(R 0.626, F 0.461)] [D acc: (0.719)(0.547, 0.891)] [G loss: 1.299] [G acc: 0.125]\n",
      "1680 [D loss: (0.541)(R 0.571, F 0.510)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.304] [G acc: 0.125]\n",
      "1681 [D loss: (0.517)(R 0.538, F 0.497)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.315] [G acc: 0.062]\n",
      "1682 [D loss: (0.530)(R 0.533, F 0.527)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.290] [G acc: 0.141]\n",
      "1683 [D loss: (0.492)(R 0.482, F 0.503)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.318] [G acc: 0.094]\n",
      "1684 [D loss: (0.627)(R 0.589, F 0.664)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.315] [G acc: 0.031]\n",
      "1685 [D loss: (0.499)(R 0.525, F 0.474)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.351] [G acc: 0.031]\n",
      "1686 [D loss: (0.596)(R 0.719, F 0.472)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.136] [G acc: 0.156]\n",
      "1687 [D loss: (0.576)(R 0.473, F 0.679)] [D acc: (0.688)(0.719, 0.656)] [G loss: 1.260] [G acc: 0.125]\n",
      "1688 [D loss: (0.554)(R 0.552, F 0.557)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.300] [G acc: 0.047]\n",
      "1689 [D loss: (0.452)(R 0.470, F 0.434)] [D acc: (0.820)(0.734, 0.906)] [G loss: 1.196] [G acc: 0.172]\n",
      "1690 [D loss: (0.484)(R 0.484, F 0.483)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.330] [G acc: 0.094]\n",
      "1691 [D loss: (0.561)(R 0.556, F 0.566)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.267] [G acc: 0.250]\n",
      "1692 [D loss: (0.464)(R 0.407, F 0.521)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.309] [G acc: 0.062]\n",
      "1693 [D loss: (0.545)(R 0.542, F 0.548)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.344] [G acc: 0.141]\n",
      "1694 [D loss: (0.569)(R 0.539, F 0.598)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.298] [G acc: 0.156]\n",
      "1695 [D loss: (0.551)(R 0.649, F 0.453)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.274] [G acc: 0.125]\n",
      "1696 [D loss: (0.550)(R 0.460, F 0.640)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.412] [G acc: 0.109]\n",
      "1697 [D loss: (0.556)(R 0.614, F 0.499)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.215] [G acc: 0.156]\n",
      "1698 [D loss: (0.585)(R 0.517, F 0.654)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.261] [G acc: 0.141]\n",
      "1699 [D loss: (0.564)(R 0.592, F 0.536)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.320] [G acc: 0.156]\n",
      "1700 [D loss: (0.557)(R 0.575, F 0.538)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.216] [G acc: 0.125]\n",
      "1701 [D loss: (0.579)(R 0.557, F 0.602)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.287] [G acc: 0.094]\n",
      "1702 [D loss: (0.532)(R 0.497, F 0.568)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.363] [G acc: 0.078]\n",
      "1703 [D loss: (0.537)(R 0.596, F 0.478)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.302] [G acc: 0.078]\n",
      "1704 [D loss: (0.665)(R 0.654, F 0.676)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.300] [G acc: 0.109]\n",
      "1705 [D loss: (0.523)(R 0.508, F 0.539)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.278] [G acc: 0.125]\n",
      "1706 [D loss: (0.615)(R 0.658, F 0.573)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.290] [G acc: 0.125]\n",
      "1707 [D loss: (0.568)(R 0.620, F 0.515)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.213] [G acc: 0.109]\n",
      "1708 [D loss: (0.620)(R 0.548, F 0.692)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.327] [G acc: 0.062]\n",
      "1709 [D loss: (0.539)(R 0.539, F 0.539)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.274] [G acc: 0.094]\n",
      "1710 [D loss: (0.540)(R 0.559, F 0.521)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.346] [G acc: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1711 [D loss: (0.626)(R 0.543, F 0.708)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.300] [G acc: 0.141]\n",
      "1712 [D loss: (0.552)(R 0.573, F 0.532)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.175] [G acc: 0.141]\n",
      "1713 [D loss: (0.509)(R 0.439, F 0.578)] [D acc: (0.766)(0.797, 0.734)] [G loss: 1.433] [G acc: 0.062]\n",
      "1714 [D loss: (0.532)(R 0.548, F 0.516)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.430] [G acc: 0.078]\n",
      "1715 [D loss: (0.524)(R 0.534, F 0.515)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.106] [G acc: 0.281]\n",
      "1716 [D loss: (0.529)(R 0.541, F 0.517)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.357] [G acc: 0.062]\n",
      "1717 [D loss: (0.552)(R 0.599, F 0.505)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.152] [G acc: 0.141]\n",
      "1718 [D loss: (0.594)(R 0.625, F 0.563)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.343] [G acc: 0.156]\n",
      "1719 [D loss: (0.647)(R 0.555, F 0.740)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.390] [G acc: 0.047]\n",
      "1720 [D loss: (0.557)(R 0.668, F 0.447)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.330] [G acc: 0.062]\n",
      "1721 [D loss: (0.506)(R 0.541, F 0.470)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.279] [G acc: 0.156]\n",
      "1722 [D loss: (0.511)(R 0.506, F 0.517)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.352] [G acc: 0.109]\n",
      "1723 [D loss: (0.493)(R 0.498, F 0.488)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.295] [G acc: 0.125]\n",
      "1724 [D loss: (0.543)(R 0.481, F 0.605)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.394] [G acc: 0.109]\n",
      "1725 [D loss: (0.504)(R 0.478, F 0.530)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.322] [G acc: 0.109]\n",
      "1726 [D loss: (0.537)(R 0.481, F 0.594)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.291] [G acc: 0.109]\n",
      "1727 [D loss: (0.568)(R 0.467, F 0.669)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.275] [G acc: 0.141]\n",
      "1728 [D loss: (0.559)(R 0.660, F 0.458)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.246] [G acc: 0.141]\n",
      "1729 [D loss: (0.593)(R 0.571, F 0.615)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.174] [G acc: 0.125]\n",
      "1730 [D loss: (0.510)(R 0.558, F 0.462)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.405] [G acc: 0.109]\n",
      "1731 [D loss: (0.493)(R 0.429, F 0.558)] [D acc: (0.820)(0.781, 0.859)] [G loss: 1.547] [G acc: 0.094]\n",
      "1732 [D loss: (0.573)(R 0.634, F 0.512)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.235] [G acc: 0.094]\n",
      "1733 [D loss: (0.552)(R 0.534, F 0.570)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.211] [G acc: 0.141]\n",
      "1734 [D loss: (0.584)(R 0.656, F 0.512)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.219] [G acc: 0.156]\n",
      "1735 [D loss: (0.591)(R 0.541, F 0.641)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.250] [G acc: 0.109]\n",
      "1736 [D loss: (0.555)(R 0.560, F 0.549)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.276] [G acc: 0.109]\n",
      "1737 [D loss: (0.512)(R 0.512, F 0.512)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.294] [G acc: 0.094]\n",
      "1738 [D loss: (0.426)(R 0.378, F 0.473)] [D acc: (0.805)(0.781, 0.828)] [G loss: 1.314] [G acc: 0.109]\n",
      "1739 [D loss: (0.446)(R 0.401, F 0.492)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.417] [G acc: 0.078]\n",
      "1740 [D loss: (0.464)(R 0.480, F 0.448)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.453] [G acc: 0.047]\n",
      "1741 [D loss: (0.599)(R 0.595, F 0.604)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.320] [G acc: 0.141]\n",
      "1742 [D loss: (0.534)(R 0.586, F 0.483)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.368] [G acc: 0.109]\n",
      "1743 [D loss: (0.476)(R 0.482, F 0.471)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.260] [G acc: 0.219]\n",
      "1744 [D loss: (0.526)(R 0.439, F 0.612)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.392] [G acc: 0.094]\n",
      "1745 [D loss: (0.509)(R 0.559, F 0.458)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.219] [G acc: 0.203]\n",
      "1746 [D loss: (0.662)(R 0.528, F 0.796)] [D acc: (0.680)(0.734, 0.625)] [G loss: 1.442] [G acc: 0.047]\n",
      "1747 [D loss: (0.585)(R 0.626, F 0.544)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.271] [G acc: 0.094]\n",
      "1748 [D loss: (0.542)(R 0.580, F 0.504)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.386] [G acc: 0.047]\n",
      "1749 [D loss: (0.508)(R 0.505, F 0.511)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.236] [G acc: 0.109]\n",
      "1750 [D loss: (0.552)(R 0.543, F 0.562)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.322] [G acc: 0.109]\n",
      "1751 [D loss: (0.573)(R 0.516, F 0.630)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.263] [G acc: 0.156]\n",
      "1752 [D loss: (0.527)(R 0.573, F 0.481)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.343] [G acc: 0.078]\n",
      "1753 [D loss: (0.571)(R 0.601, F 0.540)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.387] [G acc: 0.109]\n",
      "1754 [D loss: (0.500)(R 0.552, F 0.448)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.185] [G acc: 0.188]\n",
      "1755 [D loss: (0.609)(R 0.632, F 0.586)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.376] [G acc: 0.094]\n",
      "1756 [D loss: (0.495)(R 0.471, F 0.520)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.350] [G acc: 0.078]\n",
      "1757 [D loss: (0.527)(R 0.505, F 0.549)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.344] [G acc: 0.031]\n",
      "1758 [D loss: (0.540)(R 0.547, F 0.533)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.464] [G acc: 0.094]\n",
      "1759 [D loss: (0.556)(R 0.572, F 0.539)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.230] [G acc: 0.141]\n",
      "1760 [D loss: (0.508)(R 0.470, F 0.546)] [D acc: (0.750)(0.781, 0.719)] [G loss: 1.269] [G acc: 0.141]\n",
      "1761 [D loss: (0.619)(R 0.794, F 0.444)] [D acc: (0.648)(0.438, 0.859)] [G loss: 1.372] [G acc: 0.078]\n",
      "1762 [D loss: (0.464)(R 0.452, F 0.475)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.240] [G acc: 0.156]\n",
      "1763 [D loss: (0.598)(R 0.546, F 0.651)] [D acc: (0.656)(0.641, 0.672)] [G loss: 1.366] [G acc: 0.078]\n",
      "1764 [D loss: (0.528)(R 0.524, F 0.531)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.383] [G acc: 0.109]\n",
      "1765 [D loss: (0.529)(R 0.508, F 0.550)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.352] [G acc: 0.094]\n",
      "1766 [D loss: (0.670)(R 0.655, F 0.684)] [D acc: (0.586)(0.516, 0.656)] [G loss: 1.430] [G acc: 0.078]\n",
      "1767 [D loss: (0.602)(R 0.676, F 0.528)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.204] [G acc: 0.156]\n",
      "1768 [D loss: (0.579)(R 0.591, F 0.567)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.259] [G acc: 0.125]\n",
      "1769 [D loss: (0.546)(R 0.600, F 0.491)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.327] [G acc: 0.125]\n",
      "1770 [D loss: (0.471)(R 0.451, F 0.491)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.195] [G acc: 0.125]\n",
      "1771 [D loss: (0.439)(R 0.417, F 0.461)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.477] [G acc: 0.125]\n",
      "1772 [D loss: (0.600)(R 0.653, F 0.546)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.475] [G acc: 0.172]\n",
      "1773 [D loss: (0.453)(R 0.458, F 0.448)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.356] [G acc: 0.109]\n",
      "1774 [D loss: (0.503)(R 0.556, F 0.449)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.274] [G acc: 0.125]\n",
      "1775 [D loss: (0.534)(R 0.444, F 0.625)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.387] [G acc: 0.141]\n",
      "1776 [D loss: (0.543)(R 0.594, F 0.492)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.371] [G acc: 0.094]\n",
      "1777 [D loss: (0.540)(R 0.552, F 0.527)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.541] [G acc: 0.000]\n",
      "1778 [D loss: (0.603)(R 0.560, F 0.647)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.316] [G acc: 0.109]\n",
      "1779 [D loss: (0.521)(R 0.550, F 0.491)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.433] [G acc: 0.125]\n",
      "1780 [D loss: (0.584)(R 0.614, F 0.555)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.361] [G acc: 0.156]\n",
      "1781 [D loss: (0.541)(R 0.453, F 0.629)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.427] [G acc: 0.062]\n",
      "1782 [D loss: (0.520)(R 0.566, F 0.474)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.379] [G acc: 0.078]\n",
      "1783 [D loss: (0.551)(R 0.516, F 0.587)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.319] [G acc: 0.156]\n",
      "1784 [D loss: (0.525)(R 0.593, F 0.456)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.280] [G acc: 0.141]\n",
      "1785 [D loss: (0.524)(R 0.508, F 0.540)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.262] [G acc: 0.125]\n",
      "1786 [D loss: (0.643)(R 0.675, F 0.610)] [D acc: (0.594)(0.547, 0.641)] [G loss: 1.387] [G acc: 0.078]\n",
      "1787 [D loss: (0.608)(R 0.674, F 0.543)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.183] [G acc: 0.156]\n",
      "1788 [D loss: (0.587)(R 0.648, F 0.526)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.255] [G acc: 0.141]\n",
      "1789 [D loss: (0.514)(R 0.549, F 0.478)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.284] [G acc: 0.141]\n",
      "1790 [D loss: (0.536)(R 0.495, F 0.578)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.238] [G acc: 0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791 [D loss: (0.605)(R 0.604, F 0.605)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.276] [G acc: 0.094]\n",
      "1792 [D loss: (0.507)(R 0.561, F 0.454)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.273] [G acc: 0.125]\n",
      "1793 [D loss: (0.498)(R 0.439, F 0.557)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.343] [G acc: 0.188]\n",
      "1794 [D loss: (0.634)(R 0.536, F 0.732)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.286] [G acc: 0.078]\n",
      "1795 [D loss: (0.492)(R 0.470, F 0.515)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.362] [G acc: 0.094]\n",
      "1796 [D loss: (0.510)(R 0.513, F 0.507)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.439] [G acc: 0.062]\n",
      "1797 [D loss: (0.539)(R 0.589, F 0.490)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.406] [G acc: 0.109]\n",
      "1798 [D loss: (0.582)(R 0.548, F 0.616)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.237] [G acc: 0.203]\n",
      "1799 [D loss: (0.609)(R 0.603, F 0.615)] [D acc: (0.625)(0.578, 0.672)] [G loss: 1.257] [G acc: 0.109]\n",
      "1800 [D loss: (0.608)(R 0.709, F 0.508)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.260] [G acc: 0.062]\n",
      "1801 [D loss: (0.511)(R 0.519, F 0.502)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.264] [G acc: 0.094]\n",
      "1802 [D loss: (0.464)(R 0.502, F 0.426)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.263] [G acc: 0.125]\n",
      "1803 [D loss: (0.586)(R 0.414, F 0.758)] [D acc: (0.672)(0.734, 0.609)] [G loss: 1.514] [G acc: 0.047]\n",
      "1804 [D loss: (0.515)(R 0.589, F 0.441)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.326] [G acc: 0.047]\n",
      "1805 [D loss: (0.474)(R 0.492, F 0.456)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.258] [G acc: 0.156]\n",
      "1806 [D loss: (0.517)(R 0.533, F 0.500)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.201] [G acc: 0.188]\n",
      "1807 [D loss: (0.594)(R 0.496, F 0.692)] [D acc: (0.664)(0.688, 0.641)] [G loss: 1.241] [G acc: 0.188]\n",
      "1808 [D loss: (0.577)(R 0.568, F 0.587)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.355] [G acc: 0.094]\n",
      "1809 [D loss: (0.598)(R 0.724, F 0.471)] [D acc: (0.664)(0.500, 0.828)] [G loss: 1.344] [G acc: 0.109]\n",
      "1810 [D loss: (0.486)(R 0.487, F 0.486)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.294] [G acc: 0.062]\n",
      "1811 [D loss: (0.486)(R 0.470, F 0.503)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.277] [G acc: 0.141]\n",
      "1812 [D loss: (0.579)(R 0.534, F 0.624)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.332] [G acc: 0.031]\n",
      "1813 [D loss: (0.572)(R 0.658, F 0.486)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.189] [G acc: 0.141]\n",
      "1814 [D loss: (0.443)(R 0.433, F 0.453)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.284] [G acc: 0.156]\n",
      "1815 [D loss: (0.609)(R 0.542, F 0.676)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.398] [G acc: 0.125]\n",
      "1816 [D loss: (0.522)(R 0.559, F 0.486)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.377] [G acc: 0.125]\n",
      "1817 [D loss: (0.574)(R 0.658, F 0.489)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.205] [G acc: 0.219]\n",
      "1818 [D loss: (0.508)(R 0.580, F 0.436)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.239] [G acc: 0.109]\n",
      "1819 [D loss: (0.556)(R 0.446, F 0.666)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.216] [G acc: 0.141]\n",
      "1820 [D loss: (0.489)(R 0.484, F 0.494)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.272] [G acc: 0.125]\n",
      "1821 [D loss: (0.517)(R 0.577, F 0.457)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.426] [G acc: 0.109]\n",
      "1822 [D loss: (0.543)(R 0.518, F 0.568)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.355] [G acc: 0.125]\n",
      "1823 [D loss: (0.597)(R 0.588, F 0.606)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.338] [G acc: 0.094]\n",
      "1824 [D loss: (0.536)(R 0.559, F 0.514)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.447] [G acc: 0.078]\n",
      "1825 [D loss: (0.601)(R 0.478, F 0.725)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.343] [G acc: 0.125]\n",
      "1826 [D loss: (0.609)(R 0.703, F 0.516)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.366] [G acc: 0.078]\n",
      "1827 [D loss: (0.533)(R 0.510, F 0.556)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.386] [G acc: 0.078]\n",
      "1828 [D loss: (0.563)(R 0.575, F 0.551)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.330] [G acc: 0.078]\n",
      "1829 [D loss: (0.613)(R 0.607, F 0.618)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.208] [G acc: 0.109]\n",
      "1830 [D loss: (0.575)(R 0.671, F 0.480)] [D acc: (0.672)(0.500, 0.844)] [G loss: 1.360] [G acc: 0.125]\n",
      "1831 [D loss: (0.581)(R 0.574, F 0.587)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.305] [G acc: 0.047]\n",
      "1832 [D loss: (0.506)(R 0.557, F 0.455)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.327] [G acc: 0.078]\n",
      "1833 [D loss: (0.581)(R 0.537, F 0.625)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.211] [G acc: 0.094]\n",
      "1834 [D loss: (0.504)(R 0.557, F 0.450)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.151] [G acc: 0.109]\n",
      "1835 [D loss: (0.571)(R 0.532, F 0.609)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.313] [G acc: 0.109]\n",
      "1836 [D loss: (0.580)(R 0.662, F 0.498)] [D acc: (0.672)(0.516, 0.828)] [G loss: 1.213] [G acc: 0.125]\n",
      "1837 [D loss: (0.588)(R 0.617, F 0.559)] [D acc: (0.648)(0.500, 0.797)] [G loss: 1.121] [G acc: 0.203]\n",
      "1838 [D loss: (0.538)(R 0.598, F 0.478)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.172] [G acc: 0.141]\n",
      "1839 [D loss: (0.532)(R 0.542, F 0.522)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.145] [G acc: 0.203]\n",
      "1840 [D loss: (0.593)(R 0.400, F 0.786)] [D acc: (0.703)(0.766, 0.641)] [G loss: 1.337] [G acc: 0.109]\n",
      "1841 [D loss: (0.518)(R 0.612, F 0.423)] [D acc: (0.727)(0.562, 0.891)] [G loss: 1.297] [G acc: 0.094]\n",
      "1842 [D loss: (0.535)(R 0.555, F 0.516)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.178] [G acc: 0.219]\n",
      "1843 [D loss: (0.534)(R 0.496, F 0.572)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.302] [G acc: 0.094]\n",
      "1844 [D loss: (0.580)(R 0.528, F 0.633)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.408] [G acc: 0.094]\n",
      "1845 [D loss: (0.543)(R 0.567, F 0.520)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.311] [G acc: 0.109]\n",
      "1846 [D loss: (0.549)(R 0.568, F 0.530)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.322] [G acc: 0.078]\n",
      "1847 [D loss: (0.544)(R 0.630, F 0.458)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.195] [G acc: 0.188]\n",
      "1848 [D loss: (0.530)(R 0.540, F 0.520)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.248] [G acc: 0.125]\n",
      "1849 [D loss: (0.497)(R 0.461, F 0.533)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.414] [G acc: 0.094]\n",
      "1850 [D loss: (0.518)(R 0.540, F 0.495)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.340] [G acc: 0.094]\n",
      "1851 [D loss: (0.587)(R 0.495, F 0.679)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.266] [G acc: 0.078]\n",
      "1852 [D loss: (0.536)(R 0.621, F 0.452)] [D acc: (0.758)(0.609, 0.906)] [G loss: 1.321] [G acc: 0.062]\n",
      "1853 [D loss: (0.609)(R 0.579, F 0.639)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.282] [G acc: 0.078]\n",
      "1854 [D loss: (0.693)(R 0.728, F 0.659)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.209] [G acc: 0.109]\n",
      "1855 [D loss: (0.560)(R 0.561, F 0.558)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.163] [G acc: 0.078]\n",
      "1856 [D loss: (0.588)(R 0.573, F 0.603)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.313] [G acc: 0.141]\n",
      "1857 [D loss: (0.603)(R 0.626, F 0.580)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.247] [G acc: 0.078]\n",
      "1858 [D loss: (0.577)(R 0.580, F 0.573)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.298] [G acc: 0.062]\n",
      "1859 [D loss: (0.582)(R 0.592, F 0.572)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.098] [G acc: 0.062]\n",
      "1860 [D loss: (0.560)(R 0.644, F 0.476)] [D acc: (0.711)(0.547, 0.875)] [G loss: 1.205] [G acc: 0.094]\n",
      "1861 [D loss: (0.534)(R 0.496, F 0.572)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.167] [G acc: 0.172]\n",
      "1862 [D loss: (0.571)(R 0.509, F 0.632)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.388] [G acc: 0.109]\n",
      "1863 [D loss: (0.550)(R 0.557, F 0.543)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.278] [G acc: 0.047]\n",
      "1864 [D loss: (0.525)(R 0.420, F 0.630)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.269] [G acc: 0.125]\n",
      "1865 [D loss: (0.557)(R 0.639, F 0.475)] [D acc: (0.727)(0.562, 0.891)] [G loss: 1.201] [G acc: 0.219]\n",
      "1866 [D loss: (0.581)(R 0.569, F 0.593)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.219] [G acc: 0.125]\n",
      "1867 [D loss: (0.598)(R 0.625, F 0.571)] [D acc: (0.648)(0.516, 0.781)] [G loss: 1.252] [G acc: 0.094]\n",
      "1868 [D loss: (0.555)(R 0.494, F 0.617)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.299] [G acc: 0.062]\n",
      "1869 [D loss: (0.530)(R 0.576, F 0.485)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.305] [G acc: 0.125]\n",
      "1870 [D loss: (0.607)(R 0.680, F 0.535)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.256] [G acc: 0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1871 [D loss: (0.521)(R 0.501, F 0.541)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.281] [G acc: 0.109]\n",
      "1872 [D loss: (0.569)(R 0.586, F 0.553)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.450] [G acc: 0.094]\n",
      "1873 [D loss: (0.508)(R 0.469, F 0.546)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.297] [G acc: 0.062]\n",
      "1874 [D loss: (0.523)(R 0.573, F 0.473)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.333] [G acc: 0.078]\n",
      "1875 [D loss: (0.545)(R 0.492, F 0.598)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.227] [G acc: 0.141]\n",
      "1876 [D loss: (0.515)(R 0.582, F 0.448)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.295] [G acc: 0.078]\n",
      "1877 [D loss: (0.530)(R 0.568, F 0.493)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.305] [G acc: 0.172]\n",
      "1878 [D loss: (0.582)(R 0.544, F 0.620)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.309] [G acc: 0.156]\n",
      "1879 [D loss: (0.568)(R 0.583, F 0.553)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.327] [G acc: 0.125]\n",
      "1880 [D loss: (0.507)(R 0.444, F 0.571)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.419] [G acc: 0.062]\n",
      "1881 [D loss: (0.437)(R 0.457, F 0.416)] [D acc: (0.805)(0.688, 0.922)] [G loss: 1.267] [G acc: 0.172]\n",
      "1882 [D loss: (0.509)(R 0.479, F 0.539)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.334] [G acc: 0.125]\n",
      "1883 [D loss: (0.592)(R 0.567, F 0.616)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.360] [G acc: 0.109]\n",
      "1884 [D loss: (0.558)(R 0.624, F 0.492)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.228] [G acc: 0.141]\n",
      "1885 [D loss: (0.632)(R 0.631, F 0.634)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.323] [G acc: 0.094]\n",
      "1886 [D loss: (0.519)(R 0.562, F 0.476)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.171] [G acc: 0.203]\n",
      "1887 [D loss: (0.513)(R 0.518, F 0.509)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.264] [G acc: 0.109]\n",
      "1888 [D loss: (0.595)(R 0.555, F 0.636)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.324] [G acc: 0.062]\n",
      "1889 [D loss: (0.512)(R 0.529, F 0.495)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.248] [G acc: 0.062]\n",
      "1890 [D loss: (0.497)(R 0.492, F 0.503)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.328] [G acc: 0.125]\n",
      "1891 [D loss: (0.598)(R 0.552, F 0.645)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.260] [G acc: 0.125]\n",
      "1892 [D loss: (0.567)(R 0.607, F 0.526)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.242] [G acc: 0.156]\n",
      "1893 [D loss: (0.481)(R 0.463, F 0.498)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.226] [G acc: 0.172]\n",
      "1894 [D loss: (0.586)(R 0.580, F 0.592)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.348] [G acc: 0.094]\n",
      "1895 [D loss: (0.586)(R 0.440, F 0.731)] [D acc: (0.711)(0.766, 0.656)] [G loss: 1.261] [G acc: 0.141]\n",
      "1896 [D loss: (0.618)(R 0.689, F 0.547)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.351] [G acc: 0.062]\n",
      "1897 [D loss: (0.560)(R 0.549, F 0.572)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.202] [G acc: 0.156]\n",
      "1898 [D loss: (0.587)(R 0.640, F 0.535)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.281] [G acc: 0.141]\n",
      "1899 [D loss: (0.587)(R 0.590, F 0.585)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.251] [G acc: 0.141]\n",
      "1900 [D loss: (0.560)(R 0.510, F 0.609)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.248] [G acc: 0.141]\n",
      "1901 [D loss: (0.544)(R 0.624, F 0.464)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.432] [G acc: 0.078]\n",
      "1902 [D loss: (0.578)(R 0.562, F 0.594)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.357] [G acc: 0.125]\n",
      "1903 [D loss: (0.545)(R 0.553, F 0.536)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.325] [G acc: 0.109]\n",
      "1904 [D loss: (0.605)(R 0.660, F 0.550)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.323] [G acc: 0.141]\n",
      "1905 [D loss: (0.556)(R 0.655, F 0.456)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.366] [G acc: 0.109]\n",
      "1906 [D loss: (0.529)(R 0.561, F 0.496)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.193] [G acc: 0.141]\n",
      "1907 [D loss: (0.524)(R 0.438, F 0.611)] [D acc: (0.766)(0.781, 0.750)] [G loss: 1.373] [G acc: 0.078]\n",
      "1908 [D loss: (0.638)(R 0.678, F 0.598)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.312] [G acc: 0.094]\n",
      "1909 [D loss: (0.563)(R 0.588, F 0.538)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.232] [G acc: 0.125]\n",
      "1910 [D loss: (0.500)(R 0.450, F 0.550)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.366] [G acc: 0.031]\n",
      "1911 [D loss: (0.524)(R 0.567, F 0.481)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.269] [G acc: 0.109]\n",
      "1912 [D loss: (0.657)(R 0.572, F 0.743)] [D acc: (0.664)(0.656, 0.672)] [G loss: 1.386] [G acc: 0.125]\n",
      "1913 [D loss: (0.519)(R 0.542, F 0.495)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.290] [G acc: 0.109]\n",
      "1914 [D loss: (0.545)(R 0.539, F 0.552)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.310] [G acc: 0.062]\n",
      "1915 [D loss: (0.578)(R 0.642, F 0.514)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.306] [G acc: 0.047]\n",
      "1916 [D loss: (0.507)(R 0.468, F 0.546)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.282] [G acc: 0.094]\n",
      "1917 [D loss: (0.537)(R 0.538, F 0.536)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.337] [G acc: 0.109]\n",
      "1918 [D loss: (0.569)(R 0.568, F 0.571)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.269] [G acc: 0.078]\n",
      "1919 [D loss: (0.556)(R 0.607, F 0.505)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.273] [G acc: 0.062]\n",
      "1920 [D loss: (0.563)(R 0.542, F 0.584)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.214] [G acc: 0.156]\n",
      "1921 [D loss: (0.566)(R 0.600, F 0.531)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.229] [G acc: 0.156]\n",
      "1922 [D loss: (0.445)(R 0.438, F 0.452)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.284] [G acc: 0.141]\n",
      "1923 [D loss: (0.486)(R 0.474, F 0.497)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.338] [G acc: 0.078]\n",
      "1924 [D loss: (0.544)(R 0.585, F 0.503)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.260] [G acc: 0.141]\n",
      "1925 [D loss: (0.511)(R 0.475, F 0.548)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.332] [G acc: 0.109]\n",
      "1926 [D loss: (0.490)(R 0.418, F 0.563)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.329] [G acc: 0.047]\n",
      "1927 [D loss: (0.551)(R 0.618, F 0.483)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.492] [G acc: 0.047]\n",
      "1928 [D loss: (0.607)(R 0.623, F 0.590)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.373] [G acc: 0.125]\n",
      "1929 [D loss: (0.646)(R 0.726, F 0.566)] [D acc: (0.617)(0.500, 0.734)] [G loss: 1.259] [G acc: 0.078]\n",
      "1930 [D loss: (0.551)(R 0.457, F 0.644)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.237] [G acc: 0.109]\n",
      "1931 [D loss: (0.521)(R 0.564, F 0.477)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.347] [G acc: 0.062]\n",
      "1932 [D loss: (0.525)(R 0.524, F 0.526)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.291] [G acc: 0.125]\n",
      "1933 [D loss: (0.605)(R 0.724, F 0.485)] [D acc: (0.672)(0.516, 0.828)] [G loss: 1.358] [G acc: 0.047]\n",
      "1934 [D loss: (0.558)(R 0.440, F 0.676)] [D acc: (0.656)(0.703, 0.609)] [G loss: 1.317] [G acc: 0.094]\n",
      "1935 [D loss: (0.536)(R 0.559, F 0.513)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.229] [G acc: 0.188]\n",
      "1936 [D loss: (0.561)(R 0.488, F 0.634)] [D acc: (0.672)(0.703, 0.641)] [G loss: 1.279] [G acc: 0.156]\n",
      "1937 [D loss: (0.488)(R 0.512, F 0.464)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.391] [G acc: 0.062]\n",
      "1938 [D loss: (0.587)(R 0.595, F 0.579)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.415] [G acc: 0.062]\n",
      "1939 [D loss: (0.546)(R 0.601, F 0.491)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.237] [G acc: 0.094]\n",
      "1940 [D loss: (0.588)(R 0.588, F 0.587)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.324] [G acc: 0.047]\n",
      "1941 [D loss: (0.602)(R 0.654, F 0.550)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.257] [G acc: 0.141]\n",
      "1942 [D loss: (0.619)(R 0.587, F 0.651)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.172] [G acc: 0.188]\n",
      "1943 [D loss: (0.536)(R 0.589, F 0.484)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.351] [G acc: 0.047]\n",
      "1944 [D loss: (0.587)(R 0.625, F 0.548)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.303] [G acc: 0.047]\n",
      "1945 [D loss: (0.532)(R 0.604, F 0.461)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.206] [G acc: 0.172]\n",
      "1946 [D loss: (0.500)(R 0.494, F 0.507)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.310] [G acc: 0.156]\n",
      "1947 [D loss: (0.501)(R 0.475, F 0.528)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.284] [G acc: 0.141]\n",
      "1948 [D loss: (0.597)(R 0.539, F 0.654)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.258] [G acc: 0.094]\n",
      "1949 [D loss: (0.521)(R 0.509, F 0.533)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.351] [G acc: 0.047]\n",
      "1950 [D loss: (0.561)(R 0.588, F 0.533)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.218] [G acc: 0.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951 [D loss: (0.578)(R 0.538, F 0.618)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.384] [G acc: 0.094]\n",
      "1952 [D loss: (0.632)(R 0.760, F 0.505)] [D acc: (0.633)(0.484, 0.781)] [G loss: 1.298] [G acc: 0.078]\n",
      "1953 [D loss: (0.513)(R 0.523, F 0.503)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.194] [G acc: 0.141]\n",
      "1954 [D loss: (0.564)(R 0.667, F 0.461)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.285] [G acc: 0.156]\n",
      "1955 [D loss: (0.661)(R 0.651, F 0.671)] [D acc: (0.617)(0.547, 0.688)] [G loss: 1.334] [G acc: 0.062]\n",
      "1956 [D loss: (0.538)(R 0.548, F 0.528)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.228] [G acc: 0.188]\n",
      "1957 [D loss: (0.628)(R 0.645, F 0.612)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.268] [G acc: 0.141]\n",
      "1958 [D loss: (0.534)(R 0.620, F 0.448)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.454] [G acc: 0.125]\n",
      "1959 [D loss: (0.571)(R 0.611, F 0.532)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.331] [G acc: 0.125]\n",
      "1960 [D loss: (0.567)(R 0.559, F 0.574)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.182] [G acc: 0.156]\n",
      "1961 [D loss: (0.633)(R 0.650, F 0.617)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.244] [G acc: 0.109]\n",
      "1962 [D loss: (0.614)(R 0.648, F 0.579)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.203] [G acc: 0.078]\n",
      "1963 [D loss: (0.555)(R 0.575, F 0.534)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.182] [G acc: 0.125]\n",
      "1964 [D loss: (0.548)(R 0.520, F 0.576)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.145] [G acc: 0.078]\n",
      "1965 [D loss: (0.515)(R 0.512, F 0.517)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.175] [G acc: 0.188]\n",
      "1966 [D loss: (0.542)(R 0.517, F 0.567)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.234] [G acc: 0.125]\n",
      "1967 [D loss: (0.532)(R 0.526, F 0.538)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.150] [G acc: 0.109]\n",
      "1968 [D loss: (0.578)(R 0.519, F 0.638)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.238] [G acc: 0.109]\n",
      "1969 [D loss: (0.622)(R 0.722, F 0.521)] [D acc: (0.641)(0.469, 0.812)] [G loss: 1.204] [G acc: 0.141]\n",
      "1970 [D loss: (0.595)(R 0.599, F 0.592)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.170] [G acc: 0.109]\n",
      "1971 [D loss: (0.558)(R 0.617, F 0.499)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.249] [G acc: 0.203]\n",
      "1972 [D loss: (0.593)(R 0.676, F 0.509)] [D acc: (0.680)(0.531, 0.828)] [G loss: 1.191] [G acc: 0.156]\n",
      "1973 [D loss: (0.635)(R 0.502, F 0.767)] [D acc: (0.680)(0.734, 0.625)] [G loss: 1.148] [G acc: 0.094]\n",
      "1974 [D loss: (0.594)(R 0.646, F 0.541)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.178] [G acc: 0.094]\n",
      "1975 [D loss: (0.580)(R 0.648, F 0.511)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.193] [G acc: 0.047]\n",
      "1976 [D loss: (0.469)(R 0.467, F 0.472)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.292] [G acc: 0.109]\n",
      "1977 [D loss: (0.548)(R 0.550, F 0.547)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.248] [G acc: 0.156]\n",
      "1978 [D loss: (0.535)(R 0.515, F 0.556)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.344] [G acc: 0.172]\n",
      "1979 [D loss: (0.470)(R 0.465, F 0.476)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.272] [G acc: 0.156]\n",
      "1980 [D loss: (0.684)(R 0.733, F 0.634)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.320] [G acc: 0.141]\n",
      "1981 [D loss: (0.532)(R 0.571, F 0.493)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.362] [G acc: 0.094]\n",
      "1982 [D loss: (0.505)(R 0.439, F 0.571)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.274] [G acc: 0.047]\n",
      "1983 [D loss: (0.546)(R 0.511, F 0.582)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.314] [G acc: 0.094]\n",
      "1984 [D loss: (0.596)(R 0.630, F 0.562)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.363] [G acc: 0.125]\n",
      "1985 [D loss: (0.564)(R 0.539, F 0.589)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.444] [G acc: 0.031]\n",
      "1986 [D loss: (0.619)(R 0.721, F 0.517)] [D acc: (0.641)(0.516, 0.766)] [G loss: 1.220] [G acc: 0.109]\n",
      "1987 [D loss: (0.567)(R 0.531, F 0.602)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.311] [G acc: 0.141]\n",
      "1988 [D loss: (0.569)(R 0.604, F 0.534)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.300] [G acc: 0.141]\n",
      "1989 [D loss: (0.603)(R 0.587, F 0.620)] [D acc: (0.633)(0.562, 0.703)] [G loss: 1.184] [G acc: 0.188]\n",
      "1990 [D loss: (0.597)(R 0.475, F 0.720)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.172] [G acc: 0.109]\n",
      "1991 [D loss: (0.551)(R 0.563, F 0.539)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.227] [G acc: 0.141]\n",
      "1992 [D loss: (0.573)(R 0.640, F 0.506)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.233] [G acc: 0.141]\n",
      "1993 [D loss: (0.606)(R 0.673, F 0.540)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.131] [G acc: 0.156]\n",
      "1994 [D loss: (0.539)(R 0.456, F 0.621)] [D acc: (0.781)(0.797, 0.766)] [G loss: 1.249] [G acc: 0.125]\n",
      "1995 [D loss: (0.605)(R 0.627, F 0.584)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.232] [G acc: 0.109]\n",
      "1996 [D loss: (0.560)(R 0.647, F 0.473)] [D acc: (0.672)(0.516, 0.828)] [G loss: 1.377] [G acc: 0.078]\n",
      "1997 [D loss: (0.572)(R 0.523, F 0.622)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.306] [G acc: 0.141]\n",
      "1998 [D loss: (0.522)(R 0.556, F 0.488)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.372] [G acc: 0.078]\n",
      "1999 [D loss: (0.557)(R 0.561, F 0.552)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.299] [G acc: 0.109]\n",
      "2000 [D loss: (0.509)(R 0.515, F 0.503)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.440] [G acc: 0.109]\n",
      "2001 [D loss: (0.578)(R 0.535, F 0.621)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.438] [G acc: 0.094]\n",
      "2002 [D loss: (0.612)(R 0.602, F 0.622)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.227] [G acc: 0.078]\n",
      "2003 [D loss: (0.504)(R 0.558, F 0.450)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.311] [G acc: 0.125]\n",
      "2004 [D loss: (0.530)(R 0.561, F 0.499)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.241] [G acc: 0.094]\n",
      "2005 [D loss: (0.577)(R 0.480, F 0.673)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.359] [G acc: 0.094]\n",
      "2006 [D loss: (0.533)(R 0.496, F 0.569)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.388] [G acc: 0.125]\n",
      "2007 [D loss: (0.520)(R 0.555, F 0.485)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.332] [G acc: 0.062]\n",
      "2008 [D loss: (0.540)(R 0.607, F 0.473)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.451] [G acc: 0.078]\n",
      "2009 [D loss: (0.533)(R 0.558, F 0.509)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.464] [G acc: 0.094]\n",
      "2010 [D loss: (0.545)(R 0.530, F 0.560)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.383] [G acc: 0.094]\n",
      "2011 [D loss: (0.694)(R 0.622, F 0.767)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.294] [G acc: 0.062]\n",
      "2012 [D loss: (0.572)(R 0.641, F 0.503)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.273] [G acc: 0.094]\n",
      "2013 [D loss: (0.432)(R 0.395, F 0.469)] [D acc: (0.805)(0.812, 0.797)] [G loss: 1.204] [G acc: 0.094]\n",
      "2014 [D loss: (0.562)(R 0.610, F 0.514)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.383] [G acc: 0.109]\n",
      "2015 [D loss: (0.513)(R 0.470, F 0.557)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.413] [G acc: 0.094]\n",
      "2016 [D loss: (0.534)(R 0.435, F 0.633)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.310] [G acc: 0.078]\n",
      "2017 [D loss: (0.549)(R 0.631, F 0.467)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.183] [G acc: 0.141]\n",
      "2018 [D loss: (0.588)(R 0.526, F 0.651)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.259] [G acc: 0.094]\n",
      "2019 [D loss: (0.610)(R 0.684, F 0.536)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.307] [G acc: 0.094]\n",
      "2020 [D loss: (0.557)(R 0.589, F 0.526)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.135] [G acc: 0.156]\n",
      "2021 [D loss: (0.612)(R 0.583, F 0.642)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.198] [G acc: 0.094]\n",
      "2022 [D loss: (0.595)(R 0.542, F 0.648)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.239] [G acc: 0.141]\n",
      "2023 [D loss: (0.476)(R 0.504, F 0.448)] [D acc: (0.820)(0.734, 0.906)] [G loss: 1.286] [G acc: 0.109]\n",
      "2024 [D loss: (0.559)(R 0.502, F 0.617)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.278] [G acc: 0.078]\n",
      "2025 [D loss: (0.548)(R 0.526, F 0.570)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.313] [G acc: 0.094]\n",
      "2026 [D loss: (0.618)(R 0.614, F 0.622)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.366] [G acc: 0.078]\n",
      "2027 [D loss: (0.604)(R 0.638, F 0.571)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.357] [G acc: 0.031]\n",
      "2028 [D loss: (0.587)(R 0.628, F 0.546)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.334] [G acc: 0.031]\n",
      "2029 [D loss: (0.605)(R 0.661, F 0.548)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.250] [G acc: 0.109]\n",
      "2030 [D loss: (0.553)(R 0.577, F 0.529)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.273] [G acc: 0.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2031 [D loss: (0.522)(R 0.568, F 0.475)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.194] [G acc: 0.172]\n",
      "2032 [D loss: (0.580)(R 0.616, F 0.543)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.198] [G acc: 0.141]\n",
      "2033 [D loss: (0.626)(R 0.646, F 0.607)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.159] [G acc: 0.172]\n",
      "2034 [D loss: (0.474)(R 0.471, F 0.476)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.126] [G acc: 0.188]\n",
      "2035 [D loss: (0.641)(R 0.563, F 0.719)] [D acc: (0.625)(0.641, 0.609)] [G loss: 1.434] [G acc: 0.062]\n",
      "2036 [D loss: (0.565)(R 0.644, F 0.485)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.274] [G acc: 0.094]\n",
      "2037 [D loss: (0.507)(R 0.501, F 0.513)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.426] [G acc: 0.031]\n",
      "2038 [D loss: (0.554)(R 0.564, F 0.544)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.316] [G acc: 0.141]\n",
      "2039 [D loss: (0.507)(R 0.525, F 0.489)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.354] [G acc: 0.094]\n",
      "2040 [D loss: (0.576)(R 0.579, F 0.574)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.333] [G acc: 0.125]\n",
      "2041 [D loss: (0.552)(R 0.567, F 0.537)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.080] [G acc: 0.172]\n",
      "2042 [D loss: (0.541)(R 0.524, F 0.558)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.343] [G acc: 0.047]\n",
      "2043 [D loss: (0.588)(R 0.536, F 0.641)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.391] [G acc: 0.016]\n",
      "2044 [D loss: (0.484)(R 0.479, F 0.489)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.215] [G acc: 0.125]\n",
      "2045 [D loss: (0.544)(R 0.555, F 0.534)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.314] [G acc: 0.047]\n",
      "2046 [D loss: (0.431)(R 0.430, F 0.432)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.300] [G acc: 0.094]\n",
      "2047 [D loss: (0.533)(R 0.497, F 0.569)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.368] [G acc: 0.125]\n",
      "2048 [D loss: (0.513)(R 0.476, F 0.550)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.316] [G acc: 0.078]\n",
      "2049 [D loss: (0.516)(R 0.510, F 0.522)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.294] [G acc: 0.078]\n",
      "2050 [D loss: (0.592)(R 0.584, F 0.600)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.309] [G acc: 0.031]\n",
      "2051 [D loss: (0.531)(R 0.514, F 0.549)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.284] [G acc: 0.156]\n",
      "2052 [D loss: (0.548)(R 0.499, F 0.596)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.355] [G acc: 0.047]\n",
      "2053 [D loss: (0.602)(R 0.591, F 0.613)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.224] [G acc: 0.188]\n",
      "2054 [D loss: (0.520)(R 0.639, F 0.402)] [D acc: (0.773)(0.609, 0.938)] [G loss: 1.415] [G acc: 0.031]\n",
      "2055 [D loss: (0.590)(R 0.632, F 0.548)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.222] [G acc: 0.172]\n",
      "2056 [D loss: (0.493)(R 0.497, F 0.489)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.340] [G acc: 0.109]\n",
      "2057 [D loss: (0.573)(R 0.453, F 0.693)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.218] [G acc: 0.188]\n",
      "2058 [D loss: (0.618)(R 0.612, F 0.625)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.302] [G acc: 0.047]\n",
      "2059 [D loss: (0.550)(R 0.562, F 0.537)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.333] [G acc: 0.156]\n",
      "2060 [D loss: (0.491)(R 0.476, F 0.506)] [D acc: (0.820)(0.781, 0.859)] [G loss: 1.314] [G acc: 0.188]\n",
      "2061 [D loss: (0.531)(R 0.525, F 0.538)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.432] [G acc: 0.125]\n",
      "2062 [D loss: (0.524)(R 0.583, F 0.465)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.454] [G acc: 0.062]\n",
      "2063 [D loss: (0.580)(R 0.506, F 0.654)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.504] [G acc: 0.078]\n",
      "2064 [D loss: (0.540)(R 0.562, F 0.518)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.414] [G acc: 0.109]\n",
      "2065 [D loss: (0.516)(R 0.540, F 0.492)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.320] [G acc: 0.109]\n",
      "2066 [D loss: (0.468)(R 0.458, F 0.478)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.417] [G acc: 0.047]\n",
      "2067 [D loss: (0.488)(R 0.459, F 0.518)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.523] [G acc: 0.141]\n",
      "2068 [D loss: (0.534)(R 0.496, F 0.572)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.462] [G acc: 0.109]\n",
      "2069 [D loss: (0.568)(R 0.674, F 0.463)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.461] [G acc: 0.078]\n",
      "2070 [D loss: (0.557)(R 0.654, F 0.460)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.436] [G acc: 0.109]\n",
      "2071 [D loss: (0.668)(R 0.673, F 0.663)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.460] [G acc: 0.078]\n",
      "2072 [D loss: (0.545)(R 0.604, F 0.487)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.323] [G acc: 0.172]\n",
      "2073 [D loss: (0.604)(R 0.511, F 0.697)] [D acc: (0.703)(0.750, 0.656)] [G loss: 1.392] [G acc: 0.125]\n",
      "2074 [D loss: (0.529)(R 0.530, F 0.528)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.661] [G acc: 0.141]\n",
      "2075 [D loss: (0.663)(R 0.760, F 0.566)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.231] [G acc: 0.172]\n",
      "2076 [D loss: (0.503)(R 0.541, F 0.464)] [D acc: (0.812)(0.719, 0.906)] [G loss: 1.354] [G acc: 0.047]\n",
      "2077 [D loss: (0.536)(R 0.522, F 0.550)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.360] [G acc: 0.188]\n",
      "2078 [D loss: (0.506)(R 0.567, F 0.445)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.301] [G acc: 0.109]\n",
      "2079 [D loss: (0.593)(R 0.594, F 0.592)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.317] [G acc: 0.109]\n",
      "2080 [D loss: (0.534)(R 0.568, F 0.499)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.187] [G acc: 0.203]\n",
      "2081 [D loss: (0.499)(R 0.494, F 0.505)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.420] [G acc: 0.031]\n",
      "2082 [D loss: (0.528)(R 0.549, F 0.507)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.246] [G acc: 0.156]\n",
      "2083 [D loss: (0.604)(R 0.523, F 0.684)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.395] [G acc: 0.094]\n",
      "2084 [D loss: (0.494)(R 0.553, F 0.435)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.282] [G acc: 0.094]\n",
      "2085 [D loss: (0.608)(R 0.617, F 0.599)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.245] [G acc: 0.141]\n",
      "2086 [D loss: (0.610)(R 0.595, F 0.624)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.362] [G acc: 0.047]\n",
      "2087 [D loss: (0.501)(R 0.553, F 0.449)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.310] [G acc: 0.141]\n",
      "2088 [D loss: (0.535)(R 0.566, F 0.504)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.199] [G acc: 0.125]\n",
      "2089 [D loss: (0.483)(R 0.560, F 0.406)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.221] [G acc: 0.188]\n",
      "2090 [D loss: (0.516)(R 0.386, F 0.646)] [D acc: (0.727)(0.750, 0.703)] [G loss: 1.339] [G acc: 0.125]\n",
      "2091 [D loss: (0.524)(R 0.566, F 0.482)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.379] [G acc: 0.094]\n",
      "2092 [D loss: (0.573)(R 0.545, F 0.601)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.431] [G acc: 0.078]\n",
      "2093 [D loss: (0.531)(R 0.641, F 0.421)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.370] [G acc: 0.078]\n",
      "2094 [D loss: (0.502)(R 0.463, F 0.540)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.410] [G acc: 0.141]\n",
      "2095 [D loss: (0.518)(R 0.532, F 0.503)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.300] [G acc: 0.172]\n",
      "2096 [D loss: (0.489)(R 0.465, F 0.512)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.467] [G acc: 0.094]\n",
      "2097 [D loss: (0.564)(R 0.662, F 0.466)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.444] [G acc: 0.094]\n",
      "2098 [D loss: (0.483)(R 0.471, F 0.495)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.429] [G acc: 0.109]\n",
      "2099 [D loss: (0.586)(R 0.618, F 0.553)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.480] [G acc: 0.094]\n",
      "2100 [D loss: (0.538)(R 0.505, F 0.570)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.483] [G acc: 0.062]\n",
      "2101 [D loss: (0.581)(R 0.627, F 0.536)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.376] [G acc: 0.141]\n",
      "2102 [D loss: (0.526)(R 0.485, F 0.566)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.438] [G acc: 0.078]\n",
      "2103 [D loss: (0.657)(R 0.739, F 0.575)] [D acc: (0.602)(0.469, 0.734)] [G loss: 1.256] [G acc: 0.094]\n",
      "2104 [D loss: (0.510)(R 0.525, F 0.494)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.234] [G acc: 0.094]\n",
      "2105 [D loss: (0.545)(R 0.497, F 0.593)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.364] [G acc: 0.109]\n",
      "2106 [D loss: (0.527)(R 0.596, F 0.457)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.444] [G acc: 0.078]\n",
      "2107 [D loss: (0.555)(R 0.589, F 0.520)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.223] [G acc: 0.156]\n",
      "2108 [D loss: (0.508)(R 0.453, F 0.563)] [D acc: (0.758)(0.781, 0.734)] [G loss: 1.361] [G acc: 0.125]\n",
      "2109 [D loss: (0.476)(R 0.462, F 0.490)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.303] [G acc: 0.109]\n",
      "2110 [D loss: (0.538)(R 0.441, F 0.635)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.528] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2111 [D loss: (0.562)(R 0.592, F 0.533)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.436] [G acc: 0.078]\n",
      "2112 [D loss: (0.521)(R 0.558, F 0.484)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.403] [G acc: 0.047]\n",
      "2113 [D loss: (0.573)(R 0.522, F 0.623)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.330] [G acc: 0.109]\n",
      "2114 [D loss: (0.595)(R 0.538, F 0.651)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.490] [G acc: 0.047]\n",
      "2115 [D loss: (0.600)(R 0.709, F 0.490)] [D acc: (0.672)(0.531, 0.812)] [G loss: 1.368] [G acc: 0.094]\n",
      "2116 [D loss: (0.465)(R 0.506, F 0.425)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.313] [G acc: 0.078]\n",
      "2117 [D loss: (0.515)(R 0.432, F 0.599)] [D acc: (0.727)(0.750, 0.703)] [G loss: 1.426] [G acc: 0.078]\n",
      "2118 [D loss: (0.556)(R 0.459, F 0.652)] [D acc: (0.734)(0.766, 0.703)] [G loss: 1.389] [G acc: 0.109]\n",
      "2119 [D loss: (0.537)(R 0.640, F 0.434)] [D acc: (0.742)(0.594, 0.891)] [G loss: 1.326] [G acc: 0.156]\n",
      "2120 [D loss: (0.569)(R 0.503, F 0.634)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.434] [G acc: 0.094]\n",
      "2121 [D loss: (0.596)(R 0.551, F 0.642)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.356] [G acc: 0.062]\n",
      "2122 [D loss: (0.623)(R 0.789, F 0.458)] [D acc: (0.664)(0.484, 0.844)] [G loss: 1.364] [G acc: 0.109]\n",
      "2123 [D loss: (0.462)(R 0.474, F 0.450)] [D acc: (0.805)(0.781, 0.828)] [G loss: 1.437] [G acc: 0.109]\n",
      "2124 [D loss: (0.628)(R 0.601, F 0.655)] [D acc: (0.641)(0.562, 0.719)] [G loss: 1.368] [G acc: 0.094]\n",
      "2125 [D loss: (0.484)(R 0.538, F 0.431)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.419] [G acc: 0.125]\n",
      "2126 [D loss: (0.502)(R 0.466, F 0.538)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.549] [G acc: 0.078]\n",
      "2127 [D loss: (0.479)(R 0.537, F 0.420)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.599] [G acc: 0.094]\n",
      "2128 [D loss: (0.676)(R 0.631, F 0.721)] [D acc: (0.641)(0.656, 0.625)] [G loss: 1.455] [G acc: 0.078]\n",
      "2129 [D loss: (0.503)(R 0.560, F 0.445)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.328] [G acc: 0.078]\n",
      "2130 [D loss: (0.539)(R 0.632, F 0.446)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.406] [G acc: 0.109]\n",
      "2131 [D loss: (0.585)(R 0.568, F 0.601)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.404] [G acc: 0.078]\n",
      "2132 [D loss: (0.602)(R 0.704, F 0.499)] [D acc: (0.711)(0.547, 0.875)] [G loss: 1.396] [G acc: 0.078]\n",
      "2133 [D loss: (0.501)(R 0.531, F 0.471)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.287] [G acc: 0.141]\n",
      "2134 [D loss: (0.565)(R 0.504, F 0.626)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.297] [G acc: 0.109]\n",
      "2135 [D loss: (0.547)(R 0.494, F 0.601)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.404] [G acc: 0.062]\n",
      "2136 [D loss: (0.614)(R 0.554, F 0.674)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.361] [G acc: 0.141]\n",
      "2137 [D loss: (0.634)(R 0.655, F 0.614)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.377] [G acc: 0.094]\n",
      "2138 [D loss: (0.552)(R 0.522, F 0.583)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.410] [G acc: 0.094]\n",
      "2139 [D loss: (0.492)(R 0.486, F 0.498)] [D acc: (0.789)(0.781, 0.797)] [G loss: 1.387] [G acc: 0.094]\n",
      "2140 [D loss: (0.527)(R 0.524, F 0.530)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.452] [G acc: 0.109]\n",
      "2141 [D loss: (0.546)(R 0.534, F 0.558)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.285] [G acc: 0.156]\n",
      "2142 [D loss: (0.554)(R 0.597, F 0.512)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.464] [G acc: 0.109]\n",
      "2143 [D loss: (0.539)(R 0.575, F 0.503)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.411] [G acc: 0.094]\n",
      "2144 [D loss: (0.489)(R 0.449, F 0.528)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.439] [G acc: 0.062]\n",
      "2145 [D loss: (0.576)(R 0.694, F 0.459)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.370] [G acc: 0.125]\n",
      "2146 [D loss: (0.585)(R 0.577, F 0.592)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.326] [G acc: 0.094]\n",
      "2147 [D loss: (0.533)(R 0.604, F 0.462)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.312] [G acc: 0.094]\n",
      "2148 [D loss: (0.488)(R 0.481, F 0.495)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.341] [G acc: 0.172]\n",
      "2149 [D loss: (0.532)(R 0.567, F 0.496)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.386] [G acc: 0.172]\n",
      "2150 [D loss: (0.531)(R 0.494, F 0.568)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.407] [G acc: 0.078]\n",
      "2151 [D loss: (0.596)(R 0.579, F 0.612)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.451] [G acc: 0.078]\n",
      "2152 [D loss: (0.577)(R 0.598, F 0.556)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.377] [G acc: 0.094]\n",
      "2153 [D loss: (0.472)(R 0.541, F 0.403)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.467] [G acc: 0.109]\n",
      "2154 [D loss: (0.604)(R 0.591, F 0.618)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.393] [G acc: 0.094]\n",
      "2155 [D loss: (0.503)(R 0.478, F 0.528)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.327] [G acc: 0.172]\n",
      "2156 [D loss: (0.505)(R 0.537, F 0.473)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.312] [G acc: 0.188]\n",
      "2157 [D loss: (0.648)(R 0.576, F 0.720)] [D acc: (0.641)(0.609, 0.672)] [G loss: 1.296] [G acc: 0.109]\n",
      "2158 [D loss: (0.530)(R 0.554, F 0.505)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.424] [G acc: 0.141]\n",
      "2159 [D loss: (0.492)(R 0.524, F 0.459)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.411] [G acc: 0.062]\n",
      "2160 [D loss: (0.487)(R 0.481, F 0.492)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.454] [G acc: 0.078]\n",
      "2161 [D loss: (0.464)(R 0.468, F 0.460)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.492] [G acc: 0.109]\n",
      "2162 [D loss: (0.612)(R 0.614, F 0.610)] [D acc: (0.633)(0.609, 0.656)] [G loss: 1.453] [G acc: 0.141]\n",
      "2163 [D loss: (0.617)(R 0.773, F 0.462)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.415] [G acc: 0.109]\n",
      "2164 [D loss: (0.532)(R 0.427, F 0.637)] [D acc: (0.695)(0.734, 0.656)] [G loss: 1.420] [G acc: 0.125]\n",
      "2165 [D loss: (0.587)(R 0.573, F 0.602)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.407] [G acc: 0.125]\n",
      "2166 [D loss: (0.608)(R 0.718, F 0.497)] [D acc: (0.648)(0.516, 0.781)] [G loss: 1.294] [G acc: 0.109]\n",
      "2167 [D loss: (0.610)(R 0.604, F 0.616)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.316] [G acc: 0.094]\n",
      "2168 [D loss: (0.559)(R 0.546, F 0.572)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.444] [G acc: 0.125]\n",
      "2169 [D loss: (0.545)(R 0.603, F 0.488)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.383] [G acc: 0.016]\n",
      "2170 [D loss: (0.556)(R 0.612, F 0.500)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.303] [G acc: 0.078]\n",
      "2171 [D loss: (0.638)(R 0.569, F 0.707)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.477] [G acc: 0.062]\n",
      "2172 [D loss: (0.582)(R 0.692, F 0.471)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.241] [G acc: 0.109]\n",
      "2173 [D loss: (0.520)(R 0.558, F 0.482)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.323] [G acc: 0.141]\n",
      "2174 [D loss: (0.571)(R 0.532, F 0.610)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.325] [G acc: 0.094]\n",
      "2175 [D loss: (0.639)(R 0.678, F 0.601)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.272] [G acc: 0.125]\n",
      "2176 [D loss: (0.632)(R 0.649, F 0.615)] [D acc: (0.617)(0.594, 0.641)] [G loss: 1.343] [G acc: 0.109]\n",
      "2177 [D loss: (0.545)(R 0.621, F 0.470)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.182] [G acc: 0.219]\n",
      "2178 [D loss: (0.602)(R 0.579, F 0.625)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.375] [G acc: 0.047]\n",
      "2179 [D loss: (0.622)(R 0.700, F 0.545)] [D acc: (0.656)(0.531, 0.781)] [G loss: 1.249] [G acc: 0.109]\n",
      "2180 [D loss: (0.581)(R 0.554, F 0.608)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.291] [G acc: 0.141]\n",
      "2181 [D loss: (0.465)(R 0.442, F 0.488)] [D acc: (0.797)(0.781, 0.812)] [G loss: 1.391] [G acc: 0.062]\n",
      "2182 [D loss: (0.605)(R 0.587, F 0.624)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.315] [G acc: 0.078]\n",
      "2183 [D loss: (0.580)(R 0.651, F 0.509)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.267] [G acc: 0.094]\n",
      "2184 [D loss: (0.581)(R 0.579, F 0.583)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.278] [G acc: 0.094]\n",
      "2185 [D loss: (0.554)(R 0.599, F 0.509)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.174] [G acc: 0.125]\n",
      "2186 [D loss: (0.541)(R 0.588, F 0.494)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.276] [G acc: 0.125]\n",
      "2187 [D loss: (0.648)(R 0.590, F 0.706)] [D acc: (0.664)(0.672, 0.656)] [G loss: 1.328] [G acc: 0.156]\n",
      "2188 [D loss: (0.541)(R 0.590, F 0.493)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.278] [G acc: 0.109]\n",
      "2189 [D loss: (0.569)(R 0.569, F 0.569)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.248] [G acc: 0.156]\n",
      "2190 [D loss: (0.551)(R 0.559, F 0.544)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.257] [G acc: 0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2191 [D loss: (0.535)(R 0.449, F 0.621)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.209] [G acc: 0.156]\n",
      "2192 [D loss: (0.575)(R 0.472, F 0.678)] [D acc: (0.742)(0.766, 0.719)] [G loss: 1.332] [G acc: 0.078]\n",
      "2193 [D loss: (0.603)(R 0.666, F 0.539)] [D acc: (0.633)(0.500, 0.766)] [G loss: 1.284] [G acc: 0.078]\n",
      "2194 [D loss: (0.505)(R 0.522, F 0.489)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.263] [G acc: 0.094]\n",
      "2195 [D loss: (0.576)(R 0.528, F 0.624)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.443] [G acc: 0.109]\n",
      "2196 [D loss: (0.561)(R 0.605, F 0.516)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.167] [G acc: 0.141]\n",
      "2197 [D loss: (0.517)(R 0.473, F 0.562)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.223] [G acc: 0.172]\n",
      "2198 [D loss: (0.556)(R 0.472, F 0.640)] [D acc: (0.742)(0.781, 0.703)] [G loss: 1.369] [G acc: 0.125]\n",
      "2199 [D loss: (0.571)(R 0.576, F 0.566)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.262] [G acc: 0.078]\n",
      "2200 [D loss: (0.536)(R 0.649, F 0.424)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.241] [G acc: 0.109]\n",
      "2201 [D loss: (0.555)(R 0.492, F 0.619)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.270] [G acc: 0.125]\n",
      "2202 [D loss: (0.537)(R 0.615, F 0.459)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.277] [G acc: 0.125]\n",
      "2203 [D loss: (0.538)(R 0.435, F 0.642)] [D acc: (0.727)(0.781, 0.672)] [G loss: 1.289] [G acc: 0.141]\n",
      "2204 [D loss: (0.586)(R 0.544, F 0.627)] [D acc: (0.672)(0.703, 0.641)] [G loss: 1.274] [G acc: 0.219]\n",
      "2205 [D loss: (0.478)(R 0.496, F 0.461)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.399] [G acc: 0.094]\n",
      "2206 [D loss: (0.595)(R 0.602, F 0.588)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.336] [G acc: 0.109]\n",
      "2207 [D loss: (0.527)(R 0.548, F 0.506)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.410] [G acc: 0.062]\n",
      "2208 [D loss: (0.558)(R 0.620, F 0.497)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.190] [G acc: 0.141]\n",
      "2209 [D loss: (0.573)(R 0.581, F 0.564)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.252] [G acc: 0.078]\n",
      "2210 [D loss: (0.569)(R 0.604, F 0.535)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.220] [G acc: 0.172]\n",
      "2211 [D loss: (0.544)(R 0.527, F 0.560)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.131] [G acc: 0.156]\n",
      "2212 [D loss: (0.565)(R 0.537, F 0.594)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.157] [G acc: 0.172]\n",
      "2213 [D loss: (0.539)(R 0.547, F 0.532)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.171] [G acc: 0.141]\n",
      "2214 [D loss: (0.527)(R 0.511, F 0.543)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.233] [G acc: 0.141]\n",
      "2215 [D loss: (0.540)(R 0.522, F 0.558)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.248] [G acc: 0.141]\n",
      "2216 [D loss: (0.504)(R 0.488, F 0.521)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.328] [G acc: 0.109]\n",
      "2217 [D loss: (0.513)(R 0.582, F 0.445)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.403] [G acc: 0.062]\n",
      "2218 [D loss: (0.509)(R 0.477, F 0.540)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.271] [G acc: 0.125]\n",
      "2219 [D loss: (0.506)(R 0.571, F 0.442)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.338] [G acc: 0.156]\n",
      "2220 [D loss: (0.614)(R 0.618, F 0.609)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.273] [G acc: 0.172]\n",
      "2221 [D loss: (0.531)(R 0.518, F 0.544)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.294] [G acc: 0.094]\n",
      "2222 [D loss: (0.583)(R 0.558, F 0.608)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.381] [G acc: 0.094]\n",
      "2223 [D loss: (0.517)(R 0.540, F 0.493)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.275] [G acc: 0.125]\n",
      "2224 [D loss: (0.495)(R 0.437, F 0.553)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.431] [G acc: 0.062]\n",
      "2225 [D loss: (0.563)(R 0.577, F 0.549)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.446] [G acc: 0.062]\n",
      "2226 [D loss: (0.625)(R 0.546, F 0.703)] [D acc: (0.656)(0.656, 0.656)] [G loss: 1.470] [G acc: 0.047]\n",
      "2227 [D loss: (0.564)(R 0.655, F 0.473)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.341] [G acc: 0.094]\n",
      "2228 [D loss: (0.489)(R 0.510, F 0.469)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.339] [G acc: 0.203]\n",
      "2229 [D loss: (0.520)(R 0.575, F 0.465)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.433] [G acc: 0.094]\n",
      "2230 [D loss: (0.592)(R 0.631, F 0.553)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.346] [G acc: 0.078]\n",
      "2231 [D loss: (0.547)(R 0.586, F 0.508)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.359] [G acc: 0.125]\n",
      "2232 [D loss: (0.551)(R 0.669, F 0.432)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.452] [G acc: 0.094]\n",
      "2233 [D loss: (0.606)(R 0.532, F 0.680)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.347] [G acc: 0.141]\n",
      "2234 [D loss: (0.526)(R 0.523, F 0.530)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.284] [G acc: 0.109]\n",
      "2235 [D loss: (0.523)(R 0.464, F 0.582)] [D acc: (0.727)(0.781, 0.672)] [G loss: 1.400] [G acc: 0.031]\n",
      "2236 [D loss: (0.604)(R 0.647, F 0.561)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.263] [G acc: 0.094]\n",
      "2237 [D loss: (0.586)(R 0.610, F 0.561)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.151] [G acc: 0.141]\n",
      "2238 [D loss: (0.523)(R 0.539, F 0.506)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.171] [G acc: 0.109]\n",
      "2239 [D loss: (0.554)(R 0.566, F 0.542)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.175] [G acc: 0.188]\n",
      "2240 [D loss: (0.564)(R 0.555, F 0.573)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.323] [G acc: 0.062]\n",
      "2241 [D loss: (0.653)(R 0.732, F 0.574)] [D acc: (0.609)(0.469, 0.750)] [G loss: 1.343] [G acc: 0.062]\n",
      "2242 [D loss: (0.539)(R 0.590, F 0.488)] [D acc: (0.703)(0.547, 0.859)] [G loss: 1.315] [G acc: 0.109]\n",
      "2243 [D loss: (0.441)(R 0.417, F 0.465)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.215] [G acc: 0.141]\n",
      "2244 [D loss: (0.542)(R 0.512, F 0.572)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.315] [G acc: 0.109]\n",
      "2245 [D loss: (0.532)(R 0.504, F 0.559)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.252] [G acc: 0.141]\n",
      "2246 [D loss: (0.496)(R 0.474, F 0.517)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.350] [G acc: 0.078]\n",
      "2247 [D loss: (0.502)(R 0.486, F 0.518)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.380] [G acc: 0.078]\n",
      "2248 [D loss: (0.549)(R 0.508, F 0.591)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.515] [G acc: 0.062]\n",
      "2249 [D loss: (0.548)(R 0.588, F 0.508)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.359] [G acc: 0.094]\n",
      "2250 [D loss: (0.567)(R 0.504, F 0.630)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.277] [G acc: 0.188]\n",
      "2251 [D loss: (0.499)(R 0.574, F 0.425)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.294] [G acc: 0.141]\n",
      "2252 [D loss: (0.547)(R 0.425, F 0.668)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.433] [G acc: 0.031]\n",
      "2253 [D loss: (0.572)(R 0.639, F 0.504)] [D acc: (0.664)(0.547, 0.781)] [G loss: 1.267] [G acc: 0.125]\n",
      "2254 [D loss: (0.526)(R 0.575, F 0.478)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.272] [G acc: 0.094]\n",
      "2255 [D loss: (0.577)(R 0.615, F 0.540)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.233] [G acc: 0.109]\n",
      "2256 [D loss: (0.587)(R 0.488, F 0.687)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.306] [G acc: 0.094]\n",
      "2257 [D loss: (0.550)(R 0.657, F 0.442)] [D acc: (0.680)(0.516, 0.844)] [G loss: 1.156] [G acc: 0.172]\n",
      "2258 [D loss: (0.595)(R 0.567, F 0.624)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.214] [G acc: 0.094]\n",
      "2259 [D loss: (0.491)(R 0.532, F 0.450)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.216] [G acc: 0.109]\n",
      "2260 [D loss: (0.528)(R 0.518, F 0.537)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.348] [G acc: 0.047]\n",
      "2261 [D loss: (0.574)(R 0.548, F 0.599)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.324] [G acc: 0.125]\n",
      "2262 [D loss: (0.478)(R 0.483, F 0.473)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.256] [G acc: 0.125]\n",
      "2263 [D loss: (0.598)(R 0.472, F 0.724)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.354] [G acc: 0.078]\n",
      "2264 [D loss: (0.560)(R 0.596, F 0.524)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.295] [G acc: 0.156]\n",
      "2265 [D loss: (0.506)(R 0.517, F 0.495)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.330] [G acc: 0.125]\n",
      "2266 [D loss: (0.543)(R 0.633, F 0.453)] [D acc: (0.773)(0.625, 0.922)] [G loss: 1.367] [G acc: 0.109]\n",
      "2267 [D loss: (0.505)(R 0.431, F 0.578)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.454] [G acc: 0.047]\n",
      "2268 [D loss: (0.607)(R 0.683, F 0.530)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.459] [G acc: 0.047]\n",
      "2269 [D loss: (0.564)(R 0.590, F 0.538)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.300] [G acc: 0.141]\n",
      "2270 [D loss: (0.534)(R 0.597, F 0.471)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.296] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2271 [D loss: (0.599)(R 0.573, F 0.624)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.270] [G acc: 0.109]\n",
      "2272 [D loss: (0.516)(R 0.586, F 0.446)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.256] [G acc: 0.125]\n",
      "2273 [D loss: (0.499)(R 0.458, F 0.539)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.395] [G acc: 0.094]\n",
      "2274 [D loss: (0.564)(R 0.484, F 0.645)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.254] [G acc: 0.156]\n",
      "2275 [D loss: (0.540)(R 0.600, F 0.480)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.371] [G acc: 0.078]\n",
      "2276 [D loss: (0.478)(R 0.456, F 0.501)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.234] [G acc: 0.094]\n",
      "2277 [D loss: (0.537)(R 0.525, F 0.549)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.265] [G acc: 0.141]\n",
      "2278 [D loss: (0.509)(R 0.544, F 0.474)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.541] [G acc: 0.047]\n",
      "2279 [D loss: (0.516)(R 0.564, F 0.467)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.300] [G acc: 0.125]\n",
      "2280 [D loss: (0.585)(R 0.539, F 0.631)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.555] [G acc: 0.047]\n",
      "2281 [D loss: (0.493)(R 0.569, F 0.417)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.360] [G acc: 0.078]\n",
      "2282 [D loss: (0.549)(R 0.494, F 0.604)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.318] [G acc: 0.078]\n",
      "2283 [D loss: (0.485)(R 0.537, F 0.434)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.378] [G acc: 0.125]\n",
      "2284 [D loss: (0.593)(R 0.436, F 0.750)] [D acc: (0.680)(0.719, 0.641)] [G loss: 1.422] [G acc: 0.094]\n",
      "2285 [D loss: (0.431)(R 0.440, F 0.422)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.519] [G acc: 0.062]\n",
      "2286 [D loss: (0.533)(R 0.604, F 0.462)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.358] [G acc: 0.125]\n",
      "2287 [D loss: (0.540)(R 0.471, F 0.610)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.523] [G acc: 0.047]\n",
      "2288 [D loss: (0.505)(R 0.494, F 0.515)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.421] [G acc: 0.156]\n",
      "2289 [D loss: (0.581)(R 0.566, F 0.596)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.412] [G acc: 0.062]\n",
      "2290 [D loss: (0.639)(R 0.645, F 0.632)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.241] [G acc: 0.109]\n",
      "2291 [D loss: (0.580)(R 0.632, F 0.527)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.310] [G acc: 0.094]\n",
      "2292 [D loss: (0.518)(R 0.537, F 0.499)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.370] [G acc: 0.062]\n",
      "2293 [D loss: (0.577)(R 0.617, F 0.537)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.382] [G acc: 0.078]\n",
      "2294 [D loss: (0.540)(R 0.564, F 0.516)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.313] [G acc: 0.109]\n",
      "2295 [D loss: (0.499)(R 0.490, F 0.507)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.371] [G acc: 0.125]\n",
      "2296 [D loss: (0.549)(R 0.583, F 0.516)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.357] [G acc: 0.156]\n",
      "2297 [D loss: (0.476)(R 0.436, F 0.516)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.466] [G acc: 0.094]\n",
      "2298 [D loss: (0.549)(R 0.488, F 0.611)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.445] [G acc: 0.062]\n",
      "2299 [D loss: (0.512)(R 0.599, F 0.426)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.473] [G acc: 0.078]\n",
      "2300 [D loss: (0.525)(R 0.543, F 0.506)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.430] [G acc: 0.125]\n",
      "2301 [D loss: (0.489)(R 0.557, F 0.421)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.538] [G acc: 0.078]\n",
      "2302 [D loss: (0.486)(R 0.562, F 0.410)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.361] [G acc: 0.109]\n",
      "2303 [D loss: (0.631)(R 0.466, F 0.796)] [D acc: (0.695)(0.750, 0.641)] [G loss: 1.432] [G acc: 0.125]\n",
      "2304 [D loss: (0.509)(R 0.555, F 0.464)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.352] [G acc: 0.141]\n",
      "2305 [D loss: (0.627)(R 0.683, F 0.571)] [D acc: (0.664)(0.516, 0.812)] [G loss: 1.360] [G acc: 0.078]\n",
      "2306 [D loss: (0.529)(R 0.557, F 0.502)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.484] [G acc: 0.062]\n",
      "2307 [D loss: (0.569)(R 0.685, F 0.453)] [D acc: (0.664)(0.516, 0.812)] [G loss: 1.351] [G acc: 0.156]\n",
      "2308 [D loss: (0.521)(R 0.546, F 0.495)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.251] [G acc: 0.156]\n",
      "2309 [D loss: (0.518)(R 0.545, F 0.491)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.364] [G acc: 0.125]\n",
      "2310 [D loss: (0.574)(R 0.552, F 0.597)] [D acc: (0.680)(0.688, 0.672)] [G loss: 1.452] [G acc: 0.078]\n",
      "2311 [D loss: (0.541)(R 0.575, F 0.507)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.299] [G acc: 0.156]\n",
      "2312 [D loss: (0.553)(R 0.621, F 0.486)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.174] [G acc: 0.125]\n",
      "2313 [D loss: (0.496)(R 0.432, F 0.560)] [D acc: (0.805)(0.781, 0.828)] [G loss: 1.336] [G acc: 0.156]\n",
      "2314 [D loss: (0.535)(R 0.566, F 0.504)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.297] [G acc: 0.141]\n",
      "2315 [D loss: (0.469)(R 0.466, F 0.472)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.274] [G acc: 0.094]\n",
      "2316 [D loss: (0.506)(R 0.494, F 0.517)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.331] [G acc: 0.078]\n",
      "2317 [D loss: (0.542)(R 0.588, F 0.497)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.349] [G acc: 0.094]\n",
      "2318 [D loss: (0.486)(R 0.505, F 0.467)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.276] [G acc: 0.188]\n",
      "2319 [D loss: (0.604)(R 0.558, F 0.651)] [D acc: (0.664)(0.672, 0.656)] [G loss: 1.355] [G acc: 0.078]\n",
      "2320 [D loss: (0.552)(R 0.648, F 0.456)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.348] [G acc: 0.125]\n",
      "2321 [D loss: (0.529)(R 0.547, F 0.512)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.418] [G acc: 0.125]\n",
      "2322 [D loss: (0.667)(R 0.602, F 0.732)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.363] [G acc: 0.078]\n",
      "2323 [D loss: (0.524)(R 0.625, F 0.424)] [D acc: (0.758)(0.594, 0.922)] [G loss: 1.391] [G acc: 0.078]\n",
      "2324 [D loss: (0.530)(R 0.493, F 0.567)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.310] [G acc: 0.094]\n",
      "2325 [D loss: (0.497)(R 0.462, F 0.533)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.341] [G acc: 0.109]\n",
      "2326 [D loss: (0.533)(R 0.558, F 0.507)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.531] [G acc: 0.078]\n",
      "2327 [D loss: (0.490)(R 0.482, F 0.498)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.452] [G acc: 0.047]\n",
      "2328 [D loss: (0.520)(R 0.529, F 0.511)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.396] [G acc: 0.094]\n",
      "2329 [D loss: (0.506)(R 0.405, F 0.607)] [D acc: (0.742)(0.781, 0.703)] [G loss: 1.480] [G acc: 0.062]\n",
      "2330 [D loss: (0.508)(R 0.552, F 0.463)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.304] [G acc: 0.109]\n",
      "2331 [D loss: (0.515)(R 0.557, F 0.472)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.403] [G acc: 0.109]\n",
      "2332 [D loss: (0.548)(R 0.522, F 0.574)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.491] [G acc: 0.078]\n",
      "2333 [D loss: (0.502)(R 0.566, F 0.438)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.373] [G acc: 0.094]\n",
      "2334 [D loss: (0.503)(R 0.530, F 0.475)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.526] [G acc: 0.047]\n",
      "2335 [D loss: (0.614)(R 0.601, F 0.626)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.491] [G acc: 0.109]\n",
      "2336 [D loss: (0.512)(R 0.587, F 0.437)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.387] [G acc: 0.141]\n",
      "2337 [D loss: (0.523)(R 0.503, F 0.543)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.442] [G acc: 0.078]\n",
      "2338 [D loss: (0.580)(R 0.611, F 0.550)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.491] [G acc: 0.047]\n",
      "2339 [D loss: (0.572)(R 0.632, F 0.511)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.310] [G acc: 0.078]\n",
      "2340 [D loss: (0.507)(R 0.479, F 0.536)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.386] [G acc: 0.125]\n",
      "2341 [D loss: (0.519)(R 0.460, F 0.578)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.365] [G acc: 0.141]\n",
      "2342 [D loss: (0.523)(R 0.539, F 0.506)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.396] [G acc: 0.109]\n",
      "2343 [D loss: (0.480)(R 0.441, F 0.519)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.466] [G acc: 0.109]\n",
      "2344 [D loss: (0.573)(R 0.616, F 0.529)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.296] [G acc: 0.156]\n",
      "2345 [D loss: (0.581)(R 0.562, F 0.601)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.464] [G acc: 0.078]\n",
      "2346 [D loss: (0.527)(R 0.625, F 0.428)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.621] [G acc: 0.094]\n",
      "2347 [D loss: (0.540)(R 0.452, F 0.629)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.537] [G acc: 0.125]\n",
      "2348 [D loss: (0.532)(R 0.593, F 0.471)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.496] [G acc: 0.078]\n",
      "2349 [D loss: (0.506)(R 0.503, F 0.509)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.383] [G acc: 0.094]\n",
      "2350 [D loss: (0.519)(R 0.558, F 0.481)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.250] [G acc: 0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2351 [D loss: (0.536)(R 0.539, F 0.532)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.437] [G acc: 0.062]\n",
      "2352 [D loss: (0.560)(R 0.558, F 0.563)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.414] [G acc: 0.078]\n",
      "2353 [D loss: (0.578)(R 0.664, F 0.493)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.572] [G acc: 0.047]\n",
      "2354 [D loss: (0.510)(R 0.568, F 0.451)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.457] [G acc: 0.078]\n",
      "2355 [D loss: (0.543)(R 0.575, F 0.510)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.289] [G acc: 0.062]\n",
      "2356 [D loss: (0.562)(R 0.484, F 0.640)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.287] [G acc: 0.109]\n",
      "2357 [D loss: (0.529)(R 0.581, F 0.477)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.378] [G acc: 0.047]\n",
      "2358 [D loss: (0.486)(R 0.482, F 0.491)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.392] [G acc: 0.078]\n",
      "2359 [D loss: (0.512)(R 0.503, F 0.520)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.267] [G acc: 0.172]\n",
      "2360 [D loss: (0.560)(R 0.588, F 0.531)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.307] [G acc: 0.156]\n",
      "2361 [D loss: (0.559)(R 0.572, F 0.545)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.375] [G acc: 0.109]\n",
      "2362 [D loss: (0.518)(R 0.567, F 0.469)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.372] [G acc: 0.094]\n",
      "2363 [D loss: (0.498)(R 0.505, F 0.490)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.381] [G acc: 0.156]\n",
      "2364 [D loss: (0.482)(R 0.418, F 0.546)] [D acc: (0.805)(0.781, 0.828)] [G loss: 1.353] [G acc: 0.109]\n",
      "2365 [D loss: (0.591)(R 0.575, F 0.607)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.275] [G acc: 0.141]\n",
      "2366 [D loss: (0.565)(R 0.546, F 0.583)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.436] [G acc: 0.109]\n",
      "2367 [D loss: (0.482)(R 0.523, F 0.441)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.371] [G acc: 0.125]\n",
      "2368 [D loss: (0.585)(R 0.473, F 0.698)] [D acc: (0.734)(0.750, 0.719)] [G loss: 1.379] [G acc: 0.078]\n",
      "2369 [D loss: (0.565)(R 0.587, F 0.542)] [D acc: (0.633)(0.562, 0.703)] [G loss: 1.367] [G acc: 0.125]\n",
      "2370 [D loss: (0.542)(R 0.594, F 0.489)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.225] [G acc: 0.188]\n",
      "2371 [D loss: (0.445)(R 0.469, F 0.422)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.516] [G acc: 0.047]\n",
      "2372 [D loss: (0.484)(R 0.454, F 0.513)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.471] [G acc: 0.094]\n",
      "2373 [D loss: (0.575)(R 0.585, F 0.564)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.409] [G acc: 0.062]\n",
      "2374 [D loss: (0.573)(R 0.660, F 0.486)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.329] [G acc: 0.203]\n",
      "2375 [D loss: (0.585)(R 0.617, F 0.553)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.194] [G acc: 0.219]\n",
      "2376 [D loss: (0.602)(R 0.525, F 0.680)] [D acc: (0.672)(0.703, 0.641)] [G loss: 1.508] [G acc: 0.078]\n",
      "2377 [D loss: (0.530)(R 0.588, F 0.471)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.374] [G acc: 0.078]\n",
      "2378 [D loss: (0.611)(R 0.631, F 0.592)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.479] [G acc: 0.078]\n",
      "2379 [D loss: (0.509)(R 0.541, F 0.478)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.337] [G acc: 0.078]\n",
      "2380 [D loss: (0.527)(R 0.477, F 0.577)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.330] [G acc: 0.109]\n",
      "2381 [D loss: (0.484)(R 0.485, F 0.483)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.301] [G acc: 0.078]\n",
      "2382 [D loss: (0.511)(R 0.468, F 0.553)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.408] [G acc: 0.094]\n",
      "2383 [D loss: (0.566)(R 0.474, F 0.657)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.342] [G acc: 0.125]\n",
      "2384 [D loss: (0.570)(R 0.644, F 0.496)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.433] [G acc: 0.094]\n",
      "2385 [D loss: (0.645)(R 0.564, F 0.726)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.385] [G acc: 0.078]\n",
      "2386 [D loss: (0.484)(R 0.514, F 0.454)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.386] [G acc: 0.047]\n",
      "2387 [D loss: (0.537)(R 0.624, F 0.451)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.352] [G acc: 0.078]\n",
      "2388 [D loss: (0.453)(R 0.428, F 0.478)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.439] [G acc: 0.172]\n",
      "2389 [D loss: (0.645)(R 0.623, F 0.667)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.276] [G acc: 0.094]\n",
      "2390 [D loss: (0.567)(R 0.648, F 0.487)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.353] [G acc: 0.141]\n",
      "2391 [D loss: (0.593)(R 0.620, F 0.565)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.235] [G acc: 0.188]\n",
      "2392 [D loss: (0.470)(R 0.438, F 0.503)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.480] [G acc: 0.078]\n",
      "2393 [D loss: (0.559)(R 0.589, F 0.528)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.291] [G acc: 0.094]\n",
      "2394 [D loss: (0.534)(R 0.593, F 0.476)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.395] [G acc: 0.031]\n",
      "2395 [D loss: (0.569)(R 0.542, F 0.596)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.301] [G acc: 0.031]\n",
      "2396 [D loss: (0.569)(R 0.581, F 0.558)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.338] [G acc: 0.047]\n",
      "2397 [D loss: (0.492)(R 0.504, F 0.481)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.467] [G acc: 0.062]\n",
      "2398 [D loss: (0.546)(R 0.540, F 0.551)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.331] [G acc: 0.109]\n",
      "2399 [D loss: (0.531)(R 0.572, F 0.491)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.337] [G acc: 0.094]\n",
      "2400 [D loss: (0.571)(R 0.652, F 0.489)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.377] [G acc: 0.141]\n",
      "2401 [D loss: (0.490)(R 0.518, F 0.463)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.428] [G acc: 0.141]\n",
      "2402 [D loss: (0.479)(R 0.456, F 0.503)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.349] [G acc: 0.156]\n",
      "2403 [D loss: (0.579)(R 0.566, F 0.592)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.320] [G acc: 0.125]\n",
      "2404 [D loss: (0.549)(R 0.606, F 0.493)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.224] [G acc: 0.125]\n",
      "2405 [D loss: (0.457)(R 0.392, F 0.521)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.315] [G acc: 0.172]\n",
      "2406 [D loss: (0.471)(R 0.443, F 0.500)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.586] [G acc: 0.109]\n",
      "2407 [D loss: (0.666)(R 0.537, F 0.794)] [D acc: (0.688)(0.719, 0.656)] [G loss: 1.412] [G acc: 0.125]\n",
      "2408 [D loss: (0.562)(R 0.651, F 0.473)] [D acc: (0.734)(0.578, 0.891)] [G loss: 1.336] [G acc: 0.094]\n",
      "2409 [D loss: (0.563)(R 0.612, F 0.514)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.403] [G acc: 0.125]\n",
      "2410 [D loss: (0.608)(R 0.570, F 0.646)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.405] [G acc: 0.094]\n",
      "2411 [D loss: (0.567)(R 0.577, F 0.557)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.431] [G acc: 0.047]\n",
      "2412 [D loss: (0.547)(R 0.589, F 0.505)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.338] [G acc: 0.125]\n",
      "2413 [D loss: (0.540)(R 0.524, F 0.556)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.394] [G acc: 0.109]\n",
      "2414 [D loss: (0.552)(R 0.609, F 0.495)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.317] [G acc: 0.109]\n",
      "2415 [D loss: (0.552)(R 0.514, F 0.591)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.365] [G acc: 0.094]\n",
      "2416 [D loss: (0.506)(R 0.486, F 0.525)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.394] [G acc: 0.141]\n",
      "2417 [D loss: (0.484)(R 0.489, F 0.479)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.184] [G acc: 0.172]\n",
      "2418 [D loss: (0.517)(R 0.460, F 0.575)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.414] [G acc: 0.109]\n",
      "2419 [D loss: (0.527)(R 0.427, F 0.628)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.397] [G acc: 0.141]\n",
      "2420 [D loss: (0.527)(R 0.486, F 0.567)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.562] [G acc: 0.047]\n",
      "2421 [D loss: (0.524)(R 0.494, F 0.555)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.533] [G acc: 0.062]\n",
      "2422 [D loss: (0.506)(R 0.576, F 0.436)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.376] [G acc: 0.109]\n",
      "2423 [D loss: (0.457)(R 0.458, F 0.455)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.425] [G acc: 0.094]\n",
      "2424 [D loss: (0.534)(R 0.470, F 0.598)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.393] [G acc: 0.078]\n",
      "2425 [D loss: (0.524)(R 0.551, F 0.497)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.505] [G acc: 0.062]\n",
      "2426 [D loss: (0.635)(R 0.644, F 0.625)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.447] [G acc: 0.094]\n",
      "2427 [D loss: (0.582)(R 0.638, F 0.525)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.389] [G acc: 0.078]\n",
      "2428 [D loss: (0.589)(R 0.632, F 0.545)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.474] [G acc: 0.047]\n",
      "2429 [D loss: (0.612)(R 0.681, F 0.544)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.442] [G acc: 0.078]\n",
      "2430 [D loss: (0.575)(R 0.633, F 0.517)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.260] [G acc: 0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431 [D loss: (0.571)(R 0.606, F 0.537)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.360] [G acc: 0.094]\n",
      "2432 [D loss: (0.520)(R 0.530, F 0.509)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.299] [G acc: 0.094]\n",
      "2433 [D loss: (0.553)(R 0.603, F 0.502)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.349] [G acc: 0.094]\n",
      "2434 [D loss: (0.575)(R 0.558, F 0.593)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.437] [G acc: 0.109]\n",
      "2435 [D loss: (0.572)(R 0.580, F 0.564)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.373] [G acc: 0.125]\n",
      "2436 [D loss: (0.535)(R 0.546, F 0.524)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.240] [G acc: 0.141]\n",
      "2437 [D loss: (0.545)(R 0.522, F 0.567)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.236] [G acc: 0.156]\n",
      "2438 [D loss: (0.514)(R 0.519, F 0.510)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.288] [G acc: 0.172]\n",
      "2439 [D loss: (0.600)(R 0.595, F 0.604)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.277] [G acc: 0.188]\n",
      "2440 [D loss: (0.589)(R 0.542, F 0.636)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.620] [G acc: 0.031]\n",
      "2441 [D loss: (0.584)(R 0.672, F 0.497)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.403] [G acc: 0.094]\n",
      "2442 [D loss: (0.623)(R 0.650, F 0.595)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.249] [G acc: 0.203]\n",
      "2443 [D loss: (0.634)(R 0.564, F 0.705)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.404] [G acc: 0.078]\n",
      "2444 [D loss: (0.522)(R 0.648, F 0.395)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.287] [G acc: 0.141]\n",
      "2445 [D loss: (0.509)(R 0.515, F 0.503)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.264] [G acc: 0.078]\n",
      "2446 [D loss: (0.555)(R 0.534, F 0.577)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.249] [G acc: 0.125]\n",
      "2447 [D loss: (0.639)(R 0.568, F 0.711)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.277] [G acc: 0.109]\n",
      "2448 [D loss: (0.575)(R 0.669, F 0.482)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.225] [G acc: 0.156]\n",
      "2449 [D loss: (0.542)(R 0.628, F 0.457)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.283] [G acc: 0.156]\n",
      "2450 [D loss: (0.551)(R 0.572, F 0.530)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.415] [G acc: 0.078]\n",
      "2451 [D loss: (0.494)(R 0.479, F 0.509)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.248] [G acc: 0.172]\n",
      "2452 [D loss: (0.543)(R 0.565, F 0.521)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.290] [G acc: 0.078]\n",
      "2453 [D loss: (0.572)(R 0.577, F 0.567)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.336] [G acc: 0.109]\n",
      "2454 [D loss: (0.525)(R 0.569, F 0.481)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.330] [G acc: 0.172]\n",
      "2455 [D loss: (0.531)(R 0.559, F 0.503)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.159] [G acc: 0.156]\n",
      "2456 [D loss: (0.545)(R 0.437, F 0.653)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.423] [G acc: 0.062]\n",
      "2457 [D loss: (0.545)(R 0.544, F 0.546)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.358] [G acc: 0.062]\n",
      "2458 [D loss: (0.604)(R 0.658, F 0.551)] [D acc: (0.641)(0.516, 0.766)] [G loss: 1.237] [G acc: 0.156]\n",
      "2459 [D loss: (0.570)(R 0.572, F 0.568)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.253] [G acc: 0.172]\n",
      "2460 [D loss: (0.539)(R 0.594, F 0.484)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.366] [G acc: 0.125]\n",
      "2461 [D loss: (0.618)(R 0.624, F 0.611)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.325] [G acc: 0.109]\n",
      "2462 [D loss: (0.570)(R 0.532, F 0.608)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.184] [G acc: 0.188]\n",
      "2463 [D loss: (0.522)(R 0.518, F 0.526)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.343] [G acc: 0.094]\n",
      "2464 [D loss: (0.529)(R 0.533, F 0.525)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.245] [G acc: 0.203]\n",
      "2465 [D loss: (0.547)(R 0.572, F 0.522)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.248] [G acc: 0.172]\n",
      "2466 [D loss: (0.601)(R 0.619, F 0.582)] [D acc: (0.633)(0.562, 0.703)] [G loss: 1.282] [G acc: 0.141]\n",
      "2467 [D loss: (0.494)(R 0.483, F 0.504)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.278] [G acc: 0.125]\n",
      "2468 [D loss: (0.724)(R 0.729, F 0.719)] [D acc: (0.562)(0.484, 0.641)] [G loss: 1.313] [G acc: 0.172]\n",
      "2469 [D loss: (0.621)(R 0.721, F 0.521)] [D acc: (0.648)(0.516, 0.781)] [G loss: 1.229] [G acc: 0.078]\n",
      "2470 [D loss: (0.529)(R 0.543, F 0.514)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.283] [G acc: 0.094]\n",
      "2471 [D loss: (0.539)(R 0.541, F 0.536)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.302] [G acc: 0.141]\n",
      "2472 [D loss: (0.594)(R 0.686, F 0.501)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.139] [G acc: 0.141]\n",
      "2473 [D loss: (0.524)(R 0.527, F 0.522)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.427] [G acc: 0.047]\n",
      "2474 [D loss: (0.496)(R 0.500, F 0.492)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.422] [G acc: 0.078]\n",
      "2475 [D loss: (0.481)(R 0.492, F 0.470)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.317] [G acc: 0.141]\n",
      "2476 [D loss: (0.576)(R 0.502, F 0.650)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.401] [G acc: 0.188]\n",
      "2477 [D loss: (0.558)(R 0.559, F 0.558)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.538] [G acc: 0.109]\n",
      "2478 [D loss: (0.557)(R 0.605, F 0.509)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.324] [G acc: 0.172]\n",
      "2479 [D loss: (0.518)(R 0.548, F 0.488)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.305] [G acc: 0.109]\n",
      "2480 [D loss: (0.520)(R 0.508, F 0.533)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.346] [G acc: 0.062]\n",
      "2481 [D loss: (0.549)(R 0.550, F 0.549)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.300] [G acc: 0.125]\n",
      "2482 [D loss: (0.495)(R 0.522, F 0.467)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.341] [G acc: 0.078]\n",
      "2483 [D loss: (0.508)(R 0.441, F 0.575)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.420] [G acc: 0.109]\n",
      "2484 [D loss: (0.481)(R 0.456, F 0.506)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.288] [G acc: 0.078]\n",
      "2485 [D loss: (0.537)(R 0.407, F 0.667)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.239] [G acc: 0.156]\n",
      "2486 [D loss: (0.549)(R 0.625, F 0.472)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.262] [G acc: 0.109]\n",
      "2487 [D loss: (0.542)(R 0.583, F 0.500)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.270] [G acc: 0.156]\n",
      "2488 [D loss: (0.556)(R 0.494, F 0.617)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.242] [G acc: 0.109]\n",
      "2489 [D loss: (0.539)(R 0.420, F 0.659)] [D acc: (0.742)(0.766, 0.719)] [G loss: 1.372] [G acc: 0.078]\n",
      "2490 [D loss: (0.509)(R 0.486, F 0.533)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.461] [G acc: 0.109]\n",
      "2491 [D loss: (0.481)(R 0.500, F 0.462)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.412] [G acc: 0.078]\n",
      "2492 [D loss: (0.531)(R 0.539, F 0.523)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.244] [G acc: 0.172]\n",
      "2493 [D loss: (0.545)(R 0.547, F 0.544)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.304] [G acc: 0.172]\n",
      "2494 [D loss: (0.547)(R 0.521, F 0.573)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.392] [G acc: 0.078]\n",
      "2495 [D loss: (0.558)(R 0.562, F 0.554)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.353] [G acc: 0.141]\n",
      "2496 [D loss: (0.512)(R 0.590, F 0.433)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.516] [G acc: 0.094]\n",
      "2497 [D loss: (0.473)(R 0.455, F 0.492)] [D acc: (0.773)(0.781, 0.766)] [G loss: 1.230] [G acc: 0.094]\n",
      "2498 [D loss: (0.517)(R 0.556, F 0.477)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.315] [G acc: 0.078]\n",
      "2499 [D loss: (0.651)(R 0.596, F 0.706)] [D acc: (0.578)(0.500, 0.656)] [G loss: 1.393] [G acc: 0.078]\n",
      "2500 [D loss: (0.488)(R 0.446, F 0.529)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.386] [G acc: 0.203]\n",
      "2501 [D loss: (0.559)(R 0.559, F 0.558)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.272] [G acc: 0.219]\n",
      "2502 [D loss: (0.520)(R 0.609, F 0.430)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.356] [G acc: 0.125]\n",
      "2503 [D loss: (0.489)(R 0.419, F 0.560)] [D acc: (0.758)(0.812, 0.703)] [G loss: 1.618] [G acc: 0.062]\n",
      "2504 [D loss: (0.498)(R 0.569, F 0.426)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.443] [G acc: 0.109]\n",
      "2505 [D loss: (0.538)(R 0.568, F 0.508)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.488] [G acc: 0.125]\n",
      "2506 [D loss: (0.569)(R 0.647, F 0.490)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.289] [G acc: 0.188]\n",
      "2507 [D loss: (0.629)(R 0.606, F 0.653)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.274] [G acc: 0.062]\n",
      "2508 [D loss: (0.534)(R 0.551, F 0.518)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.306] [G acc: 0.141]\n",
      "2509 [D loss: (0.526)(R 0.521, F 0.530)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.271] [G acc: 0.141]\n",
      "2510 [D loss: (0.631)(R 0.598, F 0.664)] [D acc: (0.633)(0.562, 0.703)] [G loss: 1.335] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2511 [D loss: (0.518)(R 0.583, F 0.454)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.434] [G acc: 0.109]\n",
      "2512 [D loss: (0.597)(R 0.705, F 0.489)] [D acc: (0.711)(0.547, 0.875)] [G loss: 1.364] [G acc: 0.078]\n",
      "2513 [D loss: (0.511)(R 0.581, F 0.440)] [D acc: (0.789)(0.656, 0.922)] [G loss: 1.104] [G acc: 0.188]\n",
      "2514 [D loss: (0.499)(R 0.412, F 0.587)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.403] [G acc: 0.047]\n",
      "2515 [D loss: (0.584)(R 0.529, F 0.638)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.433] [G acc: 0.078]\n",
      "2516 [D loss: (0.562)(R 0.608, F 0.517)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.297] [G acc: 0.125]\n",
      "2517 [D loss: (0.571)(R 0.625, F 0.518)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.335] [G acc: 0.172]\n",
      "2518 [D loss: (0.492)(R 0.536, F 0.447)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.219] [G acc: 0.109]\n",
      "2519 [D loss: (0.496)(R 0.452, F 0.540)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.444] [G acc: 0.078]\n",
      "2520 [D loss: (0.542)(R 0.585, F 0.498)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.316] [G acc: 0.141]\n",
      "2521 [D loss: (0.597)(R 0.694, F 0.500)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.462] [G acc: 0.094]\n",
      "2522 [D loss: (0.650)(R 0.660, F 0.641)] [D acc: (0.641)(0.578, 0.703)] [G loss: 1.353] [G acc: 0.078]\n",
      "2523 [D loss: (0.565)(R 0.606, F 0.523)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.302] [G acc: 0.109]\n",
      "2524 [D loss: (0.527)(R 0.550, F 0.503)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.308] [G acc: 0.188]\n",
      "2525 [D loss: (0.581)(R 0.611, F 0.551)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.295] [G acc: 0.109]\n",
      "2526 [D loss: (0.455)(R 0.399, F 0.511)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.391] [G acc: 0.078]\n",
      "2527 [D loss: (0.598)(R 0.506, F 0.691)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.182] [G acc: 0.188]\n",
      "2528 [D loss: (0.524)(R 0.561, F 0.486)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.358] [G acc: 0.125]\n",
      "2529 [D loss: (0.579)(R 0.571, F 0.587)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.440] [G acc: 0.078]\n",
      "2530 [D loss: (0.496)(R 0.510, F 0.483)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.529] [G acc: 0.031]\n",
      "2531 [D loss: (0.559)(R 0.664, F 0.454)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.395] [G acc: 0.188]\n",
      "2532 [D loss: (0.434)(R 0.453, F 0.414)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.303] [G acc: 0.125]\n",
      "2533 [D loss: (0.507)(R 0.451, F 0.563)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.519] [G acc: 0.141]\n",
      "2534 [D loss: (0.641)(R 0.666, F 0.616)] [D acc: (0.633)(0.594, 0.672)] [G loss: 1.170] [G acc: 0.203]\n",
      "2535 [D loss: (0.564)(R 0.602, F 0.525)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.343] [G acc: 0.141]\n",
      "2536 [D loss: (0.619)(R 0.601, F 0.637)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.357] [G acc: 0.141]\n",
      "2537 [D loss: (0.556)(R 0.580, F 0.532)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.221] [G acc: 0.078]\n",
      "2538 [D loss: (0.631)(R 0.667, F 0.595)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.289] [G acc: 0.141]\n",
      "2539 [D loss: (0.637)(R 0.734, F 0.540)] [D acc: (0.578)(0.422, 0.734)] [G loss: 1.157] [G acc: 0.141]\n",
      "2540 [D loss: (0.552)(R 0.615, F 0.488)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.217] [G acc: 0.125]\n",
      "2541 [D loss: (0.516)(R 0.437, F 0.594)] [D acc: (0.766)(0.781, 0.750)] [G loss: 1.456] [G acc: 0.109]\n",
      "2542 [D loss: (0.522)(R 0.549, F 0.496)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.319] [G acc: 0.203]\n",
      "2543 [D loss: (0.530)(R 0.507, F 0.553)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.417] [G acc: 0.141]\n",
      "2544 [D loss: (0.550)(R 0.609, F 0.491)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.393] [G acc: 0.125]\n",
      "2545 [D loss: (0.589)(R 0.565, F 0.614)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.604] [G acc: 0.047]\n",
      "2546 [D loss: (0.522)(R 0.569, F 0.474)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.510] [G acc: 0.078]\n",
      "2547 [D loss: (0.566)(R 0.536, F 0.596)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.423] [G acc: 0.062]\n",
      "2548 [D loss: (0.552)(R 0.612, F 0.492)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.384] [G acc: 0.078]\n",
      "2549 [D loss: (0.525)(R 0.521, F 0.529)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.357] [G acc: 0.062]\n",
      "2550 [D loss: (0.583)(R 0.605, F 0.560)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.253] [G acc: 0.156]\n",
      "2551 [D loss: (0.517)(R 0.461, F 0.573)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.442] [G acc: 0.109]\n",
      "2552 [D loss: (0.504)(R 0.479, F 0.529)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.339] [G acc: 0.156]\n",
      "2553 [D loss: (0.541)(R 0.496, F 0.586)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.365] [G acc: 0.109]\n",
      "2554 [D loss: (0.589)(R 0.568, F 0.610)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.391] [G acc: 0.078]\n",
      "2555 [D loss: (0.582)(R 0.570, F 0.595)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.335] [G acc: 0.031]\n",
      "2556 [D loss: (0.492)(R 0.473, F 0.511)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.402] [G acc: 0.109]\n",
      "2557 [D loss: (0.593)(R 0.608, F 0.578)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.360] [G acc: 0.047]\n",
      "2558 [D loss: (0.550)(R 0.564, F 0.536)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.448] [G acc: 0.062]\n",
      "2559 [D loss: (0.540)(R 0.567, F 0.513)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.335] [G acc: 0.141]\n",
      "2560 [D loss: (0.555)(R 0.628, F 0.481)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.349] [G acc: 0.109]\n",
      "2561 [D loss: (0.567)(R 0.617, F 0.516)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.324] [G acc: 0.094]\n",
      "2562 [D loss: (0.596)(R 0.580, F 0.611)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.407] [G acc: 0.031]\n",
      "2563 [D loss: (0.553)(R 0.596, F 0.510)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.274] [G acc: 0.109]\n",
      "2564 [D loss: (0.524)(R 0.524, F 0.524)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.364] [G acc: 0.141]\n",
      "2565 [D loss: (0.489)(R 0.476, F 0.502)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.330] [G acc: 0.141]\n",
      "2566 [D loss: (0.489)(R 0.428, F 0.549)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.384] [G acc: 0.156]\n",
      "2567 [D loss: (0.572)(R 0.653, F 0.491)] [D acc: (0.633)(0.500, 0.766)] [G loss: 1.404] [G acc: 0.156]\n",
      "2568 [D loss: (0.449)(R 0.420, F 0.478)] [D acc: (0.820)(0.797, 0.844)] [G loss: 1.440] [G acc: 0.203]\n",
      "2569 [D loss: (0.523)(R 0.492, F 0.554)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.303] [G acc: 0.172]\n",
      "2570 [D loss: (0.468)(R 0.495, F 0.441)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.447] [G acc: 0.109]\n",
      "2571 [D loss: (0.492)(R 0.483, F 0.500)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.645] [G acc: 0.094]\n",
      "2572 [D loss: (0.619)(R 0.692, F 0.545)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.415] [G acc: 0.109]\n",
      "2573 [D loss: (0.526)(R 0.587, F 0.465)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.333] [G acc: 0.094]\n",
      "2574 [D loss: (0.602)(R 0.603, F 0.602)] [D acc: (0.633)(0.609, 0.656)] [G loss: 1.432] [G acc: 0.156]\n",
      "2575 [D loss: (0.473)(R 0.488, F 0.458)] [D acc: (0.820)(0.734, 0.906)] [G loss: 1.335] [G acc: 0.125]\n",
      "2576 [D loss: (0.489)(R 0.496, F 0.483)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.380] [G acc: 0.125]\n",
      "2577 [D loss: (0.493)(R 0.452, F 0.534)] [D acc: (0.734)(0.750, 0.719)] [G loss: 1.273] [G acc: 0.125]\n",
      "2578 [D loss: (0.558)(R 0.585, F 0.530)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.264] [G acc: 0.125]\n",
      "2579 [D loss: (0.457)(R 0.429, F 0.485)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.407] [G acc: 0.125]\n",
      "2580 [D loss: (0.608)(R 0.612, F 0.605)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.429] [G acc: 0.078]\n",
      "2581 [D loss: (0.634)(R 0.646, F 0.622)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.321] [G acc: 0.141]\n",
      "2582 [D loss: (0.516)(R 0.510, F 0.522)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.491] [G acc: 0.062]\n",
      "2583 [D loss: (0.452)(R 0.450, F 0.453)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.421] [G acc: 0.109]\n",
      "2584 [D loss: (0.659)(R 0.556, F 0.761)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.374] [G acc: 0.047]\n",
      "2585 [D loss: (0.510)(R 0.527, F 0.494)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.383] [G acc: 0.109]\n",
      "2586 [D loss: (0.474)(R 0.487, F 0.462)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.376] [G acc: 0.078]\n",
      "2587 [D loss: (0.481)(R 0.532, F 0.429)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.580] [G acc: 0.031]\n",
      "2588 [D loss: (0.546)(R 0.535, F 0.557)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.437] [G acc: 0.125]\n",
      "2589 [D loss: (0.518)(R 0.626, F 0.409)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.328] [G acc: 0.172]\n",
      "2590 [D loss: (0.493)(R 0.508, F 0.479)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.405] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2591 [D loss: (0.603)(R 0.547, F 0.659)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.469] [G acc: 0.047]\n",
      "2592 [D loss: (0.593)(R 0.552, F 0.633)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.349] [G acc: 0.078]\n",
      "2593 [D loss: (0.511)(R 0.539, F 0.483)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.341] [G acc: 0.094]\n",
      "2594 [D loss: (0.542)(R 0.406, F 0.678)] [D acc: (0.719)(0.766, 0.672)] [G loss: 1.488] [G acc: 0.062]\n",
      "2595 [D loss: (0.605)(R 0.650, F 0.560)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.362] [G acc: 0.078]\n",
      "2596 [D loss: (0.397)(R 0.438, F 0.356)] [D acc: (0.820)(0.734, 0.906)] [G loss: 1.356] [G acc: 0.078]\n",
      "2597 [D loss: (0.456)(R 0.459, F 0.452)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.470] [G acc: 0.094]\n",
      "2598 [D loss: (0.518)(R 0.542, F 0.493)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.315] [G acc: 0.156]\n",
      "2599 [D loss: (0.586)(R 0.602, F 0.570)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.294] [G acc: 0.125]\n",
      "2600 [D loss: (0.581)(R 0.514, F 0.648)] [D acc: (0.742)(0.766, 0.719)] [G loss: 1.429] [G acc: 0.141]\n",
      "2601 [D loss: (0.545)(R 0.549, F 0.541)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.321] [G acc: 0.094]\n",
      "2602 [D loss: (0.472)(R 0.527, F 0.416)] [D acc: (0.797)(0.656, 0.938)] [G loss: 1.363] [G acc: 0.094]\n",
      "2603 [D loss: (0.487)(R 0.538, F 0.436)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.369] [G acc: 0.109]\n",
      "2604 [D loss: (0.490)(R 0.454, F 0.526)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.379] [G acc: 0.172]\n",
      "2605 [D loss: (0.496)(R 0.452, F 0.540)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.463] [G acc: 0.141]\n",
      "2606 [D loss: (0.527)(R 0.507, F 0.546)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.489] [G acc: 0.094]\n",
      "2607 [D loss: (0.562)(R 0.571, F 0.554)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.484] [G acc: 0.062]\n",
      "2608 [D loss: (0.617)(R 0.670, F 0.563)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.413] [G acc: 0.125]\n",
      "2609 [D loss: (0.649)(R 0.798, F 0.500)] [D acc: (0.625)(0.500, 0.750)] [G loss: 1.453] [G acc: 0.047]\n",
      "2610 [D loss: (0.448)(R 0.467, F 0.428)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.406] [G acc: 0.109]\n",
      "2611 [D loss: (0.467)(R 0.459, F 0.475)] [D acc: (0.828)(0.781, 0.875)] [G loss: 1.400] [G acc: 0.047]\n",
      "2612 [D loss: (0.478)(R 0.500, F 0.457)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.562] [G acc: 0.125]\n",
      "2613 [D loss: (0.497)(R 0.484, F 0.511)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.488] [G acc: 0.047]\n",
      "2614 [D loss: (0.505)(R 0.532, F 0.477)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.294] [G acc: 0.062]\n",
      "2615 [D loss: (0.568)(R 0.615, F 0.522)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.482] [G acc: 0.047]\n",
      "2616 [D loss: (0.527)(R 0.485, F 0.569)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.383] [G acc: 0.109]\n",
      "2617 [D loss: (0.553)(R 0.606, F 0.500)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.419] [G acc: 0.125]\n",
      "2618 [D loss: (0.556)(R 0.434, F 0.679)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.386] [G acc: 0.078]\n",
      "2619 [D loss: (0.517)(R 0.551, F 0.482)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.370] [G acc: 0.094]\n",
      "2620 [D loss: (0.640)(R 0.563, F 0.718)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.469] [G acc: 0.047]\n",
      "2621 [D loss: (0.554)(R 0.618, F 0.489)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.323] [G acc: 0.219]\n",
      "2622 [D loss: (0.617)(R 0.666, F 0.568)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.342] [G acc: 0.125]\n",
      "2623 [D loss: (0.542)(R 0.507, F 0.577)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.380] [G acc: 0.062]\n",
      "2624 [D loss: (0.522)(R 0.502, F 0.543)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.259] [G acc: 0.156]\n",
      "2625 [D loss: (0.534)(R 0.548, F 0.520)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.270] [G acc: 0.125]\n",
      "2626 [D loss: (0.573)(R 0.591, F 0.555)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.287] [G acc: 0.109]\n",
      "2627 [D loss: (0.575)(R 0.557, F 0.592)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.377] [G acc: 0.078]\n",
      "2628 [D loss: (0.510)(R 0.531, F 0.489)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.346] [G acc: 0.125]\n",
      "2629 [D loss: (0.589)(R 0.610, F 0.568)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.432] [G acc: 0.078]\n",
      "2630 [D loss: (0.508)(R 0.519, F 0.498)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.363] [G acc: 0.109]\n",
      "2631 [D loss: (0.573)(R 0.705, F 0.441)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.373] [G acc: 0.125]\n",
      "2632 [D loss: (0.542)(R 0.563, F 0.522)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.395] [G acc: 0.062]\n",
      "2633 [D loss: (0.544)(R 0.596, F 0.491)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.345] [G acc: 0.125]\n",
      "2634 [D loss: (0.518)(R 0.591, F 0.446)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.313] [G acc: 0.047]\n",
      "2635 [D loss: (0.577)(R 0.657, F 0.497)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.283] [G acc: 0.094]\n",
      "2636 [D loss: (0.505)(R 0.464, F 0.546)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.430] [G acc: 0.062]\n",
      "2637 [D loss: (0.527)(R 0.558, F 0.497)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.345] [G acc: 0.125]\n",
      "2638 [D loss: (0.550)(R 0.498, F 0.603)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.360] [G acc: 0.125]\n",
      "2639 [D loss: (0.518)(R 0.574, F 0.461)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.266] [G acc: 0.125]\n",
      "2640 [D loss: (0.408)(R 0.352, F 0.464)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.365] [G acc: 0.141]\n",
      "2641 [D loss: (0.571)(R 0.566, F 0.576)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.409] [G acc: 0.031]\n",
      "2642 [D loss: (0.576)(R 0.690, F 0.463)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.258] [G acc: 0.219]\n",
      "2643 [D loss: (0.462)(R 0.392, F 0.532)] [D acc: (0.797)(0.797, 0.797)] [G loss: 1.356] [G acc: 0.094]\n",
      "2644 [D loss: (0.634)(R 0.646, F 0.623)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.374] [G acc: 0.078]\n",
      "2645 [D loss: (0.503)(R 0.579, F 0.428)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.299] [G acc: 0.094]\n",
      "2646 [D loss: (0.555)(R 0.551, F 0.558)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.240] [G acc: 0.156]\n",
      "2647 [D loss: (0.604)(R 0.562, F 0.647)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.407] [G acc: 0.125]\n",
      "2648 [D loss: (0.582)(R 0.570, F 0.594)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.502] [G acc: 0.047]\n",
      "2649 [D loss: (0.559)(R 0.547, F 0.571)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.275] [G acc: 0.062]\n",
      "2650 [D loss: (0.582)(R 0.608, F 0.557)] [D acc: (0.664)(0.547, 0.781)] [G loss: 1.509] [G acc: 0.062]\n",
      "2651 [D loss: (0.550)(R 0.515, F 0.586)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.347] [G acc: 0.109]\n",
      "2652 [D loss: (0.568)(R 0.559, F 0.578)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.362] [G acc: 0.078]\n",
      "2653 [D loss: (0.558)(R 0.589, F 0.528)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.308] [G acc: 0.125]\n",
      "2654 [D loss: (0.487)(R 0.455, F 0.518)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.407] [G acc: 0.094]\n",
      "2655 [D loss: (0.555)(R 0.605, F 0.505)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.282] [G acc: 0.109]\n",
      "2656 [D loss: (0.470)(R 0.475, F 0.465)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.374] [G acc: 0.156]\n",
      "2657 [D loss: (0.589)(R 0.563, F 0.615)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.448] [G acc: 0.062]\n",
      "2658 [D loss: (0.564)(R 0.632, F 0.496)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.354] [G acc: 0.094]\n",
      "2659 [D loss: (0.578)(R 0.470, F 0.686)] [D acc: (0.664)(0.719, 0.609)] [G loss: 1.427] [G acc: 0.047]\n",
      "2660 [D loss: (0.582)(R 0.608, F 0.557)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.365] [G acc: 0.078]\n",
      "2661 [D loss: (0.582)(R 0.643, F 0.521)] [D acc: (0.633)(0.500, 0.766)] [G loss: 1.187] [G acc: 0.188]\n",
      "2662 [D loss: (0.519)(R 0.530, F 0.507)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.414] [G acc: 0.094]\n",
      "2663 [D loss: (0.500)(R 0.488, F 0.512)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.286] [G acc: 0.094]\n",
      "2664 [D loss: (0.496)(R 0.520, F 0.472)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.480] [G acc: 0.062]\n",
      "2665 [D loss: (0.464)(R 0.460, F 0.468)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.381] [G acc: 0.109]\n",
      "2666 [D loss: (0.532)(R 0.530, F 0.535)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.533] [G acc: 0.094]\n",
      "2667 [D loss: (0.550)(R 0.592, F 0.507)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.367] [G acc: 0.141]\n",
      "2668 [D loss: (0.332)(R 0.295, F 0.369)] [D acc: (0.898)(0.859, 0.938)] [G loss: 1.618] [G acc: 0.031]\n",
      "2669 [D loss: (0.621)(R 0.639, F 0.603)] [D acc: (0.641)(0.609, 0.672)] [G loss: 1.449] [G acc: 0.094]\n",
      "2670 [D loss: (0.489)(R 0.540, F 0.438)] [D acc: (0.812)(0.719, 0.906)] [G loss: 1.358] [G acc: 0.047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2671 [D loss: (0.579)(R 0.522, F 0.635)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.327] [G acc: 0.078]\n",
      "2672 [D loss: (0.590)(R 0.540, F 0.639)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.416] [G acc: 0.094]\n",
      "2673 [D loss: (0.612)(R 0.697, F 0.527)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.443] [G acc: 0.078]\n",
      "2674 [D loss: (0.535)(R 0.594, F 0.476)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.440] [G acc: 0.109]\n",
      "2675 [D loss: (0.496)(R 0.626, F 0.367)] [D acc: (0.727)(0.578, 0.875)] [G loss: 1.309] [G acc: 0.125]\n",
      "2676 [D loss: (0.536)(R 0.591, F 0.481)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.198] [G acc: 0.203]\n",
      "2677 [D loss: (0.527)(R 0.534, F 0.521)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.376] [G acc: 0.125]\n",
      "2678 [D loss: (0.586)(R 0.594, F 0.579)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.311] [G acc: 0.141]\n",
      "2679 [D loss: (0.463)(R 0.518, F 0.408)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.380] [G acc: 0.109]\n",
      "2680 [D loss: (0.584)(R 0.562, F 0.606)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.355] [G acc: 0.094]\n",
      "2681 [D loss: (0.535)(R 0.543, F 0.527)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.428] [G acc: 0.078]\n",
      "2682 [D loss: (0.467)(R 0.490, F 0.443)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.461] [G acc: 0.047]\n",
      "2683 [D loss: (0.680)(R 0.633, F 0.726)] [D acc: (0.586)(0.578, 0.594)] [G loss: 1.269] [G acc: 0.125]\n",
      "2684 [D loss: (0.517)(R 0.512, F 0.522)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.347] [G acc: 0.188]\n",
      "2685 [D loss: (0.544)(R 0.593, F 0.495)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.297] [G acc: 0.141]\n",
      "2686 [D loss: (0.544)(R 0.583, F 0.505)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.398] [G acc: 0.078]\n",
      "2687 [D loss: (0.557)(R 0.534, F 0.580)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.191] [G acc: 0.172]\n",
      "2688 [D loss: (0.583)(R 0.519, F 0.647)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.427] [G acc: 0.062]\n",
      "2689 [D loss: (0.539)(R 0.579, F 0.499)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.336] [G acc: 0.094]\n",
      "2690 [D loss: (0.589)(R 0.627, F 0.551)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.210] [G acc: 0.125]\n",
      "2691 [D loss: (0.571)(R 0.474, F 0.668)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.382] [G acc: 0.125]\n",
      "2692 [D loss: (0.496)(R 0.575, F 0.417)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.192] [G acc: 0.125]\n",
      "2693 [D loss: (0.546)(R 0.551, F 0.541)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.373] [G acc: 0.094]\n",
      "2694 [D loss: (0.504)(R 0.437, F 0.571)] [D acc: (0.766)(0.781, 0.750)] [G loss: 1.366] [G acc: 0.094]\n",
      "2695 [D loss: (0.554)(R 0.558, F 0.550)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.592] [G acc: 0.031]\n",
      "2696 [D loss: (0.515)(R 0.553, F 0.477)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.436] [G acc: 0.078]\n",
      "2697 [D loss: (0.555)(R 0.541, F 0.569)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.360] [G acc: 0.078]\n",
      "2698 [D loss: (0.491)(R 0.502, F 0.480)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.327] [G acc: 0.156]\n",
      "2699 [D loss: (0.446)(R 0.482, F 0.409)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.377] [G acc: 0.094]\n",
      "2700 [D loss: (0.487)(R 0.464, F 0.510)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.348] [G acc: 0.109]\n",
      "2701 [D loss: (0.522)(R 0.389, F 0.655)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.586] [G acc: 0.078]\n",
      "2702 [D loss: (0.565)(R 0.675, F 0.455)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.490] [G acc: 0.094]\n",
      "2703 [D loss: (0.524)(R 0.562, F 0.486)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.309] [G acc: 0.125]\n",
      "2704 [D loss: (0.591)(R 0.595, F 0.587)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.391] [G acc: 0.078]\n",
      "2705 [D loss: (0.446)(R 0.414, F 0.477)] [D acc: (0.820)(0.766, 0.875)] [G loss: 1.557] [G acc: 0.141]\n",
      "2706 [D loss: (0.508)(R 0.502, F 0.514)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.427] [G acc: 0.156]\n",
      "2707 [D loss: (0.535)(R 0.585, F 0.484)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.436] [G acc: 0.141]\n",
      "2708 [D loss: (0.551)(R 0.531, F 0.570)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.580] [G acc: 0.047]\n",
      "2709 [D loss: (0.647)(R 0.567, F 0.726)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.526] [G acc: 0.062]\n",
      "2710 [D loss: (0.552)(R 0.582, F 0.521)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.518] [G acc: 0.062]\n",
      "2711 [D loss: (0.538)(R 0.719, F 0.357)] [D acc: (0.719)(0.516, 0.922)] [G loss: 1.411] [G acc: 0.125]\n",
      "2712 [D loss: (0.571)(R 0.504, F 0.637)] [D acc: (0.680)(0.703, 0.656)] [G loss: 1.288] [G acc: 0.109]\n",
      "2713 [D loss: (0.605)(R 0.648, F 0.563)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.406] [G acc: 0.141]\n",
      "2714 [D loss: (0.519)(R 0.573, F 0.466)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.432] [G acc: 0.141]\n",
      "2715 [D loss: (0.557)(R 0.609, F 0.505)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.442] [G acc: 0.094]\n",
      "2716 [D loss: (0.562)(R 0.480, F 0.645)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.281] [G acc: 0.156]\n",
      "2717 [D loss: (0.546)(R 0.620, F 0.473)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.412] [G acc: 0.094]\n",
      "2718 [D loss: (0.582)(R 0.621, F 0.543)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.294] [G acc: 0.109]\n",
      "2719 [D loss: (0.518)(R 0.503, F 0.532)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.354] [G acc: 0.141]\n",
      "2720 [D loss: (0.603)(R 0.603, F 0.603)] [D acc: (0.648)(0.641, 0.656)] [G loss: 1.258] [G acc: 0.219]\n",
      "2721 [D loss: (0.559)(R 0.472, F 0.646)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.394] [G acc: 0.078]\n",
      "2722 [D loss: (0.562)(R 0.635, F 0.489)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.279] [G acc: 0.156]\n",
      "2723 [D loss: (0.568)(R 0.553, F 0.582)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.329] [G acc: 0.125]\n",
      "2724 [D loss: (0.500)(R 0.510, F 0.490)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.268] [G acc: 0.156]\n",
      "2725 [D loss: (0.556)(R 0.491, F 0.620)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.444] [G acc: 0.125]\n",
      "2726 [D loss: (0.545)(R 0.628, F 0.462)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.377] [G acc: 0.156]\n",
      "2727 [D loss: (0.515)(R 0.462, F 0.569)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.351] [G acc: 0.141]\n",
      "2728 [D loss: (0.500)(R 0.502, F 0.497)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.308] [G acc: 0.062]\n",
      "2729 [D loss: (0.525)(R 0.498, F 0.552)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.427] [G acc: 0.141]\n",
      "2730 [D loss: (0.559)(R 0.657, F 0.460)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.433] [G acc: 0.109]\n",
      "2731 [D loss: (0.591)(R 0.532, F 0.650)] [D acc: (0.656)(0.672, 0.641)] [G loss: 1.540] [G acc: 0.094]\n",
      "2732 [D loss: (0.576)(R 0.574, F 0.578)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.382] [G acc: 0.125]\n",
      "2733 [D loss: (0.565)(R 0.676, F 0.453)] [D acc: (0.711)(0.531, 0.891)] [G loss: 1.364] [G acc: 0.094]\n",
      "2734 [D loss: (0.480)(R 0.482, F 0.477)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.315] [G acc: 0.062]\n",
      "2735 [D loss: (0.517)(R 0.520, F 0.514)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.272] [G acc: 0.094]\n",
      "2736 [D loss: (0.472)(R 0.492, F 0.453)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.501] [G acc: 0.016]\n",
      "2737 [D loss: (0.521)(R 0.573, F 0.470)] [D acc: (0.766)(0.609, 0.922)] [G loss: 1.216] [G acc: 0.234]\n",
      "2738 [D loss: (0.620)(R 0.697, F 0.543)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.292] [G acc: 0.109]\n",
      "2739 [D loss: (0.593)(R 0.636, F 0.551)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.220] [G acc: 0.125]\n",
      "2740 [D loss: (0.548)(R 0.533, F 0.563)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.471] [G acc: 0.031]\n",
      "2741 [D loss: (0.522)(R 0.548, F 0.495)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.343] [G acc: 0.094]\n",
      "2742 [D loss: (0.465)(R 0.454, F 0.476)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.434] [G acc: 0.125]\n",
      "2743 [D loss: (0.641)(R 0.653, F 0.629)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.451] [G acc: 0.078]\n",
      "2744 [D loss: (0.608)(R 0.770, F 0.447)] [D acc: (0.664)(0.484, 0.844)] [G loss: 1.313] [G acc: 0.156]\n",
      "2745 [D loss: (0.593)(R 0.657, F 0.529)] [D acc: (0.664)(0.547, 0.781)] [G loss: 1.461] [G acc: 0.062]\n",
      "2746 [D loss: (0.457)(R 0.432, F 0.481)] [D acc: (0.805)(0.750, 0.859)] [G loss: 1.265] [G acc: 0.172]\n",
      "2747 [D loss: (0.504)(R 0.461, F 0.548)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.324] [G acc: 0.094]\n",
      "2748 [D loss: (0.554)(R 0.604, F 0.505)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.413] [G acc: 0.141]\n",
      "2749 [D loss: (0.488)(R 0.462, F 0.514)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.303] [G acc: 0.172]\n",
      "2750 [D loss: (0.475)(R 0.429, F 0.521)] [D acc: (0.773)(0.781, 0.766)] [G loss: 1.352] [G acc: 0.203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2751 [D loss: (0.526)(R 0.580, F 0.472)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.466] [G acc: 0.062]\n",
      "2752 [D loss: (0.542)(R 0.595, F 0.488)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.264] [G acc: 0.156]\n",
      "2753 [D loss: (0.580)(R 0.595, F 0.565)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.311] [G acc: 0.172]\n",
      "2754 [D loss: (0.605)(R 0.663, F 0.547)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.451] [G acc: 0.141]\n",
      "2755 [D loss: (0.568)(R 0.581, F 0.554)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.491] [G acc: 0.062]\n",
      "2756 [D loss: (0.612)(R 0.676, F 0.548)] [D acc: (0.656)(0.516, 0.797)] [G loss: 1.203] [G acc: 0.109]\n",
      "2757 [D loss: (0.511)(R 0.542, F 0.481)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.284] [G acc: 0.172]\n",
      "2758 [D loss: (0.516)(R 0.579, F 0.452)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.437] [G acc: 0.078]\n",
      "2759 [D loss: (0.656)(R 0.641, F 0.671)] [D acc: (0.617)(0.562, 0.672)] [G loss: 1.277] [G acc: 0.141]\n",
      "2760 [D loss: (0.639)(R 0.759, F 0.519)] [D acc: (0.625)(0.484, 0.766)] [G loss: 1.286] [G acc: 0.047]\n",
      "2761 [D loss: (0.551)(R 0.569, F 0.532)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.267] [G acc: 0.094]\n",
      "2762 [D loss: (0.570)(R 0.506, F 0.634)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.359] [G acc: 0.125]\n",
      "2763 [D loss: (0.551)(R 0.598, F 0.505)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.238] [G acc: 0.109]\n",
      "2764 [D loss: (0.601)(R 0.516, F 0.687)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.382] [G acc: 0.109]\n",
      "2765 [D loss: (0.561)(R 0.573, F 0.549)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.389] [G acc: 0.094]\n",
      "2766 [D loss: (0.547)(R 0.584, F 0.511)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.224] [G acc: 0.141]\n",
      "2767 [D loss: (0.462)(R 0.496, F 0.427)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.247] [G acc: 0.172]\n",
      "2768 [D loss: (0.533)(R 0.488, F 0.577)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.475] [G acc: 0.031]\n",
      "2769 [D loss: (0.601)(R 0.566, F 0.637)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.501] [G acc: 0.094]\n",
      "2770 [D loss: (0.554)(R 0.625, F 0.483)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.247] [G acc: 0.141]\n",
      "2771 [D loss: (0.593)(R 0.608, F 0.579)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.354] [G acc: 0.062]\n",
      "2772 [D loss: (0.516)(R 0.530, F 0.501)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.268] [G acc: 0.125]\n",
      "2773 [D loss: (0.496)(R 0.515, F 0.476)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.255] [G acc: 0.125]\n",
      "2774 [D loss: (0.474)(R 0.431, F 0.517)] [D acc: (0.836)(0.766, 0.906)] [G loss: 1.513] [G acc: 0.078]\n",
      "2775 [D loss: (0.516)(R 0.542, F 0.489)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.415] [G acc: 0.094]\n",
      "2776 [D loss: (0.605)(R 0.609, F 0.602)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.257] [G acc: 0.078]\n",
      "2777 [D loss: (0.471)(R 0.484, F 0.458)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.423] [G acc: 0.078]\n",
      "2778 [D loss: (0.663)(R 0.595, F 0.731)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.345] [G acc: 0.094]\n",
      "2779 [D loss: (0.479)(R 0.528, F 0.430)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.476] [G acc: 0.109]\n",
      "2780 [D loss: (0.608)(R 0.550, F 0.666)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.384] [G acc: 0.109]\n",
      "2781 [D loss: (0.498)(R 0.529, F 0.468)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.427] [G acc: 0.141]\n",
      "2782 [D loss: (0.482)(R 0.471, F 0.494)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.304] [G acc: 0.156]\n",
      "2783 [D loss: (0.497)(R 0.506, F 0.487)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.616] [G acc: 0.078]\n",
      "2784 [D loss: (0.612)(R 0.492, F 0.732)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.397] [G acc: 0.109]\n",
      "2785 [D loss: (0.636)(R 0.729, F 0.543)] [D acc: (0.695)(0.547, 0.844)] [G loss: 1.310] [G acc: 0.109]\n",
      "2786 [D loss: (0.554)(R 0.610, F 0.499)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.337] [G acc: 0.094]\n",
      "2787 [D loss: (0.576)(R 0.639, F 0.514)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.238] [G acc: 0.172]\n",
      "2788 [D loss: (0.458)(R 0.465, F 0.451)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.307] [G acc: 0.141]\n",
      "2789 [D loss: (0.489)(R 0.406, F 0.571)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.413] [G acc: 0.078]\n",
      "2790 [D loss: (0.489)(R 0.484, F 0.493)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.391] [G acc: 0.141]\n",
      "2791 [D loss: (0.544)(R 0.575, F 0.512)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.364] [G acc: 0.094]\n",
      "2792 [D loss: (0.549)(R 0.570, F 0.527)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.449] [G acc: 0.047]\n",
      "2793 [D loss: (0.524)(R 0.571, F 0.477)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.341] [G acc: 0.156]\n",
      "2794 [D loss: (0.685)(R 0.545, F 0.825)] [D acc: (0.648)(0.672, 0.625)] [G loss: 1.483] [G acc: 0.016]\n",
      "2795 [D loss: (0.529)(R 0.586, F 0.473)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.395] [G acc: 0.094]\n",
      "2796 [D loss: (0.608)(R 0.736, F 0.480)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.294] [G acc: 0.156]\n",
      "2797 [D loss: (0.579)(R 0.571, F 0.588)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.165] [G acc: 0.188]\n",
      "2798 [D loss: (0.504)(R 0.540, F 0.469)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.286] [G acc: 0.141]\n",
      "2799 [D loss: (0.549)(R 0.505, F 0.593)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.393] [G acc: 0.000]\n",
      "2800 [D loss: (0.539)(R 0.576, F 0.502)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.411] [G acc: 0.047]\n",
      "2801 [D loss: (0.590)(R 0.552, F 0.627)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.312] [G acc: 0.109]\n",
      "2802 [D loss: (0.638)(R 0.715, F 0.561)] [D acc: (0.633)(0.469, 0.797)] [G loss: 1.408] [G acc: 0.031]\n",
      "2803 [D loss: (0.568)(R 0.650, F 0.487)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.379] [G acc: 0.125]\n",
      "2804 [D loss: (0.522)(R 0.557, F 0.487)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.408] [G acc: 0.062]\n",
      "2805 [D loss: (0.557)(R 0.594, F 0.520)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.233] [G acc: 0.109]\n",
      "2806 [D loss: (0.548)(R 0.548, F 0.548)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.224] [G acc: 0.141]\n",
      "2807 [D loss: (0.504)(R 0.500, F 0.509)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.394] [G acc: 0.062]\n",
      "2808 [D loss: (0.505)(R 0.514, F 0.495)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.399] [G acc: 0.078]\n",
      "2809 [D loss: (0.566)(R 0.641, F 0.490)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.416] [G acc: 0.094]\n",
      "2810 [D loss: (0.541)(R 0.550, F 0.533)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.419] [G acc: 0.094]\n",
      "2811 [D loss: (0.508)(R 0.487, F 0.530)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.335] [G acc: 0.094]\n",
      "2812 [D loss: (0.606)(R 0.602, F 0.609)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.379] [G acc: 0.078]\n",
      "2813 [D loss: (0.562)(R 0.581, F 0.543)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.407] [G acc: 0.078]\n",
      "2814 [D loss: (0.539)(R 0.607, F 0.471)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.262] [G acc: 0.141]\n",
      "2815 [D loss: (0.508)(R 0.495, F 0.521)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.341] [G acc: 0.125]\n",
      "2816 [D loss: (0.545)(R 0.581, F 0.510)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.190] [G acc: 0.203]\n",
      "2817 [D loss: (0.557)(R 0.499, F 0.615)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.321] [G acc: 0.062]\n",
      "2818 [D loss: (0.559)(R 0.513, F 0.605)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.253] [G acc: 0.141]\n",
      "2819 [D loss: (0.599)(R 0.626, F 0.572)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.298] [G acc: 0.125]\n",
      "2820 [D loss: (0.570)(R 0.580, F 0.560)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.405] [G acc: 0.078]\n",
      "2821 [D loss: (0.563)(R 0.594, F 0.531)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.327] [G acc: 0.078]\n",
      "2822 [D loss: (0.545)(R 0.498, F 0.591)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.345] [G acc: 0.031]\n",
      "2823 [D loss: (0.498)(R 0.487, F 0.510)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.371] [G acc: 0.125]\n",
      "2824 [D loss: (0.506)(R 0.452, F 0.560)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.424] [G acc: 0.109]\n",
      "2825 [D loss: (0.545)(R 0.552, F 0.538)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.465] [G acc: 0.078]\n",
      "2826 [D loss: (0.494)(R 0.570, F 0.419)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.378] [G acc: 0.125]\n",
      "2827 [D loss: (0.549)(R 0.547, F 0.550)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.350] [G acc: 0.047]\n",
      "2828 [D loss: (0.487)(R 0.556, F 0.418)] [D acc: (0.797)(0.688, 0.906)] [G loss: 1.396] [G acc: 0.047]\n",
      "2829 [D loss: (0.585)(R 0.614, F 0.556)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.316] [G acc: 0.141]\n",
      "2830 [D loss: (0.549)(R 0.503, F 0.596)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.311] [G acc: 0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831 [D loss: (0.563)(R 0.577, F 0.550)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.340] [G acc: 0.141]\n",
      "2832 [D loss: (0.504)(R 0.499, F 0.510)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.274] [G acc: 0.125]\n",
      "2833 [D loss: (0.614)(R 0.691, F 0.536)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.243] [G acc: 0.188]\n",
      "2834 [D loss: (0.489)(R 0.416, F 0.563)] [D acc: (0.820)(0.812, 0.828)] [G loss: 1.391] [G acc: 0.094]\n",
      "2835 [D loss: (0.508)(R 0.570, F 0.447)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.393] [G acc: 0.047]\n",
      "2836 [D loss: (0.510)(R 0.446, F 0.574)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.430] [G acc: 0.109]\n",
      "2837 [D loss: (0.554)(R 0.695, F 0.414)] [D acc: (0.680)(0.500, 0.859)] [G loss: 1.366] [G acc: 0.078]\n",
      "2838 [D loss: (0.551)(R 0.556, F 0.546)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.311] [G acc: 0.188]\n",
      "2839 [D loss: (0.519)(R 0.520, F 0.518)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.364] [G acc: 0.031]\n",
      "2840 [D loss: (0.481)(R 0.440, F 0.521)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.449] [G acc: 0.141]\n",
      "2841 [D loss: (0.525)(R 0.476, F 0.574)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.411] [G acc: 0.109]\n",
      "2842 [D loss: (0.464)(R 0.536, F 0.392)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.313] [G acc: 0.125]\n",
      "2843 [D loss: (0.486)(R 0.469, F 0.504)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.421] [G acc: 0.094]\n",
      "2844 [D loss: (0.506)(R 0.401, F 0.611)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.574] [G acc: 0.125]\n",
      "2845 [D loss: (0.515)(R 0.525, F 0.504)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.393] [G acc: 0.109]\n",
      "2846 [D loss: (0.517)(R 0.612, F 0.422)] [D acc: (0.742)(0.594, 0.891)] [G loss: 1.533] [G acc: 0.062]\n",
      "2847 [D loss: (0.574)(R 0.592, F 0.555)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.384] [G acc: 0.109]\n",
      "2848 [D loss: (0.497)(R 0.459, F 0.535)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.324] [G acc: 0.062]\n",
      "2849 [D loss: (0.594)(R 0.603, F 0.586)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.330] [G acc: 0.141]\n",
      "2850 [D loss: (0.555)(R 0.553, F 0.556)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.452] [G acc: 0.141]\n",
      "2851 [D loss: (0.642)(R 0.606, F 0.678)] [D acc: (0.609)(0.609, 0.609)] [G loss: 1.616] [G acc: 0.031]\n",
      "2852 [D loss: (0.532)(R 0.604, F 0.459)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.325] [G acc: 0.125]\n",
      "2853 [D loss: (0.505)(R 0.529, F 0.480)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.353] [G acc: 0.156]\n",
      "2854 [D loss: (0.577)(R 0.538, F 0.615)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.375] [G acc: 0.094]\n",
      "2855 [D loss: (0.548)(R 0.658, F 0.437)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.357] [G acc: 0.125]\n",
      "2856 [D loss: (0.457)(R 0.436, F 0.478)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.345] [G acc: 0.078]\n",
      "2857 [D loss: (0.486)(R 0.453, F 0.518)] [D acc: (0.789)(0.797, 0.781)] [G loss: 1.412] [G acc: 0.094]\n",
      "2858 [D loss: (0.570)(R 0.610, F 0.530)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.292] [G acc: 0.141]\n",
      "2859 [D loss: (0.497)(R 0.487, F 0.506)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.316] [G acc: 0.156]\n",
      "2860 [D loss: (0.614)(R 0.520, F 0.707)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.333] [G acc: 0.109]\n",
      "2861 [D loss: (0.566)(R 0.715, F 0.416)] [D acc: (0.703)(0.547, 0.859)] [G loss: 1.325] [G acc: 0.094]\n",
      "2862 [D loss: (0.506)(R 0.544, F 0.468)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.400] [G acc: 0.125]\n",
      "2863 [D loss: (0.589)(R 0.557, F 0.621)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.364] [G acc: 0.109]\n",
      "2864 [D loss: (0.424)(R 0.414, F 0.434)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.258] [G acc: 0.094]\n",
      "2865 [D loss: (0.527)(R 0.509, F 0.545)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.561] [G acc: 0.094]\n",
      "2866 [D loss: (0.546)(R 0.590, F 0.501)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.335] [G acc: 0.188]\n",
      "2867 [D loss: (0.509)(R 0.552, F 0.466)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.377] [G acc: 0.141]\n",
      "2868 [D loss: (0.599)(R 0.593, F 0.605)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.338] [G acc: 0.062]\n",
      "2869 [D loss: (0.472)(R 0.524, F 0.420)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.365] [G acc: 0.125]\n",
      "2870 [D loss: (0.495)(R 0.524, F 0.466)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.380] [G acc: 0.062]\n",
      "2871 [D loss: (0.515)(R 0.475, F 0.555)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.530] [G acc: 0.094]\n",
      "2872 [D loss: (0.478)(R 0.419, F 0.537)] [D acc: (0.789)(0.797, 0.781)] [G loss: 1.406] [G acc: 0.016]\n",
      "2873 [D loss: (0.389)(R 0.335, F 0.442)] [D acc: (0.820)(0.828, 0.812)] [G loss: 1.568] [G acc: 0.047]\n",
      "2874 [D loss: (0.431)(R 0.424, F 0.439)] [D acc: (0.812)(0.797, 0.828)] [G loss: 1.781] [G acc: 0.062]\n",
      "2875 [D loss: (0.522)(R 0.521, F 0.523)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.513] [G acc: 0.109]\n",
      "2876 [D loss: (0.479)(R 0.460, F 0.498)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.522] [G acc: 0.094]\n",
      "2877 [D loss: (0.592)(R 0.575, F 0.610)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.498] [G acc: 0.062]\n",
      "2878 [D loss: (0.565)(R 0.649, F 0.480)] [D acc: (0.695)(0.547, 0.844)] [G loss: 1.511] [G acc: 0.078]\n",
      "2879 [D loss: (0.476)(R 0.534, F 0.417)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.537] [G acc: 0.078]\n",
      "2880 [D loss: (0.515)(R 0.470, F 0.561)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.653] [G acc: 0.047]\n",
      "2881 [D loss: (0.530)(R 0.460, F 0.601)] [D acc: (0.727)(0.750, 0.703)] [G loss: 1.647] [G acc: 0.078]\n",
      "2882 [D loss: (0.523)(R 0.580, F 0.467)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.414] [G acc: 0.125]\n",
      "2883 [D loss: (0.440)(R 0.408, F 0.472)] [D acc: (0.844)(0.828, 0.859)] [G loss: 1.576] [G acc: 0.109]\n",
      "2884 [D loss: (0.589)(R 0.735, F 0.442)] [D acc: (0.695)(0.516, 0.875)] [G loss: 1.414] [G acc: 0.094]\n",
      "2885 [D loss: (0.464)(R 0.419, F 0.508)] [D acc: (0.797)(0.797, 0.797)] [G loss: 1.543] [G acc: 0.156]\n",
      "2886 [D loss: (0.536)(R 0.502, F 0.571)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.508] [G acc: 0.156]\n",
      "2887 [D loss: (0.619)(R 0.650, F 0.587)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.386] [G acc: 0.141]\n",
      "2888 [D loss: (0.559)(R 0.560, F 0.558)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.481] [G acc: 0.094]\n",
      "2889 [D loss: (0.541)(R 0.530, F 0.551)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.598] [G acc: 0.047]\n",
      "2890 [D loss: (0.599)(R 0.662, F 0.537)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.429] [G acc: 0.094]\n",
      "2891 [D loss: (0.562)(R 0.726, F 0.398)] [D acc: (0.664)(0.453, 0.875)] [G loss: 1.400] [G acc: 0.141]\n",
      "2892 [D loss: (0.578)(R 0.664, F 0.492)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.452] [G acc: 0.031]\n",
      "2893 [D loss: (0.498)(R 0.422, F 0.575)] [D acc: (0.734)(0.750, 0.719)] [G loss: 1.364] [G acc: 0.094]\n",
      "2894 [D loss: (0.589)(R 0.579, F 0.600)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.373] [G acc: 0.078]\n",
      "2895 [D loss: (0.517)(R 0.462, F 0.572)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.324] [G acc: 0.172]\n",
      "2896 [D loss: (0.589)(R 0.661, F 0.517)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.326] [G acc: 0.016]\n",
      "2897 [D loss: (0.527)(R 0.557, F 0.497)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.539] [G acc: 0.062]\n",
      "2898 [D loss: (0.503)(R 0.458, F 0.548)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.284] [G acc: 0.141]\n",
      "2899 [D loss: (0.456)(R 0.439, F 0.472)] [D acc: (0.773)(0.781, 0.766)] [G loss: 1.504] [G acc: 0.047]\n",
      "2900 [D loss: (0.446)(R 0.395, F 0.498)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.441] [G acc: 0.109]\n",
      "2901 [D loss: (0.531)(R 0.578, F 0.485)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.346] [G acc: 0.156]\n",
      "2902 [D loss: (0.601)(R 0.623, F 0.578)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.438] [G acc: 0.062]\n",
      "2903 [D loss: (0.549)(R 0.588, F 0.509)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.412] [G acc: 0.047]\n",
      "2904 [D loss: (0.562)(R 0.612, F 0.513)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.330] [G acc: 0.094]\n",
      "2905 [D loss: (0.435)(R 0.451, F 0.419)] [D acc: (0.828)(0.766, 0.891)] [G loss: 1.291] [G acc: 0.094]\n",
      "2906 [D loss: (0.411)(R 0.356, F 0.467)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.548] [G acc: 0.109]\n",
      "2907 [D loss: (0.518)(R 0.557, F 0.480)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.378] [G acc: 0.062]\n",
      "2908 [D loss: (0.600)(R 0.579, F 0.622)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.585] [G acc: 0.047]\n",
      "2909 [D loss: (0.555)(R 0.562, F 0.549)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.499] [G acc: 0.125]\n",
      "2910 [D loss: (0.464)(R 0.476, F 0.452)] [D acc: (0.836)(0.781, 0.891)] [G loss: 1.575] [G acc: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2911 [D loss: (0.566)(R 0.395, F 0.736)] [D acc: (0.789)(0.812, 0.766)] [G loss: 1.464] [G acc: 0.031]\n",
      "2912 [D loss: (0.624)(R 0.745, F 0.502)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.330] [G acc: 0.094]\n",
      "2913 [D loss: (0.461)(R 0.494, F 0.427)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.490] [G acc: 0.031]\n",
      "2914 [D loss: (0.530)(R 0.635, F 0.426)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.349] [G acc: 0.156]\n",
      "2915 [D loss: (0.480)(R 0.471, F 0.490)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.540] [G acc: 0.141]\n",
      "2916 [D loss: (0.413)(R 0.395, F 0.431)] [D acc: (0.844)(0.781, 0.906)] [G loss: 1.413] [G acc: 0.047]\n",
      "2917 [D loss: (0.568)(R 0.631, F 0.505)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.309] [G acc: 0.172]\n",
      "2918 [D loss: (0.492)(R 0.537, F 0.448)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.501] [G acc: 0.078]\n",
      "2919 [D loss: (0.569)(R 0.554, F 0.584)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.460] [G acc: 0.078]\n",
      "2920 [D loss: (0.481)(R 0.479, F 0.483)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.581] [G acc: 0.031]\n",
      "2921 [D loss: (0.535)(R 0.566, F 0.503)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.345] [G acc: 0.078]\n",
      "2922 [D loss: (0.567)(R 0.548, F 0.587)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.361] [G acc: 0.125]\n",
      "2923 [D loss: (0.457)(R 0.513, F 0.401)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.474] [G acc: 0.078]\n",
      "2924 [D loss: (0.542)(R 0.506, F 0.577)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.451] [G acc: 0.125]\n",
      "2925 [D loss: (0.552)(R 0.517, F 0.587)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.324] [G acc: 0.109]\n",
      "2926 [D loss: (0.616)(R 0.559, F 0.673)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.465] [G acc: 0.078]\n",
      "2927 [D loss: (0.451)(R 0.444, F 0.459)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.478] [G acc: 0.062]\n",
      "2928 [D loss: (0.470)(R 0.432, F 0.507)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.380] [G acc: 0.141]\n",
      "2929 [D loss: (0.538)(R 0.505, F 0.571)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.453] [G acc: 0.031]\n",
      "2930 [D loss: (0.554)(R 0.609, F 0.498)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.545] [G acc: 0.078]\n",
      "2931 [D loss: (0.515)(R 0.504, F 0.526)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.371] [G acc: 0.047]\n",
      "2932 [D loss: (0.588)(R 0.696, F 0.479)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.346] [G acc: 0.094]\n",
      "2933 [D loss: (0.521)(R 0.448, F 0.593)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.549] [G acc: 0.078]\n",
      "2934 [D loss: (0.512)(R 0.580, F 0.444)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.512] [G acc: 0.062]\n",
      "2935 [D loss: (0.568)(R 0.649, F 0.486)] [D acc: (0.656)(0.531, 0.781)] [G loss: 1.377] [G acc: 0.109]\n",
      "2936 [D loss: (0.602)(R 0.538, F 0.666)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.480] [G acc: 0.078]\n",
      "2937 [D loss: (0.572)(R 0.627, F 0.518)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.446] [G acc: 0.062]\n",
      "2938 [D loss: (0.562)(R 0.613, F 0.512)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.331] [G acc: 0.109]\n",
      "2939 [D loss: (0.524)(R 0.571, F 0.477)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.204] [G acc: 0.188]\n",
      "2940 [D loss: (0.520)(R 0.458, F 0.583)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.431] [G acc: 0.094]\n",
      "2941 [D loss: (0.552)(R 0.588, F 0.516)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.354] [G acc: 0.125]\n",
      "2942 [D loss: (0.530)(R 0.569, F 0.492)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.220] [G acc: 0.125]\n",
      "2943 [D loss: (0.583)(R 0.684, F 0.483)] [D acc: (0.711)(0.547, 0.875)] [G loss: 1.316] [G acc: 0.156]\n",
      "2944 [D loss: (0.537)(R 0.507, F 0.567)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.259] [G acc: 0.141]\n",
      "2945 [D loss: (0.583)(R 0.649, F 0.516)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.230] [G acc: 0.141]\n",
      "2946 [D loss: (0.589)(R 0.524, F 0.654)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.240] [G acc: 0.109]\n",
      "2947 [D loss: (0.564)(R 0.537, F 0.590)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.331] [G acc: 0.094]\n",
      "2948 [D loss: (0.567)(R 0.614, F 0.520)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.163] [G acc: 0.109]\n",
      "2949 [D loss: (0.499)(R 0.412, F 0.586)] [D acc: (0.734)(0.766, 0.703)] [G loss: 1.409] [G acc: 0.141]\n",
      "2950 [D loss: (0.478)(R 0.571, F 0.385)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.325] [G acc: 0.109]\n",
      "2951 [D loss: (0.561)(R 0.524, F 0.599)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.411] [G acc: 0.047]\n",
      "2952 [D loss: (0.590)(R 0.657, F 0.524)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.418] [G acc: 0.062]\n",
      "2953 [D loss: (0.540)(R 0.516, F 0.563)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.224] [G acc: 0.094]\n",
      "2954 [D loss: (0.556)(R 0.639, F 0.473)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.358] [G acc: 0.047]\n",
      "2955 [D loss: (0.489)(R 0.454, F 0.525)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.221] [G acc: 0.156]\n",
      "2956 [D loss: (0.499)(R 0.530, F 0.469)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.238] [G acc: 0.156]\n",
      "2957 [D loss: (0.519)(R 0.547, F 0.491)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.429] [G acc: 0.078]\n",
      "2958 [D loss: (0.527)(R 0.558, F 0.496)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.268] [G acc: 0.156]\n",
      "2959 [D loss: (0.556)(R 0.502, F 0.609)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.381] [G acc: 0.094]\n",
      "2960 [D loss: (0.582)(R 0.586, F 0.578)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.439] [G acc: 0.078]\n",
      "2961 [D loss: (0.557)(R 0.668, F 0.445)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.308] [G acc: 0.078]\n",
      "2962 [D loss: (0.563)(R 0.670, F 0.455)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.290] [G acc: 0.141]\n",
      "2963 [D loss: (0.472)(R 0.471, F 0.473)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.409] [G acc: 0.062]\n",
      "2964 [D loss: (0.553)(R 0.571, F 0.535)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.175] [G acc: 0.172]\n",
      "2965 [D loss: (0.531)(R 0.452, F 0.609)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.400] [G acc: 0.094]\n",
      "2966 [D loss: (0.638)(R 0.721, F 0.554)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.289] [G acc: 0.125]\n",
      "2967 [D loss: (0.520)(R 0.509, F 0.530)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.228] [G acc: 0.141]\n",
      "2968 [D loss: (0.519)(R 0.502, F 0.535)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.442] [G acc: 0.141]\n",
      "2969 [D loss: (0.458)(R 0.493, F 0.424)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.465] [G acc: 0.141]\n",
      "2970 [D loss: (0.586)(R 0.657, F 0.515)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.321] [G acc: 0.031]\n",
      "2971 [D loss: (0.432)(R 0.406, F 0.457)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.476] [G acc: 0.031]\n",
      "2972 [D loss: (0.464)(R 0.443, F 0.484)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.408] [G acc: 0.125]\n",
      "2973 [D loss: (0.536)(R 0.605, F 0.466)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.425] [G acc: 0.094]\n",
      "2974 [D loss: (0.444)(R 0.446, F 0.443)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.587] [G acc: 0.109]\n",
      "2975 [D loss: (0.497)(R 0.536, F 0.458)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.477] [G acc: 0.078]\n",
      "2976 [D loss: (0.527)(R 0.495, F 0.559)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.498] [G acc: 0.031]\n",
      "2977 [D loss: (0.603)(R 0.561, F 0.644)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.529] [G acc: 0.016]\n",
      "2978 [D loss: (0.523)(R 0.624, F 0.422)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.362] [G acc: 0.031]\n",
      "2979 [D loss: (0.657)(R 0.841, F 0.472)] [D acc: (0.641)(0.453, 0.828)] [G loss: 1.336] [G acc: 0.078]\n",
      "2980 [D loss: (0.546)(R 0.478, F 0.614)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.286] [G acc: 0.047]\n",
      "2981 [D loss: (0.513)(R 0.577, F 0.449)] [D acc: (0.734)(0.578, 0.891)] [G loss: 1.350] [G acc: 0.109]\n",
      "2982 [D loss: (0.433)(R 0.415, F 0.451)] [D acc: (0.828)(0.750, 0.906)] [G loss: 1.404] [G acc: 0.125]\n",
      "2983 [D loss: (0.588)(R 0.527, F 0.649)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.294] [G acc: 0.141]\n",
      "2984 [D loss: (0.617)(R 0.660, F 0.574)] [D acc: (0.672)(0.531, 0.812)] [G loss: 1.395] [G acc: 0.078]\n",
      "2985 [D loss: (0.543)(R 0.577, F 0.508)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.448] [G acc: 0.078]\n",
      "2986 [D loss: (0.586)(R 0.546, F 0.625)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.346] [G acc: 0.094]\n",
      "2987 [D loss: (0.512)(R 0.639, F 0.384)] [D acc: (0.766)(0.578, 0.953)] [G loss: 1.238] [G acc: 0.125]\n",
      "2988 [D loss: (0.499)(R 0.492, F 0.506)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.254] [G acc: 0.125]\n",
      "2989 [D loss: (0.554)(R 0.502, F 0.607)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.400] [G acc: 0.078]\n",
      "2990 [D loss: (0.552)(R 0.664, F 0.440)] [D acc: (0.695)(0.531, 0.859)] [G loss: 1.307] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2991 [D loss: (0.531)(R 0.525, F 0.537)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.475] [G acc: 0.047]\n",
      "2992 [D loss: (0.582)(R 0.611, F 0.553)] [D acc: (0.648)(0.516, 0.781)] [G loss: 1.273] [G acc: 0.016]\n",
      "2993 [D loss: (0.522)(R 0.563, F 0.481)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.296] [G acc: 0.062]\n",
      "2994 [D loss: (0.510)(R 0.478, F 0.543)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.296] [G acc: 0.078]\n",
      "2995 [D loss: (0.510)(R 0.589, F 0.430)] [D acc: (0.773)(0.625, 0.922)] [G loss: 1.226] [G acc: 0.141]\n",
      "2996 [D loss: (0.603)(R 0.423, F 0.783)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.226] [G acc: 0.125]\n",
      "2997 [D loss: (0.513)(R 0.569, F 0.457)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.509] [G acc: 0.078]\n",
      "2998 [D loss: (0.576)(R 0.650, F 0.501)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.389] [G acc: 0.094]\n",
      "2999 [D loss: (0.500)(R 0.529, F 0.471)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.332] [G acc: 0.047]\n",
      "3000 [D loss: (0.519)(R 0.507, F 0.532)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.311] [G acc: 0.094]\n",
      "3001 [D loss: (0.555)(R 0.523, F 0.587)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.383] [G acc: 0.109]\n",
      "3002 [D loss: (0.549)(R 0.478, F 0.620)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.450] [G acc: 0.109]\n",
      "3003 [D loss: (0.550)(R 0.610, F 0.490)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.482] [G acc: 0.047]\n",
      "3004 [D loss: (0.493)(R 0.508, F 0.478)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.438] [G acc: 0.062]\n",
      "3005 [D loss: (0.497)(R 0.540, F 0.454)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.479] [G acc: 0.094]\n",
      "3006 [D loss: (0.520)(R 0.501, F 0.539)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.480] [G acc: 0.062]\n",
      "3007 [D loss: (0.520)(R 0.583, F 0.457)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.455] [G acc: 0.047]\n",
      "3008 [D loss: (0.561)(R 0.606, F 0.516)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.291] [G acc: 0.109]\n",
      "3009 [D loss: (0.548)(R 0.620, F 0.476)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.253] [G acc: 0.094]\n",
      "3010 [D loss: (0.472)(R 0.507, F 0.437)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.259] [G acc: 0.109]\n",
      "3011 [D loss: (0.474)(R 0.426, F 0.523)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.268] [G acc: 0.188]\n",
      "3012 [D loss: (0.595)(R 0.431, F 0.759)] [D acc: (0.672)(0.688, 0.656)] [G loss: 1.442] [G acc: 0.031]\n",
      "3013 [D loss: (0.584)(R 0.666, F 0.502)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.348] [G acc: 0.078]\n",
      "3014 [D loss: (0.534)(R 0.508, F 0.561)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.363] [G acc: 0.109]\n",
      "3015 [D loss: (0.546)(R 0.609, F 0.483)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.299] [G acc: 0.109]\n",
      "3016 [D loss: (0.531)(R 0.541, F 0.520)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.307] [G acc: 0.094]\n",
      "3017 [D loss: (0.460)(R 0.508, F 0.411)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.323] [G acc: 0.094]\n",
      "3018 [D loss: (0.485)(R 0.511, F 0.460)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.298] [G acc: 0.141]\n",
      "3019 [D loss: (0.645)(R 0.562, F 0.729)] [D acc: (0.648)(0.641, 0.656)] [G loss: 1.316] [G acc: 0.156]\n",
      "3020 [D loss: (0.532)(R 0.549, F 0.515)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.390] [G acc: 0.062]\n",
      "3021 [D loss: (0.558)(R 0.581, F 0.535)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.282] [G acc: 0.156]\n",
      "3022 [D loss: (0.552)(R 0.482, F 0.622)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.393] [G acc: 0.047]\n",
      "3023 [D loss: (0.514)(R 0.542, F 0.486)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.466] [G acc: 0.062]\n",
      "3024 [D loss: (0.575)(R 0.501, F 0.649)] [D acc: (0.641)(0.688, 0.594)] [G loss: 1.209] [G acc: 0.172]\n",
      "3025 [D loss: (0.614)(R 0.645, F 0.583)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.407] [G acc: 0.047]\n",
      "3026 [D loss: (0.506)(R 0.562, F 0.449)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.388] [G acc: 0.047]\n",
      "3027 [D loss: (0.539)(R 0.559, F 0.519)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.505] [G acc: 0.078]\n",
      "3028 [D loss: (0.645)(R 0.665, F 0.625)] [D acc: (0.609)(0.578, 0.641)] [G loss: 1.388] [G acc: 0.047]\n",
      "3029 [D loss: (0.516)(R 0.566, F 0.466)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.405] [G acc: 0.047]\n",
      "3030 [D loss: (0.415)(R 0.429, F 0.402)] [D acc: (0.836)(0.781, 0.891)] [G loss: 1.149] [G acc: 0.250]\n",
      "3031 [D loss: (0.581)(R 0.548, F 0.614)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.436] [G acc: 0.125]\n",
      "3032 [D loss: (0.548)(R 0.601, F 0.495)] [D acc: (0.727)(0.578, 0.875)] [G loss: 1.296] [G acc: 0.094]\n",
      "3033 [D loss: (0.590)(R 0.661, F 0.519)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.263] [G acc: 0.125]\n",
      "3034 [D loss: (0.466)(R 0.432, F 0.500)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.392] [G acc: 0.125]\n",
      "3035 [D loss: (0.506)(R 0.533, F 0.479)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.364] [G acc: 0.047]\n",
      "3036 [D loss: (0.517)(R 0.498, F 0.537)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.322] [G acc: 0.109]\n",
      "3037 [D loss: (0.479)(R 0.441, F 0.517)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.326] [G acc: 0.094]\n",
      "3038 [D loss: (0.575)(R 0.503, F 0.648)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.490] [G acc: 0.031]\n",
      "3039 [D loss: (0.575)(R 0.697, F 0.453)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.397] [G acc: 0.062]\n",
      "3040 [D loss: (0.534)(R 0.586, F 0.482)] [D acc: (0.734)(0.578, 0.891)] [G loss: 1.259] [G acc: 0.172]\n",
      "3041 [D loss: (0.581)(R 0.512, F 0.651)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.208] [G acc: 0.172]\n",
      "3042 [D loss: (0.540)(R 0.445, F 0.635)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.273] [G acc: 0.078]\n",
      "3043 [D loss: (0.485)(R 0.507, F 0.464)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.312] [G acc: 0.172]\n",
      "3044 [D loss: (0.623)(R 0.517, F 0.728)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.370] [G acc: 0.062]\n",
      "3045 [D loss: (0.538)(R 0.667, F 0.409)] [D acc: (0.695)(0.484, 0.906)] [G loss: 1.341] [G acc: 0.078]\n",
      "3046 [D loss: (0.536)(R 0.503, F 0.569)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.394] [G acc: 0.094]\n",
      "3047 [D loss: (0.483)(R 0.574, F 0.392)] [D acc: (0.789)(0.641, 0.938)] [G loss: 1.278] [G acc: 0.125]\n",
      "3048 [D loss: (0.448)(R 0.385, F 0.511)] [D acc: (0.781)(0.797, 0.766)] [G loss: 1.460] [G acc: 0.125]\n",
      "3049 [D loss: (0.574)(R 0.572, F 0.576)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.287] [G acc: 0.203]\n",
      "3050 [D loss: (0.535)(R 0.540, F 0.531)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.402] [G acc: 0.078]\n",
      "3051 [D loss: (0.532)(R 0.629, F 0.435)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.461] [G acc: 0.109]\n",
      "3052 [D loss: (0.527)(R 0.552, F 0.502)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.422] [G acc: 0.141]\n",
      "3053 [D loss: (0.484)(R 0.477, F 0.492)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.413] [G acc: 0.125]\n",
      "3054 [D loss: (0.598)(R 0.579, F 0.617)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.460] [G acc: 0.047]\n",
      "3055 [D loss: (0.537)(R 0.612, F 0.461)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.370] [G acc: 0.047]\n",
      "3056 [D loss: (0.516)(R 0.555, F 0.477)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.341] [G acc: 0.109]\n",
      "3057 [D loss: (0.498)(R 0.479, F 0.517)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.433] [G acc: 0.156]\n",
      "3058 [D loss: (0.539)(R 0.573, F 0.505)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.457] [G acc: 0.078]\n",
      "3059 [D loss: (0.518)(R 0.474, F 0.562)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.317] [G acc: 0.109]\n",
      "3060 [D loss: (0.525)(R 0.478, F 0.572)] [D acc: (0.695)(0.734, 0.656)] [G loss: 1.450] [G acc: 0.062]\n",
      "3061 [D loss: (0.532)(R 0.540, F 0.524)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.377] [G acc: 0.156]\n",
      "3062 [D loss: (0.512)(R 0.542, F 0.481)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.318] [G acc: 0.078]\n",
      "3063 [D loss: (0.519)(R 0.544, F 0.494)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.395] [G acc: 0.109]\n",
      "3064 [D loss: (0.511)(R 0.484, F 0.539)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.357] [G acc: 0.078]\n",
      "3065 [D loss: (0.466)(R 0.455, F 0.477)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.359] [G acc: 0.078]\n",
      "3066 [D loss: (0.534)(R 0.606, F 0.463)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.354] [G acc: 0.141]\n",
      "3067 [D loss: (0.489)(R 0.505, F 0.473)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.338] [G acc: 0.062]\n",
      "3068 [D loss: (0.568)(R 0.529, F 0.607)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.374] [G acc: 0.016]\n",
      "3069 [D loss: (0.513)(R 0.526, F 0.501)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.306] [G acc: 0.094]\n",
      "3070 [D loss: (0.558)(R 0.573, F 0.544)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.424] [G acc: 0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3071 [D loss: (0.494)(R 0.532, F 0.457)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.190] [G acc: 0.156]\n",
      "3072 [D loss: (0.622)(R 0.607, F 0.636)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.219] [G acc: 0.141]\n",
      "3073 [D loss: (0.576)(R 0.651, F 0.502)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.237] [G acc: 0.094]\n",
      "3074 [D loss: (0.598)(R 0.488, F 0.707)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.521] [G acc: 0.078]\n",
      "3075 [D loss: (0.555)(R 0.565, F 0.545)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.448] [G acc: 0.109]\n",
      "3076 [D loss: (0.544)(R 0.610, F 0.478)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.380] [G acc: 0.062]\n",
      "3077 [D loss: (0.507)(R 0.471, F 0.543)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.440] [G acc: 0.031]\n",
      "3078 [D loss: (0.585)(R 0.619, F 0.550)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.401] [G acc: 0.125]\n",
      "3079 [D loss: (0.536)(R 0.603, F 0.469)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.450] [G acc: 0.109]\n",
      "3080 [D loss: (0.544)(R 0.534, F 0.555)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.311] [G acc: 0.172]\n",
      "3081 [D loss: (0.441)(R 0.476, F 0.407)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.466] [G acc: 0.062]\n",
      "3082 [D loss: (0.426)(R 0.399, F 0.454)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.405] [G acc: 0.109]\n",
      "3083 [D loss: (0.452)(R 0.428, F 0.477)] [D acc: (0.797)(0.781, 0.812)] [G loss: 1.323] [G acc: 0.109]\n",
      "3084 [D loss: (0.510)(R 0.437, F 0.582)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.557] [G acc: 0.125]\n",
      "3085 [D loss: (0.608)(R 0.552, F 0.664)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.428] [G acc: 0.125]\n",
      "3086 [D loss: (0.534)(R 0.512, F 0.556)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.378] [G acc: 0.141]\n",
      "3087 [D loss: (0.505)(R 0.541, F 0.469)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.780] [G acc: 0.016]\n",
      "3088 [D loss: (0.636)(R 0.794, F 0.477)] [D acc: (0.664)(0.500, 0.828)] [G loss: 1.409] [G acc: 0.078]\n",
      "3089 [D loss: (0.500)(R 0.481, F 0.519)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.375] [G acc: 0.141]\n",
      "3090 [D loss: (0.585)(R 0.589, F 0.581)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.401] [G acc: 0.031]\n",
      "3091 [D loss: (0.461)(R 0.541, F 0.380)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.454] [G acc: 0.078]\n",
      "3092 [D loss: (0.489)(R 0.492, F 0.486)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.497] [G acc: 0.094]\n",
      "3093 [D loss: (0.517)(R 0.595, F 0.440)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.505] [G acc: 0.094]\n",
      "3094 [D loss: (0.468)(R 0.422, F 0.515)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.558] [G acc: 0.047]\n",
      "3095 [D loss: (0.473)(R 0.531, F 0.415)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.411] [G acc: 0.062]\n",
      "3096 [D loss: (0.567)(R 0.662, F 0.472)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.438] [G acc: 0.078]\n",
      "3097 [D loss: (0.541)(R 0.624, F 0.458)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.308] [G acc: 0.094]\n",
      "3098 [D loss: (0.594)(R 0.596, F 0.592)] [D acc: (0.633)(0.578, 0.688)] [G loss: 1.219] [G acc: 0.078]\n",
      "3099 [D loss: (0.500)(R 0.539, F 0.462)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.314] [G acc: 0.062]\n",
      "3100 [D loss: (0.619)(R 0.581, F 0.657)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.416] [G acc: 0.078]\n",
      "3101 [D loss: (0.565)(R 0.650, F 0.480)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.344] [G acc: 0.078]\n",
      "3102 [D loss: (0.552)(R 0.469, F 0.634)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.351] [G acc: 0.078]\n",
      "3103 [D loss: (0.505)(R 0.593, F 0.417)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.340] [G acc: 0.094]\n",
      "3104 [D loss: (0.542)(R 0.517, F 0.568)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.365] [G acc: 0.094]\n",
      "3105 [D loss: (0.553)(R 0.614, F 0.492)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.274] [G acc: 0.141]\n",
      "3106 [D loss: (0.494)(R 0.532, F 0.457)] [D acc: (0.797)(0.688, 0.906)] [G loss: 1.436] [G acc: 0.031]\n",
      "3107 [D loss: (0.619)(R 0.659, F 0.580)] [D acc: (0.648)(0.531, 0.766)] [G loss: 1.306] [G acc: 0.109]\n",
      "3108 [D loss: (0.536)(R 0.626, F 0.447)] [D acc: (0.742)(0.594, 0.891)] [G loss: 1.331] [G acc: 0.125]\n",
      "3109 [D loss: (0.477)(R 0.432, F 0.522)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.291] [G acc: 0.141]\n",
      "3110 [D loss: (0.521)(R 0.438, F 0.604)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.322] [G acc: 0.109]\n",
      "3111 [D loss: (0.490)(R 0.478, F 0.502)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.417] [G acc: 0.078]\n",
      "3112 [D loss: (0.485)(R 0.540, F 0.429)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.346] [G acc: 0.094]\n",
      "3113 [D loss: (0.440)(R 0.414, F 0.466)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.432] [G acc: 0.078]\n",
      "3114 [D loss: (0.564)(R 0.586, F 0.543)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.397] [G acc: 0.172]\n",
      "3115 [D loss: (0.577)(R 0.550, F 0.605)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.279] [G acc: 0.156]\n",
      "3116 [D loss: (0.560)(R 0.605, F 0.515)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.329] [G acc: 0.109]\n",
      "3117 [D loss: (0.567)(R 0.640, F 0.495)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.389] [G acc: 0.125]\n",
      "3118 [D loss: (0.625)(R 0.526, F 0.724)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.258] [G acc: 0.078]\n",
      "3119 [D loss: (0.609)(R 0.523, F 0.695)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.328] [G acc: 0.047]\n",
      "3120 [D loss: (0.610)(R 0.652, F 0.567)] [D acc: (0.641)(0.484, 0.797)] [G loss: 1.227] [G acc: 0.109]\n",
      "3121 [D loss: (0.539)(R 0.591, F 0.487)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.301] [G acc: 0.094]\n",
      "3122 [D loss: (0.557)(R 0.586, F 0.529)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.283] [G acc: 0.203]\n",
      "3123 [D loss: (0.483)(R 0.455, F 0.511)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.388] [G acc: 0.062]\n",
      "3124 [D loss: (0.565)(R 0.574, F 0.556)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.456] [G acc: 0.078]\n",
      "3125 [D loss: (0.527)(R 0.508, F 0.545)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.376] [G acc: 0.062]\n",
      "3126 [D loss: (0.562)(R 0.522, F 0.602)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.277] [G acc: 0.125]\n",
      "3127 [D loss: (0.578)(R 0.619, F 0.536)] [D acc: (0.641)(0.516, 0.766)] [G loss: 1.428] [G acc: 0.031]\n",
      "3128 [D loss: (0.469)(R 0.496, F 0.443)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.440] [G acc: 0.062]\n",
      "3129 [D loss: (0.584)(R 0.530, F 0.638)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.366] [G acc: 0.062]\n",
      "3130 [D loss: (0.432)(R 0.501, F 0.364)] [D acc: (0.836)(0.719, 0.953)] [G loss: 1.457] [G acc: 0.078]\n",
      "3131 [D loss: (0.536)(R 0.540, F 0.532)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.403] [G acc: 0.078]\n",
      "3132 [D loss: (0.514)(R 0.565, F 0.464)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.490] [G acc: 0.109]\n",
      "3133 [D loss: (0.593)(R 0.498, F 0.688)] [D acc: (0.680)(0.703, 0.656)] [G loss: 1.428] [G acc: 0.062]\n",
      "3134 [D loss: (0.565)(R 0.708, F 0.422)] [D acc: (0.719)(0.531, 0.906)] [G loss: 1.299] [G acc: 0.109]\n",
      "3135 [D loss: (0.547)(R 0.538, F 0.556)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.409] [G acc: 0.109]\n",
      "3136 [D loss: (0.519)(R 0.545, F 0.494)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.207] [G acc: 0.125]\n",
      "3137 [D loss: (0.530)(R 0.458, F 0.601)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.469] [G acc: 0.094]\n",
      "3138 [D loss: (0.563)(R 0.561, F 0.565)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.404] [G acc: 0.062]\n",
      "3139 [D loss: (0.599)(R 0.657, F 0.540)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.314] [G acc: 0.078]\n",
      "3140 [D loss: (0.580)(R 0.697, F 0.463)] [D acc: (0.664)(0.500, 0.828)] [G loss: 1.330] [G acc: 0.125]\n",
      "3141 [D loss: (0.523)(R 0.482, F 0.565)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.292] [G acc: 0.141]\n",
      "3142 [D loss: (0.570)(R 0.578, F 0.562)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.316] [G acc: 0.094]\n",
      "3143 [D loss: (0.675)(R 0.638, F 0.712)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.402] [G acc: 0.094]\n",
      "3144 [D loss: (0.487)(R 0.571, F 0.402)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.351] [G acc: 0.109]\n",
      "3145 [D loss: (0.530)(R 0.553, F 0.507)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.305] [G acc: 0.156]\n",
      "3146 [D loss: (0.644)(R 0.582, F 0.707)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.450] [G acc: 0.109]\n",
      "3147 [D loss: (0.594)(R 0.656, F 0.532)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.478] [G acc: 0.078]\n",
      "3148 [D loss: (0.476)(R 0.537, F 0.415)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.319] [G acc: 0.094]\n",
      "3149 [D loss: (0.499)(R 0.448, F 0.551)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.249] [G acc: 0.141]\n",
      "3150 [D loss: (0.490)(R 0.542, F 0.437)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.433] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3151 [D loss: (0.664)(R 0.824, F 0.505)] [D acc: (0.641)(0.453, 0.828)] [G loss: 1.188] [G acc: 0.125]\n",
      "3152 [D loss: (0.527)(R 0.454, F 0.601)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.254] [G acc: 0.156]\n",
      "3153 [D loss: (0.539)(R 0.571, F 0.507)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.242] [G acc: 0.141]\n",
      "3154 [D loss: (0.535)(R 0.516, F 0.555)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.166] [G acc: 0.156]\n",
      "3155 [D loss: (0.529)(R 0.451, F 0.608)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.283] [G acc: 0.109]\n",
      "3156 [D loss: (0.532)(R 0.491, F 0.574)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.288] [G acc: 0.172]\n",
      "3157 [D loss: (0.457)(R 0.371, F 0.544)] [D acc: (0.828)(0.859, 0.797)] [G loss: 1.515] [G acc: 0.094]\n",
      "3158 [D loss: (0.481)(R 0.535, F 0.427)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.291] [G acc: 0.188]\n",
      "3159 [D loss: (0.525)(R 0.383, F 0.667)] [D acc: (0.758)(0.781, 0.734)] [G loss: 1.563] [G acc: 0.062]\n",
      "3160 [D loss: (0.558)(R 0.682, F 0.434)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.403] [G acc: 0.094]\n",
      "3161 [D loss: (0.526)(R 0.546, F 0.506)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.419] [G acc: 0.125]\n",
      "3162 [D loss: (0.546)(R 0.502, F 0.591)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.527] [G acc: 0.031]\n",
      "3163 [D loss: (0.498)(R 0.492, F 0.503)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.303] [G acc: 0.062]\n",
      "3164 [D loss: (0.608)(R 0.687, F 0.530)] [D acc: (0.719)(0.547, 0.891)] [G loss: 1.474] [G acc: 0.109]\n",
      "3165 [D loss: (0.506)(R 0.404, F 0.608)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.360] [G acc: 0.156]\n",
      "3166 [D loss: (0.527)(R 0.625, F 0.430)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.418] [G acc: 0.125]\n",
      "3167 [D loss: (0.567)(R 0.596, F 0.537)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.268] [G acc: 0.172]\n",
      "3168 [D loss: (0.594)(R 0.670, F 0.519)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.380] [G acc: 0.156]\n",
      "3169 [D loss: (0.446)(R 0.392, F 0.500)] [D acc: (0.820)(0.797, 0.844)] [G loss: 1.370] [G acc: 0.094]\n",
      "3170 [D loss: (0.576)(R 0.608, F 0.545)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.385] [G acc: 0.109]\n",
      "3171 [D loss: (0.515)(R 0.533, F 0.497)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.327] [G acc: 0.109]\n",
      "3172 [D loss: (0.602)(R 0.518, F 0.686)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.627] [G acc: 0.078]\n",
      "3173 [D loss: (0.480)(R 0.520, F 0.440)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.285] [G acc: 0.141]\n",
      "3174 [D loss: (0.508)(R 0.472, F 0.543)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.391] [G acc: 0.094]\n",
      "3175 [D loss: (0.505)(R 0.573, F 0.437)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.326] [G acc: 0.172]\n",
      "3176 [D loss: (0.519)(R 0.511, F 0.528)] [D acc: (0.695)(0.719, 0.672)] [G loss: 1.440] [G acc: 0.094]\n",
      "3177 [D loss: (0.587)(R 0.557, F 0.616)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.342] [G acc: 0.125]\n",
      "3178 [D loss: (0.543)(R 0.592, F 0.494)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.385] [G acc: 0.078]\n",
      "3179 [D loss: (0.504)(R 0.516, F 0.491)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.481] [G acc: 0.109]\n",
      "3180 [D loss: (0.540)(R 0.640, F 0.439)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.378] [G acc: 0.109]\n",
      "3181 [D loss: (0.534)(R 0.504, F 0.563)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.403] [G acc: 0.141]\n",
      "3182 [D loss: (0.503)(R 0.588, F 0.418)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.305] [G acc: 0.109]\n",
      "3183 [D loss: (0.488)(R 0.428, F 0.547)] [D acc: (0.758)(0.781, 0.734)] [G loss: 1.511] [G acc: 0.109]\n",
      "3184 [D loss: (0.466)(R 0.486, F 0.446)] [D acc: (0.805)(0.750, 0.859)] [G loss: 1.396] [G acc: 0.078]\n",
      "3185 [D loss: (0.519)(R 0.603, F 0.434)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.457] [G acc: 0.109]\n",
      "3186 [D loss: (0.535)(R 0.593, F 0.477)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.394] [G acc: 0.078]\n",
      "3187 [D loss: (0.566)(R 0.530, F 0.602)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.404] [G acc: 0.062]\n",
      "3188 [D loss: (0.551)(R 0.672, F 0.430)] [D acc: (0.680)(0.484, 0.875)] [G loss: 1.431] [G acc: 0.125]\n",
      "3189 [D loss: (0.528)(R 0.528, F 0.527)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.433] [G acc: 0.141]\n",
      "3190 [D loss: (0.629)(R 0.518, F 0.739)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.227] [G acc: 0.141]\n",
      "3191 [D loss: (0.530)(R 0.527, F 0.533)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.369] [G acc: 0.125]\n",
      "3192 [D loss: (0.475)(R 0.496, F 0.454)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.366] [G acc: 0.078]\n",
      "3193 [D loss: (0.555)(R 0.544, F 0.565)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.339] [G acc: 0.172]\n",
      "3194 [D loss: (0.543)(R 0.545, F 0.541)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.376] [G acc: 0.109]\n",
      "3195 [D loss: (0.525)(R 0.524, F 0.526)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.568] [G acc: 0.109]\n",
      "3196 [D loss: (0.573)(R 0.617, F 0.529)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.435] [G acc: 0.094]\n",
      "3197 [D loss: (0.497)(R 0.468, F 0.525)] [D acc: (0.742)(0.766, 0.719)] [G loss: 1.458] [G acc: 0.078]\n",
      "3198 [D loss: (0.499)(R 0.494, F 0.503)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.549] [G acc: 0.094]\n",
      "3199 [D loss: (0.626)(R 0.583, F 0.669)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.433] [G acc: 0.094]\n",
      "3200 [D loss: (0.510)(R 0.573, F 0.447)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.442] [G acc: 0.125]\n",
      "3201 [D loss: (0.565)(R 0.634, F 0.497)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.403] [G acc: 0.109]\n",
      "3202 [D loss: (0.518)(R 0.525, F 0.510)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.399] [G acc: 0.078]\n",
      "3203 [D loss: (0.507)(R 0.528, F 0.486)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.330] [G acc: 0.062]\n",
      "3204 [D loss: (0.585)(R 0.514, F 0.656)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.338] [G acc: 0.047]\n",
      "3205 [D loss: (0.553)(R 0.547, F 0.558)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.396] [G acc: 0.062]\n",
      "3206 [D loss: (0.573)(R 0.624, F 0.522)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.451] [G acc: 0.062]\n",
      "3207 [D loss: (0.524)(R 0.570, F 0.479)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.416] [G acc: 0.094]\n",
      "3208 [D loss: (0.470)(R 0.381, F 0.559)] [D acc: (0.844)(0.812, 0.875)] [G loss: 1.457] [G acc: 0.031]\n",
      "3209 [D loss: (0.443)(R 0.434, F 0.452)] [D acc: (0.797)(0.781, 0.812)] [G loss: 1.355] [G acc: 0.172]\n",
      "3210 [D loss: (0.451)(R 0.455, F 0.447)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.483] [G acc: 0.141]\n",
      "3211 [D loss: (0.580)(R 0.519, F 0.640)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.495] [G acc: 0.156]\n",
      "3212 [D loss: (0.517)(R 0.514, F 0.520)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.442] [G acc: 0.078]\n",
      "3213 [D loss: (0.473)(R 0.511, F 0.435)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.479] [G acc: 0.094]\n",
      "3214 [D loss: (0.539)(R 0.569, F 0.509)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.396] [G acc: 0.141]\n",
      "3215 [D loss: (0.502)(R 0.582, F 0.423)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.371] [G acc: 0.172]\n",
      "3216 [D loss: (0.502)(R 0.493, F 0.511)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.532] [G acc: 0.078]\n",
      "3217 [D loss: (0.591)(R 0.601, F 0.582)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.394] [G acc: 0.031]\n",
      "3218 [D loss: (0.485)(R 0.394, F 0.576)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.598] [G acc: 0.078]\n",
      "3219 [D loss: (0.667)(R 0.816, F 0.519)] [D acc: (0.594)(0.438, 0.750)] [G loss: 1.423] [G acc: 0.047]\n",
      "3220 [D loss: (0.591)(R 0.507, F 0.674)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.439] [G acc: 0.094]\n",
      "3221 [D loss: (0.607)(R 0.700, F 0.514)] [D acc: (0.680)(0.516, 0.844)] [G loss: 1.311] [G acc: 0.109]\n",
      "3222 [D loss: (0.565)(R 0.599, F 0.531)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.490] [G acc: 0.047]\n",
      "3223 [D loss: (0.484)(R 0.523, F 0.446)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.377] [G acc: 0.109]\n",
      "3224 [D loss: (0.492)(R 0.469, F 0.514)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.324] [G acc: 0.078]\n",
      "3225 [D loss: (0.588)(R 0.570, F 0.606)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.350] [G acc: 0.094]\n",
      "3226 [D loss: (0.580)(R 0.573, F 0.587)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.308] [G acc: 0.094]\n",
      "3227 [D loss: (0.538)(R 0.612, F 0.463)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.421] [G acc: 0.078]\n",
      "3228 [D loss: (0.628)(R 0.692, F 0.563)] [D acc: (0.625)(0.594, 0.656)] [G loss: 1.261] [G acc: 0.188]\n",
      "3229 [D loss: (0.520)(R 0.504, F 0.537)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.286] [G acc: 0.062]\n",
      "3230 [D loss: (0.574)(R 0.599, F 0.550)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.321] [G acc: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3231 [D loss: (0.504)(R 0.500, F 0.508)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.314] [G acc: 0.109]\n",
      "3232 [D loss: (0.607)(R 0.677, F 0.536)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.300] [G acc: 0.078]\n",
      "3233 [D loss: (0.440)(R 0.435, F 0.446)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.375] [G acc: 0.062]\n",
      "3234 [D loss: (0.475)(R 0.484, F 0.465)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.432] [G acc: 0.062]\n",
      "3235 [D loss: (0.537)(R 0.531, F 0.543)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.321] [G acc: 0.062]\n",
      "3236 [D loss: (0.526)(R 0.613, F 0.439)] [D acc: (0.695)(0.516, 0.875)] [G loss: 1.340] [G acc: 0.219]\n",
      "3237 [D loss: (0.582)(R 0.617, F 0.547)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.381] [G acc: 0.094]\n",
      "3238 [D loss: (0.581)(R 0.579, F 0.584)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.312] [G acc: 0.141]\n",
      "3239 [D loss: (0.599)(R 0.573, F 0.625)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.282] [G acc: 0.094]\n",
      "3240 [D loss: (0.499)(R 0.574, F 0.424)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.444] [G acc: 0.078]\n",
      "3241 [D loss: (0.519)(R 0.563, F 0.475)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.377] [G acc: 0.125]\n",
      "3242 [D loss: (0.584)(R 0.517, F 0.651)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.433] [G acc: 0.031]\n",
      "3243 [D loss: (0.552)(R 0.548, F 0.557)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.298] [G acc: 0.109]\n",
      "3244 [D loss: (0.488)(R 0.594, F 0.383)] [D acc: (0.797)(0.625, 0.969)] [G loss: 1.430] [G acc: 0.078]\n",
      "3245 [D loss: (0.487)(R 0.534, F 0.440)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.493] [G acc: 0.062]\n",
      "3246 [D loss: (0.546)(R 0.452, F 0.641)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.582] [G acc: 0.047]\n",
      "3247 [D loss: (0.580)(R 0.717, F 0.444)] [D acc: (0.711)(0.547, 0.875)] [G loss: 1.370] [G acc: 0.141]\n",
      "3248 [D loss: (0.534)(R 0.521, F 0.548)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.521] [G acc: 0.062]\n",
      "3249 [D loss: (0.524)(R 0.557, F 0.492)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.346] [G acc: 0.172]\n",
      "3250 [D loss: (0.576)(R 0.539, F 0.613)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.436] [G acc: 0.078]\n",
      "3251 [D loss: (0.565)(R 0.558, F 0.572)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.250] [G acc: 0.156]\n",
      "3252 [D loss: (0.563)(R 0.611, F 0.516)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.309] [G acc: 0.156]\n",
      "3253 [D loss: (0.556)(R 0.536, F 0.577)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.453] [G acc: 0.109]\n",
      "3254 [D loss: (0.548)(R 0.623, F 0.474)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.238] [G acc: 0.125]\n",
      "3255 [D loss: (0.572)(R 0.581, F 0.564)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.469] [G acc: 0.031]\n",
      "3256 [D loss: (0.550)(R 0.551, F 0.549)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.343] [G acc: 0.078]\n",
      "3257 [D loss: (0.481)(R 0.473, F 0.489)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.308] [G acc: 0.203]\n",
      "3258 [D loss: (0.468)(R 0.537, F 0.399)] [D acc: (0.789)(0.672, 0.906)] [G loss: 1.349] [G acc: 0.156]\n",
      "3259 [D loss: (0.540)(R 0.474, F 0.605)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.344] [G acc: 0.125]\n",
      "3260 [D loss: (0.497)(R 0.432, F 0.562)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.330] [G acc: 0.141]\n",
      "3261 [D loss: (0.555)(R 0.508, F 0.602)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.462] [G acc: 0.141]\n",
      "3262 [D loss: (0.440)(R 0.432, F 0.447)] [D acc: (0.828)(0.828, 0.828)] [G loss: 1.472] [G acc: 0.047]\n",
      "3263 [D loss: (0.478)(R 0.385, F 0.571)] [D acc: (0.766)(0.781, 0.750)] [G loss: 1.589] [G acc: 0.109]\n",
      "3264 [D loss: (0.570)(R 0.708, F 0.433)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.320] [G acc: 0.109]\n",
      "3265 [D loss: (0.566)(R 0.478, F 0.653)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.452] [G acc: 0.094]\n",
      "3266 [D loss: (0.550)(R 0.581, F 0.518)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.536] [G acc: 0.062]\n",
      "3267 [D loss: (0.580)(R 0.636, F 0.524)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.401] [G acc: 0.078]\n",
      "3268 [D loss: (0.658)(R 0.737, F 0.579)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.328] [G acc: 0.031]\n",
      "3269 [D loss: (0.539)(R 0.536, F 0.542)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.301] [G acc: 0.109]\n",
      "3270 [D loss: (0.517)(R 0.539, F 0.494)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.227] [G acc: 0.141]\n",
      "3271 [D loss: (0.525)(R 0.560, F 0.490)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.428] [G acc: 0.078]\n",
      "3272 [D loss: (0.515)(R 0.565, F 0.466)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.229] [G acc: 0.172]\n",
      "3273 [D loss: (0.485)(R 0.518, F 0.452)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.420] [G acc: 0.078]\n",
      "3274 [D loss: (0.518)(R 0.399, F 0.638)] [D acc: (0.742)(0.781, 0.703)] [G loss: 1.386] [G acc: 0.109]\n",
      "3275 [D loss: (0.440)(R 0.451, F 0.430)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.507] [G acc: 0.047]\n",
      "3276 [D loss: (0.534)(R 0.564, F 0.505)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.412] [G acc: 0.078]\n",
      "3277 [D loss: (0.526)(R 0.513, F 0.540)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.360] [G acc: 0.141]\n",
      "3278 [D loss: (0.553)(R 0.566, F 0.540)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.218] [G acc: 0.156]\n",
      "3279 [D loss: (0.534)(R 0.486, F 0.583)] [D acc: (0.727)(0.750, 0.703)] [G loss: 1.428] [G acc: 0.062]\n",
      "3280 [D loss: (0.488)(R 0.431, F 0.546)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.470] [G acc: 0.094]\n",
      "3281 [D loss: (0.635)(R 0.688, F 0.581)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.332] [G acc: 0.062]\n",
      "3282 [D loss: (0.495)(R 0.520, F 0.470)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.195] [G acc: 0.156]\n",
      "3283 [D loss: (0.561)(R 0.508, F 0.614)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.344] [G acc: 0.094]\n",
      "3284 [D loss: (0.507)(R 0.438, F 0.576)] [D acc: (0.805)(0.781, 0.828)] [G loss: 1.397] [G acc: 0.109]\n",
      "3285 [D loss: (0.623)(R 0.578, F 0.667)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.433] [G acc: 0.094]\n",
      "3286 [D loss: (0.588)(R 0.525, F 0.650)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.413] [G acc: 0.078]\n",
      "3287 [D loss: (0.611)(R 0.724, F 0.499)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.286] [G acc: 0.094]\n",
      "3288 [D loss: (0.608)(R 0.577, F 0.638)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.454] [G acc: 0.047]\n",
      "3289 [D loss: (0.591)(R 0.680, F 0.503)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.460] [G acc: 0.094]\n",
      "3290 [D loss: (0.432)(R 0.516, F 0.348)] [D acc: (0.805)(0.672, 0.938)] [G loss: 1.277] [G acc: 0.109]\n",
      "3291 [D loss: (0.501)(R 0.591, F 0.412)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.268] [G acc: 0.125]\n",
      "3292 [D loss: (0.404)(R 0.351, F 0.456)] [D acc: (0.859)(0.812, 0.906)] [G loss: 1.356] [G acc: 0.109]\n",
      "3293 [D loss: (0.518)(R 0.510, F 0.527)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.400] [G acc: 0.062]\n",
      "3294 [D loss: (0.493)(R 0.476, F 0.509)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.342] [G acc: 0.094]\n",
      "3295 [D loss: (0.483)(R 0.529, F 0.438)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.376] [G acc: 0.109]\n",
      "3296 [D loss: (0.539)(R 0.520, F 0.558)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.275] [G acc: 0.141]\n",
      "3297 [D loss: (0.631)(R 0.529, F 0.732)] [D acc: (0.648)(0.656, 0.641)] [G loss: 1.402] [G acc: 0.047]\n",
      "3298 [D loss: (0.518)(R 0.622, F 0.413)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.492] [G acc: 0.062]\n",
      "3299 [D loss: (0.450)(R 0.487, F 0.413)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.406] [G acc: 0.078]\n",
      "3300 [D loss: (0.487)(R 0.449, F 0.526)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.369] [G acc: 0.156]\n",
      "3301 [D loss: (0.577)(R 0.542, F 0.612)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.369] [G acc: 0.062]\n",
      "3302 [D loss: (0.528)(R 0.576, F 0.480)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.380] [G acc: 0.109]\n",
      "3303 [D loss: (0.541)(R 0.578, F 0.503)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.473] [G acc: 0.078]\n",
      "3304 [D loss: (0.475)(R 0.462, F 0.487)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.504] [G acc: 0.094]\n",
      "3305 [D loss: (0.457)(R 0.458, F 0.457)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.382] [G acc: 0.188]\n",
      "3306 [D loss: (0.514)(R 0.545, F 0.482)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.435] [G acc: 0.062]\n",
      "3307 [D loss: (0.545)(R 0.531, F 0.558)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.437] [G acc: 0.078]\n",
      "3308 [D loss: (0.508)(R 0.529, F 0.487)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.641] [G acc: 0.031]\n",
      "3309 [D loss: (0.560)(R 0.592, F 0.529)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.540] [G acc: 0.047]\n",
      "3310 [D loss: (0.603)(R 0.754, F 0.453)] [D acc: (0.656)(0.484, 0.828)] [G loss: 1.463] [G acc: 0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3311 [D loss: (0.534)(R 0.511, F 0.557)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.368] [G acc: 0.156]\n",
      "3312 [D loss: (0.519)(R 0.416, F 0.621)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.470] [G acc: 0.047]\n",
      "3313 [D loss: (0.539)(R 0.617, F 0.462)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.556] [G acc: 0.047]\n",
      "3314 [D loss: (0.470)(R 0.477, F 0.463)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.478] [G acc: 0.094]\n",
      "3315 [D loss: (0.430)(R 0.488, F 0.373)] [D acc: (0.820)(0.734, 0.906)] [G loss: 1.462] [G acc: 0.062]\n",
      "3316 [D loss: (0.562)(R 0.427, F 0.696)] [D acc: (0.734)(0.750, 0.719)] [G loss: 1.570] [G acc: 0.062]\n",
      "3317 [D loss: (0.653)(R 0.797, F 0.509)] [D acc: (0.688)(0.500, 0.875)] [G loss: 1.470] [G acc: 0.062]\n",
      "3318 [D loss: (0.472)(R 0.516, F 0.427)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.520] [G acc: 0.047]\n",
      "3319 [D loss: (0.522)(R 0.491, F 0.552)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.540] [G acc: 0.047]\n",
      "3320 [D loss: (0.519)(R 0.618, F 0.419)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.552] [G acc: 0.062]\n",
      "3321 [D loss: (0.434)(R 0.497, F 0.370)] [D acc: (0.828)(0.734, 0.922)] [G loss: 1.429] [G acc: 0.125]\n",
      "3322 [D loss: (0.512)(R 0.475, F 0.550)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.296] [G acc: 0.156]\n",
      "3323 [D loss: (0.496)(R 0.498, F 0.493)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.405] [G acc: 0.109]\n",
      "3324 [D loss: (0.520)(R 0.619, F 0.422)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.430] [G acc: 0.094]\n",
      "3325 [D loss: (0.484)(R 0.443, F 0.525)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.402] [G acc: 0.141]\n",
      "3326 [D loss: (0.536)(R 0.553, F 0.520)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.444] [G acc: 0.078]\n",
      "3327 [D loss: (0.603)(R 0.565, F 0.642)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.464] [G acc: 0.078]\n",
      "3328 [D loss: (0.513)(R 0.554, F 0.472)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.431] [G acc: 0.000]\n",
      "3329 [D loss: (0.565)(R 0.621, F 0.509)] [D acc: (0.680)(0.516, 0.844)] [G loss: 1.512] [G acc: 0.031]\n",
      "3330 [D loss: (0.560)(R 0.716, F 0.404)] [D acc: (0.734)(0.547, 0.922)] [G loss: 1.351] [G acc: 0.125]\n",
      "3331 [D loss: (0.567)(R 0.491, F 0.643)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.388] [G acc: 0.062]\n",
      "3332 [D loss: (0.562)(R 0.579, F 0.545)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.340] [G acc: 0.156]\n",
      "3333 [D loss: (0.524)(R 0.616, F 0.431)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.220] [G acc: 0.156]\n",
      "3334 [D loss: (0.599)(R 0.548, F 0.649)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.418] [G acc: 0.062]\n",
      "3335 [D loss: (0.507)(R 0.529, F 0.485)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.493] [G acc: 0.062]\n",
      "3336 [D loss: (0.561)(R 0.616, F 0.506)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.325] [G acc: 0.078]\n",
      "3337 [D loss: (0.547)(R 0.612, F 0.482)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.306] [G acc: 0.156]\n",
      "3338 [D loss: (0.601)(R 0.502, F 0.700)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.368] [G acc: 0.062]\n",
      "3339 [D loss: (0.579)(R 0.563, F 0.594)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.410] [G acc: 0.016]\n",
      "3340 [D loss: (0.538)(R 0.574, F 0.502)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.296] [G acc: 0.109]\n",
      "3341 [D loss: (0.486)(R 0.507, F 0.465)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.409] [G acc: 0.047]\n",
      "3342 [D loss: (0.510)(R 0.569, F 0.450)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.264] [G acc: 0.172]\n",
      "3343 [D loss: (0.502)(R 0.533, F 0.471)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.306] [G acc: 0.125]\n",
      "3344 [D loss: (0.476)(R 0.417, F 0.536)] [D acc: (0.797)(0.797, 0.797)] [G loss: 1.537] [G acc: 0.047]\n",
      "3345 [D loss: (0.553)(R 0.572, F 0.535)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.407] [G acc: 0.031]\n",
      "3346 [D loss: (0.630)(R 0.599, F 0.660)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.388] [G acc: 0.062]\n",
      "3347 [D loss: (0.500)(R 0.566, F 0.434)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.385] [G acc: 0.062]\n",
      "3348 [D loss: (0.576)(R 0.548, F 0.604)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.373] [G acc: 0.047]\n",
      "3349 [D loss: (0.522)(R 0.657, F 0.387)] [D acc: (0.758)(0.609, 0.906)] [G loss: 1.370] [G acc: 0.047]\n",
      "3350 [D loss: (0.521)(R 0.524, F 0.517)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.394] [G acc: 0.062]\n",
      "3351 [D loss: (0.470)(R 0.492, F 0.447)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.402] [G acc: 0.078]\n",
      "3352 [D loss: (0.486)(R 0.477, F 0.495)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.357] [G acc: 0.078]\n",
      "3353 [D loss: (0.507)(R 0.436, F 0.578)] [D acc: (0.742)(0.781, 0.703)] [G loss: 1.558] [G acc: 0.031]\n",
      "3354 [D loss: (0.579)(R 0.662, F 0.497)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.368] [G acc: 0.094]\n",
      "3355 [D loss: (0.577)(R 0.482, F 0.672)] [D acc: (0.805)(0.703, 0.906)] [G loss: 1.426] [G acc: 0.094]\n",
      "3356 [D loss: (0.519)(R 0.605, F 0.433)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.318] [G acc: 0.094]\n",
      "3357 [D loss: (0.521)(R 0.549, F 0.493)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.315] [G acc: 0.094]\n",
      "3358 [D loss: (0.523)(R 0.491, F 0.555)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.311] [G acc: 0.156]\n",
      "3359 [D loss: (0.482)(R 0.387, F 0.577)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.399] [G acc: 0.094]\n",
      "3360 [D loss: (0.633)(R 0.618, F 0.648)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.388] [G acc: 0.078]\n",
      "3361 [D loss: (0.448)(R 0.433, F 0.463)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.446] [G acc: 0.031]\n",
      "3362 [D loss: (0.452)(R 0.480, F 0.424)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.445] [G acc: 0.156]\n",
      "3363 [D loss: (0.505)(R 0.538, F 0.471)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.352] [G acc: 0.062]\n",
      "3364 [D loss: (0.519)(R 0.603, F 0.436)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.466] [G acc: 0.062]\n",
      "3365 [D loss: (0.440)(R 0.391, F 0.490)] [D acc: (0.812)(0.734, 0.891)] [G loss: 1.453] [G acc: 0.141]\n",
      "3366 [D loss: (0.525)(R 0.541, F 0.508)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.505] [G acc: 0.062]\n",
      "3367 [D loss: (0.495)(R 0.553, F 0.437)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.525] [G acc: 0.078]\n",
      "3368 [D loss: (0.609)(R 0.487, F 0.730)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.389] [G acc: 0.094]\n",
      "3369 [D loss: (0.575)(R 0.573, F 0.578)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.564] [G acc: 0.062]\n",
      "3370 [D loss: (0.571)(R 0.661, F 0.482)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.403] [G acc: 0.094]\n",
      "3371 [D loss: (0.523)(R 0.573, F 0.473)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.453] [G acc: 0.062]\n",
      "3372 [D loss: (0.447)(R 0.401, F 0.493)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.374] [G acc: 0.109]\n",
      "3373 [D loss: (0.561)(R 0.582, F 0.540)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.631] [G acc: 0.031]\n",
      "3374 [D loss: (0.485)(R 0.549, F 0.421)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.390] [G acc: 0.094]\n",
      "3375 [D loss: (0.522)(R 0.549, F 0.495)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.460] [G acc: 0.125]\n",
      "3376 [D loss: (0.542)(R 0.591, F 0.493)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.456] [G acc: 0.078]\n",
      "3377 [D loss: (0.546)(R 0.519, F 0.572)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.540] [G acc: 0.062]\n",
      "3378 [D loss: (0.534)(R 0.549, F 0.519)] [D acc: (0.656)(0.625, 0.688)] [G loss: 1.463] [G acc: 0.125]\n",
      "3379 [D loss: (0.444)(R 0.425, F 0.463)] [D acc: (0.828)(0.828, 0.828)] [G loss: 1.542] [G acc: 0.109]\n",
      "3380 [D loss: (0.514)(R 0.487, F 0.540)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.445] [G acc: 0.078]\n",
      "3381 [D loss: (0.514)(R 0.476, F 0.553)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.583] [G acc: 0.062]\n",
      "3382 [D loss: (0.468)(R 0.538, F 0.399)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.553] [G acc: 0.078]\n",
      "3383 [D loss: (0.485)(R 0.481, F 0.490)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.438] [G acc: 0.141]\n",
      "3384 [D loss: (0.429)(R 0.431, F 0.426)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.440] [G acc: 0.078]\n",
      "3385 [D loss: (0.642)(R 0.713, F 0.571)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.471] [G acc: 0.141]\n",
      "3386 [D loss: (0.604)(R 0.682, F 0.527)] [D acc: (0.625)(0.516, 0.734)] [G loss: 1.541] [G acc: 0.062]\n",
      "3387 [D loss: (0.575)(R 0.662, F 0.488)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.359] [G acc: 0.094]\n",
      "3388 [D loss: (0.439)(R 0.421, F 0.458)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.403] [G acc: 0.172]\n",
      "3389 [D loss: (0.503)(R 0.510, F 0.495)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.561] [G acc: 0.062]\n",
      "3390 [D loss: (0.463)(R 0.475, F 0.450)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.408] [G acc: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3391 [D loss: (0.535)(R 0.552, F 0.519)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.351] [G acc: 0.109]\n",
      "3392 [D loss: (0.512)(R 0.517, F 0.506)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.397] [G acc: 0.094]\n",
      "3393 [D loss: (0.469)(R 0.429, F 0.508)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.538] [G acc: 0.109]\n",
      "3394 [D loss: (0.518)(R 0.494, F 0.542)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.444] [G acc: 0.094]\n",
      "3395 [D loss: (0.416)(R 0.455, F 0.377)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.421] [G acc: 0.078]\n",
      "3396 [D loss: (0.533)(R 0.660, F 0.406)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.402] [G acc: 0.109]\n",
      "3397 [D loss: (0.457)(R 0.470, F 0.445)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.413] [G acc: 0.062]\n",
      "3398 [D loss: (0.458)(R 0.448, F 0.468)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.369] [G acc: 0.109]\n",
      "3399 [D loss: (0.564)(R 0.460, F 0.668)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.528] [G acc: 0.109]\n",
      "3400 [D loss: (0.517)(R 0.570, F 0.463)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.553] [G acc: 0.078]\n",
      "3401 [D loss: (0.546)(R 0.525, F 0.566)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.441] [G acc: 0.094]\n",
      "3402 [D loss: (0.595)(R 0.653, F 0.538)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.445] [G acc: 0.047]\n",
      "3403 [D loss: (0.549)(R 0.601, F 0.496)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.436] [G acc: 0.047]\n",
      "3404 [D loss: (0.595)(R 0.682, F 0.507)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.456] [G acc: 0.125]\n",
      "3405 [D loss: (0.471)(R 0.500, F 0.442)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.385] [G acc: 0.094]\n",
      "3406 [D loss: (0.543)(R 0.445, F 0.641)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.393] [G acc: 0.109]\n",
      "3407 [D loss: (0.530)(R 0.543, F 0.516)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.401] [G acc: 0.094]\n",
      "3408 [D loss: (0.437)(R 0.449, F 0.426)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.433] [G acc: 0.094]\n",
      "3409 [D loss: (0.524)(R 0.486, F 0.562)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.275] [G acc: 0.094]\n",
      "3410 [D loss: (0.565)(R 0.513, F 0.617)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.358] [G acc: 0.047]\n",
      "3411 [D loss: (0.550)(R 0.659, F 0.442)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.454] [G acc: 0.031]\n",
      "3412 [D loss: (0.548)(R 0.577, F 0.520)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.404] [G acc: 0.078]\n",
      "3413 [D loss: (0.502)(R 0.487, F 0.516)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.409] [G acc: 0.078]\n",
      "3414 [D loss: (0.497)(R 0.523, F 0.470)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.426] [G acc: 0.078]\n",
      "3415 [D loss: (0.550)(R 0.608, F 0.493)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.509] [G acc: 0.078]\n",
      "3416 [D loss: (0.521)(R 0.488, F 0.553)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.632] [G acc: 0.016]\n",
      "3417 [D loss: (0.524)(R 0.619, F 0.429)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.337] [G acc: 0.062]\n",
      "3418 [D loss: (0.693)(R 0.539, F 0.846)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.390] [G acc: 0.078]\n",
      "3419 [D loss: (0.563)(R 0.624, F 0.501)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.375] [G acc: 0.078]\n",
      "3420 [D loss: (0.549)(R 0.632, F 0.466)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.376] [G acc: 0.047]\n",
      "3421 [D loss: (0.496)(R 0.576, F 0.416)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.585] [G acc: 0.078]\n",
      "3422 [D loss: (0.512)(R 0.628, F 0.396)] [D acc: (0.773)(0.641, 0.906)] [G loss: 1.302] [G acc: 0.062]\n",
      "3423 [D loss: (0.672)(R 0.604, F 0.740)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.413] [G acc: 0.125]\n",
      "3424 [D loss: (0.558)(R 0.672, F 0.444)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.251] [G acc: 0.141]\n",
      "3425 [D loss: (0.473)(R 0.495, F 0.450)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.387] [G acc: 0.078]\n",
      "3426 [D loss: (0.543)(R 0.537, F 0.548)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.520] [G acc: 0.047]\n",
      "3427 [D loss: (0.560)(R 0.693, F 0.428)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.442] [G acc: 0.094]\n",
      "3428 [D loss: (0.598)(R 0.582, F 0.614)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.422] [G acc: 0.062]\n",
      "3429 [D loss: (0.543)(R 0.555, F 0.531)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.421] [G acc: 0.031]\n",
      "3430 [D loss: (0.620)(R 0.795, F 0.446)] [D acc: (0.672)(0.469, 0.875)] [G loss: 1.465] [G acc: 0.047]\n",
      "3431 [D loss: (0.424)(R 0.373, F 0.476)] [D acc: (0.820)(0.797, 0.844)] [G loss: 1.561] [G acc: 0.062]\n",
      "3432 [D loss: (0.549)(R 0.627, F 0.470)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.339] [G acc: 0.062]\n",
      "3433 [D loss: (0.531)(R 0.590, F 0.472)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.440] [G acc: 0.125]\n",
      "3434 [D loss: (0.594)(R 0.565, F 0.624)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.373] [G acc: 0.156]\n",
      "3435 [D loss: (0.592)(R 0.661, F 0.523)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.413] [G acc: 0.109]\n",
      "3436 [D loss: (0.465)(R 0.479, F 0.451)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.410] [G acc: 0.109]\n",
      "3437 [D loss: (0.440)(R 0.425, F 0.456)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.408] [G acc: 0.109]\n",
      "3438 [D loss: (0.455)(R 0.489, F 0.420)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.369] [G acc: 0.047]\n",
      "3439 [D loss: (0.608)(R 0.549, F 0.666)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.448] [G acc: 0.094]\n",
      "3440 [D loss: (0.493)(R 0.536, F 0.450)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.346] [G acc: 0.109]\n",
      "3441 [D loss: (0.534)(R 0.500, F 0.567)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.331] [G acc: 0.156]\n",
      "3442 [D loss: (0.445)(R 0.387, F 0.504)] [D acc: (0.789)(0.781, 0.797)] [G loss: 1.465] [G acc: 0.078]\n",
      "3443 [D loss: (0.495)(R 0.502, F 0.489)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.508] [G acc: 0.062]\n",
      "3444 [D loss: (0.709)(R 0.562, F 0.856)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.410] [G acc: 0.094]\n",
      "3445 [D loss: (0.547)(R 0.616, F 0.478)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.350] [G acc: 0.062]\n",
      "3446 [D loss: (0.501)(R 0.434, F 0.568)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.441] [G acc: 0.094]\n",
      "3447 [D loss: (0.496)(R 0.575, F 0.417)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.384] [G acc: 0.125]\n",
      "3448 [D loss: (0.518)(R 0.477, F 0.560)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.475] [G acc: 0.062]\n",
      "3449 [D loss: (0.482)(R 0.514, F 0.449)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.352] [G acc: 0.109]\n",
      "3450 [D loss: (0.518)(R 0.508, F 0.528)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.464] [G acc: 0.062]\n",
      "3451 [D loss: (0.511)(R 0.600, F 0.421)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.439] [G acc: 0.156]\n",
      "3452 [D loss: (0.546)(R 0.589, F 0.503)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.284] [G acc: 0.141]\n",
      "3453 [D loss: (0.620)(R 0.454, F 0.786)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.408] [G acc: 0.125]\n",
      "3454 [D loss: (0.549)(R 0.675, F 0.423)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.569] [G acc: 0.109]\n",
      "3455 [D loss: (0.529)(R 0.607, F 0.451)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.327] [G acc: 0.094]\n",
      "3456 [D loss: (0.554)(R 0.550, F 0.558)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.380] [G acc: 0.062]\n",
      "3457 [D loss: (0.445)(R 0.433, F 0.456)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.299] [G acc: 0.078]\n",
      "3458 [D loss: (0.462)(R 0.531, F 0.392)] [D acc: (0.812)(0.734, 0.891)] [G loss: 1.395] [G acc: 0.078]\n",
      "3459 [D loss: (0.523)(R 0.517, F 0.529)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.377] [G acc: 0.109]\n",
      "3460 [D loss: (0.629)(R 0.518, F 0.741)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.488] [G acc: 0.094]\n",
      "3461 [D loss: (0.593)(R 0.702, F 0.485)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.394] [G acc: 0.125]\n",
      "3462 [D loss: (0.442)(R 0.389, F 0.496)] [D acc: (0.828)(0.812, 0.844)] [G loss: 1.290] [G acc: 0.172]\n",
      "3463 [D loss: (0.553)(R 0.522, F 0.583)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.347] [G acc: 0.109]\n",
      "3464 [D loss: (0.507)(R 0.556, F 0.458)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.569] [G acc: 0.094]\n",
      "3465 [D loss: (0.512)(R 0.515, F 0.508)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.524] [G acc: 0.047]\n",
      "3466 [D loss: (0.602)(R 0.522, F 0.683)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.360] [G acc: 0.094]\n",
      "3467 [D loss: (0.469)(R 0.530, F 0.408)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.525] [G acc: 0.094]\n",
      "3468 [D loss: (0.472)(R 0.525, F 0.418)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.488] [G acc: 0.062]\n",
      "3469 [D loss: (0.538)(R 0.490, F 0.586)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.525] [G acc: 0.047]\n",
      "3470 [D loss: (0.508)(R 0.543, F 0.474)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.450] [G acc: 0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3471 [D loss: (0.595)(R 0.797, F 0.393)] [D acc: (0.719)(0.500, 0.938)] [G loss: 1.335] [G acc: 0.109]\n",
      "3472 [D loss: (0.620)(R 0.578, F 0.662)] [D acc: (0.625)(0.547, 0.703)] [G loss: 1.446] [G acc: 0.078]\n",
      "3473 [D loss: (0.502)(R 0.489, F 0.516)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.455] [G acc: 0.078]\n",
      "3474 [D loss: (0.473)(R 0.477, F 0.469)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.511] [G acc: 0.094]\n",
      "3475 [D loss: (0.490)(R 0.519, F 0.461)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.478] [G acc: 0.094]\n",
      "3476 [D loss: (0.473)(R 0.345, F 0.601)] [D acc: (0.789)(0.781, 0.797)] [G loss: 1.511] [G acc: 0.078]\n",
      "3477 [D loss: (0.512)(R 0.571, F 0.454)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.448] [G acc: 0.141]\n",
      "3478 [D loss: (0.587)(R 0.603, F 0.572)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.462] [G acc: 0.125]\n",
      "3479 [D loss: (0.558)(R 0.688, F 0.429)] [D acc: (0.711)(0.531, 0.891)] [G loss: 1.325] [G acc: 0.125]\n",
      "3480 [D loss: (0.487)(R 0.430, F 0.543)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.507] [G acc: 0.031]\n",
      "3481 [D loss: (0.562)(R 0.638, F 0.485)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.422] [G acc: 0.016]\n",
      "3482 [D loss: (0.537)(R 0.508, F 0.565)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.402] [G acc: 0.125]\n",
      "3483 [D loss: (0.500)(R 0.487, F 0.514)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.478] [G acc: 0.078]\n",
      "3484 [D loss: (0.531)(R 0.515, F 0.548)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.470] [G acc: 0.078]\n",
      "3485 [D loss: (0.540)(R 0.556, F 0.524)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.419] [G acc: 0.047]\n",
      "3486 [D loss: (0.733)(R 0.804, F 0.662)] [D acc: (0.602)(0.516, 0.688)] [G loss: 1.381] [G acc: 0.062]\n",
      "3487 [D loss: (0.510)(R 0.539, F 0.481)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.616] [G acc: 0.016]\n",
      "3488 [D loss: (0.482)(R 0.550, F 0.414)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.502] [G acc: 0.125]\n",
      "3489 [D loss: (0.448)(R 0.456, F 0.441)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.414] [G acc: 0.156]\n",
      "3490 [D loss: (0.498)(R 0.527, F 0.469)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.291] [G acc: 0.203]\n",
      "3491 [D loss: (0.527)(R 0.500, F 0.555)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.439] [G acc: 0.094]\n",
      "3492 [D loss: (0.611)(R 0.615, F 0.607)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.423] [G acc: 0.094]\n",
      "3493 [D loss: (0.548)(R 0.549, F 0.546)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.410] [G acc: 0.094]\n",
      "3494 [D loss: (0.573)(R 0.657, F 0.489)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.499] [G acc: 0.109]\n",
      "3495 [D loss: (0.501)(R 0.610, F 0.393)] [D acc: (0.797)(0.688, 0.906)] [G loss: 1.339] [G acc: 0.094]\n",
      "3496 [D loss: (0.419)(R 0.438, F 0.400)] [D acc: (0.820)(0.750, 0.891)] [G loss: 1.214] [G acc: 0.156]\n",
      "3497 [D loss: (0.606)(R 0.528, F 0.684)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.339] [G acc: 0.156]\n",
      "3498 [D loss: (0.483)(R 0.500, F 0.466)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.380] [G acc: 0.109]\n",
      "3499 [D loss: (0.517)(R 0.444, F 0.589)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.359] [G acc: 0.172]\n",
      "3500 [D loss: (0.563)(R 0.552, F 0.574)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.511] [G acc: 0.062]\n",
      "3501 [D loss: (0.626)(R 0.758, F 0.493)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.356] [G acc: 0.125]\n",
      "3502 [D loss: (0.475)(R 0.472, F 0.477)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.411] [G acc: 0.047]\n",
      "3503 [D loss: (0.558)(R 0.623, F 0.492)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.382] [G acc: 0.141]\n",
      "3504 [D loss: (0.632)(R 0.620, F 0.643)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.374] [G acc: 0.094]\n",
      "3505 [D loss: (0.604)(R 0.645, F 0.562)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.391] [G acc: 0.156]\n",
      "3506 [D loss: (0.597)(R 0.670, F 0.524)] [D acc: (0.633)(0.531, 0.734)] [G loss: 1.248] [G acc: 0.172]\n",
      "3507 [D loss: (0.525)(R 0.595, F 0.455)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.217] [G acc: 0.172]\n",
      "3508 [D loss: (0.512)(R 0.532, F 0.491)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.341] [G acc: 0.125]\n",
      "3509 [D loss: (0.514)(R 0.508, F 0.519)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.265] [G acc: 0.156]\n",
      "3510 [D loss: (0.623)(R 0.640, F 0.605)] [D acc: (0.648)(0.641, 0.656)] [G loss: 1.341] [G acc: 0.062]\n",
      "3511 [D loss: (0.463)(R 0.507, F 0.419)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.326] [G acc: 0.156]\n",
      "3512 [D loss: (0.554)(R 0.547, F 0.562)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.338] [G acc: 0.125]\n",
      "3513 [D loss: (0.509)(R 0.438, F 0.580)] [D acc: (0.797)(0.828, 0.766)] [G loss: 1.504] [G acc: 0.125]\n",
      "3514 [D loss: (0.497)(R 0.545, F 0.448)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.434] [G acc: 0.094]\n",
      "3515 [D loss: (0.541)(R 0.450, F 0.633)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.689] [G acc: 0.031]\n",
      "3516 [D loss: (0.455)(R 0.520, F 0.390)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.555] [G acc: 0.078]\n",
      "3517 [D loss: (0.461)(R 0.441, F 0.480)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.341] [G acc: 0.078]\n",
      "3518 [D loss: (0.492)(R 0.396, F 0.588)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.549] [G acc: 0.125]\n",
      "3519 [D loss: (0.525)(R 0.515, F 0.534)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.562] [G acc: 0.109]\n",
      "3520 [D loss: (0.553)(R 0.535, F 0.571)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.373] [G acc: 0.109]\n",
      "3521 [D loss: (0.542)(R 0.580, F 0.505)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.453] [G acc: 0.141]\n",
      "3522 [D loss: (0.589)(R 0.623, F 0.555)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.276] [G acc: 0.125]\n",
      "3523 [D loss: (0.517)(R 0.525, F 0.509)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.509] [G acc: 0.109]\n",
      "3524 [D loss: (0.533)(R 0.583, F 0.483)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.269] [G acc: 0.141]\n",
      "3525 [D loss: (0.529)(R 0.532, F 0.525)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.322] [G acc: 0.203]\n",
      "3526 [D loss: (0.640)(R 0.713, F 0.567)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.422] [G acc: 0.031]\n",
      "3527 [D loss: (0.611)(R 0.483, F 0.740)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.423] [G acc: 0.125]\n",
      "3528 [D loss: (0.504)(R 0.607, F 0.401)] [D acc: (0.797)(0.688, 0.906)] [G loss: 1.418] [G acc: 0.094]\n",
      "3529 [D loss: (0.467)(R 0.515, F 0.418)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.387] [G acc: 0.109]\n",
      "3530 [D loss: (0.480)(R 0.486, F 0.475)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.478] [G acc: 0.109]\n",
      "3531 [D loss: (0.511)(R 0.551, F 0.471)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.335] [G acc: 0.172]\n",
      "3532 [D loss: (0.605)(R 0.572, F 0.638)] [D acc: (0.641)(0.609, 0.672)] [G loss: 1.250] [G acc: 0.156]\n",
      "3533 [D loss: (0.534)(R 0.559, F 0.509)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.591] [G acc: 0.094]\n",
      "3534 [D loss: (0.595)(R 0.575, F 0.615)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.569] [G acc: 0.094]\n",
      "3535 [D loss: (0.539)(R 0.649, F 0.428)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.545] [G acc: 0.031]\n",
      "3536 [D loss: (0.484)(R 0.489, F 0.480)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.532] [G acc: 0.062]\n",
      "3537 [D loss: (0.628)(R 0.518, F 0.738)] [D acc: (0.695)(0.719, 0.672)] [G loss: 1.292] [G acc: 0.109]\n",
      "3538 [D loss: (0.608)(R 0.567, F 0.648)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.379] [G acc: 0.141]\n",
      "3539 [D loss: (0.544)(R 0.655, F 0.433)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.396] [G acc: 0.141]\n",
      "3540 [D loss: (0.439)(R 0.357, F 0.521)] [D acc: (0.797)(0.844, 0.750)] [G loss: 1.557] [G acc: 0.047]\n",
      "3541 [D loss: (0.494)(R 0.498, F 0.491)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.453] [G acc: 0.047]\n",
      "3542 [D loss: (0.485)(R 0.431, F 0.539)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.512] [G acc: 0.078]\n",
      "3543 [D loss: (0.447)(R 0.421, F 0.472)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.680] [G acc: 0.047]\n",
      "3544 [D loss: (0.547)(R 0.564, F 0.531)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.452] [G acc: 0.047]\n",
      "3545 [D loss: (0.556)(R 0.642, F 0.470)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.427] [G acc: 0.141]\n",
      "3546 [D loss: (0.533)(R 0.542, F 0.524)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.389] [G acc: 0.125]\n",
      "3547 [D loss: (0.567)(R 0.555, F 0.580)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.593] [G acc: 0.031]\n",
      "3548 [D loss: (0.513)(R 0.521, F 0.504)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.457] [G acc: 0.094]\n",
      "3549 [D loss: (0.469)(R 0.515, F 0.422)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.615] [G acc: 0.062]\n",
      "3550 [D loss: (0.489)(R 0.483, F 0.495)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.576] [G acc: 0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3551 [D loss: (0.521)(R 0.611, F 0.430)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.567] [G acc: 0.047]\n",
      "3552 [D loss: (0.570)(R 0.478, F 0.661)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.482] [G acc: 0.078]\n",
      "3553 [D loss: (0.542)(R 0.547, F 0.537)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.524] [G acc: 0.078]\n",
      "3554 [D loss: (0.453)(R 0.466, F 0.440)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.552] [G acc: 0.109]\n",
      "3555 [D loss: (0.572)(R 0.659, F 0.486)] [D acc: (0.672)(0.516, 0.828)] [G loss: 1.477] [G acc: 0.109]\n",
      "3556 [D loss: (0.555)(R 0.591, F 0.519)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.414] [G acc: 0.109]\n",
      "3557 [D loss: (0.571)(R 0.600, F 0.543)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.477] [G acc: 0.062]\n",
      "3558 [D loss: (0.539)(R 0.508, F 0.570)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.564] [G acc: 0.094]\n",
      "3559 [D loss: (0.576)(R 0.679, F 0.474)] [D acc: (0.695)(0.547, 0.844)] [G loss: 1.375] [G acc: 0.109]\n",
      "3560 [D loss: (0.546)(R 0.573, F 0.519)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.472] [G acc: 0.094]\n",
      "3561 [D loss: (0.599)(R 0.531, F 0.666)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.598] [G acc: 0.016]\n",
      "3562 [D loss: (0.542)(R 0.578, F 0.506)] [D acc: (0.805)(0.734, 0.875)] [G loss: 1.374] [G acc: 0.078]\n",
      "3563 [D loss: (0.527)(R 0.574, F 0.479)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.335] [G acc: 0.094]\n",
      "3564 [D loss: (0.484)(R 0.497, F 0.471)] [D acc: (0.844)(0.781, 0.906)] [G loss: 1.265] [G acc: 0.188]\n",
      "3565 [D loss: (0.546)(R 0.578, F 0.514)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.265] [G acc: 0.141]\n",
      "3566 [D loss: (0.577)(R 0.576, F 0.577)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.399] [G acc: 0.094]\n",
      "3567 [D loss: (0.541)(R 0.566, F 0.516)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.349] [G acc: 0.156]\n",
      "3568 [D loss: (0.588)(R 0.611, F 0.565)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.309] [G acc: 0.078]\n",
      "3569 [D loss: (0.466)(R 0.456, F 0.475)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.384] [G acc: 0.094]\n",
      "3570 [D loss: (0.540)(R 0.513, F 0.568)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.444] [G acc: 0.078]\n",
      "3571 [D loss: (0.597)(R 0.453, F 0.740)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.621] [G acc: 0.031]\n",
      "3572 [D loss: (0.560)(R 0.712, F 0.407)] [D acc: (0.742)(0.578, 0.906)] [G loss: 1.461] [G acc: 0.047]\n",
      "3573 [D loss: (0.514)(R 0.532, F 0.496)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.441] [G acc: 0.125]\n",
      "3574 [D loss: (0.444)(R 0.471, F 0.417)] [D acc: (0.820)(0.750, 0.891)] [G loss: 1.318] [G acc: 0.172]\n",
      "3575 [D loss: (0.636)(R 0.525, F 0.748)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.242] [G acc: 0.156]\n",
      "3576 [D loss: (0.533)(R 0.545, F 0.521)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.374] [G acc: 0.078]\n",
      "3577 [D loss: (0.501)(R 0.552, F 0.451)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.448] [G acc: 0.078]\n",
      "3578 [D loss: (0.575)(R 0.564, F 0.587)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.447] [G acc: 0.109]\n",
      "3579 [D loss: (0.606)(R 0.722, F 0.490)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.302] [G acc: 0.156]\n",
      "3580 [D loss: (0.630)(R 0.542, F 0.718)] [D acc: (0.641)(0.625, 0.656)] [G loss: 1.404] [G acc: 0.047]\n",
      "3581 [D loss: (0.588)(R 0.684, F 0.492)] [D acc: (0.648)(0.547, 0.750)] [G loss: 1.348] [G acc: 0.141]\n",
      "3582 [D loss: (0.530)(R 0.551, F 0.510)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.346] [G acc: 0.125]\n",
      "3583 [D loss: (0.476)(R 0.492, F 0.461)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.364] [G acc: 0.109]\n",
      "3584 [D loss: (0.534)(R 0.479, F 0.588)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.564] [G acc: 0.141]\n",
      "3585 [D loss: (0.537)(R 0.451, F 0.623)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.618] [G acc: 0.047]\n",
      "3586 [D loss: (0.638)(R 0.713, F 0.564)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.310] [G acc: 0.141]\n",
      "3587 [D loss: (0.548)(R 0.571, F 0.525)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.391] [G acc: 0.125]\n",
      "3588 [D loss: (0.657)(R 0.624, F 0.690)] [D acc: (0.617)(0.578, 0.656)] [G loss: 1.325] [G acc: 0.094]\n",
      "3589 [D loss: (0.502)(R 0.558, F 0.447)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.319] [G acc: 0.109]\n",
      "3590 [D loss: (0.476)(R 0.516, F 0.436)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.311] [G acc: 0.125]\n",
      "3591 [D loss: (0.531)(R 0.472, F 0.590)] [D acc: (0.758)(0.781, 0.734)] [G loss: 1.489] [G acc: 0.062]\n",
      "3592 [D loss: (0.609)(R 0.633, F 0.586)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.389] [G acc: 0.109]\n",
      "3593 [D loss: (0.576)(R 0.667, F 0.486)] [D acc: (0.680)(0.531, 0.828)] [G loss: 1.483] [G acc: 0.047]\n",
      "3594 [D loss: (0.639)(R 0.710, F 0.568)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.358] [G acc: 0.078]\n",
      "3595 [D loss: (0.514)(R 0.489, F 0.539)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.348] [G acc: 0.141]\n",
      "3596 [D loss: (0.471)(R 0.504, F 0.437)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.339] [G acc: 0.172]\n",
      "3597 [D loss: (0.669)(R 0.531, F 0.808)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.434] [G acc: 0.094]\n",
      "3598 [D loss: (0.567)(R 0.672, F 0.462)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.519] [G acc: 0.109]\n",
      "3599 [D loss: (0.577)(R 0.571, F 0.583)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.393] [G acc: 0.062]\n",
      "3600 [D loss: (0.522)(R 0.527, F 0.518)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.373] [G acc: 0.156]\n",
      "3601 [D loss: (0.527)(R 0.409, F 0.645)] [D acc: (0.703)(0.750, 0.656)] [G loss: 1.406] [G acc: 0.062]\n",
      "3602 [D loss: (0.514)(R 0.543, F 0.486)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.458] [G acc: 0.062]\n",
      "3603 [D loss: (0.408)(R 0.271, F 0.546)] [D acc: (0.820)(0.922, 0.719)] [G loss: 1.381] [G acc: 0.172]\n",
      "3604 [D loss: (0.607)(R 0.538, F 0.676)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.558] [G acc: 0.031]\n",
      "3605 [D loss: (0.578)(R 0.745, F 0.411)] [D acc: (0.664)(0.469, 0.859)] [G loss: 1.468] [G acc: 0.078]\n",
      "3606 [D loss: (0.550)(R 0.540, F 0.559)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.378] [G acc: 0.094]\n",
      "3607 [D loss: (0.541)(R 0.544, F 0.538)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.465] [G acc: 0.109]\n",
      "3608 [D loss: (0.565)(R 0.692, F 0.437)] [D acc: (0.680)(0.500, 0.859)] [G loss: 1.319] [G acc: 0.156]\n",
      "3609 [D loss: (0.526)(R 0.523, F 0.529)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.357] [G acc: 0.109]\n",
      "3610 [D loss: (0.543)(R 0.594, F 0.493)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.325] [G acc: 0.125]\n",
      "3611 [D loss: (0.615)(R 0.593, F 0.637)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.377] [G acc: 0.109]\n",
      "3612 [D loss: (0.466)(R 0.482, F 0.451)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.387] [G acc: 0.156]\n",
      "3613 [D loss: (0.432)(R 0.420, F 0.444)] [D acc: (0.828)(0.812, 0.844)] [G loss: 1.390] [G acc: 0.125]\n",
      "3614 [D loss: (0.514)(R 0.515, F 0.514)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.369] [G acc: 0.094]\n",
      "3615 [D loss: (0.459)(R 0.403, F 0.515)] [D acc: (0.742)(0.766, 0.719)] [G loss: 1.617] [G acc: 0.141]\n",
      "3616 [D loss: (0.657)(R 0.634, F 0.679)] [D acc: (0.656)(0.594, 0.719)] [G loss: 1.447] [G acc: 0.062]\n",
      "3617 [D loss: (0.537)(R 0.651, F 0.423)] [D acc: (0.742)(0.578, 0.906)] [G loss: 1.383] [G acc: 0.094]\n",
      "3618 [D loss: (0.552)(R 0.572, F 0.533)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.422] [G acc: 0.125]\n",
      "3619 [D loss: (0.601)(R 0.662, F 0.540)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.374] [G acc: 0.109]\n",
      "3620 [D loss: (0.609)(R 0.581, F 0.636)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.450] [G acc: 0.078]\n",
      "3621 [D loss: (0.512)(R 0.554, F 0.470)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.328] [G acc: 0.062]\n",
      "3622 [D loss: (0.470)(R 0.474, F 0.467)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.415] [G acc: 0.047]\n",
      "3623 [D loss: (0.556)(R 0.577, F 0.535)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.491] [G acc: 0.094]\n",
      "3624 [D loss: (0.516)(R 0.538, F 0.493)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.466] [G acc: 0.031]\n",
      "3625 [D loss: (0.521)(R 0.492, F 0.549)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.432] [G acc: 0.094]\n",
      "3626 [D loss: (0.600)(R 0.475, F 0.725)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.389] [G acc: 0.094]\n",
      "3627 [D loss: (0.638)(R 0.736, F 0.540)] [D acc: (0.633)(0.500, 0.766)] [G loss: 1.274] [G acc: 0.094]\n",
      "3628 [D loss: (0.589)(R 0.598, F 0.580)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.382] [G acc: 0.109]\n",
      "3629 [D loss: (0.625)(R 0.655, F 0.596)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.350] [G acc: 0.062]\n",
      "3630 [D loss: (0.566)(R 0.647, F 0.486)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.255] [G acc: 0.156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3631 [D loss: (0.560)(R 0.451, F 0.670)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.420] [G acc: 0.062]\n",
      "3632 [D loss: (0.451)(R 0.401, F 0.500)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.383] [G acc: 0.078]\n",
      "3633 [D loss: (0.574)(R 0.711, F 0.438)] [D acc: (0.633)(0.438, 0.828)] [G loss: 1.357] [G acc: 0.109]\n",
      "3634 [D loss: (0.490)(R 0.465, F 0.516)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.420] [G acc: 0.062]\n",
      "3635 [D loss: (0.526)(R 0.589, F 0.463)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.252] [G acc: 0.062]\n",
      "3636 [D loss: (0.518)(R 0.562, F 0.474)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.211] [G acc: 0.188]\n",
      "3637 [D loss: (0.551)(R 0.510, F 0.593)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.295] [G acc: 0.125]\n",
      "3638 [D loss: (0.593)(R 0.579, F 0.608)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.312] [G acc: 0.094]\n",
      "3639 [D loss: (0.562)(R 0.687, F 0.438)] [D acc: (0.703)(0.547, 0.859)] [G loss: 1.331] [G acc: 0.172]\n",
      "3640 [D loss: (0.551)(R 0.507, F 0.594)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.334] [G acc: 0.047]\n",
      "3641 [D loss: (0.573)(R 0.574, F 0.571)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.326] [G acc: 0.156]\n",
      "3642 [D loss: (0.536)(R 0.587, F 0.484)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.310] [G acc: 0.109]\n",
      "3643 [D loss: (0.603)(R 0.559, F 0.647)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.317] [G acc: 0.031]\n",
      "3644 [D loss: (0.476)(R 0.454, F 0.498)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.416] [G acc: 0.078]\n",
      "3645 [D loss: (0.483)(R 0.559, F 0.408)] [D acc: (0.750)(0.594, 0.906)] [G loss: 1.252] [G acc: 0.172]\n",
      "3646 [D loss: (0.558)(R 0.578, F 0.538)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.281] [G acc: 0.125]\n",
      "3647 [D loss: (0.565)(R 0.572, F 0.557)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.367] [G acc: 0.141]\n",
      "3648 [D loss: (0.550)(R 0.654, F 0.447)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.343] [G acc: 0.141]\n",
      "3649 [D loss: (0.554)(R 0.596, F 0.512)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.312] [G acc: 0.188]\n",
      "3650 [D loss: (0.440)(R 0.349, F 0.530)] [D acc: (0.789)(0.828, 0.750)] [G loss: 1.452] [G acc: 0.125]\n",
      "3651 [D loss: (0.446)(R 0.492, F 0.401)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.437] [G acc: 0.094]\n",
      "3652 [D loss: (0.502)(R 0.434, F 0.571)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.414] [G acc: 0.094]\n",
      "3653 [D loss: (0.509)(R 0.531, F 0.488)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.320] [G acc: 0.156]\n",
      "3654 [D loss: (0.545)(R 0.555, F 0.534)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.424] [G acc: 0.141]\n",
      "3655 [D loss: (0.438)(R 0.422, F 0.454)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.498] [G acc: 0.078]\n",
      "3656 [D loss: (0.451)(R 0.456, F 0.446)] [D acc: (0.805)(0.781, 0.828)] [G loss: 1.585] [G acc: 0.078]\n",
      "3657 [D loss: (0.513)(R 0.402, F 0.624)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.651] [G acc: 0.078]\n",
      "3658 [D loss: (0.552)(R 0.601, F 0.503)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.509] [G acc: 0.062]\n",
      "3659 [D loss: (0.601)(R 0.510, F 0.692)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.487] [G acc: 0.047]\n",
      "3660 [D loss: (0.562)(R 0.683, F 0.440)] [D acc: (0.695)(0.531, 0.859)] [G loss: 1.412] [G acc: 0.094]\n",
      "3661 [D loss: (0.551)(R 0.621, F 0.482)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.337] [G acc: 0.094]\n",
      "3662 [D loss: (0.533)(R 0.567, F 0.499)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.245] [G acc: 0.141]\n",
      "3663 [D loss: (0.569)(R 0.609, F 0.530)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.463] [G acc: 0.031]\n",
      "3664 [D loss: (0.500)(R 0.544, F 0.455)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.315] [G acc: 0.172]\n",
      "3665 [D loss: (0.602)(R 0.513, F 0.691)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.354] [G acc: 0.094]\n",
      "3666 [D loss: (0.512)(R 0.560, F 0.464)] [D acc: (0.742)(0.578, 0.906)] [G loss: 1.290] [G acc: 0.109]\n",
      "3667 [D loss: (0.570)(R 0.623, F 0.518)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.405] [G acc: 0.047]\n",
      "3668 [D loss: (0.630)(R 0.644, F 0.617)] [D acc: (0.641)(0.547, 0.734)] [G loss: 1.203] [G acc: 0.188]\n",
      "3669 [D loss: (0.510)(R 0.487, F 0.533)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.389] [G acc: 0.078]\n",
      "3670 [D loss: (0.494)(R 0.533, F 0.454)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.442] [G acc: 0.078]\n",
      "3671 [D loss: (0.529)(R 0.585, F 0.473)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.322] [G acc: 0.141]\n",
      "3672 [D loss: (0.647)(R 0.547, F 0.748)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.296] [G acc: 0.109]\n",
      "3673 [D loss: (0.519)(R 0.585, F 0.454)] [D acc: (0.734)(0.578, 0.891)] [G loss: 1.393] [G acc: 0.062]\n",
      "3674 [D loss: (0.535)(R 0.630, F 0.439)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.273] [G acc: 0.125]\n",
      "3675 [D loss: (0.463)(R 0.431, F 0.494)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.314] [G acc: 0.125]\n",
      "3676 [D loss: (0.654)(R 0.740, F 0.568)] [D acc: (0.633)(0.531, 0.734)] [G loss: 1.414] [G acc: 0.078]\n",
      "3677 [D loss: (0.556)(R 0.655, F 0.457)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.279] [G acc: 0.078]\n",
      "3678 [D loss: (0.520)(R 0.542, F 0.497)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.281] [G acc: 0.141]\n",
      "3679 [D loss: (0.566)(R 0.584, F 0.548)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.262] [G acc: 0.094]\n",
      "3680 [D loss: (0.450)(R 0.461, F 0.438)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.313] [G acc: 0.109]\n",
      "3681 [D loss: (0.574)(R 0.640, F 0.507)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.403] [G acc: 0.172]\n",
      "3682 [D loss: (0.559)(R 0.530, F 0.587)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.436] [G acc: 0.062]\n",
      "3683 [D loss: (0.575)(R 0.668, F 0.482)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.449] [G acc: 0.047]\n",
      "3684 [D loss: (0.440)(R 0.468, F 0.412)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.275] [G acc: 0.156]\n",
      "3685 [D loss: (0.505)(R 0.499, F 0.510)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.394] [G acc: 0.047]\n",
      "3686 [D loss: (0.505)(R 0.445, F 0.564)] [D acc: (0.781)(0.781, 0.781)] [G loss: 1.401] [G acc: 0.078]\n",
      "3687 [D loss: (0.578)(R 0.576, F 0.580)] [D acc: (0.672)(0.625, 0.719)] [G loss: 1.503] [G acc: 0.094]\n",
      "3688 [D loss: (0.458)(R 0.463, F 0.454)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.442] [G acc: 0.125]\n",
      "3689 [D loss: (0.551)(R 0.638, F 0.463)] [D acc: (0.656)(0.547, 0.766)] [G loss: 1.469] [G acc: 0.047]\n",
      "3690 [D loss: (0.549)(R 0.578, F 0.521)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.425] [G acc: 0.109]\n",
      "3691 [D loss: (0.458)(R 0.451, F 0.465)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.354] [G acc: 0.188]\n",
      "3692 [D loss: (0.657)(R 0.611, F 0.702)] [D acc: (0.633)(0.594, 0.672)] [G loss: 1.615] [G acc: 0.031]\n",
      "3693 [D loss: (0.570)(R 0.712, F 0.428)] [D acc: (0.703)(0.500, 0.906)] [G loss: 1.428] [G acc: 0.109]\n",
      "3694 [D loss: (0.634)(R 0.672, F 0.595)] [D acc: (0.617)(0.484, 0.750)] [G loss: 1.406] [G acc: 0.078]\n",
      "3695 [D loss: (0.552)(R 0.493, F 0.611)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.284] [G acc: 0.062]\n",
      "3696 [D loss: (0.552)(R 0.604, F 0.500)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.386] [G acc: 0.094]\n",
      "3697 [D loss: (0.575)(R 0.646, F 0.504)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.465] [G acc: 0.047]\n",
      "3698 [D loss: (0.493)(R 0.520, F 0.466)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.285] [G acc: 0.094]\n",
      "3699 [D loss: (0.541)(R 0.489, F 0.593)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.455] [G acc: 0.031]\n",
      "3700 [D loss: (0.564)(R 0.581, F 0.547)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.433] [G acc: 0.078]\n",
      "3701 [D loss: (0.555)(R 0.663, F 0.447)] [D acc: (0.703)(0.547, 0.859)] [G loss: 1.220] [G acc: 0.156]\n",
      "3702 [D loss: (0.623)(R 0.543, F 0.702)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.329] [G acc: 0.062]\n",
      "3703 [D loss: (0.520)(R 0.529, F 0.510)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.343] [G acc: 0.094]\n",
      "3704 [D loss: (0.565)(R 0.641, F 0.488)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.367] [G acc: 0.062]\n",
      "3705 [D loss: (0.538)(R 0.525, F 0.551)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.284] [G acc: 0.172]\n",
      "3706 [D loss: (0.558)(R 0.451, F 0.666)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.247] [G acc: 0.094]\n",
      "3707 [D loss: (0.470)(R 0.502, F 0.438)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.362] [G acc: 0.141]\n",
      "3708 [D loss: (0.588)(R 0.646, F 0.530)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.233] [G acc: 0.250]\n",
      "3709 [D loss: (0.573)(R 0.532, F 0.613)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.395] [G acc: 0.047]\n",
      "3710 [D loss: (0.593)(R 0.572, F 0.615)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.482] [G acc: 0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3711 [D loss: (0.483)(R 0.490, F 0.476)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.389] [G acc: 0.094]\n",
      "3712 [D loss: (0.539)(R 0.539, F 0.539)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.399] [G acc: 0.078]\n",
      "3713 [D loss: (0.543)(R 0.541, F 0.546)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.345] [G acc: 0.062]\n",
      "3714 [D loss: (0.532)(R 0.552, F 0.512)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.303] [G acc: 0.078]\n",
      "3715 [D loss: (0.565)(R 0.475, F 0.655)] [D acc: (0.719)(0.781, 0.656)] [G loss: 1.525] [G acc: 0.078]\n",
      "3716 [D loss: (0.543)(R 0.620, F 0.465)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.340] [G acc: 0.109]\n",
      "3717 [D loss: (0.562)(R 0.543, F 0.581)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.444] [G acc: 0.125]\n",
      "3718 [D loss: (0.527)(R 0.511, F 0.544)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.450] [G acc: 0.062]\n",
      "3719 [D loss: (0.481)(R 0.477, F 0.485)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.283] [G acc: 0.188]\n",
      "3720 [D loss: (0.607)(R 0.517, F 0.697)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.440] [G acc: 0.156]\n",
      "3721 [D loss: (0.526)(R 0.569, F 0.482)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.395] [G acc: 0.094]\n",
      "3722 [D loss: (0.519)(R 0.512, F 0.526)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.235] [G acc: 0.203]\n",
      "3723 [D loss: (0.516)(R 0.536, F 0.497)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.239] [G acc: 0.141]\n",
      "3724 [D loss: (0.557)(R 0.559, F 0.555)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.438] [G acc: 0.078]\n",
      "3725 [D loss: (0.489)(R 0.479, F 0.500)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.442] [G acc: 0.062]\n",
      "3726 [D loss: (0.551)(R 0.559, F 0.543)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.332] [G acc: 0.125]\n",
      "3727 [D loss: (0.570)(R 0.593, F 0.548)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.390] [G acc: 0.078]\n",
      "3728 [D loss: (0.571)(R 0.573, F 0.568)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.461] [G acc: 0.047]\n",
      "3729 [D loss: (0.652)(R 0.605, F 0.699)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.362] [G acc: 0.047]\n",
      "3730 [D loss: (0.485)(R 0.575, F 0.396)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.402] [G acc: 0.078]\n",
      "3731 [D loss: (0.533)(R 0.568, F 0.498)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.375] [G acc: 0.094]\n",
      "3732 [D loss: (0.545)(R 0.592, F 0.498)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.307] [G acc: 0.109]\n",
      "3733 [D loss: (0.523)(R 0.568, F 0.478)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.364] [G acc: 0.094]\n",
      "3734 [D loss: (0.535)(R 0.535, F 0.536)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.420] [G acc: 0.062]\n",
      "3735 [D loss: (0.550)(R 0.526, F 0.574)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.416] [G acc: 0.062]\n",
      "3736 [D loss: (0.563)(R 0.551, F 0.575)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.549] [G acc: 0.031]\n",
      "3737 [D loss: (0.467)(R 0.434, F 0.500)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.434] [G acc: 0.109]\n",
      "3738 [D loss: (0.553)(R 0.593, F 0.512)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.225] [G acc: 0.250]\n",
      "3739 [D loss: (0.536)(R 0.510, F 0.563)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.592] [G acc: 0.078]\n",
      "3740 [D loss: (0.536)(R 0.595, F 0.476)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.378] [G acc: 0.109]\n",
      "3741 [D loss: (0.491)(R 0.452, F 0.530)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.346] [G acc: 0.109]\n",
      "3742 [D loss: (0.543)(R 0.611, F 0.474)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.457] [G acc: 0.031]\n",
      "3743 [D loss: (0.506)(R 0.575, F 0.437)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.313] [G acc: 0.094]\n",
      "3744 [D loss: (0.613)(R 0.701, F 0.524)] [D acc: (0.680)(0.531, 0.828)] [G loss: 1.231] [G acc: 0.172]\n",
      "3745 [D loss: (0.595)(R 0.553, F 0.636)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.254] [G acc: 0.047]\n",
      "3746 [D loss: (0.563)(R 0.467, F 0.660)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.241] [G acc: 0.094]\n",
      "3747 [D loss: (0.572)(R 0.641, F 0.503)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.351] [G acc: 0.094]\n",
      "3748 [D loss: (0.479)(R 0.442, F 0.516)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.377] [G acc: 0.078]\n",
      "3749 [D loss: (0.559)(R 0.485, F 0.633)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.341] [G acc: 0.078]\n",
      "3750 [D loss: (0.550)(R 0.623, F 0.476)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.421] [G acc: 0.109]\n",
      "3751 [D loss: (0.636)(R 0.685, F 0.587)] [D acc: (0.641)(0.531, 0.750)] [G loss: 1.325] [G acc: 0.094]\n",
      "3752 [D loss: (0.455)(R 0.503, F 0.407)] [D acc: (0.820)(0.688, 0.953)] [G loss: 1.416] [G acc: 0.047]\n",
      "3753 [D loss: (0.603)(R 0.548, F 0.659)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.262] [G acc: 0.109]\n",
      "3754 [D loss: (0.555)(R 0.671, F 0.439)] [D acc: (0.672)(0.516, 0.828)] [G loss: 1.310] [G acc: 0.141]\n",
      "3755 [D loss: (0.559)(R 0.523, F 0.595)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.296] [G acc: 0.141]\n",
      "3756 [D loss: (0.514)(R 0.550, F 0.477)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.413] [G acc: 0.078]\n",
      "3757 [D loss: (0.489)(R 0.474, F 0.505)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.320] [G acc: 0.109]\n",
      "3758 [D loss: (0.541)(R 0.586, F 0.496)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.316] [G acc: 0.156]\n",
      "3759 [D loss: (0.539)(R 0.556, F 0.523)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.282] [G acc: 0.141]\n",
      "3760 [D loss: (0.534)(R 0.539, F 0.529)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.280] [G acc: 0.094]\n",
      "3761 [D loss: (0.488)(R 0.450, F 0.526)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.407] [G acc: 0.094]\n",
      "3762 [D loss: (0.498)(R 0.460, F 0.536)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.494] [G acc: 0.109]\n",
      "3763 [D loss: (0.486)(R 0.551, F 0.420)] [D acc: (0.773)(0.641, 0.906)] [G loss: 1.487] [G acc: 0.109]\n",
      "3764 [D loss: (0.473)(R 0.439, F 0.508)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.435] [G acc: 0.141]\n",
      "3765 [D loss: (0.527)(R 0.516, F 0.539)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.394] [G acc: 0.031]\n",
      "3766 [D loss: (0.591)(R 0.614, F 0.567)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.714] [G acc: 0.062]\n",
      "3767 [D loss: (0.666)(R 0.708, F 0.624)] [D acc: (0.648)(0.547, 0.750)] [G loss: 1.424] [G acc: 0.062]\n",
      "3768 [D loss: (0.512)(R 0.484, F 0.540)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.294] [G acc: 0.125]\n",
      "3769 [D loss: (0.559)(R 0.473, F 0.644)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.476] [G acc: 0.094]\n",
      "3770 [D loss: (0.483)(R 0.494, F 0.472)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.421] [G acc: 0.094]\n",
      "3771 [D loss: (0.579)(R 0.554, F 0.603)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.448] [G acc: 0.141]\n",
      "3772 [D loss: (0.604)(R 0.601, F 0.607)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.489] [G acc: 0.094]\n",
      "3773 [D loss: (0.527)(R 0.657, F 0.396)] [D acc: (0.750)(0.594, 0.906)] [G loss: 1.477] [G acc: 0.109]\n",
      "3774 [D loss: (0.495)(R 0.437, F 0.553)] [D acc: (0.773)(0.828, 0.719)] [G loss: 1.367] [G acc: 0.109]\n",
      "3775 [D loss: (0.571)(R 0.617, F 0.526)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.447] [G acc: 0.078]\n",
      "3776 [D loss: (0.537)(R 0.601, F 0.473)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.313] [G acc: 0.141]\n",
      "3777 [D loss: (0.519)(R 0.468, F 0.571)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.401] [G acc: 0.078]\n",
      "3778 [D loss: (0.570)(R 0.639, F 0.501)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.313] [G acc: 0.125]\n",
      "3779 [D loss: (0.508)(R 0.555, F 0.462)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.366] [G acc: 0.141]\n",
      "3780 [D loss: (0.534)(R 0.511, F 0.557)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.334] [G acc: 0.078]\n",
      "3781 [D loss: (0.532)(R 0.594, F 0.469)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.395] [G acc: 0.156]\n",
      "3782 [D loss: (0.565)(R 0.539, F 0.590)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.344] [G acc: 0.078]\n",
      "3783 [D loss: (0.575)(R 0.628, F 0.522)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.300] [G acc: 0.078]\n",
      "3784 [D loss: (0.535)(R 0.549, F 0.521)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.317] [G acc: 0.188]\n",
      "3785 [D loss: (0.573)(R 0.559, F 0.586)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.409] [G acc: 0.109]\n",
      "3786 [D loss: (0.577)(R 0.601, F 0.552)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.196] [G acc: 0.156]\n",
      "3787 [D loss: (0.477)(R 0.452, F 0.502)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.273] [G acc: 0.141]\n",
      "3788 [D loss: (0.473)(R 0.474, F 0.471)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.436] [G acc: 0.125]\n",
      "3789 [D loss: (0.500)(R 0.505, F 0.495)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.274] [G acc: 0.141]\n",
      "3790 [D loss: (0.513)(R 0.447, F 0.580)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.473] [G acc: 0.047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3791 [D loss: (0.528)(R 0.536, F 0.519)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.364] [G acc: 0.156]\n",
      "3792 [D loss: (0.511)(R 0.595, F 0.427)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.288] [G acc: 0.156]\n",
      "3793 [D loss: (0.475)(R 0.367, F 0.583)] [D acc: (0.766)(0.812, 0.719)] [G loss: 1.415] [G acc: 0.078]\n",
      "3794 [D loss: (0.509)(R 0.506, F 0.512)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.429] [G acc: 0.078]\n",
      "3795 [D loss: (0.535)(R 0.625, F 0.445)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.481] [G acc: 0.109]\n",
      "3796 [D loss: (0.446)(R 0.436, F 0.456)] [D acc: (0.805)(0.781, 0.828)] [G loss: 1.332] [G acc: 0.109]\n",
      "3797 [D loss: (0.552)(R 0.569, F 0.535)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.395] [G acc: 0.078]\n",
      "3798 [D loss: (0.592)(R 0.605, F 0.579)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.350] [G acc: 0.078]\n",
      "3799 [D loss: (0.568)(R 0.578, F 0.557)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.400] [G acc: 0.094]\n",
      "3800 [D loss: (0.503)(R 0.561, F 0.446)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.150] [G acc: 0.141]\n",
      "3801 [D loss: (0.455)(R 0.462, F 0.448)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.520] [G acc: 0.047]\n",
      "3802 [D loss: (0.548)(R 0.620, F 0.477)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.279] [G acc: 0.141]\n",
      "3803 [D loss: (0.465)(R 0.412, F 0.519)] [D acc: (0.773)(0.781, 0.766)] [G loss: 1.254] [G acc: 0.094]\n",
      "3804 [D loss: (0.693)(R 0.388, F 0.997)] [D acc: (0.719)(0.812, 0.625)] [G loss: 1.326] [G acc: 0.141]\n",
      "3805 [D loss: (0.518)(R 0.595, F 0.441)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.340] [G acc: 0.141]\n",
      "3806 [D loss: (0.577)(R 0.671, F 0.482)] [D acc: (0.688)(0.516, 0.859)] [G loss: 1.296] [G acc: 0.219]\n",
      "3807 [D loss: (0.555)(R 0.580, F 0.531)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.283] [G acc: 0.141]\n",
      "3808 [D loss: (0.472)(R 0.484, F 0.459)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.402] [G acc: 0.125]\n",
      "3809 [D loss: (0.465)(R 0.484, F 0.446)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.337] [G acc: 0.109]\n",
      "3810 [D loss: (0.465)(R 0.440, F 0.490)] [D acc: (0.789)(0.781, 0.797)] [G loss: 1.474] [G acc: 0.078]\n",
      "3811 [D loss: (0.525)(R 0.523, F 0.528)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.328] [G acc: 0.141]\n",
      "3812 [D loss: (0.508)(R 0.559, F 0.457)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.311] [G acc: 0.219]\n",
      "3813 [D loss: (0.603)(R 0.515, F 0.690)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.568] [G acc: 0.047]\n",
      "3814 [D loss: (0.564)(R 0.664, F 0.463)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.363] [G acc: 0.109]\n",
      "3815 [D loss: (0.502)(R 0.507, F 0.496)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.304] [G acc: 0.125]\n",
      "3816 [D loss: (0.548)(R 0.581, F 0.515)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.394] [G acc: 0.109]\n",
      "3817 [D loss: (0.392)(R 0.377, F 0.406)] [D acc: (0.836)(0.812, 0.859)] [G loss: 1.611] [G acc: 0.031]\n",
      "3818 [D loss: (0.438)(R 0.467, F 0.408)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.207] [G acc: 0.219]\n",
      "3819 [D loss: (0.614)(R 0.565, F 0.664)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.529] [G acc: 0.109]\n",
      "3820 [D loss: (0.527)(R 0.637, F 0.418)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.615] [G acc: 0.062]\n",
      "3821 [D loss: (0.411)(R 0.433, F 0.389)] [D acc: (0.812)(0.734, 0.891)] [G loss: 1.533] [G acc: 0.062]\n",
      "3822 [D loss: (0.511)(R 0.515, F 0.507)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.456] [G acc: 0.125]\n",
      "3823 [D loss: (0.555)(R 0.632, F 0.478)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.454] [G acc: 0.125]\n",
      "3824 [D loss: (0.610)(R 0.581, F 0.640)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.412] [G acc: 0.125]\n",
      "3825 [D loss: (0.635)(R 0.599, F 0.670)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.287] [G acc: 0.031]\n",
      "3826 [D loss: (0.487)(R 0.610, F 0.364)] [D acc: (0.758)(0.609, 0.906)] [G loss: 1.490] [G acc: 0.109]\n",
      "3827 [D loss: (0.505)(R 0.547, F 0.463)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.472] [G acc: 0.141]\n",
      "3828 [D loss: (0.461)(R 0.449, F 0.472)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.396] [G acc: 0.109]\n",
      "3829 [D loss: (0.537)(R 0.529, F 0.545)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.247] [G acc: 0.172]\n",
      "3830 [D loss: (0.547)(R 0.554, F 0.540)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.383] [G acc: 0.078]\n",
      "3831 [D loss: (0.500)(R 0.530, F 0.470)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.478] [G acc: 0.094]\n",
      "3832 [D loss: (0.417)(R 0.377, F 0.457)] [D acc: (0.789)(0.797, 0.781)] [G loss: 1.340] [G acc: 0.125]\n",
      "3833 [D loss: (0.553)(R 0.595, F 0.510)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.336] [G acc: 0.219]\n",
      "3834 [D loss: (0.587)(R 0.555, F 0.620)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.446] [G acc: 0.094]\n",
      "3835 [D loss: (0.621)(R 0.600, F 0.643)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.414] [G acc: 0.125]\n",
      "3836 [D loss: (0.565)(R 0.527, F 0.603)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.541] [G acc: 0.062]\n",
      "3837 [D loss: (0.512)(R 0.568, F 0.457)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.555] [G acc: 0.047]\n",
      "3838 [D loss: (0.475)(R 0.476, F 0.474)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.353] [G acc: 0.078]\n",
      "3839 [D loss: (0.487)(R 0.454, F 0.520)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.348] [G acc: 0.078]\n",
      "3840 [D loss: (0.484)(R 0.447, F 0.522)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.380] [G acc: 0.062]\n",
      "3841 [D loss: (0.557)(R 0.553, F 0.562)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.411] [G acc: 0.094]\n",
      "3842 [D loss: (0.508)(R 0.550, F 0.466)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.350] [G acc: 0.109]\n",
      "3843 [D loss: (0.591)(R 0.657, F 0.524)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.390] [G acc: 0.094]\n",
      "3844 [D loss: (0.563)(R 0.607, F 0.519)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.431] [G acc: 0.078]\n",
      "3845 [D loss: (0.509)(R 0.439, F 0.579)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.414] [G acc: 0.188]\n",
      "3846 [D loss: (0.579)(R 0.585, F 0.573)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.439] [G acc: 0.094]\n",
      "3847 [D loss: (0.545)(R 0.669, F 0.420)] [D acc: (0.711)(0.547, 0.875)] [G loss: 1.465] [G acc: 0.078]\n",
      "3848 [D loss: (0.519)(R 0.574, F 0.463)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.499] [G acc: 0.078]\n",
      "3849 [D loss: (0.513)(R 0.490, F 0.535)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.378] [G acc: 0.094]\n",
      "3850 [D loss: (0.460)(R 0.397, F 0.523)] [D acc: (0.797)(0.812, 0.781)] [G loss: 1.547] [G acc: 0.047]\n",
      "3851 [D loss: (0.548)(R 0.556, F 0.539)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.494] [G acc: 0.078]\n",
      "3852 [D loss: (0.515)(R 0.517, F 0.513)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.554] [G acc: 0.047]\n",
      "3853 [D loss: (0.579)(R 0.695, F 0.462)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.263] [G acc: 0.172]\n",
      "3854 [D loss: (0.517)(R 0.470, F 0.563)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.406] [G acc: 0.078]\n",
      "3855 [D loss: (0.469)(R 0.552, F 0.387)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.321] [G acc: 0.125]\n",
      "3856 [D loss: (0.615)(R 0.517, F 0.712)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.441] [G acc: 0.062]\n",
      "3857 [D loss: (0.607)(R 0.752, F 0.461)] [D acc: (0.656)(0.453, 0.859)] [G loss: 1.355] [G acc: 0.141]\n",
      "3858 [D loss: (0.571)(R 0.598, F 0.543)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.466] [G acc: 0.047]\n",
      "3859 [D loss: (0.495)(R 0.559, F 0.431)] [D acc: (0.797)(0.703, 0.891)] [G loss: 1.457] [G acc: 0.047]\n",
      "3860 [D loss: (0.670)(R 0.593, F 0.747)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.420] [G acc: 0.062]\n",
      "3861 [D loss: (0.454)(R 0.477, F 0.430)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.409] [G acc: 0.078]\n",
      "3862 [D loss: (0.548)(R 0.534, F 0.562)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.284] [G acc: 0.141]\n",
      "3863 [D loss: (0.543)(R 0.595, F 0.492)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.288] [G acc: 0.094]\n",
      "3864 [D loss: (0.582)(R 0.562, F 0.601)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.315] [G acc: 0.094]\n",
      "3865 [D loss: (0.519)(R 0.524, F 0.514)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.368] [G acc: 0.078]\n",
      "3866 [D loss: (0.428)(R 0.409, F 0.446)] [D acc: (0.820)(0.812, 0.828)] [G loss: 1.323] [G acc: 0.156]\n",
      "3867 [D loss: (0.552)(R 0.618, F 0.486)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.243] [G acc: 0.062]\n",
      "3868 [D loss: (0.461)(R 0.395, F 0.527)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.522] [G acc: 0.047]\n",
      "3869 [D loss: (0.489)(R 0.500, F 0.477)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.594] [G acc: 0.016]\n",
      "3870 [D loss: (0.628)(R 0.613, F 0.643)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.427] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3871 [D loss: (0.473)(R 0.407, F 0.540)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.321] [G acc: 0.062]\n",
      "3872 [D loss: (0.524)(R 0.539, F 0.510)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.450] [G acc: 0.016]\n",
      "3873 [D loss: (0.539)(R 0.561, F 0.517)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.423] [G acc: 0.078]\n",
      "3874 [D loss: (0.519)(R 0.630, F 0.408)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.398] [G acc: 0.109]\n",
      "3875 [D loss: (0.614)(R 0.557, F 0.671)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.478] [G acc: 0.078]\n",
      "3876 [D loss: (0.572)(R 0.652, F 0.491)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.248] [G acc: 0.109]\n",
      "3877 [D loss: (0.569)(R 0.588, F 0.550)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.321] [G acc: 0.125]\n",
      "3878 [D loss: (0.525)(R 0.522, F 0.527)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.466] [G acc: 0.125]\n",
      "3879 [D loss: (0.490)(R 0.475, F 0.504)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.394] [G acc: 0.094]\n",
      "3880 [D loss: (0.498)(R 0.518, F 0.479)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.433] [G acc: 0.094]\n",
      "3881 [D loss: (0.598)(R 0.633, F 0.563)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.397] [G acc: 0.062]\n",
      "3882 [D loss: (0.491)(R 0.562, F 0.421)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.379] [G acc: 0.109]\n",
      "3883 [D loss: (0.477)(R 0.469, F 0.486)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.366] [G acc: 0.094]\n",
      "3884 [D loss: (0.517)(R 0.475, F 0.560)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.324] [G acc: 0.141]\n",
      "3885 [D loss: (0.603)(R 0.515, F 0.691)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.460] [G acc: 0.062]\n",
      "3886 [D loss: (0.526)(R 0.661, F 0.392)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.442] [G acc: 0.109]\n",
      "3887 [D loss: (0.379)(R 0.404, F 0.355)] [D acc: (0.875)(0.797, 0.953)] [G loss: 1.428] [G acc: 0.125]\n",
      "3888 [D loss: (0.510)(R 0.394, F 0.627)] [D acc: (0.828)(0.828, 0.828)] [G loss: 1.391] [G acc: 0.125]\n",
      "3889 [D loss: (0.433)(R 0.456, F 0.411)] [D acc: (0.820)(0.781, 0.859)] [G loss: 1.352] [G acc: 0.078]\n",
      "3890 [D loss: (0.569)(R 0.414, F 0.725)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.496] [G acc: 0.031]\n",
      "3891 [D loss: (0.543)(R 0.569, F 0.518)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.663] [G acc: 0.062]\n",
      "3892 [D loss: (0.555)(R 0.645, F 0.466)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.589] [G acc: 0.062]\n",
      "3893 [D loss: (0.547)(R 0.578, F 0.516)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.642] [G acc: 0.094]\n",
      "3894 [D loss: (0.505)(R 0.529, F 0.480)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.303] [G acc: 0.125]\n",
      "3895 [D loss: (0.518)(R 0.514, F 0.523)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.514] [G acc: 0.078]\n",
      "3896 [D loss: (0.457)(R 0.413, F 0.501)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.452] [G acc: 0.094]\n",
      "3897 [D loss: (0.522)(R 0.583, F 0.462)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.472] [G acc: 0.094]\n",
      "3898 [D loss: (0.577)(R 0.570, F 0.584)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.503] [G acc: 0.062]\n",
      "3899 [D loss: (0.542)(R 0.526, F 0.558)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.561] [G acc: 0.062]\n",
      "3900 [D loss: (0.564)(R 0.632, F 0.497)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.388] [G acc: 0.094]\n",
      "3901 [D loss: (0.534)(R 0.564, F 0.505)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.478] [G acc: 0.078]\n",
      "3902 [D loss: (0.526)(R 0.568, F 0.484)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.479] [G acc: 0.016]\n",
      "3903 [D loss: (0.478)(R 0.529, F 0.428)] [D acc: (0.805)(0.703, 0.906)] [G loss: 1.302] [G acc: 0.172]\n",
      "3904 [D loss: (0.485)(R 0.431, F 0.538)] [D acc: (0.766)(0.781, 0.750)] [G loss: 1.598] [G acc: 0.062]\n",
      "3905 [D loss: (0.603)(R 0.632, F 0.575)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.491] [G acc: 0.078]\n",
      "3906 [D loss: (0.499)(R 0.572, F 0.426)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.440] [G acc: 0.094]\n",
      "3907 [D loss: (0.558)(R 0.580, F 0.536)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.450] [G acc: 0.109]\n",
      "3908 [D loss: (0.486)(R 0.517, F 0.455)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.313] [G acc: 0.156]\n",
      "3909 [D loss: (0.466)(R 0.492, F 0.439)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.410] [G acc: 0.172]\n",
      "3910 [D loss: (0.420)(R 0.359, F 0.482)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.460] [G acc: 0.078]\n",
      "3911 [D loss: (0.554)(R 0.523, F 0.585)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.461] [G acc: 0.047]\n",
      "3912 [D loss: (0.601)(R 0.669, F 0.533)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.412] [G acc: 0.109]\n",
      "3913 [D loss: (0.569)(R 0.617, F 0.522)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.409] [G acc: 0.078]\n",
      "3914 [D loss: (0.552)(R 0.603, F 0.500)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.365] [G acc: 0.078]\n",
      "3915 [D loss: (0.548)(R 0.566, F 0.531)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.351] [G acc: 0.078]\n",
      "3916 [D loss: (0.530)(R 0.554, F 0.506)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.290] [G acc: 0.156]\n",
      "3917 [D loss: (0.535)(R 0.561, F 0.509)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.419] [G acc: 0.094]\n",
      "3918 [D loss: (0.576)(R 0.511, F 0.640)] [D acc: (0.648)(0.625, 0.672)] [G loss: 1.537] [G acc: 0.031]\n",
      "3919 [D loss: (0.554)(R 0.674, F 0.434)] [D acc: (0.727)(0.547, 0.906)] [G loss: 1.225] [G acc: 0.078]\n",
      "3920 [D loss: (0.480)(R 0.536, F 0.425)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.480] [G acc: 0.031]\n",
      "3921 [D loss: (0.471)(R 0.492, F 0.450)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.417] [G acc: 0.078]\n",
      "3922 [D loss: (0.550)(R 0.476, F 0.623)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.454] [G acc: 0.078]\n",
      "3923 [D loss: (0.522)(R 0.590, F 0.453)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.428] [G acc: 0.078]\n",
      "3924 [D loss: (0.557)(R 0.621, F 0.492)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.258] [G acc: 0.156]\n",
      "3925 [D loss: (0.581)(R 0.600, F 0.562)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.350] [G acc: 0.094]\n",
      "3926 [D loss: (0.551)(R 0.670, F 0.431)] [D acc: (0.727)(0.547, 0.906)] [G loss: 1.299] [G acc: 0.047]\n",
      "3927 [D loss: (0.473)(R 0.511, F 0.435)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.392] [G acc: 0.047]\n",
      "3928 [D loss: (0.555)(R 0.580, F 0.530)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.339] [G acc: 0.109]\n",
      "3929 [D loss: (0.551)(R 0.552, F 0.551)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.256] [G acc: 0.094]\n",
      "3930 [D loss: (0.520)(R 0.536, F 0.504)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.282] [G acc: 0.125]\n",
      "3931 [D loss: (0.549)(R 0.585, F 0.513)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.282] [G acc: 0.156]\n",
      "3932 [D loss: (0.484)(R 0.511, F 0.457)] [D acc: (0.805)(0.734, 0.875)] [G loss: 1.294] [G acc: 0.094]\n",
      "3933 [D loss: (0.421)(R 0.421, F 0.421)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.393] [G acc: 0.125]\n",
      "3934 [D loss: (0.422)(R 0.429, F 0.416)] [D acc: (0.805)(0.703, 0.906)] [G loss: 1.350] [G acc: 0.109]\n",
      "3935 [D loss: (0.512)(R 0.544, F 0.480)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.344] [G acc: 0.109]\n",
      "3936 [D loss: (0.533)(R 0.401, F 0.664)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.544] [G acc: 0.047]\n",
      "3937 [D loss: (0.501)(R 0.552, F 0.450)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.438] [G acc: 0.047]\n",
      "3938 [D loss: (0.425)(R 0.440, F 0.409)] [D acc: (0.820)(0.734, 0.906)] [G loss: 1.549] [G acc: 0.062]\n",
      "3939 [D loss: (0.485)(R 0.512, F 0.457)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.479] [G acc: 0.016]\n",
      "3940 [D loss: (0.418)(R 0.396, F 0.441)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.575] [G acc: 0.062]\n",
      "3941 [D loss: (0.531)(R 0.574, F 0.489)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.626] [G acc: 0.016]\n",
      "3942 [D loss: (0.607)(R 0.531, F 0.682)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.448] [G acc: 0.094]\n",
      "3943 [D loss: (0.585)(R 0.702, F 0.467)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.419] [G acc: 0.125]\n",
      "3944 [D loss: (0.553)(R 0.595, F 0.510)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.488] [G acc: 0.031]\n",
      "3945 [D loss: (0.421)(R 0.438, F 0.404)] [D acc: (0.828)(0.734, 0.922)] [G loss: 1.421] [G acc: 0.047]\n",
      "3946 [D loss: (0.517)(R 0.576, F 0.458)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.544] [G acc: 0.094]\n",
      "3947 [D loss: (0.455)(R 0.471, F 0.438)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.372] [G acc: 0.125]\n",
      "3948 [D loss: (0.537)(R 0.463, F 0.611)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.545] [G acc: 0.062]\n",
      "3949 [D loss: (0.499)(R 0.609, F 0.388)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.393] [G acc: 0.109]\n",
      "3950 [D loss: (0.517)(R 0.433, F 0.602)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.491] [G acc: 0.031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3951 [D loss: (0.564)(R 0.689, F 0.439)] [D acc: (0.680)(0.531, 0.828)] [G loss: 1.291] [G acc: 0.094]\n",
      "3952 [D loss: (0.474)(R 0.493, F 0.455)] [D acc: (0.805)(0.703, 0.906)] [G loss: 1.400] [G acc: 0.094]\n",
      "3953 [D loss: (0.501)(R 0.444, F 0.559)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.384] [G acc: 0.078]\n",
      "3954 [D loss: (0.486)(R 0.501, F 0.471)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.515] [G acc: 0.109]\n",
      "3955 [D loss: (0.456)(R 0.526, F 0.387)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.495] [G acc: 0.109]\n",
      "3956 [D loss: (0.563)(R 0.626, F 0.500)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.314] [G acc: 0.125]\n",
      "3957 [D loss: (0.467)(R 0.510, F 0.425)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.427] [G acc: 0.078]\n",
      "3958 [D loss: (0.495)(R 0.467, F 0.524)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.468] [G acc: 0.047]\n",
      "3959 [D loss: (0.543)(R 0.589, F 0.497)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.455] [G acc: 0.078]\n",
      "3960 [D loss: (0.469)(R 0.457, F 0.480)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.524] [G acc: 0.078]\n",
      "3961 [D loss: (0.610)(R 0.671, F 0.550)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.480] [G acc: 0.047]\n",
      "3962 [D loss: (0.600)(R 0.636, F 0.564)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.291] [G acc: 0.125]\n",
      "3963 [D loss: (0.456)(R 0.532, F 0.381)] [D acc: (0.781)(0.641, 0.922)] [G loss: 1.291] [G acc: 0.094]\n",
      "3964 [D loss: (0.655)(R 0.576, F 0.733)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.507] [G acc: 0.094]\n",
      "3965 [D loss: (0.533)(R 0.584, F 0.483)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.391] [G acc: 0.078]\n",
      "3966 [D loss: (0.588)(R 0.655, F 0.520)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.376] [G acc: 0.156]\n",
      "3967 [D loss: (0.524)(R 0.613, F 0.435)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.404] [G acc: 0.109]\n",
      "3968 [D loss: (0.501)(R 0.452, F 0.549)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.399] [G acc: 0.125]\n",
      "3969 [D loss: (0.558)(R 0.604, F 0.513)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.458] [G acc: 0.141]\n",
      "3970 [D loss: (0.529)(R 0.367, F 0.690)] [D acc: (0.742)(0.781, 0.703)] [G loss: 1.461] [G acc: 0.094]\n",
      "3971 [D loss: (0.423)(R 0.515, F 0.330)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.356] [G acc: 0.125]\n",
      "3972 [D loss: (0.490)(R 0.518, F 0.462)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.440] [G acc: 0.125]\n",
      "3973 [D loss: (0.599)(R 0.677, F 0.520)] [D acc: (0.680)(0.594, 0.766)] [G loss: 1.423] [G acc: 0.078]\n",
      "3974 [D loss: (0.520)(R 0.593, F 0.447)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.482] [G acc: 0.047]\n",
      "3975 [D loss: (0.580)(R 0.536, F 0.624)] [D acc: (0.727)(0.734, 0.719)] [G loss: 1.356] [G acc: 0.141]\n",
      "3976 [D loss: (0.505)(R 0.564, F 0.447)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.381] [G acc: 0.094]\n",
      "3977 [D loss: (0.511)(R 0.513, F 0.508)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.473] [G acc: 0.109]\n",
      "3978 [D loss: (0.534)(R 0.521, F 0.547)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.539] [G acc: 0.047]\n",
      "3979 [D loss: (0.495)(R 0.550, F 0.439)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.527] [G acc: 0.047]\n",
      "3980 [D loss: (0.556)(R 0.609, F 0.503)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.489] [G acc: 0.062]\n",
      "3981 [D loss: (0.468)(R 0.489, F 0.446)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.659] [G acc: 0.031]\n",
      "3982 [D loss: (0.506)(R 0.548, F 0.465)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.598] [G acc: 0.078]\n",
      "3983 [D loss: (0.504)(R 0.520, F 0.488)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.583] [G acc: 0.094]\n",
      "3984 [D loss: (0.455)(R 0.521, F 0.389)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.693] [G acc: 0.062]\n",
      "3985 [D loss: (0.560)(R 0.574, F 0.547)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.489] [G acc: 0.109]\n",
      "3986 [D loss: (0.503)(R 0.484, F 0.521)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.518] [G acc: 0.062]\n",
      "3987 [D loss: (0.535)(R 0.455, F 0.615)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.575] [G acc: 0.078]\n",
      "3988 [D loss: (0.523)(R 0.648, F 0.398)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.630] [G acc: 0.078]\n",
      "3989 [D loss: (0.450)(R 0.460, F 0.441)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.409] [G acc: 0.078]\n",
      "3990 [D loss: (0.559)(R 0.623, F 0.494)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.568] [G acc: 0.062]\n",
      "3991 [D loss: (0.646)(R 0.670, F 0.623)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.415] [G acc: 0.062]\n",
      "3992 [D loss: (0.532)(R 0.572, F 0.493)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.496] [G acc: 0.047]\n",
      "3993 [D loss: (0.598)(R 0.638, F 0.557)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.255] [G acc: 0.109]\n",
      "3994 [D loss: (0.457)(R 0.492, F 0.421)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.358] [G acc: 0.156]\n",
      "3995 [D loss: (0.545)(R 0.557, F 0.532)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.276] [G acc: 0.125]\n",
      "3996 [D loss: (0.601)(R 0.572, F 0.629)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.398] [G acc: 0.094]\n",
      "3997 [D loss: (0.519)(R 0.595, F 0.442)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.362] [G acc: 0.047]\n",
      "3998 [D loss: (0.542)(R 0.586, F 0.498)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.370] [G acc: 0.125]\n",
      "3999 [D loss: (0.507)(R 0.524, F 0.490)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.305] [G acc: 0.156]\n",
      "4000 [D loss: (0.586)(R 0.593, F 0.579)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.346] [G acc: 0.125]\n",
      "4001 [D loss: (0.480)(R 0.526, F 0.435)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.361] [G acc: 0.062]\n",
      "4002 [D loss: (0.457)(R 0.437, F 0.476)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.334] [G acc: 0.156]\n",
      "4003 [D loss: (0.552)(R 0.563, F 0.540)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.221] [G acc: 0.062]\n",
      "4004 [D loss: (0.564)(R 0.577, F 0.551)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.233] [G acc: 0.141]\n",
      "4005 [D loss: (0.537)(R 0.489, F 0.585)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.386] [G acc: 0.078]\n",
      "4006 [D loss: (0.520)(R 0.504, F 0.536)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.373] [G acc: 0.141]\n",
      "4007 [D loss: (0.507)(R 0.458, F 0.556)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.409] [G acc: 0.062]\n",
      "4008 [D loss: (0.488)(R 0.477, F 0.499)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.362] [G acc: 0.141]\n",
      "4009 [D loss: (0.531)(R 0.480, F 0.582)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.458] [G acc: 0.031]\n",
      "4010 [D loss: (0.535)(R 0.625, F 0.445)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.496] [G acc: 0.078]\n",
      "4011 [D loss: (0.449)(R 0.465, F 0.433)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.451] [G acc: 0.062]\n",
      "4012 [D loss: (0.520)(R 0.446, F 0.595)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.423] [G acc: 0.078]\n",
      "4013 [D loss: (0.520)(R 0.484, F 0.556)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.433] [G acc: 0.062]\n",
      "4014 [D loss: (0.488)(R 0.405, F 0.571)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.496] [G acc: 0.078]\n",
      "4015 [D loss: (0.617)(R 0.760, F 0.475)] [D acc: (0.672)(0.500, 0.844)] [G loss: 1.467] [G acc: 0.062]\n",
      "4016 [D loss: (0.560)(R 0.649, F 0.471)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.499] [G acc: 0.078]\n",
      "4017 [D loss: (0.540)(R 0.513, F 0.566)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.579] [G acc: 0.000]\n",
      "4018 [D loss: (0.520)(R 0.663, F 0.377)] [D acc: (0.719)(0.531, 0.906)] [G loss: 1.486] [G acc: 0.094]\n",
      "4019 [D loss: (0.429)(R 0.380, F 0.478)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.666] [G acc: 0.094]\n",
      "4020 [D loss: (0.583)(R 0.607, F 0.559)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.474] [G acc: 0.047]\n",
      "4021 [D loss: (0.557)(R 0.527, F 0.586)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.574] [G acc: 0.047]\n",
      "4022 [D loss: (0.529)(R 0.517, F 0.541)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.557] [G acc: 0.047]\n",
      "4023 [D loss: (0.540)(R 0.652, F 0.427)] [D acc: (0.695)(0.531, 0.859)] [G loss: 1.504] [G acc: 0.094]\n",
      "4024 [D loss: (0.515)(R 0.521, F 0.509)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.570] [G acc: 0.047]\n",
      "4025 [D loss: (0.605)(R 0.523, F 0.686)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.453] [G acc: 0.047]\n",
      "4026 [D loss: (0.571)(R 0.615, F 0.526)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.521] [G acc: 0.047]\n",
      "4027 [D loss: (0.500)(R 0.545, F 0.454)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.599] [G acc: 0.062]\n",
      "4028 [D loss: (0.477)(R 0.595, F 0.359)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.463] [G acc: 0.078]\n",
      "4029 [D loss: (0.568)(R 0.584, F 0.552)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.373] [G acc: 0.109]\n",
      "4030 [D loss: (0.528)(R 0.534, F 0.522)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.527] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4031 [D loss: (0.464)(R 0.534, F 0.394)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.456] [G acc: 0.094]\n",
      "4032 [D loss: (0.488)(R 0.546, F 0.430)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.318] [G acc: 0.141]\n",
      "4033 [D loss: (0.494)(R 0.507, F 0.482)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.378] [G acc: 0.188]\n",
      "4034 [D loss: (0.523)(R 0.589, F 0.457)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.436] [G acc: 0.094]\n",
      "4035 [D loss: (0.488)(R 0.451, F 0.524)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.702] [G acc: 0.109]\n",
      "4036 [D loss: (0.458)(R 0.415, F 0.500)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.711] [G acc: 0.031]\n",
      "4037 [D loss: (0.484)(R 0.509, F 0.460)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.553] [G acc: 0.141]\n",
      "4038 [D loss: (0.436)(R 0.409, F 0.462)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.601] [G acc: 0.156]\n",
      "4039 [D loss: (0.508)(R 0.500, F 0.515)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.592] [G acc: 0.141]\n",
      "4040 [D loss: (0.460)(R 0.539, F 0.381)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.656] [G acc: 0.062]\n",
      "4041 [D loss: (0.456)(R 0.445, F 0.467)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.511] [G acc: 0.094]\n",
      "4042 [D loss: (0.543)(R 0.593, F 0.494)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.681] [G acc: 0.047]\n",
      "4043 [D loss: (0.504)(R 0.520, F 0.489)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.536] [G acc: 0.109]\n",
      "4044 [D loss: (0.546)(R 0.618, F 0.474)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.546] [G acc: 0.125]\n",
      "4045 [D loss: (0.441)(R 0.416, F 0.466)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.427] [G acc: 0.094]\n",
      "4046 [D loss: (0.452)(R 0.380, F 0.523)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.538] [G acc: 0.094]\n",
      "4047 [D loss: (0.641)(R 0.718, F 0.565)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.324] [G acc: 0.156]\n",
      "4048 [D loss: (0.540)(R 0.550, F 0.531)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.339] [G acc: 0.172]\n",
      "4049 [D loss: (0.441)(R 0.436, F 0.445)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.478] [G acc: 0.109]\n",
      "4050 [D loss: (0.468)(R 0.412, F 0.523)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.462] [G acc: 0.109]\n",
      "4051 [D loss: (0.528)(R 0.540, F 0.516)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.585] [G acc: 0.047]\n",
      "4052 [D loss: (0.524)(R 0.599, F 0.450)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.597] [G acc: 0.125]\n",
      "4053 [D loss: (0.507)(R 0.529, F 0.486)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.389] [G acc: 0.156]\n",
      "4054 [D loss: (0.520)(R 0.612, F 0.427)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.507] [G acc: 0.062]\n",
      "4055 [D loss: (0.608)(R 0.435, F 0.781)] [D acc: (0.727)(0.750, 0.703)] [G loss: 1.493] [G acc: 0.078]\n",
      "4056 [D loss: (0.554)(R 0.553, F 0.555)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.452] [G acc: 0.094]\n",
      "4057 [D loss: (0.575)(R 0.515, F 0.636)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.469] [G acc: 0.172]\n",
      "4058 [D loss: (0.499)(R 0.596, F 0.403)] [D acc: (0.773)(0.641, 0.906)] [G loss: 1.491] [G acc: 0.047]\n",
      "4059 [D loss: (0.479)(R 0.462, F 0.497)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.324] [G acc: 0.125]\n",
      "4060 [D loss: (0.484)(R 0.511, F 0.457)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.353] [G acc: 0.125]\n",
      "4061 [D loss: (0.678)(R 0.579, F 0.776)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.432] [G acc: 0.047]\n",
      "4062 [D loss: (0.534)(R 0.563, F 0.505)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.393] [G acc: 0.031]\n",
      "4063 [D loss: (0.482)(R 0.530, F 0.434)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.533] [G acc: 0.062]\n",
      "4064 [D loss: (0.548)(R 0.534, F 0.563)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.454] [G acc: 0.109]\n",
      "4065 [D loss: (0.557)(R 0.596, F 0.518)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.361] [G acc: 0.078]\n",
      "4066 [D loss: (0.500)(R 0.490, F 0.510)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.499] [G acc: 0.094]\n",
      "4067 [D loss: (0.594)(R 0.688, F 0.500)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.406] [G acc: 0.094]\n",
      "4068 [D loss: (0.515)(R 0.486, F 0.543)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.372] [G acc: 0.125]\n",
      "4069 [D loss: (0.491)(R 0.556, F 0.426)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.420] [G acc: 0.156]\n",
      "4070 [D loss: (0.552)(R 0.553, F 0.551)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.469] [G acc: 0.078]\n",
      "4071 [D loss: (0.585)(R 0.547, F 0.622)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.575] [G acc: 0.031]\n",
      "4072 [D loss: (0.587)(R 0.716, F 0.459)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.469] [G acc: 0.062]\n",
      "4073 [D loss: (0.506)(R 0.516, F 0.496)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.332] [G acc: 0.172]\n",
      "4074 [D loss: (0.509)(R 0.613, F 0.406)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.458] [G acc: 0.078]\n",
      "4075 [D loss: (0.403)(R 0.337, F 0.468)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.500] [G acc: 0.125]\n",
      "4076 [D loss: (0.529)(R 0.586, F 0.471)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.453] [G acc: 0.141]\n",
      "4077 [D loss: (0.514)(R 0.517, F 0.511)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.422] [G acc: 0.094]\n",
      "4078 [D loss: (0.585)(R 0.501, F 0.670)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.471] [G acc: 0.094]\n",
      "4079 [D loss: (0.573)(R 0.543, F 0.603)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.503] [G acc: 0.047]\n",
      "4080 [D loss: (0.571)(R 0.596, F 0.547)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.374] [G acc: 0.125]\n",
      "4081 [D loss: (0.489)(R 0.505, F 0.472)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.613] [G acc: 0.094]\n",
      "4082 [D loss: (0.516)(R 0.593, F 0.440)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.329] [G acc: 0.109]\n",
      "4083 [D loss: (0.535)(R 0.447, F 0.622)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.589] [G acc: 0.047]\n",
      "4084 [D loss: (0.612)(R 0.762, F 0.462)] [D acc: (0.680)(0.516, 0.844)] [G loss: 1.420] [G acc: 0.062]\n",
      "4085 [D loss: (0.607)(R 0.653, F 0.562)] [D acc: (0.648)(0.547, 0.750)] [G loss: 1.338] [G acc: 0.047]\n",
      "4086 [D loss: (0.557)(R 0.592, F 0.523)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.380] [G acc: 0.094]\n",
      "4087 [D loss: (0.502)(R 0.557, F 0.447)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.299] [G acc: 0.109]\n",
      "4088 [D loss: (0.464)(R 0.399, F 0.530)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.380] [G acc: 0.109]\n",
      "4089 [D loss: (0.488)(R 0.574, F 0.401)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.472] [G acc: 0.109]\n",
      "4090 [D loss: (0.480)(R 0.501, F 0.458)] [D acc: (0.812)(0.734, 0.891)] [G loss: 1.419] [G acc: 0.125]\n",
      "4091 [D loss: (0.478)(R 0.442, F 0.514)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.445] [G acc: 0.062]\n",
      "4092 [D loss: (0.517)(R 0.452, F 0.582)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.370] [G acc: 0.047]\n",
      "4093 [D loss: (0.512)(R 0.525, F 0.499)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.348] [G acc: 0.078]\n",
      "4094 [D loss: (0.559)(R 0.527, F 0.590)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.330] [G acc: 0.141]\n",
      "4095 [D loss: (0.502)(R 0.427, F 0.578)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.537] [G acc: 0.031]\n",
      "4096 [D loss: (0.477)(R 0.553, F 0.401)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.410] [G acc: 0.156]\n",
      "4097 [D loss: (0.544)(R 0.540, F 0.548)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.400] [G acc: 0.094]\n",
      "4098 [D loss: (0.467)(R 0.497, F 0.436)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.551] [G acc: 0.062]\n",
      "4099 [D loss: (0.490)(R 0.489, F 0.491)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.396] [G acc: 0.141]\n",
      "4100 [D loss: (0.560)(R 0.477, F 0.643)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.425] [G acc: 0.062]\n",
      "4101 [D loss: (0.609)(R 0.690, F 0.528)] [D acc: (0.727)(0.562, 0.891)] [G loss: 1.449] [G acc: 0.062]\n",
      "4102 [D loss: (0.549)(R 0.625, F 0.473)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.411] [G acc: 0.125]\n",
      "4103 [D loss: (0.598)(R 0.501, F 0.695)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.741] [G acc: 0.094]\n",
      "4104 [D loss: (0.467)(R 0.524, F 0.411)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.532] [G acc: 0.062]\n",
      "4105 [D loss: (0.506)(R 0.459, F 0.552)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.314] [G acc: 0.141]\n",
      "4106 [D loss: (0.520)(R 0.474, F 0.567)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.396] [G acc: 0.094]\n",
      "4107 [D loss: (0.514)(R 0.600, F 0.429)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.477] [G acc: 0.094]\n",
      "4108 [D loss: (0.513)(R 0.558, F 0.468)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.371] [G acc: 0.109]\n",
      "4109 [D loss: (0.532)(R 0.511, F 0.553)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.440] [G acc: 0.109]\n",
      "4110 [D loss: (0.526)(R 0.561, F 0.491)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.507] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4111 [D loss: (0.543)(R 0.580, F 0.506)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.450] [G acc: 0.125]\n",
      "4112 [D loss: (0.560)(R 0.569, F 0.551)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.515] [G acc: 0.078]\n",
      "4113 [D loss: (0.474)(R 0.508, F 0.440)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.470] [G acc: 0.125]\n",
      "4114 [D loss: (0.611)(R 0.628, F 0.594)] [D acc: (0.641)(0.562, 0.719)] [G loss: 1.305] [G acc: 0.109]\n",
      "4115 [D loss: (0.568)(R 0.618, F 0.519)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.328] [G acc: 0.188]\n",
      "4116 [D loss: (0.434)(R 0.479, F 0.389)] [D acc: (0.805)(0.688, 0.922)] [G loss: 1.432] [G acc: 0.094]\n",
      "4117 [D loss: (0.508)(R 0.480, F 0.536)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.475] [G acc: 0.062]\n",
      "4118 [D loss: (0.547)(R 0.625, F 0.468)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.384] [G acc: 0.141]\n",
      "4119 [D loss: (0.496)(R 0.413, F 0.579)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.513] [G acc: 0.062]\n",
      "4120 [D loss: (0.509)(R 0.550, F 0.468)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.446] [G acc: 0.094]\n",
      "4121 [D loss: (0.586)(R 0.658, F 0.513)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.374] [G acc: 0.094]\n",
      "4122 [D loss: (0.590)(R 0.670, F 0.509)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.231] [G acc: 0.141]\n",
      "4123 [D loss: (0.533)(R 0.586, F 0.480)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.289] [G acc: 0.109]\n",
      "4124 [D loss: (0.466)(R 0.466, F 0.466)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.329] [G acc: 0.203]\n",
      "4125 [D loss: (0.490)(R 0.427, F 0.553)] [D acc: (0.742)(0.766, 0.719)] [G loss: 1.336] [G acc: 0.156]\n",
      "4126 [D loss: (0.490)(R 0.533, F 0.447)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.499] [G acc: 0.109]\n",
      "4127 [D loss: (0.492)(R 0.396, F 0.589)] [D acc: (0.797)(0.797, 0.797)] [G loss: 1.575] [G acc: 0.141]\n",
      "4128 [D loss: (0.592)(R 0.775, F 0.409)] [D acc: (0.695)(0.469, 0.922)] [G loss: 1.466] [G acc: 0.109]\n",
      "4129 [D loss: (0.518)(R 0.585, F 0.451)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.438] [G acc: 0.062]\n",
      "4130 [D loss: (0.464)(R 0.505, F 0.423)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.410] [G acc: 0.219]\n",
      "4131 [D loss: (0.539)(R 0.461, F 0.616)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.424] [G acc: 0.203]\n",
      "4132 [D loss: (0.565)(R 0.516, F 0.615)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.511] [G acc: 0.062]\n",
      "4133 [D loss: (0.538)(R 0.562, F 0.515)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.429] [G acc: 0.078]\n",
      "4134 [D loss: (0.552)(R 0.648, F 0.457)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.529] [G acc: 0.078]\n",
      "4135 [D loss: (0.562)(R 0.475, F 0.648)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.640] [G acc: 0.078]\n",
      "4136 [D loss: (0.586)(R 0.653, F 0.520)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.471] [G acc: 0.031]\n",
      "4137 [D loss: (0.549)(R 0.527, F 0.572)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.307] [G acc: 0.125]\n",
      "4138 [D loss: (0.492)(R 0.567, F 0.417)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.404] [G acc: 0.109]\n",
      "4139 [D loss: (0.422)(R 0.393, F 0.451)] [D acc: (0.805)(0.781, 0.828)] [G loss: 1.431] [G acc: 0.094]\n",
      "4140 [D loss: (0.604)(R 0.539, F 0.669)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.425] [G acc: 0.047]\n",
      "4141 [D loss: (0.506)(R 0.581, F 0.430)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.336] [G acc: 0.125]\n",
      "4142 [D loss: (0.574)(R 0.639, F 0.509)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.431] [G acc: 0.125]\n",
      "4143 [D loss: (0.483)(R 0.544, F 0.422)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.349] [G acc: 0.125]\n",
      "4144 [D loss: (0.515)(R 0.466, F 0.564)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.475] [G acc: 0.094]\n",
      "4145 [D loss: (0.469)(R 0.527, F 0.410)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.574] [G acc: 0.047]\n",
      "4146 [D loss: (0.504)(R 0.519, F 0.490)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.562] [G acc: 0.016]\n",
      "4147 [D loss: (0.523)(R 0.487, F 0.560)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.502] [G acc: 0.047]\n",
      "4148 [D loss: (0.535)(R 0.551, F 0.520)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.337] [G acc: 0.156]\n",
      "4149 [D loss: (0.542)(R 0.621, F 0.463)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.377] [G acc: 0.172]\n",
      "4150 [D loss: (0.529)(R 0.562, F 0.496)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.330] [G acc: 0.109]\n",
      "4151 [D loss: (0.439)(R 0.451, F 0.427)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.454] [G acc: 0.094]\n",
      "4152 [D loss: (0.529)(R 0.610, F 0.448)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.385] [G acc: 0.141]\n",
      "4153 [D loss: (0.535)(R 0.501, F 0.570)] [D acc: (0.727)(0.750, 0.703)] [G loss: 1.264] [G acc: 0.141]\n",
      "4154 [D loss: (0.518)(R 0.525, F 0.511)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.313] [G acc: 0.094]\n",
      "4155 [D loss: (0.493)(R 0.544, F 0.442)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.281] [G acc: 0.094]\n",
      "4156 [D loss: (0.486)(R 0.376, F 0.596)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.481] [G acc: 0.141]\n",
      "4157 [D loss: (0.541)(R 0.576, F 0.506)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.363] [G acc: 0.047]\n",
      "4158 [D loss: (0.483)(R 0.527, F 0.439)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.478] [G acc: 0.094]\n",
      "4159 [D loss: (0.662)(R 0.613, F 0.711)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.492] [G acc: 0.047]\n",
      "4160 [D loss: (0.505)(R 0.602, F 0.407)] [D acc: (0.742)(0.594, 0.891)] [G loss: 1.335] [G acc: 0.094]\n",
      "4161 [D loss: (0.563)(R 0.497, F 0.629)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.280] [G acc: 0.094]\n",
      "4162 [D loss: (0.449)(R 0.467, F 0.430)] [D acc: (0.805)(0.734, 0.875)] [G loss: 1.293] [G acc: 0.078]\n",
      "4163 [D loss: (0.421)(R 0.328, F 0.515)] [D acc: (0.805)(0.828, 0.781)] [G loss: 1.359] [G acc: 0.094]\n",
      "4164 [D loss: (0.541)(R 0.428, F 0.653)] [D acc: (0.797)(0.797, 0.797)] [G loss: 1.593] [G acc: 0.094]\n",
      "4165 [D loss: (0.497)(R 0.594, F 0.400)] [D acc: (0.789)(0.656, 0.922)] [G loss: 1.536] [G acc: 0.062]\n",
      "4166 [D loss: (0.517)(R 0.572, F 0.462)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.467] [G acc: 0.078]\n",
      "4167 [D loss: (0.507)(R 0.589, F 0.425)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.570] [G acc: 0.062]\n",
      "4168 [D loss: (0.554)(R 0.662, F 0.447)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.531] [G acc: 0.078]\n",
      "4169 [D loss: (0.553)(R 0.478, F 0.629)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.505] [G acc: 0.078]\n",
      "4170 [D loss: (0.610)(R 0.710, F 0.511)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.350] [G acc: 0.109]\n",
      "4171 [D loss: (0.605)(R 0.617, F 0.592)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.466] [G acc: 0.094]\n",
      "4172 [D loss: (0.533)(R 0.592, F 0.474)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.526] [G acc: 0.047]\n",
      "4173 [D loss: (0.433)(R 0.495, F 0.372)] [D acc: (0.836)(0.734, 0.938)] [G loss: 1.467] [G acc: 0.094]\n",
      "4174 [D loss: (0.493)(R 0.489, F 0.497)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.332] [G acc: 0.141]\n",
      "4175 [D loss: (0.492)(R 0.532, F 0.452)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.353] [G acc: 0.141]\n",
      "4176 [D loss: (0.538)(R 0.528, F 0.548)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.541] [G acc: 0.094]\n",
      "4177 [D loss: (0.535)(R 0.513, F 0.558)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.375] [G acc: 0.062]\n",
      "4178 [D loss: (0.492)(R 0.482, F 0.503)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.464] [G acc: 0.094]\n",
      "4179 [D loss: (0.502)(R 0.544, F 0.460)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.415] [G acc: 0.094]\n",
      "4180 [D loss: (0.527)(R 0.577, F 0.478)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.308] [G acc: 0.078]\n",
      "4181 [D loss: (0.484)(R 0.481, F 0.486)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.471] [G acc: 0.078]\n",
      "4182 [D loss: (0.535)(R 0.472, F 0.597)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.545] [G acc: 0.094]\n",
      "4183 [D loss: (0.477)(R 0.570, F 0.384)] [D acc: (0.742)(0.594, 0.891)] [G loss: 1.383] [G acc: 0.125]\n",
      "4184 [D loss: (0.519)(R 0.527, F 0.512)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.384] [G acc: 0.156]\n",
      "4185 [D loss: (0.533)(R 0.633, F 0.434)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.349] [G acc: 0.062]\n",
      "4186 [D loss: (0.456)(R 0.408, F 0.504)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.402] [G acc: 0.172]\n",
      "4187 [D loss: (0.520)(R 0.526, F 0.514)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.471] [G acc: 0.078]\n",
      "4188 [D loss: (0.508)(R 0.486, F 0.530)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.464] [G acc: 0.047]\n",
      "4189 [D loss: (0.520)(R 0.550, F 0.489)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.412] [G acc: 0.094]\n",
      "4190 [D loss: (0.544)(R 0.495, F 0.592)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.618] [G acc: 0.047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4191 [D loss: (0.416)(R 0.406, F 0.425)] [D acc: (0.820)(0.781, 0.859)] [G loss: 1.498] [G acc: 0.031]\n",
      "4192 [D loss: (0.583)(R 0.611, F 0.555)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.397] [G acc: 0.062]\n",
      "4193 [D loss: (0.462)(R 0.499, F 0.424)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.375] [G acc: 0.188]\n",
      "4194 [D loss: (0.516)(R 0.427, F 0.605)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.502] [G acc: 0.109]\n",
      "4195 [D loss: (0.617)(R 0.593, F 0.640)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.422] [G acc: 0.047]\n",
      "4196 [D loss: (0.533)(R 0.615, F 0.450)] [D acc: (0.750)(0.594, 0.906)] [G loss: 1.443] [G acc: 0.094]\n",
      "4197 [D loss: (0.536)(R 0.551, F 0.521)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.368] [G acc: 0.094]\n",
      "4198 [D loss: (0.469)(R 0.545, F 0.392)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.438] [G acc: 0.109]\n",
      "4199 [D loss: (0.526)(R 0.549, F 0.503)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.293] [G acc: 0.109]\n",
      "4200 [D loss: (0.524)(R 0.542, F 0.505)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.415] [G acc: 0.109]\n",
      "4201 [D loss: (0.523)(R 0.516, F 0.531)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.372] [G acc: 0.094]\n",
      "4202 [D loss: (0.554)(R 0.638, F 0.469)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.440] [G acc: 0.078]\n",
      "4203 [D loss: (0.492)(R 0.515, F 0.469)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.368] [G acc: 0.125]\n",
      "4204 [D loss: (0.534)(R 0.512, F 0.556)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.367] [G acc: 0.094]\n",
      "4205 [D loss: (0.532)(R 0.492, F 0.572)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.435] [G acc: 0.109]\n",
      "4206 [D loss: (0.552)(R 0.591, F 0.513)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.340] [G acc: 0.109]\n",
      "4207 [D loss: (0.524)(R 0.516, F 0.533)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.377] [G acc: 0.078]\n",
      "4208 [D loss: (0.488)(R 0.545, F 0.430)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.442] [G acc: 0.078]\n",
      "4209 [D loss: (0.575)(R 0.579, F 0.571)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.366] [G acc: 0.062]\n",
      "4210 [D loss: (0.553)(R 0.647, F 0.460)] [D acc: (0.711)(0.531, 0.891)] [G loss: 1.229] [G acc: 0.156]\n",
      "4211 [D loss: (0.555)(R 0.591, F 0.518)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.347] [G acc: 0.078]\n",
      "4212 [D loss: (0.548)(R 0.569, F 0.528)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.339] [G acc: 0.109]\n",
      "4213 [D loss: (0.507)(R 0.467, F 0.547)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.440] [G acc: 0.031]\n",
      "4214 [D loss: (0.481)(R 0.517, F 0.445)] [D acc: (0.805)(0.734, 0.875)] [G loss: 1.327] [G acc: 0.125]\n",
      "4215 [D loss: (0.446)(R 0.467, F 0.426)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.442] [G acc: 0.062]\n",
      "4216 [D loss: (0.539)(R 0.414, F 0.663)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.370] [G acc: 0.094]\n",
      "4217 [D loss: (0.614)(R 0.793, F 0.436)] [D acc: (0.680)(0.469, 0.891)] [G loss: 1.395] [G acc: 0.125]\n",
      "4218 [D loss: (0.554)(R 0.560, F 0.548)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.367] [G acc: 0.078]\n",
      "4219 [D loss: (0.533)(R 0.530, F 0.536)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.324] [G acc: 0.109]\n",
      "4220 [D loss: (0.511)(R 0.533, F 0.489)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.388] [G acc: 0.078]\n",
      "4221 [D loss: (0.620)(R 0.582, F 0.658)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.378] [G acc: 0.094]\n",
      "4222 [D loss: (0.520)(R 0.527, F 0.513)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.361] [G acc: 0.078]\n",
      "4223 [D loss: (0.519)(R 0.569, F 0.469)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.281] [G acc: 0.078]\n",
      "4224 [D loss: (0.530)(R 0.527, F 0.533)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.271] [G acc: 0.125]\n",
      "4225 [D loss: (0.526)(R 0.559, F 0.493)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.282] [G acc: 0.078]\n",
      "4226 [D loss: (0.553)(R 0.574, F 0.533)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.290] [G acc: 0.109]\n",
      "4227 [D loss: (0.524)(R 0.511, F 0.538)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.265] [G acc: 0.109]\n",
      "4228 [D loss: (0.510)(R 0.490, F 0.530)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.263] [G acc: 0.156]\n",
      "4229 [D loss: (0.456)(R 0.511, F 0.401)] [D acc: (0.812)(0.719, 0.906)] [G loss: 1.215] [G acc: 0.125]\n",
      "4230 [D loss: (0.604)(R 0.536, F 0.672)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.405] [G acc: 0.094]\n",
      "4231 [D loss: (0.551)(R 0.618, F 0.483)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.262] [G acc: 0.094]\n",
      "4232 [D loss: (0.636)(R 0.541, F 0.731)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.261] [G acc: 0.078]\n",
      "4233 [D loss: (0.518)(R 0.509, F 0.527)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.371] [G acc: 0.125]\n",
      "4234 [D loss: (0.575)(R 0.586, F 0.565)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.352] [G acc: 0.109]\n",
      "4235 [D loss: (0.536)(R 0.561, F 0.511)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.485] [G acc: 0.016]\n",
      "4236 [D loss: (0.620)(R 0.643, F 0.596)] [D acc: (0.648)(0.594, 0.703)] [G loss: 1.406] [G acc: 0.062]\n",
      "4237 [D loss: (0.566)(R 0.604, F 0.527)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.419] [G acc: 0.062]\n",
      "4238 [D loss: (0.532)(R 0.500, F 0.565)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.463] [G acc: 0.062]\n",
      "4239 [D loss: (0.482)(R 0.484, F 0.479)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.492] [G acc: 0.031]\n",
      "4240 [D loss: (0.583)(R 0.550, F 0.616)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.411] [G acc: 0.078]\n",
      "4241 [D loss: (0.499)(R 0.550, F 0.448)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.275] [G acc: 0.141]\n",
      "4242 [D loss: (0.478)(R 0.428, F 0.528)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.339] [G acc: 0.031]\n",
      "4243 [D loss: (0.521)(R 0.539, F 0.502)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.389] [G acc: 0.094]\n",
      "4244 [D loss: (0.499)(R 0.579, F 0.420)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.397] [G acc: 0.062]\n",
      "4245 [D loss: (0.522)(R 0.478, F 0.566)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.408] [G acc: 0.047]\n",
      "4246 [D loss: (0.577)(R 0.614, F 0.541)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.292] [G acc: 0.109]\n",
      "4247 [D loss: (0.432)(R 0.468, F 0.397)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.449] [G acc: 0.109]\n",
      "4248 [D loss: (0.527)(R 0.501, F 0.553)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.469] [G acc: 0.062]\n",
      "4249 [D loss: (0.530)(R 0.513, F 0.547)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.408] [G acc: 0.062]\n",
      "4250 [D loss: (0.524)(R 0.503, F 0.544)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.415] [G acc: 0.031]\n",
      "4251 [D loss: (0.515)(R 0.475, F 0.555)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.341] [G acc: 0.047]\n",
      "4252 [D loss: (0.511)(R 0.646, F 0.376)] [D acc: (0.734)(0.562, 0.906)] [G loss: 1.388] [G acc: 0.094]\n",
      "4253 [D loss: (0.521)(R 0.556, F 0.486)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.471] [G acc: 0.094]\n",
      "4254 [D loss: (0.507)(R 0.473, F 0.540)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.271] [G acc: 0.141]\n",
      "4255 [D loss: (0.611)(R 0.657, F 0.565)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.221] [G acc: 0.219]\n",
      "4256 [D loss: (0.538)(R 0.594, F 0.483)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.253] [G acc: 0.141]\n",
      "4257 [D loss: (0.434)(R 0.413, F 0.455)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.345] [G acc: 0.125]\n",
      "4258 [D loss: (0.557)(R 0.420, F 0.694)] [D acc: (0.734)(0.750, 0.719)] [G loss: 1.386] [G acc: 0.047]\n",
      "4259 [D loss: (0.542)(R 0.614, F 0.470)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.559] [G acc: 0.062]\n",
      "4260 [D loss: (0.454)(R 0.489, F 0.418)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.448] [G acc: 0.109]\n",
      "4261 [D loss: (0.469)(R 0.455, F 0.482)] [D acc: (0.797)(0.781, 0.812)] [G loss: 1.464] [G acc: 0.094]\n",
      "4262 [D loss: (0.468)(R 0.471, F 0.465)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.445] [G acc: 0.094]\n",
      "4263 [D loss: (0.470)(R 0.483, F 0.458)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.452] [G acc: 0.156]\n",
      "4264 [D loss: (0.498)(R 0.460, F 0.535)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.465] [G acc: 0.109]\n",
      "4265 [D loss: (0.555)(R 0.577, F 0.534)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.482] [G acc: 0.062]\n",
      "4266 [D loss: (0.577)(R 0.680, F 0.473)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.431] [G acc: 0.031]\n",
      "4267 [D loss: (0.546)(R 0.544, F 0.548)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.460] [G acc: 0.109]\n",
      "4268 [D loss: (0.469)(R 0.500, F 0.438)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.362] [G acc: 0.141]\n",
      "4269 [D loss: (0.496)(R 0.413, F 0.580)] [D acc: (0.773)(0.781, 0.766)] [G loss: 1.482] [G acc: 0.078]\n",
      "4270 [D loss: (0.537)(R 0.639, F 0.436)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.380] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4271 [D loss: (0.526)(R 0.482, F 0.569)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.377] [G acc: 0.078]\n",
      "4272 [D loss: (0.500)(R 0.499, F 0.501)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.393] [G acc: 0.125]\n",
      "4273 [D loss: (0.500)(R 0.582, F 0.419)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.442] [G acc: 0.125]\n",
      "4274 [D loss: (0.502)(R 0.461, F 0.543)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.357] [G acc: 0.125]\n",
      "4275 [D loss: (0.544)(R 0.641, F 0.446)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.507] [G acc: 0.141]\n",
      "4276 [D loss: (0.439)(R 0.477, F 0.401)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.487] [G acc: 0.109]\n",
      "4277 [D loss: (0.539)(R 0.651, F 0.427)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.351] [G acc: 0.172]\n",
      "4278 [D loss: (0.653)(R 0.440, F 0.865)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.502] [G acc: 0.000]\n",
      "4279 [D loss: (0.562)(R 0.661, F 0.463)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.425] [G acc: 0.094]\n",
      "4280 [D loss: (0.573)(R 0.666, F 0.481)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.450] [G acc: 0.047]\n",
      "4281 [D loss: (0.476)(R 0.499, F 0.452)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.539] [G acc: 0.156]\n",
      "4282 [D loss: (0.487)(R 0.457, F 0.517)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.460] [G acc: 0.172]\n",
      "4283 [D loss: (0.415)(R 0.461, F 0.369)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.507] [G acc: 0.062]\n",
      "4284 [D loss: (0.561)(R 0.639, F 0.482)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.350] [G acc: 0.125]\n",
      "4285 [D loss: (0.497)(R 0.428, F 0.566)] [D acc: (0.781)(0.781, 0.781)] [G loss: 1.555] [G acc: 0.047]\n",
      "4286 [D loss: (0.613)(R 0.532, F 0.694)] [D acc: (0.617)(0.609, 0.625)] [G loss: 1.589] [G acc: 0.047]\n",
      "4287 [D loss: (0.440)(R 0.462, F 0.419)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.386] [G acc: 0.078]\n",
      "4288 [D loss: (0.582)(R 0.574, F 0.589)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.571] [G acc: 0.125]\n",
      "4289 [D loss: (0.567)(R 0.599, F 0.536)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.394] [G acc: 0.094]\n",
      "4290 [D loss: (0.544)(R 0.503, F 0.586)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.607] [G acc: 0.031]\n",
      "4291 [D loss: (0.553)(R 0.688, F 0.417)] [D acc: (0.711)(0.500, 0.922)] [G loss: 1.339] [G acc: 0.141]\n",
      "4292 [D loss: (0.555)(R 0.559, F 0.552)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.554] [G acc: 0.031]\n",
      "4293 [D loss: (0.570)(R 0.572, F 0.567)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.452] [G acc: 0.062]\n",
      "4294 [D loss: (0.592)(R 0.606, F 0.579)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.287] [G acc: 0.094]\n",
      "4295 [D loss: (0.502)(R 0.516, F 0.488)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.356] [G acc: 0.125]\n",
      "4296 [D loss: (0.511)(R 0.572, F 0.451)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.330] [G acc: 0.109]\n",
      "4297 [D loss: (0.442)(R 0.433, F 0.451)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.553] [G acc: 0.078]\n",
      "4298 [D loss: (0.519)(R 0.435, F 0.604)] [D acc: (0.711)(0.750, 0.672)] [G loss: 1.512] [G acc: 0.047]\n",
      "4299 [D loss: (0.479)(R 0.454, F 0.505)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.284] [G acc: 0.188]\n",
      "4300 [D loss: (0.432)(R 0.403, F 0.462)] [D acc: (0.820)(0.797, 0.844)] [G loss: 1.459] [G acc: 0.031]\n",
      "4301 [D loss: (0.476)(R 0.484, F 0.467)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.333] [G acc: 0.078]\n",
      "4302 [D loss: (0.528)(R 0.540, F 0.515)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.370] [G acc: 0.094]\n",
      "4303 [D loss: (0.508)(R 0.498, F 0.518)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.299] [G acc: 0.109]\n",
      "4304 [D loss: (0.625)(R 0.619, F 0.631)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.408] [G acc: 0.047]\n",
      "4305 [D loss: (0.571)(R 0.676, F 0.467)] [D acc: (0.695)(0.531, 0.859)] [G loss: 1.417] [G acc: 0.062]\n",
      "4306 [D loss: (0.511)(R 0.584, F 0.438)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.258] [G acc: 0.125]\n",
      "4307 [D loss: (0.486)(R 0.530, F 0.442)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.281] [G acc: 0.141]\n",
      "4308 [D loss: (0.559)(R 0.444, F 0.674)] [D acc: (0.711)(0.766, 0.656)] [G loss: 1.387] [G acc: 0.062]\n",
      "4309 [D loss: (0.531)(R 0.591, F 0.471)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.443] [G acc: 0.031]\n",
      "4310 [D loss: (0.480)(R 0.611, F 0.350)] [D acc: (0.773)(0.594, 0.953)] [G loss: 1.400] [G acc: 0.094]\n",
      "4311 [D loss: (0.462)(R 0.437, F 0.487)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.345] [G acc: 0.188]\n",
      "4312 [D loss: (0.497)(R 0.445, F 0.550)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.567] [G acc: 0.047]\n",
      "4313 [D loss: (0.508)(R 0.600, F 0.417)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.453] [G acc: 0.109]\n",
      "4314 [D loss: (0.517)(R 0.535, F 0.499)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.361] [G acc: 0.141]\n",
      "4315 [D loss: (0.522)(R 0.511, F 0.534)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.333] [G acc: 0.078]\n",
      "4316 [D loss: (0.627)(R 0.546, F 0.707)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.426] [G acc: 0.078]\n",
      "4317 [D loss: (0.521)(R 0.629, F 0.412)] [D acc: (0.766)(0.625, 0.906)] [G loss: 1.496] [G acc: 0.078]\n",
      "4318 [D loss: (0.504)(R 0.539, F 0.470)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.334] [G acc: 0.109]\n",
      "4319 [D loss: (0.474)(R 0.486, F 0.462)] [D acc: (0.805)(0.750, 0.859)] [G loss: 1.345] [G acc: 0.109]\n",
      "4320 [D loss: (0.524)(R 0.625, F 0.423)] [D acc: (0.758)(0.609, 0.906)] [G loss: 1.534] [G acc: 0.031]\n",
      "4321 [D loss: (0.436)(R 0.413, F 0.458)] [D acc: (0.797)(0.703, 0.891)] [G loss: 1.372] [G acc: 0.125]\n",
      "4322 [D loss: (0.608)(R 0.512, F 0.704)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.480] [G acc: 0.141]\n",
      "4323 [D loss: (0.496)(R 0.620, F 0.372)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.403] [G acc: 0.047]\n",
      "4324 [D loss: (0.613)(R 0.461, F 0.765)] [D acc: (0.727)(0.750, 0.703)] [G loss: 1.445] [G acc: 0.047]\n",
      "4325 [D loss: (0.479)(R 0.553, F 0.404)] [D acc: (0.828)(0.703, 0.953)] [G loss: 1.486] [G acc: 0.062]\n",
      "4326 [D loss: (0.459)(R 0.469, F 0.449)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.575] [G acc: 0.078]\n",
      "4327 [D loss: (0.472)(R 0.489, F 0.454)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.707] [G acc: 0.016]\n",
      "4328 [D loss: (0.420)(R 0.463, F 0.378)] [D acc: (0.812)(0.734, 0.891)] [G loss: 1.516] [G acc: 0.125]\n",
      "4329 [D loss: (0.483)(R 0.469, F 0.496)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.271] [G acc: 0.156]\n",
      "4330 [D loss: (0.521)(R 0.430, F 0.612)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.297] [G acc: 0.109]\n",
      "4331 [D loss: (0.528)(R 0.585, F 0.472)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.574] [G acc: 0.062]\n",
      "4332 [D loss: (0.506)(R 0.566, F 0.447)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.647] [G acc: 0.016]\n",
      "4333 [D loss: (0.467)(R 0.450, F 0.484)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.523] [G acc: 0.062]\n",
      "4334 [D loss: (0.666)(R 0.435, F 0.897)] [D acc: (0.680)(0.719, 0.641)] [G loss: 1.663] [G acc: 0.047]\n",
      "4335 [D loss: (0.573)(R 0.698, F 0.448)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.430] [G acc: 0.094]\n",
      "4336 [D loss: (0.567)(R 0.613, F 0.522)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.490] [G acc: 0.125]\n",
      "4337 [D loss: (0.596)(R 0.644, F 0.549)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.531] [G acc: 0.062]\n",
      "4338 [D loss: (0.531)(R 0.570, F 0.492)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.432] [G acc: 0.078]\n",
      "4339 [D loss: (0.449)(R 0.465, F 0.433)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.561] [G acc: 0.062]\n",
      "4340 [D loss: (0.532)(R 0.682, F 0.381)] [D acc: (0.703)(0.531, 0.875)] [G loss: 1.408] [G acc: 0.094]\n",
      "4341 [D loss: (0.423)(R 0.409, F 0.438)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.480] [G acc: 0.062]\n",
      "4342 [D loss: (0.616)(R 0.586, F 0.646)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.356] [G acc: 0.094]\n",
      "4343 [D loss: (0.471)(R 0.542, F 0.401)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.497] [G acc: 0.031]\n",
      "4344 [D loss: (0.549)(R 0.501, F 0.597)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.564] [G acc: 0.031]\n",
      "4345 [D loss: (0.550)(R 0.602, F 0.497)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.369] [G acc: 0.094]\n",
      "4346 [D loss: (0.505)(R 0.454, F 0.556)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.525] [G acc: 0.047]\n",
      "4347 [D loss: (0.544)(R 0.618, F 0.469)] [D acc: (0.734)(0.578, 0.891)] [G loss: 1.295] [G acc: 0.188]\n",
      "4348 [D loss: (0.465)(R 0.520, F 0.410)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.497] [G acc: 0.078]\n",
      "4349 [D loss: (0.472)(R 0.529, F 0.416)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.411] [G acc: 0.094]\n",
      "4350 [D loss: (0.559)(R 0.569, F 0.548)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.610] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4351 [D loss: (0.489)(R 0.487, F 0.491)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.416] [G acc: 0.141]\n",
      "4352 [D loss: (0.475)(R 0.581, F 0.370)] [D acc: (0.773)(0.625, 0.922)] [G loss: 1.432] [G acc: 0.109]\n",
      "4353 [D loss: (0.603)(R 0.585, F 0.622)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.406] [G acc: 0.109]\n",
      "4354 [D loss: (0.466)(R 0.572, F 0.361)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.529] [G acc: 0.094]\n",
      "4355 [D loss: (0.537)(R 0.410, F 0.665)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.439] [G acc: 0.094]\n",
      "4356 [D loss: (0.511)(R 0.479, F 0.544)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.683] [G acc: 0.062]\n",
      "4357 [D loss: (0.523)(R 0.647, F 0.400)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.340] [G acc: 0.125]\n",
      "4358 [D loss: (0.576)(R 0.500, F 0.652)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.422] [G acc: 0.125]\n",
      "4359 [D loss: (0.575)(R 0.667, F 0.484)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.360] [G acc: 0.047]\n",
      "4360 [D loss: (0.472)(R 0.492, F 0.452)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.505] [G acc: 0.094]\n",
      "4361 [D loss: (0.487)(R 0.483, F 0.491)] [D acc: (0.805)(0.750, 0.859)] [G loss: 1.377] [G acc: 0.109]\n",
      "4362 [D loss: (0.534)(R 0.523, F 0.545)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.421] [G acc: 0.156]\n",
      "4363 [D loss: (0.514)(R 0.520, F 0.509)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.439] [G acc: 0.078]\n",
      "4364 [D loss: (0.517)(R 0.513, F 0.521)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.377] [G acc: 0.078]\n",
      "4365 [D loss: (0.451)(R 0.467, F 0.435)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.473] [G acc: 0.109]\n",
      "4366 [D loss: (0.557)(R 0.594, F 0.520)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.436] [G acc: 0.047]\n",
      "4367 [D loss: (0.500)(R 0.580, F 0.421)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.447] [G acc: 0.094]\n",
      "4368 [D loss: (0.508)(R 0.424, F 0.592)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.605] [G acc: 0.047]\n",
      "4369 [D loss: (0.547)(R 0.458, F 0.635)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.478] [G acc: 0.109]\n",
      "4370 [D loss: (0.583)(R 0.659, F 0.507)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.434] [G acc: 0.109]\n",
      "4371 [D loss: (0.574)(R 0.582, F 0.565)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.454] [G acc: 0.062]\n",
      "4372 [D loss: (0.599)(R 0.716, F 0.481)] [D acc: (0.680)(0.531, 0.828)] [G loss: 1.245] [G acc: 0.125]\n",
      "4373 [D loss: (0.518)(R 0.587, F 0.449)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.401] [G acc: 0.094]\n",
      "4374 [D loss: (0.518)(R 0.454, F 0.583)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.588] [G acc: 0.031]\n",
      "4375 [D loss: (0.590)(R 0.646, F 0.534)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.378] [G acc: 0.078]\n",
      "4376 [D loss: (0.535)(R 0.600, F 0.469)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.433] [G acc: 0.062]\n",
      "4377 [D loss: (0.521)(R 0.585, F 0.457)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.372] [G acc: 0.141]\n",
      "4378 [D loss: (0.429)(R 0.446, F 0.412)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.400] [G acc: 0.062]\n",
      "4379 [D loss: (0.437)(R 0.442, F 0.433)] [D acc: (0.805)(0.781, 0.828)] [G loss: 1.416] [G acc: 0.109]\n",
      "4380 [D loss: (0.498)(R 0.453, F 0.543)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.486] [G acc: 0.062]\n",
      "4381 [D loss: (0.637)(R 0.669, F 0.605)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.587] [G acc: 0.047]\n",
      "4382 [D loss: (0.576)(R 0.622, F 0.530)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.448] [G acc: 0.031]\n",
      "4383 [D loss: (0.479)(R 0.509, F 0.450)] [D acc: (0.820)(0.766, 0.875)] [G loss: 1.579] [G acc: 0.125]\n",
      "4384 [D loss: (0.583)(R 0.467, F 0.700)] [D acc: (0.703)(0.750, 0.656)] [G loss: 1.413] [G acc: 0.109]\n",
      "4385 [D loss: (0.614)(R 0.729, F 0.498)] [D acc: (0.656)(0.516, 0.797)] [G loss: 1.456] [G acc: 0.094]\n",
      "4386 [D loss: (0.509)(R 0.563, F 0.456)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.342] [G acc: 0.109]\n",
      "4387 [D loss: (0.548)(R 0.524, F 0.572)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.411] [G acc: 0.141]\n",
      "4388 [D loss: (0.492)(R 0.534, F 0.451)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.520] [G acc: 0.062]\n",
      "4389 [D loss: (0.603)(R 0.654, F 0.551)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.321] [G acc: 0.141]\n",
      "4390 [D loss: (0.541)(R 0.482, F 0.600)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.383] [G acc: 0.125]\n",
      "4391 [D loss: (0.532)(R 0.623, F 0.440)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.432] [G acc: 0.078]\n",
      "4392 [D loss: (0.472)(R 0.439, F 0.505)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.450] [G acc: 0.078]\n",
      "4393 [D loss: (0.590)(R 0.596, F 0.584)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.466] [G acc: 0.094]\n",
      "4394 [D loss: (0.561)(R 0.517, F 0.606)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.417] [G acc: 0.156]\n",
      "4395 [D loss: (0.528)(R 0.504, F 0.551)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.411] [G acc: 0.141]\n",
      "4396 [D loss: (0.540)(R 0.648, F 0.431)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.367] [G acc: 0.094]\n",
      "4397 [D loss: (0.527)(R 0.491, F 0.563)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.367] [G acc: 0.109]\n",
      "4398 [D loss: (0.571)(R 0.547, F 0.595)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.481] [G acc: 0.094]\n",
      "4399 [D loss: (0.491)(R 0.566, F 0.415)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.515] [G acc: 0.047]\n",
      "4400 [D loss: (0.602)(R 0.551, F 0.654)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.266] [G acc: 0.078]\n",
      "4401 [D loss: (0.509)(R 0.414, F 0.604)] [D acc: (0.766)(0.797, 0.734)] [G loss: 1.453] [G acc: 0.078]\n",
      "4402 [D loss: (0.543)(R 0.544, F 0.542)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.440] [G acc: 0.078]\n",
      "4403 [D loss: (0.542)(R 0.577, F 0.508)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.435] [G acc: 0.109]\n",
      "4404 [D loss: (0.588)(R 0.662, F 0.514)] [D acc: (0.664)(0.547, 0.781)] [G loss: 1.421] [G acc: 0.078]\n",
      "4405 [D loss: (0.552)(R 0.666, F 0.439)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.248] [G acc: 0.125]\n",
      "4406 [D loss: (0.540)(R 0.554, F 0.526)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.445] [G acc: 0.125]\n",
      "4407 [D loss: (0.595)(R 0.534, F 0.657)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.295] [G acc: 0.125]\n",
      "4408 [D loss: (0.589)(R 0.679, F 0.499)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.297] [G acc: 0.109]\n",
      "4409 [D loss: (0.508)(R 0.514, F 0.503)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.377] [G acc: 0.062]\n",
      "4410 [D loss: (0.465)(R 0.431, F 0.500)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.326] [G acc: 0.156]\n",
      "4411 [D loss: (0.558)(R 0.567, F 0.550)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.303] [G acc: 0.156]\n",
      "4412 [D loss: (0.603)(R 0.666, F 0.539)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.417] [G acc: 0.109]\n",
      "4413 [D loss: (0.555)(R 0.465, F 0.646)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.473] [G acc: 0.062]\n",
      "4414 [D loss: (0.475)(R 0.550, F 0.400)] [D acc: (0.820)(0.703, 0.938)] [G loss: 1.402] [G acc: 0.047]\n",
      "4415 [D loss: (0.573)(R 0.542, F 0.603)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.332] [G acc: 0.094]\n",
      "4416 [D loss: (0.469)(R 0.514, F 0.423)] [D acc: (0.820)(0.750, 0.891)] [G loss: 1.527] [G acc: 0.031]\n",
      "4417 [D loss: (0.550)(R 0.617, F 0.483)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.287] [G acc: 0.156]\n",
      "4418 [D loss: (0.539)(R 0.528, F 0.549)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.348] [G acc: 0.078]\n",
      "4419 [D loss: (0.500)(R 0.499, F 0.500)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.494] [G acc: 0.078]\n",
      "4420 [D loss: (0.643)(R 0.526, F 0.760)] [D acc: (0.641)(0.625, 0.656)] [G loss: 1.480] [G acc: 0.078]\n",
      "4421 [D loss: (0.470)(R 0.511, F 0.429)] [D acc: (0.805)(0.703, 0.906)] [G loss: 1.651] [G acc: 0.031]\n",
      "4422 [D loss: (0.527)(R 0.623, F 0.432)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.396] [G acc: 0.062]\n",
      "4423 [D loss: (0.452)(R 0.435, F 0.469)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.475] [G acc: 0.094]\n",
      "4424 [D loss: (0.450)(R 0.386, F 0.515)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.549] [G acc: 0.094]\n",
      "4425 [D loss: (0.457)(R 0.543, F 0.370)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.322] [G acc: 0.188]\n",
      "4426 [D loss: (0.445)(R 0.403, F 0.487)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.643] [G acc: 0.047]\n",
      "4427 [D loss: (0.543)(R 0.611, F 0.474)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.390] [G acc: 0.141]\n",
      "4428 [D loss: (0.600)(R 0.602, F 0.598)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.469] [G acc: 0.062]\n",
      "4429 [D loss: (0.518)(R 0.482, F 0.554)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.545] [G acc: 0.016]\n",
      "4430 [D loss: (0.524)(R 0.609, F 0.438)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.528] [G acc: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4431 [D loss: (0.429)(R 0.451, F 0.406)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.560] [G acc: 0.094]\n",
      "4432 [D loss: (0.460)(R 0.407, F 0.514)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.311] [G acc: 0.062]\n",
      "4433 [D loss: (0.553)(R 0.583, F 0.523)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.480] [G acc: 0.078]\n",
      "4434 [D loss: (0.567)(R 0.578, F 0.556)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.476] [G acc: 0.078]\n",
      "4435 [D loss: (0.573)(R 0.645, F 0.501)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.354] [G acc: 0.094]\n",
      "4436 [D loss: (0.512)(R 0.557, F 0.467)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.476] [G acc: 0.078]\n",
      "4437 [D loss: (0.715)(R 0.824, F 0.605)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.354] [G acc: 0.047]\n",
      "4438 [D loss: (0.545)(R 0.590, F 0.501)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.274] [G acc: 0.125]\n",
      "4439 [D loss: (0.597)(R 0.568, F 0.625)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.195] [G acc: 0.109]\n",
      "4440 [D loss: (0.568)(R 0.569, F 0.568)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.477] [G acc: 0.094]\n",
      "4441 [D loss: (0.539)(R 0.492, F 0.587)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.483] [G acc: 0.094]\n",
      "4442 [D loss: (0.530)(R 0.503, F 0.557)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.329] [G acc: 0.109]\n",
      "4443 [D loss: (0.497)(R 0.552, F 0.441)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.475] [G acc: 0.094]\n",
      "4444 [D loss: (0.472)(R 0.536, F 0.409)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.496] [G acc: 0.094]\n",
      "4445 [D loss: (0.449)(R 0.419, F 0.478)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.527] [G acc: 0.031]\n",
      "4446 [D loss: (0.501)(R 0.429, F 0.573)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.559] [G acc: 0.078]\n",
      "4447 [D loss: (0.571)(R 0.718, F 0.423)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.571] [G acc: 0.062]\n",
      "4448 [D loss: (0.469)(R 0.520, F 0.418)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.365] [G acc: 0.062]\n",
      "4449 [D loss: (0.570)(R 0.463, F 0.677)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.368] [G acc: 0.094]\n",
      "4450 [D loss: (0.396)(R 0.350, F 0.441)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.357] [G acc: 0.156]\n",
      "4451 [D loss: (0.415)(R 0.405, F 0.425)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.734] [G acc: 0.031]\n",
      "4452 [D loss: (0.590)(R 0.596, F 0.583)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.419] [G acc: 0.109]\n",
      "4453 [D loss: (0.460)(R 0.400, F 0.519)] [D acc: (0.773)(0.781, 0.766)] [G loss: 1.569] [G acc: 0.047]\n",
      "4454 [D loss: (0.559)(R 0.675, F 0.443)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.397] [G acc: 0.109]\n",
      "4455 [D loss: (0.572)(R 0.661, F 0.484)] [D acc: (0.664)(0.547, 0.781)] [G loss: 1.353] [G acc: 0.125]\n",
      "4456 [D loss: (0.523)(R 0.564, F 0.482)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.375] [G acc: 0.125]\n",
      "4457 [D loss: (0.555)(R 0.553, F 0.556)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.394] [G acc: 0.094]\n",
      "4458 [D loss: (0.572)(R 0.558, F 0.587)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.360] [G acc: 0.078]\n",
      "4459 [D loss: (0.470)(R 0.502, F 0.437)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.301] [G acc: 0.172]\n",
      "4460 [D loss: (0.572)(R 0.523, F 0.622)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.471] [G acc: 0.141]\n",
      "4461 [D loss: (0.593)(R 0.676, F 0.510)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.420] [G acc: 0.141]\n",
      "4462 [D loss: (0.480)(R 0.517, F 0.442)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.390] [G acc: 0.125]\n",
      "4463 [D loss: (0.493)(R 0.460, F 0.525)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.350] [G acc: 0.172]\n",
      "4464 [D loss: (0.512)(R 0.551, F 0.473)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.671] [G acc: 0.125]\n",
      "4465 [D loss: (0.545)(R 0.570, F 0.521)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.460] [G acc: 0.062]\n",
      "4466 [D loss: (0.454)(R 0.543, F 0.364)] [D acc: (0.789)(0.656, 0.922)] [G loss: 1.502] [G acc: 0.125]\n",
      "4467 [D loss: (0.596)(R 0.498, F 0.693)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.568] [G acc: 0.047]\n",
      "4468 [D loss: (0.563)(R 0.631, F 0.496)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.350] [G acc: 0.156]\n",
      "4469 [D loss: (0.521)(R 0.543, F 0.498)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.608] [G acc: 0.000]\n",
      "4470 [D loss: (0.560)(R 0.528, F 0.592)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.591] [G acc: 0.062]\n",
      "4471 [D loss: (0.589)(R 0.628, F 0.550)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.412] [G acc: 0.078]\n",
      "4472 [D loss: (0.660)(R 0.674, F 0.646)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.443] [G acc: 0.109]\n",
      "4473 [D loss: (0.534)(R 0.561, F 0.508)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.386] [G acc: 0.062]\n",
      "4474 [D loss: (0.546)(R 0.572, F 0.521)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.477] [G acc: 0.094]\n",
      "4475 [D loss: (0.550)(R 0.598, F 0.502)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.344] [G acc: 0.094]\n",
      "4476 [D loss: (0.585)(R 0.605, F 0.566)] [D acc: (0.641)(0.625, 0.656)] [G loss: 1.511] [G acc: 0.047]\n",
      "4477 [D loss: (0.499)(R 0.506, F 0.492)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.324] [G acc: 0.125]\n",
      "4478 [D loss: (0.608)(R 0.501, F 0.715)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.501] [G acc: 0.047]\n",
      "4479 [D loss: (0.514)(R 0.539, F 0.488)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.369] [G acc: 0.156]\n",
      "4480 [D loss: (0.566)(R 0.552, F 0.580)] [D acc: (0.625)(0.547, 0.703)] [G loss: 1.247] [G acc: 0.109]\n",
      "4481 [D loss: (0.480)(R 0.563, F 0.397)] [D acc: (0.750)(0.594, 0.906)] [G loss: 1.360] [G acc: 0.219]\n",
      "4482 [D loss: (0.577)(R 0.573, F 0.581)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.193] [G acc: 0.094]\n",
      "4483 [D loss: (0.490)(R 0.441, F 0.539)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.396] [G acc: 0.094]\n",
      "4484 [D loss: (0.574)(R 0.610, F 0.538)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.144] [G acc: 0.172]\n",
      "4485 [D loss: (0.500)(R 0.467, F 0.532)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.339] [G acc: 0.094]\n",
      "4486 [D loss: (0.655)(R 0.550, F 0.760)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.517] [G acc: 0.109]\n",
      "4487 [D loss: (0.538)(R 0.632, F 0.445)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.343] [G acc: 0.141]\n",
      "4488 [D loss: (0.537)(R 0.590, F 0.484)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.425] [G acc: 0.078]\n",
      "4489 [D loss: (0.500)(R 0.550, F 0.450)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.365] [G acc: 0.141]\n",
      "4490 [D loss: (0.510)(R 0.528, F 0.492)] [D acc: (0.742)(0.594, 0.891)] [G loss: 1.287] [G acc: 0.141]\n",
      "4491 [D loss: (0.496)(R 0.557, F 0.436)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.353] [G acc: 0.172]\n",
      "4492 [D loss: (0.626)(R 0.648, F 0.605)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.374] [G acc: 0.156]\n",
      "4493 [D loss: (0.541)(R 0.472, F 0.610)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.289] [G acc: 0.125]\n",
      "4494 [D loss: (0.441)(R 0.452, F 0.430)] [D acc: (0.820)(0.766, 0.875)] [G loss: 1.400] [G acc: 0.109]\n",
      "4495 [D loss: (0.493)(R 0.460, F 0.525)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.461] [G acc: 0.109]\n",
      "4496 [D loss: (0.530)(R 0.560, F 0.499)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.441] [G acc: 0.109]\n",
      "4497 [D loss: (0.459)(R 0.446, F 0.472)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.478] [G acc: 0.047]\n",
      "4498 [D loss: (0.521)(R 0.555, F 0.488)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.403] [G acc: 0.188]\n",
      "4499 [D loss: (0.522)(R 0.585, F 0.458)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.532] [G acc: 0.062]\n",
      "4500 [D loss: (0.524)(R 0.479, F 0.568)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.456] [G acc: 0.172]\n",
      "4501 [D loss: (0.549)(R 0.596, F 0.502)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.603] [G acc: 0.062]\n",
      "4502 [D loss: (0.565)(R 0.611, F 0.519)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.536] [G acc: 0.062]\n",
      "4503 [D loss: (0.556)(R 0.462, F 0.650)] [D acc: (0.727)(0.766, 0.688)] [G loss: 1.585] [G acc: 0.141]\n",
      "4504 [D loss: (0.553)(R 0.642, F 0.464)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.480] [G acc: 0.078]\n",
      "4505 [D loss: (0.511)(R 0.578, F 0.444)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.388] [G acc: 0.078]\n",
      "4506 [D loss: (0.561)(R 0.593, F 0.529)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.414] [G acc: 0.062]\n",
      "4507 [D loss: (0.585)(R 0.637, F 0.534)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.342] [G acc: 0.094]\n",
      "4508 [D loss: (0.497)(R 0.466, F 0.527)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.227] [G acc: 0.172]\n",
      "4509 [D loss: (0.512)(R 0.478, F 0.545)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.405] [G acc: 0.109]\n",
      "4510 [D loss: (0.562)(R 0.582, F 0.543)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.447] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4511 [D loss: (0.526)(R 0.550, F 0.503)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.584] [G acc: 0.031]\n",
      "4512 [D loss: (0.570)(R 0.594, F 0.546)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.456] [G acc: 0.109]\n",
      "4513 [D loss: (0.479)(R 0.555, F 0.404)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.416] [G acc: 0.109]\n",
      "4514 [D loss: (0.469)(R 0.466, F 0.472)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.479] [G acc: 0.031]\n",
      "4515 [D loss: (0.546)(R 0.504, F 0.587)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.455] [G acc: 0.047]\n",
      "4516 [D loss: (0.590)(R 0.710, F 0.470)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.495] [G acc: 0.156]\n",
      "4517 [D loss: (0.567)(R 0.577, F 0.557)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.466] [G acc: 0.125]\n",
      "4518 [D loss: (0.512)(R 0.549, F 0.475)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.412] [G acc: 0.094]\n",
      "4519 [D loss: (0.521)(R 0.483, F 0.560)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.434] [G acc: 0.016]\n",
      "4520 [D loss: (0.448)(R 0.469, F 0.428)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.329] [G acc: 0.141]\n",
      "4521 [D loss: (0.454)(R 0.471, F 0.436)] [D acc: (0.820)(0.750, 0.891)] [G loss: 1.477] [G acc: 0.031]\n",
      "4522 [D loss: (0.530)(R 0.569, F 0.491)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.483] [G acc: 0.109]\n",
      "4523 [D loss: (0.588)(R 0.522, F 0.655)] [D acc: (0.656)(0.656, 0.656)] [G loss: 1.401] [G acc: 0.141]\n",
      "4524 [D loss: (0.543)(R 0.553, F 0.532)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.478] [G acc: 0.125]\n",
      "4525 [D loss: (0.505)(R 0.477, F 0.534)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.542] [G acc: 0.078]\n",
      "4526 [D loss: (0.501)(R 0.519, F 0.483)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.446] [G acc: 0.109]\n",
      "4527 [D loss: (0.532)(R 0.522, F 0.541)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.431] [G acc: 0.125]\n",
      "4528 [D loss: (0.511)(R 0.505, F 0.516)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.549] [G acc: 0.062]\n",
      "4529 [D loss: (0.536)(R 0.513, F 0.560)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.629] [G acc: 0.031]\n",
      "4530 [D loss: (0.574)(R 0.556, F 0.591)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.505] [G acc: 0.062]\n",
      "4531 [D loss: (0.553)(R 0.655, F 0.451)] [D acc: (0.680)(0.531, 0.828)] [G loss: 1.433] [G acc: 0.062]\n",
      "4532 [D loss: (0.481)(R 0.542, F 0.420)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.270] [G acc: 0.172]\n",
      "4533 [D loss: (0.504)(R 0.409, F 0.598)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.581] [G acc: 0.062]\n",
      "4534 [D loss: (0.514)(R 0.588, F 0.439)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.509] [G acc: 0.078]\n",
      "4535 [D loss: (0.569)(R 0.453, F 0.686)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.610] [G acc: 0.062]\n",
      "4536 [D loss: (0.551)(R 0.685, F 0.418)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.462] [G acc: 0.078]\n",
      "4537 [D loss: (0.564)(R 0.666, F 0.463)] [D acc: (0.703)(0.547, 0.859)] [G loss: 1.509] [G acc: 0.062]\n",
      "4538 [D loss: (0.523)(R 0.557, F 0.488)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.324] [G acc: 0.094]\n",
      "4539 [D loss: (0.494)(R 0.476, F 0.513)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.328] [G acc: 0.141]\n",
      "4540 [D loss: (0.396)(R 0.334, F 0.457)] [D acc: (0.844)(0.828, 0.859)] [G loss: 1.658] [G acc: 0.062]\n",
      "4541 [D loss: (0.512)(R 0.588, F 0.436)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.542] [G acc: 0.047]\n",
      "4542 [D loss: (0.494)(R 0.568, F 0.421)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.462] [G acc: 0.094]\n",
      "4543 [D loss: (0.577)(R 0.537, F 0.616)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.609] [G acc: 0.062]\n",
      "4544 [D loss: (0.523)(R 0.557, F 0.490)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.517] [G acc: 0.062]\n",
      "4545 [D loss: (0.566)(R 0.545, F 0.587)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.438] [G acc: 0.031]\n",
      "4546 [D loss: (0.558)(R 0.673, F 0.443)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.541] [G acc: 0.016]\n",
      "4547 [D loss: (0.551)(R 0.652, F 0.450)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.522] [G acc: 0.094]\n",
      "4548 [D loss: (0.463)(R 0.483, F 0.443)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.436] [G acc: 0.094]\n",
      "4549 [D loss: (0.597)(R 0.668, F 0.525)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.357] [G acc: 0.062]\n",
      "4550 [D loss: (0.608)(R 0.579, F 0.636)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.354] [G acc: 0.109]\n",
      "4551 [D loss: (0.419)(R 0.446, F 0.392)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.383] [G acc: 0.062]\n",
      "4552 [D loss: (0.522)(R 0.510, F 0.534)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.518] [G acc: 0.078]\n",
      "4553 [D loss: (0.456)(R 0.490, F 0.422)] [D acc: (0.797)(0.703, 0.891)] [G loss: 1.479] [G acc: 0.047]\n",
      "4554 [D loss: (0.419)(R 0.432, F 0.406)] [D acc: (0.812)(0.719, 0.906)] [G loss: 1.567] [G acc: 0.109]\n",
      "4555 [D loss: (0.463)(R 0.409, F 0.518)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.555] [G acc: 0.047]\n",
      "4556 [D loss: (0.549)(R 0.617, F 0.481)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.295] [G acc: 0.078]\n",
      "4557 [D loss: (0.522)(R 0.582, F 0.463)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.391] [G acc: 0.125]\n",
      "4558 [D loss: (0.437)(R 0.408, F 0.466)] [D acc: (0.812)(0.828, 0.797)] [G loss: 1.404] [G acc: 0.125]\n",
      "4559 [D loss: (0.547)(R 0.601, F 0.494)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.366] [G acc: 0.188]\n",
      "4560 [D loss: (0.632)(R 0.616, F 0.647)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.259] [G acc: 0.094]\n",
      "4561 [D loss: (0.534)(R 0.596, F 0.473)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.353] [G acc: 0.062]\n",
      "4562 [D loss: (0.558)(R 0.582, F 0.534)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.413] [G acc: 0.094]\n",
      "4563 [D loss: (0.519)(R 0.576, F 0.463)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.378] [G acc: 0.156]\n",
      "4564 [D loss: (0.527)(R 0.572, F 0.482)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.375] [G acc: 0.109]\n",
      "4565 [D loss: (0.546)(R 0.509, F 0.582)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.472] [G acc: 0.047]\n",
      "4566 [D loss: (0.599)(R 0.685, F 0.514)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.381] [G acc: 0.078]\n",
      "4567 [D loss: (0.587)(R 0.560, F 0.614)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.396] [G acc: 0.062]\n",
      "4568 [D loss: (0.457)(R 0.489, F 0.426)] [D acc: (0.789)(0.672, 0.906)] [G loss: 1.447] [G acc: 0.062]\n",
      "4569 [D loss: (0.479)(R 0.382, F 0.576)] [D acc: (0.789)(0.797, 0.781)] [G loss: 1.542] [G acc: 0.031]\n",
      "4570 [D loss: (0.563)(R 0.616, F 0.509)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.382] [G acc: 0.156]\n",
      "4571 [D loss: (0.526)(R 0.573, F 0.480)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.428] [G acc: 0.078]\n",
      "4572 [D loss: (0.462)(R 0.375, F 0.549)] [D acc: (0.773)(0.812, 0.734)] [G loss: 1.508] [G acc: 0.109]\n",
      "4573 [D loss: (0.532)(R 0.587, F 0.476)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.616] [G acc: 0.094]\n",
      "4574 [D loss: (0.509)(R 0.537, F 0.481)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.507] [G acc: 0.047]\n",
      "4575 [D loss: (0.414)(R 0.446, F 0.383)] [D acc: (0.820)(0.766, 0.875)] [G loss: 1.524] [G acc: 0.047]\n",
      "4576 [D loss: (0.489)(R 0.458, F 0.521)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.534] [G acc: 0.094]\n",
      "4577 [D loss: (0.561)(R 0.545, F 0.577)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.425] [G acc: 0.078]\n",
      "4578 [D loss: (0.502)(R 0.518, F 0.485)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.528] [G acc: 0.109]\n",
      "4579 [D loss: (0.521)(R 0.541, F 0.501)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.511] [G acc: 0.094]\n",
      "4580 [D loss: (0.532)(R 0.631, F 0.433)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.533] [G acc: 0.078]\n",
      "4581 [D loss: (0.473)(R 0.353, F 0.593)] [D acc: (0.766)(0.797, 0.734)] [G loss: 1.401] [G acc: 0.141]\n",
      "4582 [D loss: (0.524)(R 0.546, F 0.502)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.594] [G acc: 0.125]\n",
      "4583 [D loss: (0.676)(R 0.721, F 0.631)] [D acc: (0.656)(0.500, 0.812)] [G loss: 1.411] [G acc: 0.047]\n",
      "4584 [D loss: (0.493)(R 0.535, F 0.451)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.480] [G acc: 0.047]\n",
      "4585 [D loss: (0.492)(R 0.484, F 0.501)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.474] [G acc: 0.188]\n",
      "4586 [D loss: (0.537)(R 0.463, F 0.611)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.503] [G acc: 0.125]\n",
      "4587 [D loss: (0.488)(R 0.518, F 0.458)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.540] [G acc: 0.078]\n",
      "4588 [D loss: (0.495)(R 0.540, F 0.450)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.497] [G acc: 0.125]\n",
      "4589 [D loss: (0.516)(R 0.555, F 0.477)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.368] [G acc: 0.125]\n",
      "4590 [D loss: (0.546)(R 0.596, F 0.497)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.397] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4591 [D loss: (0.484)(R 0.487, F 0.480)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.408] [G acc: 0.094]\n",
      "4592 [D loss: (0.605)(R 0.532, F 0.679)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.443] [G acc: 0.078]\n",
      "4593 [D loss: (0.620)(R 0.793, F 0.446)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.381] [G acc: 0.109]\n",
      "4594 [D loss: (0.495)(R 0.517, F 0.474)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.493] [G acc: 0.047]\n",
      "4595 [D loss: (0.513)(R 0.565, F 0.460)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.282] [G acc: 0.172]\n",
      "4596 [D loss: (0.523)(R 0.489, F 0.557)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.471] [G acc: 0.062]\n",
      "4597 [D loss: (0.473)(R 0.408, F 0.537)] [D acc: (0.758)(0.781, 0.734)] [G loss: 1.324] [G acc: 0.109]\n",
      "4598 [D loss: (0.589)(R 0.653, F 0.526)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.455] [G acc: 0.016]\n",
      "4599 [D loss: (0.531)(R 0.525, F 0.537)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.411] [G acc: 0.062]\n",
      "4600 [D loss: (0.507)(R 0.553, F 0.462)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.392] [G acc: 0.094]\n",
      "4601 [D loss: (0.447)(R 0.409, F 0.485)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.364] [G acc: 0.141]\n",
      "4602 [D loss: (0.573)(R 0.486, F 0.660)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.576] [G acc: 0.062]\n",
      "4603 [D loss: (0.664)(R 0.787, F 0.541)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.340] [G acc: 0.062]\n",
      "4604 [D loss: (0.528)(R 0.500, F 0.556)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.471] [G acc: 0.078]\n",
      "4605 [D loss: (0.549)(R 0.601, F 0.497)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.320] [G acc: 0.109]\n",
      "4606 [D loss: (0.505)(R 0.503, F 0.508)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.279] [G acc: 0.094]\n",
      "4607 [D loss: (0.525)(R 0.530, F 0.520)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.369] [G acc: 0.078]\n",
      "4608 [D loss: (0.522)(R 0.634, F 0.411)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.425] [G acc: 0.156]\n",
      "4609 [D loss: (0.545)(R 0.529, F 0.561)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.400] [G acc: 0.125]\n",
      "4610 [D loss: (0.434)(R 0.499, F 0.369)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.357] [G acc: 0.125]\n",
      "4611 [D loss: (0.515)(R 0.401, F 0.630)] [D acc: (0.727)(0.781, 0.672)] [G loss: 1.410] [G acc: 0.094]\n",
      "4612 [D loss: (0.479)(R 0.520, F 0.439)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.654] [G acc: 0.047]\n",
      "4613 [D loss: (0.534)(R 0.537, F 0.531)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.599] [G acc: 0.031]\n",
      "4614 [D loss: (0.493)(R 0.493, F 0.494)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.558] [G acc: 0.047]\n",
      "4615 [D loss: (0.505)(R 0.535, F 0.475)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.421] [G acc: 0.047]\n",
      "4616 [D loss: (0.473)(R 0.504, F 0.442)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.471] [G acc: 0.109]\n",
      "4617 [D loss: (0.508)(R 0.499, F 0.516)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.480] [G acc: 0.078]\n",
      "4618 [D loss: (0.527)(R 0.583, F 0.471)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.544] [G acc: 0.125]\n",
      "4619 [D loss: (0.538)(R 0.502, F 0.573)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.471] [G acc: 0.047]\n",
      "4620 [D loss: (0.528)(R 0.555, F 0.501)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.581] [G acc: 0.109]\n",
      "4621 [D loss: (0.563)(R 0.593, F 0.533)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.528] [G acc: 0.109]\n",
      "4622 [D loss: (0.488)(R 0.573, F 0.403)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.499] [G acc: 0.062]\n",
      "4623 [D loss: (0.550)(R 0.534, F 0.567)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.425] [G acc: 0.141]\n",
      "4624 [D loss: (0.504)(R 0.499, F 0.510)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.492] [G acc: 0.078]\n",
      "4625 [D loss: (0.480)(R 0.516, F 0.443)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.435] [G acc: 0.125]\n",
      "4626 [D loss: (0.541)(R 0.562, F 0.520)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.588] [G acc: 0.109]\n",
      "4627 [D loss: (0.617)(R 0.716, F 0.518)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.521] [G acc: 0.062]\n",
      "4628 [D loss: (0.622)(R 0.501, F 0.743)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.421] [G acc: 0.094]\n",
      "4629 [D loss: (0.583)(R 0.630, F 0.536)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.429] [G acc: 0.094]\n",
      "4630 [D loss: (0.572)(R 0.649, F 0.496)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.428] [G acc: 0.094]\n",
      "4631 [D loss: (0.491)(R 0.567, F 0.415)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.344] [G acc: 0.078]\n",
      "4632 [D loss: (0.578)(R 0.395, F 0.761)] [D acc: (0.711)(0.766, 0.656)] [G loss: 1.358] [G acc: 0.078]\n",
      "4633 [D loss: (0.604)(R 0.731, F 0.477)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.413] [G acc: 0.109]\n",
      "4634 [D loss: (0.498)(R 0.534, F 0.463)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.449] [G acc: 0.125]\n",
      "4635 [D loss: (0.534)(R 0.606, F 0.461)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.347] [G acc: 0.094]\n",
      "4636 [D loss: (0.553)(R 0.688, F 0.418)] [D acc: (0.703)(0.516, 0.891)] [G loss: 1.280] [G acc: 0.219]\n",
      "4637 [D loss: (0.558)(R 0.506, F 0.610)] [D acc: (0.695)(0.719, 0.672)] [G loss: 1.586] [G acc: 0.078]\n",
      "4638 [D loss: (0.531)(R 0.611, F 0.452)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.503] [G acc: 0.016]\n",
      "4639 [D loss: (0.555)(R 0.566, F 0.543)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.387] [G acc: 0.125]\n",
      "4640 [D loss: (0.580)(R 0.569, F 0.591)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.423] [G acc: 0.078]\n",
      "4641 [D loss: (0.536)(R 0.529, F 0.542)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.339] [G acc: 0.078]\n",
      "4642 [D loss: (0.606)(R 0.709, F 0.504)] [D acc: (0.664)(0.516, 0.812)] [G loss: 1.341] [G acc: 0.188]\n",
      "4643 [D loss: (0.548)(R 0.577, F 0.518)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.405] [G acc: 0.094]\n",
      "4644 [D loss: (0.542)(R 0.569, F 0.516)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.440] [G acc: 0.094]\n",
      "4645 [D loss: (0.462)(R 0.478, F 0.447)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.421] [G acc: 0.125]\n",
      "4646 [D loss: (0.489)(R 0.459, F 0.518)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.593] [G acc: 0.094]\n",
      "4647 [D loss: (0.546)(R 0.575, F 0.517)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.251] [G acc: 0.109]\n",
      "4648 [D loss: (0.487)(R 0.484, F 0.490)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.406] [G acc: 0.078]\n",
      "4649 [D loss: (0.460)(R 0.467, F 0.453)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.469] [G acc: 0.031]\n",
      "4650 [D loss: (0.569)(R 0.593, F 0.545)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.472] [G acc: 0.062]\n",
      "4651 [D loss: (0.463)(R 0.525, F 0.401)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.327] [G acc: 0.188]\n",
      "4652 [D loss: (0.590)(R 0.501, F 0.678)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.496] [G acc: 0.094]\n",
      "4653 [D loss: (0.522)(R 0.534, F 0.509)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.413] [G acc: 0.078]\n",
      "4654 [D loss: (0.645)(R 0.701, F 0.589)] [D acc: (0.656)(0.562, 0.750)] [G loss: 1.337] [G acc: 0.094]\n",
      "4655 [D loss: (0.542)(R 0.591, F 0.493)] [D acc: (0.758)(0.594, 0.922)] [G loss: 1.501] [G acc: 0.078]\n",
      "4656 [D loss: (0.541)(R 0.526, F 0.556)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.318] [G acc: 0.078]\n",
      "4657 [D loss: (0.503)(R 0.452, F 0.554)] [D acc: (0.758)(0.781, 0.734)] [G loss: 1.341] [G acc: 0.078]\n",
      "4658 [D loss: (0.570)(R 0.705, F 0.436)] [D acc: (0.672)(0.469, 0.875)] [G loss: 1.333] [G acc: 0.078]\n",
      "4659 [D loss: (0.521)(R 0.426, F 0.616)] [D acc: (0.789)(0.797, 0.781)] [G loss: 1.302] [G acc: 0.156]\n",
      "4660 [D loss: (0.577)(R 0.568, F 0.587)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.430] [G acc: 0.062]\n",
      "4661 [D loss: (0.465)(R 0.399, F 0.530)] [D acc: (0.820)(0.812, 0.828)] [G loss: 1.413] [G acc: 0.109]\n",
      "4662 [D loss: (0.489)(R 0.531, F 0.447)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.379] [G acc: 0.062]\n",
      "4663 [D loss: (0.553)(R 0.599, F 0.506)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.461] [G acc: 0.078]\n",
      "4664 [D loss: (0.561)(R 0.530, F 0.591)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.349] [G acc: 0.031]\n",
      "4665 [D loss: (0.481)(R 0.501, F 0.460)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.468] [G acc: 0.094]\n",
      "4666 [D loss: (0.511)(R 0.475, F 0.548)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.324] [G acc: 0.141]\n",
      "4667 [D loss: (0.502)(R 0.465, F 0.538)] [D acc: (0.805)(0.734, 0.875)] [G loss: 1.559] [G acc: 0.094]\n",
      "4668 [D loss: (0.409)(R 0.391, F 0.426)] [D acc: (0.844)(0.781, 0.906)] [G loss: 1.418] [G acc: 0.109]\n",
      "4669 [D loss: (0.481)(R 0.542, F 0.421)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.462] [G acc: 0.062]\n",
      "4670 [D loss: (0.441)(R 0.391, F 0.492)] [D acc: (0.820)(0.797, 0.844)] [G loss: 1.460] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4671 [D loss: (0.608)(R 0.410, F 0.806)] [D acc: (0.750)(0.797, 0.703)] [G loss: 1.740] [G acc: 0.031]\n",
      "4672 [D loss: (0.572)(R 0.682, F 0.462)] [D acc: (0.734)(0.562, 0.906)] [G loss: 1.451] [G acc: 0.062]\n",
      "4673 [D loss: (0.546)(R 0.603, F 0.489)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.527] [G acc: 0.047]\n",
      "4674 [D loss: (0.444)(R 0.505, F 0.382)] [D acc: (0.828)(0.750, 0.906)] [G loss: 1.331] [G acc: 0.062]\n",
      "4675 [D loss: (0.491)(R 0.587, F 0.395)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.441] [G acc: 0.109]\n",
      "4676 [D loss: (0.536)(R 0.442, F 0.630)] [D acc: (0.781)(0.797, 0.766)] [G loss: 1.586] [G acc: 0.047]\n",
      "4677 [D loss: (0.474)(R 0.485, F 0.463)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.344] [G acc: 0.156]\n",
      "4678 [D loss: (0.542)(R 0.524, F 0.560)] [D acc: (0.734)(0.750, 0.719)] [G loss: 1.572] [G acc: 0.047]\n",
      "4679 [D loss: (0.448)(R 0.432, F 0.465)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.510] [G acc: 0.047]\n",
      "4680 [D loss: (0.571)(R 0.566, F 0.576)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.513] [G acc: 0.094]\n",
      "4681 [D loss: (0.611)(R 0.662, F 0.560)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.499] [G acc: 0.141]\n",
      "4682 [D loss: (0.547)(R 0.608, F 0.486)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.355] [G acc: 0.078]\n",
      "4683 [D loss: (0.547)(R 0.615, F 0.479)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.427] [G acc: 0.141]\n",
      "4684 [D loss: (0.503)(R 0.583, F 0.423)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.332] [G acc: 0.125]\n",
      "4685 [D loss: (0.408)(R 0.378, F 0.438)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.424] [G acc: 0.141]\n",
      "4686 [D loss: (0.553)(R 0.517, F 0.590)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.564] [G acc: 0.016]\n",
      "4687 [D loss: (0.543)(R 0.689, F 0.397)] [D acc: (0.703)(0.531, 0.875)] [G loss: 1.445] [G acc: 0.125]\n",
      "4688 [D loss: (0.552)(R 0.512, F 0.592)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.379] [G acc: 0.141]\n",
      "4689 [D loss: (0.568)(R 0.588, F 0.548)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.515] [G acc: 0.109]\n",
      "4690 [D loss: (0.501)(R 0.547, F 0.454)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.513] [G acc: 0.047]\n",
      "4691 [D loss: (0.532)(R 0.504, F 0.560)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.386] [G acc: 0.094]\n",
      "4692 [D loss: (0.479)(R 0.487, F 0.470)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.285] [G acc: 0.141]\n",
      "4693 [D loss: (0.577)(R 0.652, F 0.503)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.486] [G acc: 0.047]\n",
      "4694 [D loss: (0.596)(R 0.611, F 0.582)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.514] [G acc: 0.031]\n",
      "4695 [D loss: (0.547)(R 0.523, F 0.572)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.489] [G acc: 0.062]\n",
      "4696 [D loss: (0.546)(R 0.650, F 0.442)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.358] [G acc: 0.141]\n",
      "4697 [D loss: (0.539)(R 0.626, F 0.453)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.558] [G acc: 0.062]\n",
      "4698 [D loss: (0.597)(R 0.510, F 0.685)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.349] [G acc: 0.094]\n",
      "4699 [D loss: (0.559)(R 0.551, F 0.566)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.355] [G acc: 0.125]\n",
      "4700 [D loss: (0.433)(R 0.466, F 0.400)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.395] [G acc: 0.094]\n",
      "4701 [D loss: (0.559)(R 0.628, F 0.491)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.267] [G acc: 0.203]\n",
      "4702 [D loss: (0.512)(R 0.512, F 0.513)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.482] [G acc: 0.062]\n",
      "4703 [D loss: (0.493)(R 0.497, F 0.488)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.323] [G acc: 0.141]\n",
      "4704 [D loss: (0.475)(R 0.531, F 0.419)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.360] [G acc: 0.125]\n",
      "4705 [D loss: (0.489)(R 0.454, F 0.523)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.548] [G acc: 0.094]\n",
      "4706 [D loss: (0.477)(R 0.472, F 0.482)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.445] [G acc: 0.062]\n",
      "4707 [D loss: (0.482)(R 0.452, F 0.511)] [D acc: (0.820)(0.797, 0.844)] [G loss: 1.533] [G acc: 0.078]\n",
      "4708 [D loss: (0.498)(R 0.454, F 0.543)] [D acc: (0.766)(0.781, 0.750)] [G loss: 1.499] [G acc: 0.141]\n",
      "4709 [D loss: (0.475)(R 0.526, F 0.425)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.435] [G acc: 0.156]\n",
      "4710 [D loss: (0.520)(R 0.440, F 0.601)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.523] [G acc: 0.094]\n",
      "4711 [D loss: (0.482)(R 0.558, F 0.407)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.570] [G acc: 0.062]\n",
      "4712 [D loss: (0.546)(R 0.575, F 0.516)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.631] [G acc: 0.062]\n",
      "4713 [D loss: (0.518)(R 0.577, F 0.459)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.436] [G acc: 0.125]\n",
      "4714 [D loss: (0.474)(R 0.486, F 0.461)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.634] [G acc: 0.031]\n",
      "4715 [D loss: (0.532)(R 0.539, F 0.524)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.532] [G acc: 0.125]\n",
      "4716 [D loss: (0.470)(R 0.464, F 0.476)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.514] [G acc: 0.047]\n",
      "4717 [D loss: (0.475)(R 0.454, F 0.496)] [D acc: (0.797)(0.781, 0.812)] [G loss: 1.618] [G acc: 0.062]\n",
      "4718 [D loss: (0.471)(R 0.503, F 0.438)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.449] [G acc: 0.094]\n",
      "4719 [D loss: (0.473)(R 0.536, F 0.410)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.498] [G acc: 0.078]\n",
      "4720 [D loss: (0.517)(R 0.567, F 0.468)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.515] [G acc: 0.047]\n",
      "4721 [D loss: (0.525)(R 0.461, F 0.589)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.802] [G acc: 0.062]\n",
      "4722 [D loss: (0.510)(R 0.623, F 0.396)] [D acc: (0.742)(0.594, 0.891)] [G loss: 1.371] [G acc: 0.125]\n",
      "4723 [D loss: (0.553)(R 0.521, F 0.586)] [D acc: (0.664)(0.672, 0.656)] [G loss: 1.381] [G acc: 0.062]\n",
      "4724 [D loss: (0.532)(R 0.570, F 0.493)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.566] [G acc: 0.016]\n",
      "4725 [D loss: (0.578)(R 0.591, F 0.565)] [D acc: (0.648)(0.578, 0.719)] [G loss: 1.428] [G acc: 0.078]\n",
      "4726 [D loss: (0.479)(R 0.559, F 0.399)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.583] [G acc: 0.094]\n",
      "4727 [D loss: (0.594)(R 0.524, F 0.664)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.408] [G acc: 0.094]\n",
      "4728 [D loss: (0.484)(R 0.479, F 0.488)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.414] [G acc: 0.141]\n",
      "4729 [D loss: (0.597)(R 0.648, F 0.546)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.463] [G acc: 0.062]\n",
      "4730 [D loss: (0.442)(R 0.484, F 0.399)] [D acc: (0.805)(0.688, 0.922)] [G loss: 1.497] [G acc: 0.125]\n",
      "4731 [D loss: (0.492)(R 0.501, F 0.483)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.393] [G acc: 0.078]\n",
      "4732 [D loss: (0.496)(R 0.553, F 0.439)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.422] [G acc: 0.062]\n",
      "4733 [D loss: (0.550)(R 0.412, F 0.688)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.516] [G acc: 0.078]\n",
      "4734 [D loss: (0.513)(R 0.646, F 0.381)] [D acc: (0.742)(0.578, 0.906)] [G loss: 1.358] [G acc: 0.109]\n",
      "4735 [D loss: (0.611)(R 0.695, F 0.527)] [D acc: (0.680)(0.531, 0.828)] [G loss: 1.250] [G acc: 0.156]\n",
      "4736 [D loss: (0.532)(R 0.568, F 0.497)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.285] [G acc: 0.156]\n",
      "4737 [D loss: (0.516)(R 0.558, F 0.474)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.599] [G acc: 0.047]\n",
      "4738 [D loss: (0.601)(R 0.612, F 0.590)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.314] [G acc: 0.094]\n",
      "4739 [D loss: (0.522)(R 0.583, F 0.461)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.416] [G acc: 0.047]\n",
      "4740 [D loss: (0.569)(R 0.620, F 0.519)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.448] [G acc: 0.078]\n",
      "4741 [D loss: (0.472)(R 0.527, F 0.418)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.400] [G acc: 0.062]\n",
      "4742 [D loss: (0.530)(R 0.597, F 0.463)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.320] [G acc: 0.188]\n",
      "4743 [D loss: (0.609)(R 0.634, F 0.584)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.332] [G acc: 0.094]\n",
      "4744 [D loss: (0.591)(R 0.531, F 0.651)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.310] [G acc: 0.094]\n",
      "4745 [D loss: (0.538)(R 0.640, F 0.435)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.360] [G acc: 0.031]\n",
      "4746 [D loss: (0.583)(R 0.639, F 0.526)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.347] [G acc: 0.109]\n",
      "4747 [D loss: (0.471)(R 0.468, F 0.475)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.353] [G acc: 0.125]\n",
      "4748 [D loss: (0.547)(R 0.575, F 0.518)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.293] [G acc: 0.062]\n",
      "4749 [D loss: (0.536)(R 0.531, F 0.540)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.294] [G acc: 0.094]\n",
      "4750 [D loss: (0.480)(R 0.462, F 0.497)] [D acc: (0.805)(0.750, 0.859)] [G loss: 1.315] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4751 [D loss: (0.549)(R 0.492, F 0.606)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.336] [G acc: 0.078]\n",
      "4752 [D loss: (0.530)(R 0.593, F 0.466)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.235] [G acc: 0.109]\n",
      "4753 [D loss: (0.495)(R 0.434, F 0.557)] [D acc: (0.797)(0.781, 0.812)] [G loss: 1.333] [G acc: 0.109]\n",
      "4754 [D loss: (0.449)(R 0.476, F 0.421)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.305] [G acc: 0.141]\n",
      "4755 [D loss: (0.455)(R 0.414, F 0.495)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.493] [G acc: 0.109]\n",
      "4756 [D loss: (0.652)(R 0.541, F 0.762)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.550] [G acc: 0.016]\n",
      "4757 [D loss: (0.567)(R 0.746, F 0.389)] [D acc: (0.711)(0.500, 0.922)] [G loss: 1.394] [G acc: 0.125]\n",
      "4758 [D loss: (0.508)(R 0.612, F 0.405)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.423] [G acc: 0.156]\n",
      "4759 [D loss: (0.484)(R 0.475, F 0.493)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.364] [G acc: 0.141]\n",
      "4760 [D loss: (0.454)(R 0.387, F 0.522)] [D acc: (0.773)(0.781, 0.766)] [G loss: 1.623] [G acc: 0.078]\n",
      "4761 [D loss: (0.525)(R 0.503, F 0.548)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.447] [G acc: 0.078]\n",
      "4762 [D loss: (0.543)(R 0.611, F 0.475)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.326] [G acc: 0.125]\n",
      "4763 [D loss: (0.511)(R 0.501, F 0.521)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.364] [G acc: 0.172]\n",
      "4764 [D loss: (0.537)(R 0.564, F 0.510)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.325] [G acc: 0.156]\n",
      "4765 [D loss: (0.458)(R 0.452, F 0.463)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.513] [G acc: 0.125]\n",
      "4766 [D loss: (0.580)(R 0.561, F 0.598)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.452] [G acc: 0.078]\n",
      "4767 [D loss: (0.596)(R 0.593, F 0.598)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.440] [G acc: 0.094]\n",
      "4768 [D loss: (0.490)(R 0.545, F 0.436)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.385] [G acc: 0.078]\n",
      "4769 [D loss: (0.461)(R 0.478, F 0.445)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.465] [G acc: 0.094]\n",
      "4770 [D loss: (0.531)(R 0.448, F 0.615)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.521] [G acc: 0.109]\n",
      "4771 [D loss: (0.501)(R 0.604, F 0.398)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.591] [G acc: 0.047]\n",
      "4772 [D loss: (0.618)(R 0.647, F 0.589)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.391] [G acc: 0.062]\n",
      "4773 [D loss: (0.593)(R 0.571, F 0.615)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.449] [G acc: 0.078]\n",
      "4774 [D loss: (0.486)(R 0.592, F 0.380)] [D acc: (0.805)(0.672, 0.938)] [G loss: 1.433] [G acc: 0.141]\n",
      "4775 [D loss: (0.503)(R 0.486, F 0.520)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.427] [G acc: 0.125]\n",
      "4776 [D loss: (0.439)(R 0.452, F 0.426)] [D acc: (0.820)(0.750, 0.891)] [G loss: 1.413] [G acc: 0.062]\n",
      "4777 [D loss: (0.490)(R 0.477, F 0.502)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.617] [G acc: 0.078]\n",
      "4778 [D loss: (0.508)(R 0.576, F 0.441)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.607] [G acc: 0.062]\n",
      "4779 [D loss: (0.484)(R 0.515, F 0.452)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.428] [G acc: 0.078]\n",
      "4780 [D loss: (0.580)(R 0.580, F 0.579)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.425] [G acc: 0.078]\n",
      "4781 [D loss: (0.516)(R 0.398, F 0.635)] [D acc: (0.789)(0.781, 0.797)] [G loss: 1.392] [G acc: 0.062]\n",
      "4782 [D loss: (0.576)(R 0.591, F 0.561)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.495] [G acc: 0.125]\n",
      "4783 [D loss: (0.592)(R 0.643, F 0.540)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.497] [G acc: 0.078]\n",
      "4784 [D loss: (0.587)(R 0.716, F 0.457)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.432] [G acc: 0.031]\n",
      "4785 [D loss: (0.442)(R 0.494, F 0.391)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.477] [G acc: 0.094]\n",
      "4786 [D loss: (0.506)(R 0.462, F 0.550)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.539] [G acc: 0.109]\n",
      "4787 [D loss: (0.635)(R 0.549, F 0.721)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.436] [G acc: 0.047]\n",
      "4788 [D loss: (0.494)(R 0.595, F 0.394)] [D acc: (0.727)(0.516, 0.938)] [G loss: 1.500] [G acc: 0.094]\n",
      "4789 [D loss: (0.613)(R 0.711, F 0.514)] [D acc: (0.695)(0.516, 0.875)] [G loss: 1.479] [G acc: 0.094]\n",
      "4790 [D loss: (0.467)(R 0.515, F 0.418)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.491] [G acc: 0.094]\n",
      "4791 [D loss: (0.491)(R 0.489, F 0.492)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.418] [G acc: 0.141]\n",
      "4792 [D loss: (0.572)(R 0.482, F 0.662)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.447] [G acc: 0.047]\n",
      "4793 [D loss: (0.446)(R 0.537, F 0.355)] [D acc: (0.781)(0.641, 0.922)] [G loss: 1.541] [G acc: 0.094]\n",
      "4794 [D loss: (0.580)(R 0.577, F 0.583)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.553] [G acc: 0.094]\n",
      "4795 [D loss: (0.589)(R 0.599, F 0.580)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.380] [G acc: 0.109]\n",
      "4796 [D loss: (0.572)(R 0.677, F 0.466)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.300] [G acc: 0.062]\n",
      "4797 [D loss: (0.461)(R 0.477, F 0.445)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.476] [G acc: 0.047]\n",
      "4798 [D loss: (0.616)(R 0.592, F 0.640)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.432] [G acc: 0.047]\n",
      "4799 [D loss: (0.534)(R 0.534, F 0.533)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.451] [G acc: 0.094]\n",
      "4800 [D loss: (0.468)(R 0.480, F 0.456)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.436] [G acc: 0.062]\n",
      "4801 [D loss: (0.541)(R 0.568, F 0.514)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.529] [G acc: 0.094]\n",
      "4802 [D loss: (0.577)(R 0.650, F 0.504)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.456] [G acc: 0.094]\n",
      "4803 [D loss: (0.556)(R 0.509, F 0.604)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.343] [G acc: 0.109]\n",
      "4804 [D loss: (0.572)(R 0.614, F 0.530)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.362] [G acc: 0.078]\n",
      "4805 [D loss: (0.544)(R 0.559, F 0.529)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.298] [G acc: 0.172]\n",
      "4806 [D loss: (0.504)(R 0.551, F 0.456)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.479] [G acc: 0.031]\n",
      "4807 [D loss: (0.542)(R 0.517, F 0.566)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.508] [G acc: 0.094]\n",
      "4808 [D loss: (0.453)(R 0.499, F 0.407)] [D acc: (0.812)(0.734, 0.891)] [G loss: 1.387] [G acc: 0.031]\n",
      "4809 [D loss: (0.481)(R 0.447, F 0.515)] [D acc: (0.703)(0.656, 0.750)] [G loss: 1.528] [G acc: 0.078]\n",
      "4810 [D loss: (0.520)(R 0.550, F 0.490)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.508] [G acc: 0.062]\n",
      "4811 [D loss: (0.533)(R 0.607, F 0.459)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.524] [G acc: 0.078]\n",
      "4812 [D loss: (0.524)(R 0.530, F 0.518)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.487] [G acc: 0.125]\n",
      "4813 [D loss: (0.510)(R 0.615, F 0.404)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.424] [G acc: 0.078]\n",
      "4814 [D loss: (0.510)(R 0.490, F 0.530)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.462] [G acc: 0.062]\n",
      "4815 [D loss: (0.555)(R 0.572, F 0.538)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.358] [G acc: 0.125]\n",
      "4816 [D loss: (0.497)(R 0.490, F 0.504)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.489] [G acc: 0.156]\n",
      "4817 [D loss: (0.572)(R 0.565, F 0.579)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.374] [G acc: 0.125]\n",
      "4818 [D loss: (0.534)(R 0.572, F 0.495)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.529] [G acc: 0.062]\n",
      "4819 [D loss: (0.585)(R 0.531, F 0.639)] [D acc: (0.672)(0.672, 0.672)] [G loss: 1.511] [G acc: 0.062]\n",
      "4820 [D loss: (0.519)(R 0.591, F 0.447)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.325] [G acc: 0.125]\n",
      "4821 [D loss: (0.488)(R 0.426, F 0.550)] [D acc: (0.734)(0.750, 0.719)] [G loss: 1.406] [G acc: 0.141]\n",
      "4822 [D loss: (0.558)(R 0.519, F 0.596)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.442] [G acc: 0.156]\n",
      "4823 [D loss: (0.448)(R 0.473, F 0.423)] [D acc: (0.812)(0.797, 0.828)] [G loss: 1.492] [G acc: 0.109]\n",
      "4824 [D loss: (0.569)(R 0.563, F 0.575)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.518] [G acc: 0.094]\n",
      "4825 [D loss: (0.539)(R 0.576, F 0.503)] [D acc: (0.711)(0.547, 0.875)] [G loss: 1.307] [G acc: 0.141]\n",
      "4826 [D loss: (0.550)(R 0.610, F 0.490)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.498] [G acc: 0.078]\n",
      "4827 [D loss: (0.597)(R 0.577, F 0.616)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.481] [G acc: 0.078]\n",
      "4828 [D loss: (0.543)(R 0.626, F 0.459)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.568] [G acc: 0.016]\n",
      "4829 [D loss: (0.611)(R 0.690, F 0.532)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.308] [G acc: 0.141]\n",
      "4830 [D loss: (0.497)(R 0.513, F 0.481)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.511] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4831 [D loss: (0.427)(R 0.403, F 0.450)] [D acc: (0.812)(0.797, 0.828)] [G loss: 1.333] [G acc: 0.172]\n",
      "4832 [D loss: (0.653)(R 0.629, F 0.677)] [D acc: (0.680)(0.656, 0.703)] [G loss: 1.303] [G acc: 0.109]\n",
      "4833 [D loss: (0.624)(R 0.671, F 0.578)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.311] [G acc: 0.172]\n",
      "4834 [D loss: (0.484)(R 0.446, F 0.522)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.381] [G acc: 0.094]\n",
      "4835 [D loss: (0.475)(R 0.524, F 0.426)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.440] [G acc: 0.047]\n",
      "4836 [D loss: (0.426)(R 0.328, F 0.524)] [D acc: (0.844)(0.859, 0.828)] [G loss: 1.475] [G acc: 0.109]\n",
      "4837 [D loss: (0.570)(R 0.573, F 0.568)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.389] [G acc: 0.078]\n",
      "4838 [D loss: (0.625)(R 0.696, F 0.554)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.469] [G acc: 0.078]\n",
      "4839 [D loss: (0.584)(R 0.563, F 0.606)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.487] [G acc: 0.078]\n",
      "4840 [D loss: (0.487)(R 0.519, F 0.454)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.424] [G acc: 0.078]\n",
      "4841 [D loss: (0.532)(R 0.633, F 0.432)] [D acc: (0.719)(0.547, 0.891)] [G loss: 1.333] [G acc: 0.109]\n",
      "4842 [D loss: (0.527)(R 0.472, F 0.582)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.309] [G acc: 0.156]\n",
      "4843 [D loss: (0.454)(R 0.458, F 0.449)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.298] [G acc: 0.172]\n",
      "4844 [D loss: (0.489)(R 0.544, F 0.435)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.397] [G acc: 0.156]\n",
      "4845 [D loss: (0.573)(R 0.453, F 0.692)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.480] [G acc: 0.094]\n",
      "4846 [D loss: (0.528)(R 0.573, F 0.483)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.502] [G acc: 0.141]\n",
      "4847 [D loss: (0.599)(R 0.588, F 0.610)] [D acc: (0.641)(0.641, 0.641)] [G loss: 1.453] [G acc: 0.125]\n",
      "4848 [D loss: (0.586)(R 0.606, F 0.566)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.466] [G acc: 0.094]\n",
      "4849 [D loss: (0.559)(R 0.604, F 0.513)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.448] [G acc: 0.078]\n",
      "4850 [D loss: (0.518)(R 0.482, F 0.555)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.429] [G acc: 0.047]\n",
      "4851 [D loss: (0.515)(R 0.597, F 0.432)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.517] [G acc: 0.109]\n",
      "4852 [D loss: (0.682)(R 0.515, F 0.849)] [D acc: (0.727)(0.781, 0.672)] [G loss: 1.454] [G acc: 0.094]\n",
      "4853 [D loss: (0.577)(R 0.731, F 0.424)] [D acc: (0.703)(0.531, 0.875)] [G loss: 1.495] [G acc: 0.094]\n",
      "4854 [D loss: (0.464)(R 0.464, F 0.464)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.186] [G acc: 0.156]\n",
      "4855 [D loss: (0.577)(R 0.486, F 0.668)] [D acc: (0.719)(0.750, 0.688)] [G loss: 1.408] [G acc: 0.062]\n",
      "4856 [D loss: (0.474)(R 0.493, F 0.455)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.381] [G acc: 0.078]\n",
      "4857 [D loss: (0.570)(R 0.482, F 0.659)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.435] [G acc: 0.031]\n",
      "4858 [D loss: (0.506)(R 0.584, F 0.429)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.430] [G acc: 0.062]\n",
      "4859 [D loss: (0.579)(R 0.631, F 0.526)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.396] [G acc: 0.125]\n",
      "4860 [D loss: (0.596)(R 0.584, F 0.609)] [D acc: (0.664)(0.641, 0.688)] [G loss: 1.399] [G acc: 0.062]\n",
      "4861 [D loss: (0.520)(R 0.594, F 0.446)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.411] [G acc: 0.047]\n",
      "4862 [D loss: (0.560)(R 0.472, F 0.648)] [D acc: (0.734)(0.797, 0.672)] [G loss: 1.433] [G acc: 0.031]\n",
      "4863 [D loss: (0.496)(R 0.482, F 0.509)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.326] [G acc: 0.094]\n",
      "4864 [D loss: (0.524)(R 0.575, F 0.473)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.509] [G acc: 0.078]\n",
      "4865 [D loss: (0.513)(R 0.570, F 0.456)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.384] [G acc: 0.109]\n",
      "4866 [D loss: (0.530)(R 0.505, F 0.555)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.408] [G acc: 0.141]\n",
      "4867 [D loss: (0.574)(R 0.496, F 0.652)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.360] [G acc: 0.109]\n",
      "4868 [D loss: (0.565)(R 0.619, F 0.510)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.443] [G acc: 0.156]\n",
      "4869 [D loss: (0.571)(R 0.447, F 0.695)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.427] [G acc: 0.109]\n",
      "4870 [D loss: (0.491)(R 0.569, F 0.413)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.406] [G acc: 0.094]\n",
      "4871 [D loss: (0.588)(R 0.577, F 0.600)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.277] [G acc: 0.125]\n",
      "4872 [D loss: (0.524)(R 0.501, F 0.547)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.524] [G acc: 0.062]\n",
      "4873 [D loss: (0.501)(R 0.541, F 0.461)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.397] [G acc: 0.141]\n",
      "4874 [D loss: (0.565)(R 0.617, F 0.512)] [D acc: (0.734)(0.578, 0.891)] [G loss: 1.420] [G acc: 0.078]\n",
      "4875 [D loss: (0.553)(R 0.540, F 0.566)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.355] [G acc: 0.125]\n",
      "4876 [D loss: (0.605)(R 0.648, F 0.563)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.371] [G acc: 0.141]\n",
      "4877 [D loss: (0.514)(R 0.421, F 0.607)] [D acc: (0.797)(0.828, 0.766)] [G loss: 1.388] [G acc: 0.094]\n",
      "4878 [D loss: (0.510)(R 0.502, F 0.518)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.410] [G acc: 0.109]\n",
      "4879 [D loss: (0.613)(R 0.581, F 0.645)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.567] [G acc: 0.062]\n",
      "4880 [D loss: (0.539)(R 0.607, F 0.471)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.401] [G acc: 0.125]\n",
      "4881 [D loss: (0.557)(R 0.612, F 0.502)] [D acc: (0.672)(0.641, 0.703)] [G loss: 1.250] [G acc: 0.125]\n",
      "4882 [D loss: (0.557)(R 0.583, F 0.532)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.369] [G acc: 0.109]\n",
      "4883 [D loss: (0.511)(R 0.558, F 0.464)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.460] [G acc: 0.109]\n",
      "4884 [D loss: (0.487)(R 0.539, F 0.434)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.417] [G acc: 0.094]\n",
      "4885 [D loss: (0.500)(R 0.484, F 0.517)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.449] [G acc: 0.125]\n",
      "4886 [D loss: (0.460)(R 0.492, F 0.429)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.452] [G acc: 0.109]\n",
      "4887 [D loss: (0.477)(R 0.436, F 0.518)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.413] [G acc: 0.141]\n",
      "4888 [D loss: (0.469)(R 0.521, F 0.418)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.461] [G acc: 0.078]\n",
      "4889 [D loss: (0.601)(R 0.555, F 0.647)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.482] [G acc: 0.094]\n",
      "4890 [D loss: (0.562)(R 0.609, F 0.515)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.455] [G acc: 0.062]\n",
      "4891 [D loss: (0.505)(R 0.675, F 0.335)] [D acc: (0.734)(0.531, 0.938)] [G loss: 1.336] [G acc: 0.125]\n",
      "4892 [D loss: (0.479)(R 0.538, F 0.421)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.366] [G acc: 0.109]\n",
      "4893 [D loss: (0.526)(R 0.504, F 0.549)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.211] [G acc: 0.203]\n",
      "4894 [D loss: (0.576)(R 0.517, F 0.635)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.300] [G acc: 0.109]\n",
      "4895 [D loss: (0.597)(R 0.670, F 0.524)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.476] [G acc: 0.062]\n",
      "4896 [D loss: (0.394)(R 0.307, F 0.481)] [D acc: (0.820)(0.859, 0.781)] [G loss: 1.569] [G acc: 0.031]\n",
      "4897 [D loss: (0.538)(R 0.595, F 0.481)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.419] [G acc: 0.094]\n",
      "4898 [D loss: (0.576)(R 0.640, F 0.512)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.201] [G acc: 0.203]\n",
      "4899 [D loss: (0.603)(R 0.586, F 0.619)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.412] [G acc: 0.141]\n",
      "4900 [D loss: (0.557)(R 0.587, F 0.527)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.389] [G acc: 0.094]\n",
      "4901 [D loss: (0.497)(R 0.465, F 0.529)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.481] [G acc: 0.141]\n",
      "4902 [D loss: (0.531)(R 0.531, F 0.532)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.497] [G acc: 0.078]\n",
      "4903 [D loss: (0.458)(R 0.513, F 0.402)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.430] [G acc: 0.078]\n",
      "4904 [D loss: (0.731)(R 0.529, F 0.933)] [D acc: (0.586)(0.641, 0.531)] [G loss: 1.485] [G acc: 0.031]\n",
      "4905 [D loss: (0.590)(R 0.761, F 0.418)] [D acc: (0.664)(0.469, 0.859)] [G loss: 1.516] [G acc: 0.062]\n",
      "4906 [D loss: (0.561)(R 0.630, F 0.493)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.313] [G acc: 0.109]\n",
      "4907 [D loss: (0.576)(R 0.564, F 0.588)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.366] [G acc: 0.062]\n",
      "4908 [D loss: (0.637)(R 0.744, F 0.530)] [D acc: (0.656)(0.531, 0.781)] [G loss: 1.304] [G acc: 0.078]\n",
      "4909 [D loss: (0.522)(R 0.576, F 0.468)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.352] [G acc: 0.047]\n",
      "4910 [D loss: (0.637)(R 0.513, F 0.760)] [D acc: (0.672)(0.688, 0.656)] [G loss: 1.314] [G acc: 0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4911 [D loss: (0.532)(R 0.616, F 0.447)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.444] [G acc: 0.047]\n",
      "4912 [D loss: (0.470)(R 0.446, F 0.494)] [D acc: (0.781)(0.781, 0.781)] [G loss: 1.248] [G acc: 0.141]\n",
      "4913 [D loss: (0.550)(R 0.582, F 0.517)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.379] [G acc: 0.125]\n",
      "4914 [D loss: (0.532)(R 0.458, F 0.605)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.429] [G acc: 0.109]\n",
      "4915 [D loss: (0.473)(R 0.423, F 0.523)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.389] [G acc: 0.109]\n",
      "4916 [D loss: (0.561)(R 0.526, F 0.597)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.376] [G acc: 0.031]\n",
      "4917 [D loss: (0.511)(R 0.547, F 0.474)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.393] [G acc: 0.094]\n",
      "4918 [D loss: (0.569)(R 0.560, F 0.578)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.351] [G acc: 0.094]\n",
      "4919 [D loss: (0.565)(R 0.599, F 0.531)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.317] [G acc: 0.047]\n",
      "4920 [D loss: (0.500)(R 0.547, F 0.453)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.434] [G acc: 0.016]\n",
      "4921 [D loss: (0.549)(R 0.510, F 0.588)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.393] [G acc: 0.078]\n",
      "4922 [D loss: (0.527)(R 0.562, F 0.492)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.299] [G acc: 0.125]\n",
      "4923 [D loss: (0.553)(R 0.623, F 0.483)] [D acc: (0.680)(0.531, 0.828)] [G loss: 1.479] [G acc: 0.062]\n",
      "4924 [D loss: (0.525)(R 0.597, F 0.454)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.394] [G acc: 0.047]\n",
      "4925 [D loss: (0.508)(R 0.513, F 0.503)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.317] [G acc: 0.078]\n",
      "4926 [D loss: (0.600)(R 0.582, F 0.618)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.251] [G acc: 0.125]\n",
      "4927 [D loss: (0.512)(R 0.466, F 0.559)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.387] [G acc: 0.062]\n",
      "4928 [D loss: (0.517)(R 0.545, F 0.490)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.328] [G acc: 0.062]\n",
      "4929 [D loss: (0.571)(R 0.596, F 0.547)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.464] [G acc: 0.094]\n",
      "4930 [D loss: (0.559)(R 0.636, F 0.482)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.476] [G acc: 0.016]\n",
      "4931 [D loss: (0.542)(R 0.638, F 0.445)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.351] [G acc: 0.094]\n",
      "4932 [D loss: (0.512)(R 0.551, F 0.473)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.388] [G acc: 0.094]\n",
      "4933 [D loss: (0.543)(R 0.664, F 0.422)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.450] [G acc: 0.062]\n",
      "4934 [D loss: (0.465)(R 0.423, F 0.507)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.265] [G acc: 0.109]\n",
      "4935 [D loss: (0.542)(R 0.510, F 0.574)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.400] [G acc: 0.125]\n",
      "4936 [D loss: (0.543)(R 0.554, F 0.531)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.289] [G acc: 0.109]\n",
      "4937 [D loss: (0.489)(R 0.476, F 0.503)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.473] [G acc: 0.062]\n",
      "4938 [D loss: (0.501)(R 0.539, F 0.464)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.307] [G acc: 0.125]\n",
      "4939 [D loss: (0.523)(R 0.462, F 0.584)] [D acc: (0.742)(0.766, 0.719)] [G loss: 1.381] [G acc: 0.031]\n",
      "4940 [D loss: (0.588)(R 0.614, F 0.563)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.398] [G acc: 0.047]\n",
      "4941 [D loss: (0.481)(R 0.514, F 0.448)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.434] [G acc: 0.047]\n",
      "4942 [D loss: (0.466)(R 0.504, F 0.428)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.378] [G acc: 0.156]\n",
      "4943 [D loss: (0.472)(R 0.448, F 0.497)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.571] [G acc: 0.062]\n",
      "4944 [D loss: (0.512)(R 0.599, F 0.426)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.386] [G acc: 0.094]\n",
      "4945 [D loss: (0.560)(R 0.596, F 0.524)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.436] [G acc: 0.078]\n",
      "4946 [D loss: (0.519)(R 0.520, F 0.519)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.490] [G acc: 0.109]\n",
      "4947 [D loss: (0.556)(R 0.658, F 0.454)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.415] [G acc: 0.062]\n",
      "4948 [D loss: (0.605)(R 0.622, F 0.588)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.400] [G acc: 0.094]\n",
      "4949 [D loss: (0.619)(R 0.597, F 0.641)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.331] [G acc: 0.109]\n",
      "4950 [D loss: (0.467)(R 0.519, F 0.416)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.431] [G acc: 0.062]\n",
      "4951 [D loss: (0.498)(R 0.522, F 0.475)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.451] [G acc: 0.078]\n",
      "4952 [D loss: (0.535)(R 0.536, F 0.533)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.512] [G acc: 0.062]\n",
      "4953 [D loss: (0.508)(R 0.542, F 0.475)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.420] [G acc: 0.141]\n",
      "4954 [D loss: (0.584)(R 0.477, F 0.690)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.432] [G acc: 0.047]\n",
      "4955 [D loss: (0.527)(R 0.604, F 0.450)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.543] [G acc: 0.094]\n",
      "4956 [D loss: (0.527)(R 0.560, F 0.493)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.539] [G acc: 0.016]\n",
      "4957 [D loss: (0.548)(R 0.471, F 0.625)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.540] [G acc: 0.078]\n",
      "4958 [D loss: (0.556)(R 0.589, F 0.523)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.419] [G acc: 0.078]\n",
      "4959 [D loss: (0.479)(R 0.565, F 0.393)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.361] [G acc: 0.062]\n",
      "4960 [D loss: (0.478)(R 0.486, F 0.471)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.443] [G acc: 0.047]\n",
      "4961 [D loss: (0.482)(R 0.495, F 0.469)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.485] [G acc: 0.062]\n",
      "4962 [D loss: (0.562)(R 0.621, F 0.503)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.662] [G acc: 0.047]\n",
      "4963 [D loss: (0.518)(R 0.582, F 0.454)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.482] [G acc: 0.094]\n",
      "4964 [D loss: (0.509)(R 0.498, F 0.521)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.510] [G acc: 0.094]\n",
      "4965 [D loss: (0.582)(R 0.653, F 0.512)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.436] [G acc: 0.047]\n",
      "4966 [D loss: (0.515)(R 0.604, F 0.426)] [D acc: (0.766)(0.625, 0.906)] [G loss: 1.484] [G acc: 0.078]\n",
      "4967 [D loss: (0.512)(R 0.464, F 0.561)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.405] [G acc: 0.094]\n",
      "4968 [D loss: (0.500)(R 0.486, F 0.514)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.428] [G acc: 0.047]\n",
      "4969 [D loss: (0.527)(R 0.426, F 0.628)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.401] [G acc: 0.078]\n",
      "4970 [D loss: (0.578)(R 0.708, F 0.448)] [D acc: (0.664)(0.484, 0.844)] [G loss: 1.365] [G acc: 0.078]\n",
      "4971 [D loss: (0.491)(R 0.519, F 0.463)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.229] [G acc: 0.109]\n",
      "4972 [D loss: (0.530)(R 0.518, F 0.541)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.301] [G acc: 0.141]\n",
      "4973 [D loss: (0.473)(R 0.426, F 0.521)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.278] [G acc: 0.094]\n",
      "4974 [D loss: (0.575)(R 0.570, F 0.581)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.273] [G acc: 0.188]\n",
      "4975 [D loss: (0.531)(R 0.479, F 0.583)] [D acc: (0.734)(0.734, 0.734)] [G loss: 1.534] [G acc: 0.062]\n",
      "4976 [D loss: (0.597)(R 0.588, F 0.606)] [D acc: (0.633)(0.594, 0.672)] [G loss: 1.406] [G acc: 0.031]\n",
      "4977 [D loss: (0.471)(R 0.487, F 0.455)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.255] [G acc: 0.078]\n",
      "4978 [D loss: (0.474)(R 0.435, F 0.513)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.467] [G acc: 0.016]\n",
      "4979 [D loss: (0.409)(R 0.474, F 0.345)] [D acc: (0.828)(0.734, 0.922)] [G loss: 1.425] [G acc: 0.094]\n",
      "4980 [D loss: (0.624)(R 0.437, F 0.812)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.533] [G acc: 0.047]\n",
      "4981 [D loss: (0.568)(R 0.693, F 0.443)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.461] [G acc: 0.078]\n",
      "4982 [D loss: (0.547)(R 0.610, F 0.484)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.398] [G acc: 0.094]\n",
      "4983 [D loss: (0.444)(R 0.454, F 0.435)] [D acc: (0.812)(0.719, 0.906)] [G loss: 1.346] [G acc: 0.109]\n",
      "4984 [D loss: (0.477)(R 0.515, F 0.439)] [D acc: (0.812)(0.734, 0.891)] [G loss: 1.433] [G acc: 0.078]\n",
      "4985 [D loss: (0.590)(R 0.485, F 0.695)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.520] [G acc: 0.062]\n",
      "4986 [D loss: (0.524)(R 0.477, F 0.572)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.531] [G acc: 0.109]\n",
      "4987 [D loss: (0.526)(R 0.584, F 0.469)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.411] [G acc: 0.078]\n",
      "4988 [D loss: (0.536)(R 0.606, F 0.466)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.375] [G acc: 0.094]\n",
      "4989 [D loss: (0.528)(R 0.527, F 0.529)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.443] [G acc: 0.078]\n",
      "4990 [D loss: (0.514)(R 0.551, F 0.476)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.520] [G acc: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4991 [D loss: (0.554)(R 0.610, F 0.499)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.327] [G acc: 0.125]\n",
      "4992 [D loss: (0.564)(R 0.523, F 0.606)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.378] [G acc: 0.078]\n",
      "4993 [D loss: (0.599)(R 0.563, F 0.634)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.409] [G acc: 0.078]\n",
      "4994 [D loss: (0.570)(R 0.606, F 0.534)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.310] [G acc: 0.125]\n",
      "4995 [D loss: (0.444)(R 0.471, F 0.417)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.338] [G acc: 0.062]\n",
      "4996 [D loss: (0.581)(R 0.633, F 0.528)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.400] [G acc: 0.094]\n",
      "4997 [D loss: (0.624)(R 0.546, F 0.703)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.394] [G acc: 0.062]\n",
      "4998 [D loss: (0.569)(R 0.561, F 0.577)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.400] [G acc: 0.125]\n",
      "4999 [D loss: (0.454)(R 0.534, F 0.373)] [D acc: (0.797)(0.672, 0.922)] [G loss: 1.359] [G acc: 0.078]\n",
      "5000 [D loss: (0.524)(R 0.524, F 0.524)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.460] [G acc: 0.031]\n",
      "5001 [D loss: (0.510)(R 0.463, F 0.557)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.468] [G acc: 0.078]\n",
      "5002 [D loss: (0.483)(R 0.491, F 0.475)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.654] [G acc: 0.016]\n",
      "5003 [D loss: (0.554)(R 0.597, F 0.510)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.538] [G acc: 0.062]\n",
      "5004 [D loss: (0.529)(R 0.614, F 0.445)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.369] [G acc: 0.109]\n",
      "5005 [D loss: (0.450)(R 0.425, F 0.476)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.456] [G acc: 0.109]\n",
      "5006 [D loss: (0.484)(R 0.465, F 0.502)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.590] [G acc: 0.047]\n",
      "5007 [D loss: (0.486)(R 0.596, F 0.377)] [D acc: (0.766)(0.625, 0.906)] [G loss: 1.473] [G acc: 0.078]\n",
      "5008 [D loss: (0.489)(R 0.395, F 0.583)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.530] [G acc: 0.047]\n",
      "5009 [D loss: (0.485)(R 0.441, F 0.529)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.468] [G acc: 0.062]\n",
      "5010 [D loss: (0.527)(R 0.602, F 0.451)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.529] [G acc: 0.109]\n",
      "5011 [D loss: (0.450)(R 0.440, F 0.460)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.431] [G acc: 0.094]\n",
      "5012 [D loss: (0.552)(R 0.601, F 0.502)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.519] [G acc: 0.125]\n",
      "5013 [D loss: (0.586)(R 0.598, F 0.575)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.537] [G acc: 0.094]\n",
      "5014 [D loss: (0.533)(R 0.621, F 0.445)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.460] [G acc: 0.203]\n",
      "5015 [D loss: (0.422)(R 0.424, F 0.419)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.461] [G acc: 0.141]\n",
      "5016 [D loss: (0.507)(R 0.514, F 0.500)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.383] [G acc: 0.109]\n",
      "5017 [D loss: (0.479)(R 0.415, F 0.543)] [D acc: (0.789)(0.797, 0.781)] [G loss: 1.641] [G acc: 0.078]\n",
      "5018 [D loss: (0.570)(R 0.706, F 0.433)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.509] [G acc: 0.078]\n",
      "5019 [D loss: (0.485)(R 0.475, F 0.495)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.463] [G acc: 0.109]\n",
      "5020 [D loss: (0.548)(R 0.658, F 0.438)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.469] [G acc: 0.109]\n",
      "5021 [D loss: (0.565)(R 0.658, F 0.472)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.322] [G acc: 0.141]\n",
      "5022 [D loss: (0.623)(R 0.629, F 0.617)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.390] [G acc: 0.062]\n",
      "5023 [D loss: (0.441)(R 0.452, F 0.431)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.444] [G acc: 0.062]\n",
      "5024 [D loss: (0.525)(R 0.639, F 0.411)] [D acc: (0.750)(0.594, 0.906)] [G loss: 1.357] [G acc: 0.078]\n",
      "5025 [D loss: (0.494)(R 0.491, F 0.496)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.466] [G acc: 0.094]\n",
      "5026 [D loss: (0.495)(R 0.543, F 0.447)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.336] [G acc: 0.125]\n",
      "5027 [D loss: (0.522)(R 0.553, F 0.491)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.354] [G acc: 0.094]\n",
      "5028 [D loss: (0.508)(R 0.494, F 0.521)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.441] [G acc: 0.078]\n",
      "5029 [D loss: (0.594)(R 0.511, F 0.676)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.392] [G acc: 0.031]\n",
      "5030 [D loss: (0.475)(R 0.527, F 0.424)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.408] [G acc: 0.078]\n",
      "5031 [D loss: (0.532)(R 0.592, F 0.473)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.309] [G acc: 0.109]\n",
      "5032 [D loss: (0.585)(R 0.646, F 0.524)] [D acc: (0.664)(0.562, 0.766)] [G loss: 1.327] [G acc: 0.062]\n",
      "5033 [D loss: (0.580)(R 0.523, F 0.637)] [D acc: (0.664)(0.625, 0.703)] [G loss: 1.329] [G acc: 0.031]\n",
      "5034 [D loss: (0.571)(R 0.653, F 0.488)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.364] [G acc: 0.094]\n",
      "5035 [D loss: (0.564)(R 0.596, F 0.532)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.290] [G acc: 0.172]\n",
      "5036 [D loss: (0.564)(R 0.652, F 0.476)] [D acc: (0.695)(0.547, 0.844)] [G loss: 1.472] [G acc: 0.109]\n",
      "5037 [D loss: (0.560)(R 0.478, F 0.641)] [D acc: (0.758)(0.812, 0.703)] [G loss: 1.384] [G acc: 0.062]\n",
      "5038 [D loss: (0.485)(R 0.457, F 0.514)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.287] [G acc: 0.141]\n",
      "5039 [D loss: (0.535)(R 0.555, F 0.515)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.263] [G acc: 0.188]\n",
      "5040 [D loss: (0.545)(R 0.523, F 0.568)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.407] [G acc: 0.031]\n",
      "5041 [D loss: (0.491)(R 0.571, F 0.411)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.413] [G acc: 0.094]\n",
      "5042 [D loss: (0.543)(R 0.570, F 0.516)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.386] [G acc: 0.094]\n",
      "5043 [D loss: (0.571)(R 0.589, F 0.554)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.423] [G acc: 0.047]\n",
      "5044 [D loss: (0.532)(R 0.667, F 0.396)] [D acc: (0.742)(0.578, 0.906)] [G loss: 1.357] [G acc: 0.125]\n",
      "5045 [D loss: (0.503)(R 0.395, F 0.611)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.405] [G acc: 0.109]\n",
      "5046 [D loss: (0.518)(R 0.610, F 0.426)] [D acc: (0.766)(0.625, 0.906)] [G loss: 1.300] [G acc: 0.062]\n",
      "5047 [D loss: (0.534)(R 0.599, F 0.469)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.401] [G acc: 0.109]\n",
      "5048 [D loss: (0.526)(R 0.572, F 0.480)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.410] [G acc: 0.078]\n",
      "5049 [D loss: (0.542)(R 0.473, F 0.610)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.592] [G acc: 0.031]\n",
      "5050 [D loss: (0.636)(R 0.743, F 0.530)] [D acc: (0.641)(0.516, 0.766)] [G loss: 1.280] [G acc: 0.156]\n",
      "5051 [D loss: (0.454)(R 0.462, F 0.447)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.289] [G acc: 0.188]\n",
      "5052 [D loss: (0.479)(R 0.384, F 0.573)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.459] [G acc: 0.094]\n",
      "5053 [D loss: (0.536)(R 0.442, F 0.630)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.464] [G acc: 0.031]\n",
      "5054 [D loss: (0.476)(R 0.509, F 0.443)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.359] [G acc: 0.109]\n",
      "5055 [D loss: (0.496)(R 0.511, F 0.480)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.454] [G acc: 0.078]\n",
      "5056 [D loss: (0.507)(R 0.518, F 0.496)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.518] [G acc: 0.047]\n",
      "5057 [D loss: (0.509)(R 0.574, F 0.444)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.414] [G acc: 0.141]\n",
      "5058 [D loss: (0.569)(R 0.648, F 0.490)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.468] [G acc: 0.031]\n",
      "5059 [D loss: (0.518)(R 0.533, F 0.503)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.442] [G acc: 0.047]\n",
      "5060 [D loss: (0.467)(R 0.577, F 0.357)] [D acc: (0.812)(0.703, 0.922)] [G loss: 1.387] [G acc: 0.125]\n",
      "5061 [D loss: (0.464)(R 0.428, F 0.501)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.470] [G acc: 0.047]\n",
      "5062 [D loss: (0.491)(R 0.525, F 0.457)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.521] [G acc: 0.125]\n",
      "5063 [D loss: (0.573)(R 0.606, F 0.541)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.306] [G acc: 0.062]\n",
      "5064 [D loss: (0.618)(R 0.557, F 0.679)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.453] [G acc: 0.047]\n",
      "5065 [D loss: (0.523)(R 0.547, F 0.500)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.360] [G acc: 0.094]\n",
      "5066 [D loss: (0.554)(R 0.641, F 0.468)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.404] [G acc: 0.062]\n",
      "5067 [D loss: (0.441)(R 0.460, F 0.422)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.311] [G acc: 0.219]\n",
      "5068 [D loss: (0.580)(R 0.548, F 0.612)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.324] [G acc: 0.094]\n",
      "5069 [D loss: (0.482)(R 0.525, F 0.439)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.470] [G acc: 0.062]\n",
      "5070 [D loss: (0.566)(R 0.637, F 0.494)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.383] [G acc: 0.094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5071 [D loss: (0.503)(R 0.460, F 0.545)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.271] [G acc: 0.125]\n",
      "5072 [D loss: (0.537)(R 0.532, F 0.542)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.382] [G acc: 0.078]\n",
      "5073 [D loss: (0.479)(R 0.428, F 0.531)] [D acc: (0.758)(0.781, 0.734)] [G loss: 1.546] [G acc: 0.062]\n",
      "5074 [D loss: (0.557)(R 0.622, F 0.491)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.339] [G acc: 0.141]\n",
      "5075 [D loss: (0.556)(R 0.533, F 0.580)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.490] [G acc: 0.062]\n",
      "5076 [D loss: (0.541)(R 0.591, F 0.491)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.391] [G acc: 0.078]\n",
      "5077 [D loss: (0.471)(R 0.562, F 0.380)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.395] [G acc: 0.078]\n",
      "5078 [D loss: (0.483)(R 0.449, F 0.516)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.525] [G acc: 0.031]\n",
      "5079 [D loss: (0.538)(R 0.615, F 0.461)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.400] [G acc: 0.078]\n",
      "5080 [D loss: (0.528)(R 0.479, F 0.577)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.333] [G acc: 0.141]\n",
      "5081 [D loss: (0.450)(R 0.381, F 0.519)] [D acc: (0.820)(0.859, 0.781)] [G loss: 1.421] [G acc: 0.125]\n",
      "5082 [D loss: (0.454)(R 0.498, F 0.409)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.590] [G acc: 0.078]\n",
      "5083 [D loss: (0.495)(R 0.467, F 0.524)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.401] [G acc: 0.078]\n",
      "5084 [D loss: (0.499)(R 0.486, F 0.512)] [D acc: (0.703)(0.688, 0.719)] [G loss: 1.466] [G acc: 0.078]\n",
      "5085 [D loss: (0.568)(R 0.638, F 0.498)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.458] [G acc: 0.047]\n",
      "5086 [D loss: (0.628)(R 0.465, F 0.790)] [D acc: (0.719)(0.766, 0.672)] [G loss: 1.354] [G acc: 0.078]\n",
      "5087 [D loss: (0.596)(R 0.627, F 0.564)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.364] [G acc: 0.062]\n",
      "5088 [D loss: (0.489)(R 0.530, F 0.448)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.410] [G acc: 0.031]\n",
      "5089 [D loss: (0.509)(R 0.570, F 0.447)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.468] [G acc: 0.109]\n",
      "5090 [D loss: (0.505)(R 0.394, F 0.615)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.547] [G acc: 0.062]\n",
      "5091 [D loss: (0.490)(R 0.610, F 0.369)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.826] [G acc: 0.031]\n",
      "5092 [D loss: (0.432)(R 0.437, F 0.428)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.447] [G acc: 0.109]\n",
      "5093 [D loss: (0.667)(R 0.654, F 0.679)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.362] [G acc: 0.062]\n",
      "5094 [D loss: (0.554)(R 0.643, F 0.464)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.334] [G acc: 0.094]\n",
      "5095 [D loss: (0.513)(R 0.467, F 0.558)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.402] [G acc: 0.109]\n",
      "5096 [D loss: (0.523)(R 0.529, F 0.517)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.341] [G acc: 0.172]\n",
      "5097 [D loss: (0.499)(R 0.537, F 0.461)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.440] [G acc: 0.078]\n",
      "5098 [D loss: (0.518)(R 0.516, F 0.520)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.469] [G acc: 0.094]\n",
      "5099 [D loss: (0.499)(R 0.602, F 0.396)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.465] [G acc: 0.125]\n",
      "5100 [D loss: (0.562)(R 0.546, F 0.578)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.460] [G acc: 0.125]\n",
      "5101 [D loss: (0.504)(R 0.566, F 0.443)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.391] [G acc: 0.141]\n",
      "5102 [D loss: (0.504)(R 0.547, F 0.462)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.262] [G acc: 0.094]\n",
      "5103 [D loss: (0.542)(R 0.495, F 0.589)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.680] [G acc: 0.062]\n",
      "5104 [D loss: (0.511)(R 0.535, F 0.486)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.292] [G acc: 0.203]\n",
      "5105 [D loss: (0.501)(R 0.550, F 0.452)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.401] [G acc: 0.078]\n",
      "5106 [D loss: (0.595)(R 0.535, F 0.654)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.460] [G acc: 0.078]\n",
      "5107 [D loss: (0.521)(R 0.595, F 0.448)] [D acc: (0.758)(0.609, 0.906)] [G loss: 1.492] [G acc: 0.094]\n",
      "5108 [D loss: (0.574)(R 0.614, F 0.535)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.322] [G acc: 0.094]\n",
      "5109 [D loss: (0.550)(R 0.535, F 0.565)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.415] [G acc: 0.094]\n",
      "5110 [D loss: (0.532)(R 0.558, F 0.505)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.284] [G acc: 0.078]\n",
      "5111 [D loss: (0.521)(R 0.566, F 0.476)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.396] [G acc: 0.109]\n",
      "5112 [D loss: (0.573)(R 0.603, F 0.542)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.362] [G acc: 0.078]\n",
      "5113 [D loss: (0.507)(R 0.566, F 0.449)] [D acc: (0.758)(0.625, 0.891)] [G loss: 1.357] [G acc: 0.141]\n",
      "5114 [D loss: (0.559)(R 0.478, F 0.640)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.360] [G acc: 0.062]\n",
      "5115 [D loss: (0.434)(R 0.411, F 0.457)] [D acc: (0.820)(0.797, 0.844)] [G loss: 1.433] [G acc: 0.109]\n",
      "5116 [D loss: (0.487)(R 0.520, F 0.453)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.424] [G acc: 0.109]\n",
      "5117 [D loss: (0.486)(R 0.406, F 0.567)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.389] [G acc: 0.047]\n",
      "5118 [D loss: (0.465)(R 0.475, F 0.456)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.400] [G acc: 0.078]\n",
      "5119 [D loss: (0.623)(R 0.557, F 0.689)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.370] [G acc: 0.109]\n",
      "5120 [D loss: (0.569)(R 0.684, F 0.455)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.442] [G acc: 0.094]\n",
      "5121 [D loss: (0.441)(R 0.477, F 0.405)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.467] [G acc: 0.094]\n",
      "5122 [D loss: (0.552)(R 0.495, F 0.608)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.376] [G acc: 0.125]\n",
      "5123 [D loss: (0.496)(R 0.576, F 0.417)] [D acc: (0.773)(0.641, 0.906)] [G loss: 1.361] [G acc: 0.125]\n",
      "5124 [D loss: (0.563)(R 0.460, F 0.665)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.392] [G acc: 0.141]\n",
      "5125 [D loss: (0.456)(R 0.492, F 0.420)] [D acc: (0.805)(0.703, 0.906)] [G loss: 1.582] [G acc: 0.094]\n",
      "5126 [D loss: (0.560)(R 0.631, F 0.488)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.555] [G acc: 0.047]\n",
      "5127 [D loss: (0.558)(R 0.648, F 0.468)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.330] [G acc: 0.016]\n",
      "5128 [D loss: (0.494)(R 0.531, F 0.457)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.336] [G acc: 0.125]\n",
      "5129 [D loss: (0.527)(R 0.477, F 0.578)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.398] [G acc: 0.125]\n",
      "5130 [D loss: (0.454)(R 0.477, F 0.431)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.361] [G acc: 0.125]\n",
      "5131 [D loss: (0.540)(R 0.525, F 0.554)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.435] [G acc: 0.125]\n",
      "5132 [D loss: (0.529)(R 0.545, F 0.512)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.363] [G acc: 0.094]\n",
      "5133 [D loss: (0.482)(R 0.562, F 0.402)] [D acc: (0.758)(0.609, 0.906)] [G loss: 1.387] [G acc: 0.156]\n",
      "5134 [D loss: (0.622)(R 0.709, F 0.536)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.469] [G acc: 0.109]\n",
      "5135 [D loss: (0.615)(R 0.669, F 0.561)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.350] [G acc: 0.078]\n",
      "5136 [D loss: (0.566)(R 0.504, F 0.627)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.475] [G acc: 0.094]\n",
      "5137 [D loss: (0.542)(R 0.426, F 0.658)] [D acc: (0.750)(0.781, 0.719)] [G loss: 1.358] [G acc: 0.125]\n",
      "5138 [D loss: (0.471)(R 0.548, F 0.394)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.593] [G acc: 0.031]\n",
      "5139 [D loss: (0.488)(R 0.418, F 0.558)] [D acc: (0.766)(0.797, 0.734)] [G loss: 1.566] [G acc: 0.016]\n",
      "5140 [D loss: (0.568)(R 0.617, F 0.518)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.380] [G acc: 0.062]\n",
      "5141 [D loss: (0.536)(R 0.446, F 0.626)] [D acc: (0.719)(0.734, 0.703)] [G loss: 1.453] [G acc: 0.109]\n",
      "5142 [D loss: (0.456)(R 0.492, F 0.421)] [D acc: (0.805)(0.688, 0.922)] [G loss: 1.563] [G acc: 0.047]\n",
      "5143 [D loss: (0.450)(R 0.500, F 0.400)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.558] [G acc: 0.062]\n",
      "5144 [D loss: (0.504)(R 0.592, F 0.416)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.339] [G acc: 0.078]\n",
      "5145 [D loss: (0.558)(R 0.625, F 0.490)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.546] [G acc: 0.062]\n",
      "5146 [D loss: (0.359)(R 0.326, F 0.392)] [D acc: (0.875)(0.859, 0.891)] [G loss: 1.593] [G acc: 0.094]\n",
      "5147 [D loss: (0.539)(R 0.376, F 0.702)] [D acc: (0.773)(0.781, 0.766)] [G loss: 1.636] [G acc: 0.078]\n",
      "5148 [D loss: (0.629)(R 0.795, F 0.462)] [D acc: (0.672)(0.516, 0.828)] [G loss: 1.645] [G acc: 0.094]\n",
      "5149 [D loss: (0.525)(R 0.551, F 0.499)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.597] [G acc: 0.078]\n",
      "5150 [D loss: (0.478)(R 0.510, F 0.446)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.589] [G acc: 0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5151 [D loss: (0.510)(R 0.468, F 0.553)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.603] [G acc: 0.047]\n",
      "5152 [D loss: (0.489)(R 0.510, F 0.468)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.468] [G acc: 0.094]\n",
      "5153 [D loss: (0.530)(R 0.587, F 0.472)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.525] [G acc: 0.141]\n",
      "5154 [D loss: (0.459)(R 0.423, F 0.495)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.533] [G acc: 0.094]\n",
      "5155 [D loss: (0.500)(R 0.487, F 0.513)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.589] [G acc: 0.047]\n",
      "5156 [D loss: (0.503)(R 0.608, F 0.399)] [D acc: (0.742)(0.562, 0.922)] [G loss: 1.438] [G acc: 0.094]\n",
      "5157 [D loss: (0.517)(R 0.580, F 0.453)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.615] [G acc: 0.047]\n",
      "5158 [D loss: (0.540)(R 0.421, F 0.659)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.651] [G acc: 0.031]\n",
      "5159 [D loss: (0.565)(R 0.637, F 0.493)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.425] [G acc: 0.047]\n",
      "5160 [D loss: (0.542)(R 0.694, F 0.389)] [D acc: (0.703)(0.484, 0.922)] [G loss: 1.409] [G acc: 0.109]\n",
      "5161 [D loss: (0.487)(R 0.443, F 0.531)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.489] [G acc: 0.094]\n",
      "5162 [D loss: (0.539)(R 0.558, F 0.521)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.359] [G acc: 0.141]\n",
      "5163 [D loss: (0.456)(R 0.450, F 0.463)] [D acc: (0.836)(0.812, 0.859)] [G loss: 1.621] [G acc: 0.078]\n",
      "5164 [D loss: (0.558)(R 0.565, F 0.551)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.522] [G acc: 0.062]\n",
      "5165 [D loss: (0.504)(R 0.568, F 0.440)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.427] [G acc: 0.109]\n",
      "5166 [D loss: (0.474)(R 0.459, F 0.489)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.518] [G acc: 0.094]\n",
      "5167 [D loss: (0.530)(R 0.501, F 0.558)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.547] [G acc: 0.109]\n",
      "5168 [D loss: (0.550)(R 0.636, F 0.465)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.528] [G acc: 0.047]\n",
      "5169 [D loss: (0.615)(R 0.523, F 0.708)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.572] [G acc: 0.047]\n",
      "5170 [D loss: (0.511)(R 0.571, F 0.452)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.456] [G acc: 0.094]\n",
      "5171 [D loss: (0.488)(R 0.558, F 0.417)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.555] [G acc: 0.078]\n",
      "5172 [D loss: (0.550)(R 0.601, F 0.500)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.510] [G acc: 0.062]\n",
      "5173 [D loss: (0.549)(R 0.636, F 0.462)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.397] [G acc: 0.156]\n",
      "5174 [D loss: (0.527)(R 0.534, F 0.520)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.481] [G acc: 0.062]\n",
      "5175 [D loss: (0.579)(R 0.630, F 0.527)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.297] [G acc: 0.094]\n",
      "5176 [D loss: (0.524)(R 0.511, F 0.537)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.605] [G acc: 0.047]\n",
      "5177 [D loss: (0.499)(R 0.470, F 0.529)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.490] [G acc: 0.062]\n",
      "5178 [D loss: (0.540)(R 0.549, F 0.532)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.575] [G acc: 0.062]\n",
      "5179 [D loss: (0.512)(R 0.550, F 0.474)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.562] [G acc: 0.078]\n",
      "5180 [D loss: (0.569)(R 0.650, F 0.488)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.385] [G acc: 0.109]\n",
      "5181 [D loss: (0.577)(R 0.642, F 0.512)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.454] [G acc: 0.078]\n",
      "5182 [D loss: (0.580)(R 0.606, F 0.555)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.442] [G acc: 0.062]\n",
      "5183 [D loss: (0.491)(R 0.453, F 0.528)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.526] [G acc: 0.078]\n",
      "5184 [D loss: (0.542)(R 0.669, F 0.416)] [D acc: (0.742)(0.594, 0.891)] [G loss: 1.363] [G acc: 0.094]\n",
      "5185 [D loss: (0.489)(R 0.525, F 0.453)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.421] [G acc: 0.109]\n",
      "5186 [D loss: (0.505)(R 0.514, F 0.497)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.320] [G acc: 0.172]\n",
      "5187 [D loss: (0.561)(R 0.468, F 0.654)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.398] [G acc: 0.031]\n",
      "5188 [D loss: (0.477)(R 0.412, F 0.542)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.481] [G acc: 0.094]\n",
      "5189 [D loss: (0.497)(R 0.601, F 0.394)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.457] [G acc: 0.047]\n",
      "5190 [D loss: (0.536)(R 0.569, F 0.503)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.281] [G acc: 0.109]\n",
      "5191 [D loss: (0.486)(R 0.424, F 0.548)] [D acc: (0.797)(0.781, 0.812)] [G loss: 1.485] [G acc: 0.125]\n",
      "5192 [D loss: (0.505)(R 0.435, F 0.574)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.376] [G acc: 0.094]\n",
      "5193 [D loss: (0.451)(R 0.450, F 0.452)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.407] [G acc: 0.125]\n",
      "5194 [D loss: (0.428)(R 0.419, F 0.438)] [D acc: (0.805)(0.750, 0.859)] [G loss: 1.536] [G acc: 0.094]\n",
      "5195 [D loss: (0.533)(R 0.528, F 0.539)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.534] [G acc: 0.047]\n",
      "5196 [D loss: (0.591)(R 0.656, F 0.527)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.594] [G acc: 0.062]\n",
      "5197 [D loss: (0.487)(R 0.545, F 0.429)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.453] [G acc: 0.125]\n",
      "5198 [D loss: (0.557)(R 0.506, F 0.608)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.519] [G acc: 0.031]\n",
      "5199 [D loss: (0.512)(R 0.646, F 0.378)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.433] [G acc: 0.062]\n",
      "5200 [D loss: (0.434)(R 0.370, F 0.499)] [D acc: (0.812)(0.828, 0.797)] [G loss: 1.429] [G acc: 0.078]\n",
      "5201 [D loss: (0.500)(R 0.525, F 0.475)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.642] [G acc: 0.047]\n",
      "5202 [D loss: (0.418)(R 0.410, F 0.425)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.633] [G acc: 0.047]\n",
      "5203 [D loss: (0.476)(R 0.607, F 0.346)] [D acc: (0.805)(0.703, 0.906)] [G loss: 1.611] [G acc: 0.078]\n",
      "5204 [D loss: (0.468)(R 0.493, F 0.442)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.532] [G acc: 0.078]\n",
      "5205 [D loss: (0.535)(R 0.476, F 0.593)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.624] [G acc: 0.062]\n",
      "5206 [D loss: (0.448)(R 0.512, F 0.384)] [D acc: (0.805)(0.703, 0.906)] [G loss: 1.623] [G acc: 0.094]\n",
      "5207 [D loss: (0.439)(R 0.373, F 0.504)] [D acc: (0.789)(0.781, 0.797)] [G loss: 1.547] [G acc: 0.062]\n",
      "5208 [D loss: (0.535)(R 0.646, F 0.423)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.514] [G acc: 0.109]\n",
      "5209 [D loss: (0.465)(R 0.487, F 0.443)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.609] [G acc: 0.109]\n",
      "5210 [D loss: (0.561)(R 0.505, F 0.618)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.581] [G acc: 0.094]\n",
      "5211 [D loss: (0.575)(R 0.689, F 0.462)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.557] [G acc: 0.047]\n",
      "5212 [D loss: (0.528)(R 0.601, F 0.456)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.611] [G acc: 0.062]\n",
      "5213 [D loss: (0.536)(R 0.619, F 0.454)] [D acc: (0.766)(0.625, 0.906)] [G loss: 1.456] [G acc: 0.078]\n",
      "5214 [D loss: (0.537)(R 0.487, F 0.588)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.500] [G acc: 0.078]\n",
      "5215 [D loss: (0.516)(R 0.513, F 0.519)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.434] [G acc: 0.062]\n",
      "5216 [D loss: (0.486)(R 0.523, F 0.450)] [D acc: (0.805)(0.688, 0.922)] [G loss: 1.441] [G acc: 0.094]\n",
      "5217 [D loss: (0.531)(R 0.540, F 0.523)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.448] [G acc: 0.062]\n",
      "5218 [D loss: (0.493)(R 0.475, F 0.511)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.330] [G acc: 0.141]\n",
      "5219 [D loss: (0.506)(R 0.577, F 0.435)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.430] [G acc: 0.078]\n",
      "5220 [D loss: (0.522)(R 0.553, F 0.492)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.394] [G acc: 0.109]\n",
      "5221 [D loss: (0.539)(R 0.522, F 0.555)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.274] [G acc: 0.125]\n",
      "5222 [D loss: (0.483)(R 0.508, F 0.458)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.394] [G acc: 0.141]\n",
      "5223 [D loss: (0.551)(R 0.536, F 0.566)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.368] [G acc: 0.141]\n",
      "5224 [D loss: (0.475)(R 0.448, F 0.501)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.421] [G acc: 0.188]\n",
      "5225 [D loss: (0.527)(R 0.502, F 0.551)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.385] [G acc: 0.156]\n",
      "5226 [D loss: (0.531)(R 0.501, F 0.562)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.292] [G acc: 0.188]\n",
      "5227 [D loss: (0.500)(R 0.418, F 0.581)] [D acc: (0.789)(0.781, 0.797)] [G loss: 1.527] [G acc: 0.078]\n",
      "5228 [D loss: (0.575)(R 0.629, F 0.521)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.468] [G acc: 0.094]\n",
      "5229 [D loss: (0.570)(R 0.531, F 0.609)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.642] [G acc: 0.078]\n",
      "5230 [D loss: (0.477)(R 0.470, F 0.485)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.563] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5231 [D loss: (0.545)(R 0.567, F 0.523)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.647] [G acc: 0.094]\n",
      "5232 [D loss: (0.668)(R 0.677, F 0.659)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.437] [G acc: 0.062]\n",
      "5233 [D loss: (0.620)(R 0.754, F 0.486)] [D acc: (0.648)(0.531, 0.766)] [G loss: 1.519] [G acc: 0.094]\n",
      "5234 [D loss: (0.486)(R 0.507, F 0.465)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.572] [G acc: 0.062]\n",
      "5235 [D loss: (0.487)(R 0.528, F 0.447)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.554] [G acc: 0.016]\n",
      "5236 [D loss: (0.551)(R 0.597, F 0.506)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.359] [G acc: 0.141]\n",
      "5237 [D loss: (0.495)(R 0.573, F 0.417)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.497] [G acc: 0.062]\n",
      "5238 [D loss: (0.539)(R 0.542, F 0.537)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.475] [G acc: 0.031]\n",
      "5239 [D loss: (0.609)(R 0.707, F 0.512)] [D acc: (0.609)(0.453, 0.766)] [G loss: 1.368] [G acc: 0.156]\n",
      "5240 [D loss: (0.584)(R 0.540, F 0.629)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.466] [G acc: 0.094]\n",
      "5241 [D loss: (0.550)(R 0.505, F 0.594)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.509] [G acc: 0.062]\n",
      "5242 [D loss: (0.527)(R 0.512, F 0.542)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.434] [G acc: 0.094]\n",
      "5243 [D loss: (0.530)(R 0.502, F 0.558)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.560] [G acc: 0.062]\n",
      "5244 [D loss: (0.497)(R 0.534, F 0.461)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.340] [G acc: 0.125]\n",
      "5245 [D loss: (0.587)(R 0.686, F 0.488)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.318] [G acc: 0.125]\n",
      "5246 [D loss: (0.526)(R 0.470, F 0.582)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.342] [G acc: 0.141]\n",
      "5247 [D loss: (0.527)(R 0.505, F 0.550)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.315] [G acc: 0.172]\n",
      "5248 [D loss: (0.488)(R 0.478, F 0.499)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.357] [G acc: 0.125]\n",
      "5249 [D loss: (0.513)(R 0.527, F 0.499)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.424] [G acc: 0.141]\n",
      "5250 [D loss: (0.477)(R 0.560, F 0.395)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.422] [G acc: 0.094]\n",
      "5251 [D loss: (0.465)(R 0.451, F 0.480)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.597] [G acc: 0.031]\n",
      "5252 [D loss: (0.643)(R 0.595, F 0.690)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.558] [G acc: 0.016]\n",
      "5253 [D loss: (0.430)(R 0.508, F 0.352)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.566] [G acc: 0.094]\n",
      "5254 [D loss: (0.575)(R 0.653, F 0.497)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.348] [G acc: 0.156]\n",
      "5255 [D loss: (0.498)(R 0.545, F 0.451)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.280] [G acc: 0.125]\n",
      "5256 [D loss: (0.442)(R 0.404, F 0.479)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.513] [G acc: 0.094]\n",
      "5257 [D loss: (0.481)(R 0.478, F 0.484)] [D acc: (0.797)(0.766, 0.828)] [G loss: 1.394] [G acc: 0.125]\n",
      "5258 [D loss: (0.568)(R 0.551, F 0.585)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.331] [G acc: 0.109]\n",
      "5259 [D loss: (0.517)(R 0.476, F 0.558)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.445] [G acc: 0.125]\n",
      "5260 [D loss: (0.515)(R 0.534, F 0.495)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.503] [G acc: 0.078]\n",
      "5261 [D loss: (0.443)(R 0.488, F 0.399)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.407] [G acc: 0.141]\n",
      "5262 [D loss: (0.567)(R 0.598, F 0.537)] [D acc: (0.703)(0.672, 0.734)] [G loss: 1.505] [G acc: 0.094]\n",
      "5263 [D loss: (0.383)(R 0.375, F 0.391)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.499] [G acc: 0.125]\n",
      "5264 [D loss: (0.489)(R 0.400, F 0.578)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.748] [G acc: 0.125]\n",
      "5265 [D loss: (0.565)(R 0.663, F 0.468)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.535] [G acc: 0.094]\n",
      "5266 [D loss: (0.494)(R 0.572, F 0.415)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.381] [G acc: 0.172]\n",
      "5267 [D loss: (0.469)(R 0.510, F 0.428)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.390] [G acc: 0.156]\n",
      "5268 [D loss: (0.476)(R 0.386, F 0.566)] [D acc: (0.742)(0.766, 0.719)] [G loss: 1.426] [G acc: 0.125]\n",
      "5269 [D loss: (0.626)(R 0.495, F 0.758)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.483] [G acc: 0.094]\n",
      "5270 [D loss: (0.574)(R 0.640, F 0.508)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.565] [G acc: 0.078]\n",
      "5271 [D loss: (0.465)(R 0.544, F 0.386)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.500] [G acc: 0.188]\n",
      "5272 [D loss: (0.589)(R 0.566, F 0.611)] [D acc: (0.648)(0.625, 0.672)] [G loss: 1.595] [G acc: 0.047]\n",
      "5273 [D loss: (0.463)(R 0.532, F 0.394)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.465] [G acc: 0.047]\n",
      "5274 [D loss: (0.498)(R 0.587, F 0.410)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.511] [G acc: 0.047]\n",
      "5275 [D loss: (0.538)(R 0.521, F 0.555)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.605] [G acc: 0.094]\n",
      "5276 [D loss: (0.491)(R 0.482, F 0.499)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.359] [G acc: 0.156]\n",
      "5277 [D loss: (0.474)(R 0.460, F 0.488)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.532] [G acc: 0.062]\n",
      "5278 [D loss: (0.543)(R 0.563, F 0.522)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.376] [G acc: 0.094]\n",
      "5279 [D loss: (0.621)(R 0.538, F 0.705)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.592] [G acc: 0.094]\n",
      "5280 [D loss: (0.513)(R 0.656, F 0.371)] [D acc: (0.727)(0.578, 0.875)] [G loss: 1.438] [G acc: 0.062]\n",
      "5281 [D loss: (0.478)(R 0.537, F 0.418)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.492] [G acc: 0.172]\n",
      "5282 [D loss: (0.531)(R 0.558, F 0.505)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.426] [G acc: 0.141]\n",
      "5283 [D loss: (0.573)(R 0.545, F 0.602)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.376] [G acc: 0.141]\n",
      "5284 [D loss: (0.459)(R 0.434, F 0.483)] [D acc: (0.820)(0.766, 0.875)] [G loss: 1.460] [G acc: 0.156]\n",
      "5285 [D loss: (0.443)(R 0.418, F 0.468)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.595] [G acc: 0.062]\n",
      "5286 [D loss: (0.492)(R 0.530, F 0.454)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.544] [G acc: 0.094]\n",
      "5287 [D loss: (0.534)(R 0.446, F 0.621)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.521] [G acc: 0.078]\n",
      "5288 [D loss: (0.527)(R 0.594, F 0.461)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.722] [G acc: 0.062]\n",
      "5289 [D loss: (0.521)(R 0.528, F 0.515)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.458] [G acc: 0.156]\n",
      "5290 [D loss: (0.487)(R 0.521, F 0.454)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.678] [G acc: 0.031]\n",
      "5291 [D loss: (0.457)(R 0.572, F 0.342)] [D acc: (0.805)(0.688, 0.922)] [G loss: 1.598] [G acc: 0.078]\n",
      "5292 [D loss: (0.431)(R 0.406, F 0.457)] [D acc: (0.766)(0.766, 0.766)] [G loss: 1.433] [G acc: 0.141]\n",
      "5293 [D loss: (0.548)(R 0.449, F 0.648)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.423] [G acc: 0.094]\n",
      "5294 [D loss: (0.597)(R 0.692, F 0.502)] [D acc: (0.703)(0.562, 0.844)] [G loss: 1.467] [G acc: 0.094]\n",
      "5295 [D loss: (0.527)(R 0.565, F 0.488)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.586] [G acc: 0.031]\n",
      "5296 [D loss: (0.412)(R 0.412, F 0.412)] [D acc: (0.828)(0.781, 0.875)] [G loss: 1.370] [G acc: 0.156]\n",
      "5297 [D loss: (0.593)(R 0.660, F 0.525)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.414] [G acc: 0.094]\n",
      "5298 [D loss: (0.701)(R 0.740, F 0.661)] [D acc: (0.617)(0.531, 0.703)] [G loss: 1.446] [G acc: 0.094]\n",
      "5299 [D loss: (0.509)(R 0.635, F 0.383)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.339] [G acc: 0.109]\n",
      "5300 [D loss: (0.527)(R 0.502, F 0.553)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.326] [G acc: 0.094]\n",
      "5301 [D loss: (0.562)(R 0.656, F 0.468)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.381] [G acc: 0.094]\n",
      "5302 [D loss: (0.478)(R 0.523, F 0.433)] [D acc: (0.797)(0.703, 0.891)] [G loss: 1.500] [G acc: 0.031]\n",
      "5303 [D loss: (0.570)(R 0.616, F 0.524)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.368] [G acc: 0.094]\n",
      "5304 [D loss: (0.495)(R 0.543, F 0.446)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.454] [G acc: 0.047]\n",
      "5305 [D loss: (0.507)(R 0.485, F 0.530)] [D acc: (0.750)(0.734, 0.766)] [G loss: 1.342] [G acc: 0.047]\n",
      "5306 [D loss: (0.485)(R 0.533, F 0.436)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.318] [G acc: 0.172]\n",
      "5307 [D loss: (0.494)(R 0.467, F 0.522)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.362] [G acc: 0.109]\n",
      "5308 [D loss: (0.471)(R 0.494, F 0.448)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.399] [G acc: 0.094]\n",
      "5309 [D loss: (0.516)(R 0.447, F 0.584)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.587] [G acc: 0.047]\n",
      "5310 [D loss: (0.543)(R 0.630, F 0.456)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.313] [G acc: 0.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311 [D loss: (0.452)(R 0.432, F 0.471)] [D acc: (0.812)(0.812, 0.812)] [G loss: 1.339] [G acc: 0.141]\n",
      "5312 [D loss: (0.430)(R 0.359, F 0.501)] [D acc: (0.781)(0.797, 0.766)] [G loss: 1.604] [G acc: 0.078]\n",
      "5313 [D loss: (0.437)(R 0.379, F 0.494)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.636] [G acc: 0.062]\n",
      "5314 [D loss: (0.544)(R 0.625, F 0.463)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.720] [G acc: 0.047]\n",
      "5315 [D loss: (0.588)(R 0.583, F 0.593)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.501] [G acc: 0.094]\n",
      "5316 [D loss: (0.493)(R 0.566, F 0.421)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.503] [G acc: 0.062]\n",
      "5317 [D loss: (0.516)(R 0.614, F 0.418)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.506] [G acc: 0.094]\n",
      "5318 [D loss: (0.679)(R 0.619, F 0.738)] [D acc: (0.641)(0.609, 0.672)] [G loss: 1.449] [G acc: 0.062]\n",
      "5319 [D loss: (0.533)(R 0.608, F 0.458)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.293] [G acc: 0.266]\n",
      "5320 [D loss: (0.561)(R 0.527, F 0.595)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.373] [G acc: 0.078]\n",
      "5321 [D loss: (0.502)(R 0.520, F 0.484)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.403] [G acc: 0.062]\n",
      "5322 [D loss: (0.535)(R 0.536, F 0.534)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.467] [G acc: 0.094]\n",
      "5323 [D loss: (0.519)(R 0.545, F 0.493)] [D acc: (0.773)(0.641, 0.906)] [G loss: 1.392] [G acc: 0.047]\n",
      "5324 [D loss: (0.503)(R 0.516, F 0.491)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.490] [G acc: 0.047]\n",
      "5325 [D loss: (0.553)(R 0.605, F 0.502)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.462] [G acc: 0.109]\n",
      "5326 [D loss: (0.459)(R 0.512, F 0.407)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.464] [G acc: 0.062]\n",
      "5327 [D loss: (0.532)(R 0.517, F 0.547)] [D acc: (0.664)(0.672, 0.656)] [G loss: 1.462] [G acc: 0.078]\n",
      "5328 [D loss: (0.496)(R 0.485, F 0.506)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.489] [G acc: 0.109]\n",
      "5329 [D loss: (0.575)(R 0.626, F 0.524)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.443] [G acc: 0.062]\n",
      "5330 [D loss: (0.535)(R 0.589, F 0.481)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.309] [G acc: 0.141]\n",
      "5331 [D loss: (0.546)(R 0.629, F 0.463)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.244] [G acc: 0.062]\n",
      "5332 [D loss: (0.507)(R 0.472, F 0.542)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.599] [G acc: 0.078]\n",
      "5333 [D loss: (0.534)(R 0.595, F 0.474)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.413] [G acc: 0.094]\n",
      "5334 [D loss: (0.538)(R 0.428, F 0.647)] [D acc: (0.750)(0.781, 0.719)] [G loss: 1.343] [G acc: 0.125]\n",
      "5335 [D loss: (0.539)(R 0.558, F 0.519)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.476] [G acc: 0.094]\n",
      "5336 [D loss: (0.485)(R 0.498, F 0.473)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.432] [G acc: 0.078]\n",
      "5337 [D loss: (0.461)(R 0.477, F 0.444)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.438] [G acc: 0.047]\n",
      "5338 [D loss: (0.482)(R 0.446, F 0.518)] [D acc: (0.758)(0.750, 0.766)] [G loss: 1.512] [G acc: 0.000]\n",
      "5339 [D loss: (0.488)(R 0.424, F 0.551)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.469] [G acc: 0.062]\n",
      "5340 [D loss: (0.645)(R 0.825, F 0.466)] [D acc: (0.656)(0.469, 0.844)] [G loss: 1.442] [G acc: 0.078]\n",
      "5341 [D loss: (0.570)(R 0.600, F 0.540)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.233] [G acc: 0.078]\n",
      "5342 [D loss: (0.561)(R 0.504, F 0.619)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.361] [G acc: 0.062]\n",
      "5343 [D loss: (0.548)(R 0.557, F 0.540)] [D acc: (0.656)(0.609, 0.703)] [G loss: 1.403] [G acc: 0.078]\n",
      "5344 [D loss: (0.552)(R 0.593, F 0.510)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.358] [G acc: 0.062]\n",
      "5345 [D loss: (0.485)(R 0.438, F 0.531)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.553] [G acc: 0.047]\n",
      "5346 [D loss: (0.516)(R 0.570, F 0.461)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.322] [G acc: 0.109]\n",
      "5347 [D loss: (0.556)(R 0.542, F 0.570)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.280] [G acc: 0.156]\n",
      "5348 [D loss: (0.419)(R 0.359, F 0.479)] [D acc: (0.820)(0.797, 0.844)] [G loss: 1.312] [G acc: 0.125]\n",
      "5349 [D loss: (0.608)(R 0.476, F 0.740)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.445] [G acc: 0.125]\n",
      "5350 [D loss: (0.482)(R 0.553, F 0.411)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.484] [G acc: 0.062]\n",
      "5351 [D loss: (0.536)(R 0.462, F 0.611)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.419] [G acc: 0.078]\n",
      "5352 [D loss: (0.516)(R 0.573, F 0.458)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.389] [G acc: 0.062]\n",
      "5353 [D loss: (0.564)(R 0.604, F 0.525)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.447] [G acc: 0.156]\n",
      "5354 [D loss: (0.494)(R 0.515, F 0.472)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.527] [G acc: 0.031]\n",
      "5355 [D loss: (0.518)(R 0.583, F 0.453)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.511] [G acc: 0.062]\n",
      "5356 [D loss: (0.541)(R 0.604, F 0.478)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.366] [G acc: 0.078]\n",
      "5357 [D loss: (0.514)(R 0.558, F 0.470)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.510] [G acc: 0.141]\n",
      "5358 [D loss: (0.532)(R 0.464, F 0.600)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.496] [G acc: 0.141]\n",
      "5359 [D loss: (0.465)(R 0.453, F 0.477)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.442] [G acc: 0.062]\n",
      "5360 [D loss: (0.460)(R 0.401, F 0.519)] [D acc: (0.789)(0.828, 0.750)] [G loss: 1.561] [G acc: 0.047]\n",
      "5361 [D loss: (0.481)(R 0.519, F 0.442)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.557] [G acc: 0.062]\n",
      "5362 [D loss: (0.502)(R 0.481, F 0.522)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.499] [G acc: 0.078]\n",
      "5363 [D loss: (0.573)(R 0.577, F 0.569)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.680] [G acc: 0.078]\n",
      "5364 [D loss: (0.616)(R 0.720, F 0.512)] [D acc: (0.672)(0.562, 0.781)] [G loss: 1.545] [G acc: 0.062]\n",
      "5365 [D loss: (0.472)(R 0.469, F 0.476)] [D acc: (0.836)(0.797, 0.875)] [G loss: 1.336] [G acc: 0.156]\n",
      "5366 [D loss: (0.443)(R 0.482, F 0.404)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.401] [G acc: 0.125]\n",
      "5367 [D loss: (0.454)(R 0.454, F 0.454)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.476] [G acc: 0.047]\n",
      "5368 [D loss: (0.508)(R 0.463, F 0.553)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.485] [G acc: 0.109]\n",
      "5369 [D loss: (0.582)(R 0.646, F 0.518)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.537] [G acc: 0.078]\n",
      "5370 [D loss: (0.540)(R 0.619, F 0.461)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.506] [G acc: 0.016]\n",
      "5371 [D loss: (0.479)(R 0.537, F 0.422)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.503] [G acc: 0.094]\n",
      "5372 [D loss: (0.487)(R 0.501, F 0.472)] [D acc: (0.836)(0.766, 0.906)] [G loss: 1.789] [G acc: 0.156]\n",
      "5373 [D loss: (0.685)(R 0.723, F 0.647)] [D acc: (0.633)(0.531, 0.734)] [G loss: 1.398] [G acc: 0.094]\n",
      "5374 [D loss: (0.599)(R 0.603, F 0.594)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.359] [G acc: 0.047]\n",
      "5375 [D loss: (0.522)(R 0.646, F 0.398)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.364] [G acc: 0.109]\n",
      "5376 [D loss: (0.580)(R 0.544, F 0.616)] [D acc: (0.711)(0.734, 0.688)] [G loss: 1.410] [G acc: 0.062]\n",
      "5377 [D loss: (0.615)(R 0.784, F 0.446)] [D acc: (0.672)(0.531, 0.812)] [G loss: 1.420] [G acc: 0.094]\n",
      "5378 [D loss: (0.442)(R 0.465, F 0.418)] [D acc: (0.805)(0.734, 0.875)] [G loss: 1.286] [G acc: 0.141]\n",
      "5379 [D loss: (0.534)(R 0.495, F 0.573)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.380] [G acc: 0.078]\n",
      "5380 [D loss: (0.649)(R 0.721, F 0.576)] [D acc: (0.648)(0.531, 0.766)] [G loss: 1.471] [G acc: 0.047]\n",
      "5381 [D loss: (0.508)(R 0.566, F 0.450)] [D acc: (0.742)(0.641, 0.844)] [G loss: 1.491] [G acc: 0.141]\n",
      "5382 [D loss: (0.588)(R 0.718, F 0.458)] [D acc: (0.656)(0.484, 0.828)] [G loss: 1.240] [G acc: 0.078]\n",
      "5383 [D loss: (0.485)(R 0.395, F 0.575)] [D acc: (0.750)(0.797, 0.703)] [G loss: 1.537] [G acc: 0.078]\n",
      "5384 [D loss: (0.527)(R 0.664, F 0.389)] [D acc: (0.758)(0.594, 0.922)] [G loss: 1.405] [G acc: 0.141]\n",
      "5385 [D loss: (0.511)(R 0.457, F 0.566)] [D acc: (0.805)(0.750, 0.859)] [G loss: 1.512] [G acc: 0.047]\n",
      "5386 [D loss: (0.572)(R 0.548, F 0.596)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.371] [G acc: 0.109]\n",
      "5387 [D loss: (0.564)(R 0.714, F 0.415)] [D acc: (0.695)(0.516, 0.875)] [G loss: 1.365] [G acc: 0.078]\n",
      "5388 [D loss: (0.452)(R 0.446, F 0.457)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.449] [G acc: 0.047]\n",
      "5389 [D loss: (0.579)(R 0.581, F 0.577)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.400] [G acc: 0.062]\n",
      "5390 [D loss: (0.570)(R 0.631, F 0.510)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.429] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5391 [D loss: (0.456)(R 0.459, F 0.452)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.335] [G acc: 0.125]\n",
      "5392 [D loss: (0.540)(R 0.520, F 0.559)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.367] [G acc: 0.125]\n",
      "5393 [D loss: (0.570)(R 0.629, F 0.512)] [D acc: (0.688)(0.578, 0.797)] [G loss: 1.430] [G acc: 0.078]\n",
      "5394 [D loss: (0.545)(R 0.515, F 0.576)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.474] [G acc: 0.094]\n",
      "5395 [D loss: (0.529)(R 0.567, F 0.491)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.470] [G acc: 0.109]\n",
      "5396 [D loss: (0.505)(R 0.569, F 0.441)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.302] [G acc: 0.125]\n",
      "5397 [D loss: (0.512)(R 0.461, F 0.563)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.314] [G acc: 0.141]\n",
      "5398 [D loss: (0.560)(R 0.527, F 0.592)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.483] [G acc: 0.031]\n",
      "5399 [D loss: (0.536)(R 0.600, F 0.471)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.343] [G acc: 0.078]\n",
      "5400 [D loss: (0.489)(R 0.560, F 0.418)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.367] [G acc: 0.141]\n",
      "5401 [D loss: (0.436)(R 0.439, F 0.434)] [D acc: (0.820)(0.766, 0.875)] [G loss: 1.387] [G acc: 0.094]\n",
      "5402 [D loss: (0.459)(R 0.470, F 0.449)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.560] [G acc: 0.062]\n",
      "5403 [D loss: (0.529)(R 0.549, F 0.508)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.525] [G acc: 0.094]\n",
      "5404 [D loss: (0.530)(R 0.600, F 0.461)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.556] [G acc: 0.016]\n",
      "5405 [D loss: (0.499)(R 0.506, F 0.493)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.303] [G acc: 0.188]\n",
      "5406 [D loss: (0.526)(R 0.527, F 0.525)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.455] [G acc: 0.109]\n",
      "5407 [D loss: (0.564)(R 0.600, F 0.528)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.592] [G acc: 0.094]\n",
      "5408 [D loss: (0.548)(R 0.640, F 0.456)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.454] [G acc: 0.094]\n",
      "5409 [D loss: (0.501)(R 0.486, F 0.516)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.375] [G acc: 0.047]\n",
      "5410 [D loss: (0.515)(R 0.572, F 0.459)] [D acc: (0.727)(0.594, 0.859)] [G loss: 1.531] [G acc: 0.078]\n",
      "5411 [D loss: (0.513)(R 0.537, F 0.488)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.418] [G acc: 0.062]\n",
      "5412 [D loss: (0.572)(R 0.624, F 0.520)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.415] [G acc: 0.062]\n",
      "5413 [D loss: (0.543)(R 0.537, F 0.548)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.413] [G acc: 0.125]\n",
      "5414 [D loss: (0.453)(R 0.402, F 0.504)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.413] [G acc: 0.078]\n",
      "5415 [D loss: (0.572)(R 0.478, F 0.665)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.397] [G acc: 0.094]\n",
      "5416 [D loss: (0.486)(R 0.484, F 0.488)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.581] [G acc: 0.062]\n",
      "5417 [D loss: (0.479)(R 0.459, F 0.499)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.626] [G acc: 0.016]\n",
      "5418 [D loss: (0.449)(R 0.440, F 0.459)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.385] [G acc: 0.016]\n",
      "5419 [D loss: (0.506)(R 0.504, F 0.507)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.417] [G acc: 0.062]\n",
      "5420 [D loss: (0.506)(R 0.558, F 0.453)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.563] [G acc: 0.109]\n",
      "5421 [D loss: (0.488)(R 0.469, F 0.508)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.528] [G acc: 0.031]\n",
      "5422 [D loss: (0.453)(R 0.535, F 0.372)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.592] [G acc: 0.109]\n",
      "5423 [D loss: (0.601)(R 0.652, F 0.550)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.494] [G acc: 0.047]\n",
      "5424 [D loss: (0.568)(R 0.612, F 0.524)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.365] [G acc: 0.125]\n",
      "5425 [D loss: (0.553)(R 0.519, F 0.587)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.388] [G acc: 0.047]\n",
      "5426 [D loss: (0.426)(R 0.478, F 0.373)] [D acc: (0.812)(0.703, 0.922)] [G loss: 1.448] [G acc: 0.078]\n",
      "5427 [D loss: (0.524)(R 0.511, F 0.536)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.522] [G acc: 0.047]\n",
      "5428 [D loss: (0.498)(R 0.550, F 0.446)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.354] [G acc: 0.094]\n",
      "5429 [D loss: (0.490)(R 0.403, F 0.578)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.518] [G acc: 0.078]\n",
      "5430 [D loss: (0.621)(R 0.682, F 0.559)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.583] [G acc: 0.094]\n",
      "5431 [D loss: (0.436)(R 0.406, F 0.467)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.392] [G acc: 0.188]\n",
      "5432 [D loss: (0.556)(R 0.616, F 0.497)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.609] [G acc: 0.078]\n",
      "5433 [D loss: (0.516)(R 0.540, F 0.492)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.572] [G acc: 0.125]\n",
      "5434 [D loss: (0.421)(R 0.416, F 0.426)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.558] [G acc: 0.109]\n",
      "5435 [D loss: (0.522)(R 0.460, F 0.584)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.364] [G acc: 0.094]\n",
      "5436 [D loss: (0.377)(R 0.367, F 0.388)] [D acc: (0.820)(0.797, 0.844)] [G loss: 1.469] [G acc: 0.078]\n",
      "5437 [D loss: (0.526)(R 0.404, F 0.648)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.597] [G acc: 0.031]\n",
      "5438 [D loss: (0.745)(R 0.725, F 0.764)] [D acc: (0.641)(0.594, 0.688)] [G loss: 1.361] [G acc: 0.078]\n",
      "5439 [D loss: (0.456)(R 0.535, F 0.378)] [D acc: (0.820)(0.734, 0.906)] [G loss: 1.367] [G acc: 0.094]\n",
      "5440 [D loss: (0.514)(R 0.559, F 0.470)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.265] [G acc: 0.141]\n",
      "5441 [D loss: (0.537)(R 0.553, F 0.521)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.344] [G acc: 0.078]\n",
      "5442 [D loss: (0.543)(R 0.525, F 0.562)] [D acc: (0.641)(0.609, 0.672)] [G loss: 1.348] [G acc: 0.094]\n",
      "5443 [D loss: (0.603)(R 0.577, F 0.628)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.428] [G acc: 0.047]\n",
      "5444 [D loss: (0.500)(R 0.485, F 0.515)] [D acc: (0.758)(0.672, 0.844)] [G loss: 1.332] [G acc: 0.125]\n",
      "5445 [D loss: (0.465)(R 0.399, F 0.531)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.664] [G acc: 0.062]\n",
      "5446 [D loss: (0.499)(R 0.506, F 0.491)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.501] [G acc: 0.062]\n",
      "5447 [D loss: (0.497)(R 0.533, F 0.462)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.502] [G acc: 0.062]\n",
      "5448 [D loss: (0.524)(R 0.595, F 0.453)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.571] [G acc: 0.094]\n",
      "5449 [D loss: (0.480)(R 0.535, F 0.425)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.385] [G acc: 0.078]\n",
      "5450 [D loss: (0.574)(R 0.502, F 0.646)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.404] [G acc: 0.156]\n",
      "5451 [D loss: (0.611)(R 0.719, F 0.502)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.489] [G acc: 0.031]\n",
      "5452 [D loss: (0.589)(R 0.637, F 0.541)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.318] [G acc: 0.062]\n",
      "5453 [D loss: (0.565)(R 0.591, F 0.538)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.394] [G acc: 0.078]\n",
      "5454 [D loss: (0.533)(R 0.591, F 0.474)] [D acc: (0.688)(0.562, 0.812)] [G loss: 1.465] [G acc: 0.109]\n",
      "5455 [D loss: (0.530)(R 0.472, F 0.588)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.366] [G acc: 0.094]\n",
      "5456 [D loss: (0.522)(R 0.594, F 0.450)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.376] [G acc: 0.109]\n",
      "5457 [D loss: (0.574)(R 0.389, F 0.759)] [D acc: (0.758)(0.781, 0.734)] [G loss: 1.444] [G acc: 0.094]\n",
      "5458 [D loss: (0.553)(R 0.697, F 0.409)] [D acc: (0.672)(0.484, 0.859)] [G loss: 1.379] [G acc: 0.125]\n",
      "5459 [D loss: (0.568)(R 0.613, F 0.524)] [D acc: (0.711)(0.609, 0.812)] [G loss: 1.299] [G acc: 0.094]\n",
      "5460 [D loss: (0.542)(R 0.633, F 0.450)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.318] [G acc: 0.141]\n",
      "5461 [D loss: (0.596)(R 0.520, F 0.672)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.445] [G acc: 0.078]\n",
      "5462 [D loss: (0.576)(R 0.695, F 0.457)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.350] [G acc: 0.125]\n",
      "5463 [D loss: (0.547)(R 0.546, F 0.547)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.456] [G acc: 0.094]\n",
      "5464 [D loss: (0.503)(R 0.556, F 0.450)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.367] [G acc: 0.109]\n",
      "5465 [D loss: (0.479)(R 0.520, F 0.439)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.491] [G acc: 0.094]\n",
      "5466 [D loss: (0.480)(R 0.566, F 0.394)] [D acc: (0.797)(0.688, 0.906)] [G loss: 1.418] [G acc: 0.141]\n",
      "5467 [D loss: (0.548)(R 0.520, F 0.576)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.382] [G acc: 0.094]\n",
      "5468 [D loss: (0.522)(R 0.561, F 0.484)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.464] [G acc: 0.109]\n",
      "5469 [D loss: (0.552)(R 0.417, F 0.688)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.560] [G acc: 0.062]\n",
      "5470 [D loss: (0.576)(R 0.679, F 0.472)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.461] [G acc: 0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5471 [D loss: (0.491)(R 0.472, F 0.511)] [D acc: (0.781)(0.781, 0.781)] [G loss: 1.512] [G acc: 0.094]\n",
      "5472 [D loss: (0.470)(R 0.448, F 0.492)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.561] [G acc: 0.078]\n",
      "5473 [D loss: (0.463)(R 0.474, F 0.452)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.392] [G acc: 0.188]\n",
      "5474 [D loss: (0.582)(R 0.658, F 0.505)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.433] [G acc: 0.125]\n",
      "5475 [D loss: (0.553)(R 0.529, F 0.577)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.547] [G acc: 0.047]\n",
      "5476 [D loss: (0.428)(R 0.384, F 0.472)] [D acc: (0.805)(0.781, 0.828)] [G loss: 1.523] [G acc: 0.109]\n",
      "5477 [D loss: (0.513)(R 0.526, F 0.501)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.659] [G acc: 0.062]\n",
      "5478 [D loss: (0.454)(R 0.489, F 0.419)] [D acc: (0.797)(0.703, 0.891)] [G loss: 1.680] [G acc: 0.047]\n",
      "5479 [D loss: (0.550)(R 0.631, F 0.468)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.564] [G acc: 0.078]\n",
      "5480 [D loss: (0.480)(R 0.548, F 0.411)] [D acc: (0.781)(0.656, 0.906)] [G loss: 1.545] [G acc: 0.094]\n",
      "5481 [D loss: (0.589)(R 0.600, F 0.578)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.525] [G acc: 0.031]\n",
      "5482 [D loss: (0.529)(R 0.626, F 0.432)] [D acc: (0.695)(0.578, 0.812)] [G loss: 1.596] [G acc: 0.078]\n",
      "5483 [D loss: (0.424)(R 0.335, F 0.514)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.539] [G acc: 0.094]\n",
      "5484 [D loss: (0.530)(R 0.531, F 0.528)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.647] [G acc: 0.062]\n",
      "5485 [D loss: (0.483)(R 0.527, F 0.439)] [D acc: (0.797)(0.703, 0.891)] [G loss: 1.506] [G acc: 0.109]\n",
      "5486 [D loss: (0.490)(R 0.435, F 0.544)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.616] [G acc: 0.078]\n",
      "5487 [D loss: (0.422)(R 0.438, F 0.405)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.510] [G acc: 0.078]\n",
      "5488 [D loss: (0.560)(R 0.564, F 0.557)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.433] [G acc: 0.125]\n",
      "5489 [D loss: (0.526)(R 0.637, F 0.415)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.482] [G acc: 0.125]\n",
      "5490 [D loss: (0.493)(R 0.395, F 0.590)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.230] [G acc: 0.219]\n",
      "5491 [D loss: (0.507)(R 0.605, F 0.409)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.519] [G acc: 0.141]\n",
      "5492 [D loss: (0.481)(R 0.430, F 0.532)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.449] [G acc: 0.078]\n",
      "5493 [D loss: (0.525)(R 0.653, F 0.397)] [D acc: (0.773)(0.656, 0.891)] [G loss: 1.594] [G acc: 0.125]\n",
      "5494 [D loss: (0.440)(R 0.408, F 0.473)] [D acc: (0.789)(0.781, 0.797)] [G loss: 1.519] [G acc: 0.062]\n",
      "5495 [D loss: (0.585)(R 0.568, F 0.603)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.545] [G acc: 0.109]\n",
      "5496 [D loss: (0.466)(R 0.502, F 0.431)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.429] [G acc: 0.203]\n",
      "5497 [D loss: (0.518)(R 0.504, F 0.533)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.676] [G acc: 0.031]\n",
      "5498 [D loss: (0.512)(R 0.566, F 0.458)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.546] [G acc: 0.125]\n",
      "5499 [D loss: (0.491)(R 0.483, F 0.498)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.544] [G acc: 0.078]\n",
      "5500 [D loss: (0.500)(R 0.514, F 0.487)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.600] [G acc: 0.094]\n",
      "5501 [D loss: (0.567)(R 0.482, F 0.652)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.541] [G acc: 0.078]\n",
      "5502 [D loss: (0.494)(R 0.600, F 0.389)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.460] [G acc: 0.078]\n",
      "5503 [D loss: (0.472)(R 0.440, F 0.503)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.585] [G acc: 0.031]\n",
      "5504 [D loss: (0.375)(R 0.370, F 0.380)] [D acc: (0.852)(0.812, 0.891)] [G loss: 1.581] [G acc: 0.109]\n",
      "5505 [D loss: (0.503)(R 0.464, F 0.542)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.561] [G acc: 0.078]\n",
      "5506 [D loss: (0.514)(R 0.571, F 0.456)] [D acc: (0.820)(0.750, 0.891)] [G loss: 1.457] [G acc: 0.094]\n",
      "5507 [D loss: (0.507)(R 0.531, F 0.483)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.383] [G acc: 0.172]\n",
      "5508 [D loss: (0.525)(R 0.511, F 0.539)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.428] [G acc: 0.094]\n",
      "5509 [D loss: (0.518)(R 0.492, F 0.544)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.400] [G acc: 0.094]\n",
      "5510 [D loss: (0.498)(R 0.550, F 0.446)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.515] [G acc: 0.156]\n",
      "5511 [D loss: (0.500)(R 0.470, F 0.531)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.357] [G acc: 0.250]\n",
      "5512 [D loss: (0.552)(R 0.499, F 0.604)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.628] [G acc: 0.109]\n",
      "5513 [D loss: (0.515)(R 0.572, F 0.457)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.593] [G acc: 0.141]\n",
      "5514 [D loss: (0.474)(R 0.485, F 0.463)] [D acc: (0.836)(0.781, 0.891)] [G loss: 1.667] [G acc: 0.125]\n",
      "5515 [D loss: (0.455)(R 0.421, F 0.488)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.515] [G acc: 0.141]\n",
      "5516 [D loss: (0.507)(R 0.526, F 0.489)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.704] [G acc: 0.047]\n",
      "5517 [D loss: (0.583)(R 0.628, F 0.538)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.617] [G acc: 0.047]\n",
      "5518 [D loss: (0.625)(R 0.516, F 0.734)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.544] [G acc: 0.047]\n",
      "5519 [D loss: (0.611)(R 0.735, F 0.486)] [D acc: (0.680)(0.547, 0.812)] [G loss: 1.512] [G acc: 0.094]\n",
      "5520 [D loss: (0.489)(R 0.504, F 0.475)] [D acc: (0.797)(0.781, 0.812)] [G loss: 1.464] [G acc: 0.078]\n",
      "5521 [D loss: (0.465)(R 0.486, F 0.445)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.454] [G acc: 0.094]\n",
      "5522 [D loss: (0.433)(R 0.364, F 0.502)] [D acc: (0.828)(0.812, 0.844)] [G loss: 1.469] [G acc: 0.156]\n",
      "5523 [D loss: (0.579)(R 0.601, F 0.558)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.384] [G acc: 0.094]\n",
      "5524 [D loss: (0.507)(R 0.545, F 0.469)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.539] [G acc: 0.094]\n",
      "5525 [D loss: (0.533)(R 0.526, F 0.540)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.588] [G acc: 0.062]\n",
      "5526 [D loss: (0.540)(R 0.482, F 0.597)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.626] [G acc: 0.062]\n",
      "5527 [D loss: (0.551)(R 0.740, F 0.363)] [D acc: (0.727)(0.531, 0.922)] [G loss: 1.618] [G acc: 0.125]\n",
      "5528 [D loss: (0.539)(R 0.571, F 0.508)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.409] [G acc: 0.094]\n",
      "5529 [D loss: (0.463)(R 0.447, F 0.480)] [D acc: (0.820)(0.750, 0.891)] [G loss: 1.538] [G acc: 0.047]\n",
      "5530 [D loss: (0.507)(R 0.492, F 0.523)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.396] [G acc: 0.219]\n",
      "5531 [D loss: (0.475)(R 0.491, F 0.459)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.431] [G acc: 0.094]\n",
      "5532 [D loss: (0.547)(R 0.580, F 0.515)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.413] [G acc: 0.062]\n",
      "5533 [D loss: (0.522)(R 0.586, F 0.458)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.531] [G acc: 0.078]\n",
      "5534 [D loss: (0.474)(R 0.552, F 0.397)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.521] [G acc: 0.109]\n",
      "5535 [D loss: (0.567)(R 0.445, F 0.689)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.425] [G acc: 0.047]\n",
      "5536 [D loss: (0.563)(R 0.595, F 0.531)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.362] [G acc: 0.078]\n",
      "5537 [D loss: (0.560)(R 0.645, F 0.475)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.465] [G acc: 0.000]\n",
      "5538 [D loss: (0.504)(R 0.511, F 0.498)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.421] [G acc: 0.109]\n",
      "5539 [D loss: (0.468)(R 0.493, F 0.442)] [D acc: (0.781)(0.688, 0.875)] [G loss: 1.442] [G acc: 0.062]\n",
      "5540 [D loss: (0.477)(R 0.397, F 0.556)] [D acc: (0.820)(0.797, 0.844)] [G loss: 1.461] [G acc: 0.062]\n",
      "5541 [D loss: (0.491)(R 0.495, F 0.488)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.573] [G acc: 0.078]\n",
      "5542 [D loss: (0.390)(R 0.380, F 0.399)] [D acc: (0.836)(0.797, 0.875)] [G loss: 1.656] [G acc: 0.062]\n",
      "5543 [D loss: (0.461)(R 0.500, F 0.421)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.598] [G acc: 0.078]\n",
      "5544 [D loss: (0.505)(R 0.435, F 0.576)] [D acc: (0.750)(0.766, 0.734)] [G loss: 1.660] [G acc: 0.062]\n",
      "5545 [D loss: (0.556)(R 0.627, F 0.485)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.569] [G acc: 0.062]\n",
      "5546 [D loss: (0.540)(R 0.590, F 0.490)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.694] [G acc: 0.031]\n",
      "5547 [D loss: (0.519)(R 0.474, F 0.565)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.565] [G acc: 0.031]\n",
      "5548 [D loss: (0.497)(R 0.522, F 0.472)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.529] [G acc: 0.094]\n",
      "5549 [D loss: (0.466)(R 0.409, F 0.524)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.510] [G acc: 0.094]\n",
      "5550 [D loss: (0.513)(R 0.514, F 0.512)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.448] [G acc: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5551 [D loss: (0.475)(R 0.535, F 0.416)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.590] [G acc: 0.078]\n",
      "5552 [D loss: (0.419)(R 0.478, F 0.361)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.410] [G acc: 0.172]\n",
      "5553 [D loss: (0.508)(R 0.351, F 0.664)] [D acc: (0.766)(0.844, 0.688)] [G loss: 1.751] [G acc: 0.062]\n",
      "5554 [D loss: (0.495)(R 0.624, F 0.366)] [D acc: (0.742)(0.562, 0.922)] [G loss: 1.466] [G acc: 0.062]\n",
      "5555 [D loss: (0.575)(R 0.590, F 0.560)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.463] [G acc: 0.094]\n",
      "5556 [D loss: (0.539)(R 0.456, F 0.623)] [D acc: (0.727)(0.766, 0.688)] [G loss: 1.547] [G acc: 0.094]\n",
      "5557 [D loss: (0.592)(R 0.562, F 0.623)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.574] [G acc: 0.078]\n",
      "5558 [D loss: (0.554)(R 0.682, F 0.427)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.338] [G acc: 0.078]\n",
      "5559 [D loss: (0.602)(R 0.626, F 0.578)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.295] [G acc: 0.125]\n",
      "5560 [D loss: (0.551)(R 0.635, F 0.466)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.353] [G acc: 0.094]\n",
      "5561 [D loss: (0.466)(R 0.464, F 0.468)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.514] [G acc: 0.031]\n",
      "5562 [D loss: (0.514)(R 0.559, F 0.469)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.317] [G acc: 0.094]\n",
      "5563 [D loss: (0.428)(R 0.500, F 0.355)] [D acc: (0.828)(0.719, 0.938)] [G loss: 1.401] [G acc: 0.078]\n",
      "5564 [D loss: (0.572)(R 0.605, F 0.539)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.609] [G acc: 0.047]\n",
      "5565 [D loss: (0.506)(R 0.490, F 0.522)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.533] [G acc: 0.047]\n",
      "5566 [D loss: (0.482)(R 0.486, F 0.479)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.562] [G acc: 0.109]\n",
      "5567 [D loss: (0.523)(R 0.433, F 0.613)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.649] [G acc: 0.047]\n",
      "5568 [D loss: (0.545)(R 0.697, F 0.393)] [D acc: (0.711)(0.547, 0.875)] [G loss: 1.554] [G acc: 0.078]\n",
      "5569 [D loss: (0.482)(R 0.565, F 0.400)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.474] [G acc: 0.094]\n",
      "5570 [D loss: (0.554)(R 0.567, F 0.542)] [D acc: (0.695)(0.672, 0.719)] [G loss: 1.443] [G acc: 0.078]\n",
      "5571 [D loss: (0.491)(R 0.474, F 0.507)] [D acc: (0.812)(0.688, 0.938)] [G loss: 1.492] [G acc: 0.078]\n",
      "5572 [D loss: (0.635)(R 0.505, F 0.765)] [D acc: (0.719)(0.719, 0.719)] [G loss: 1.545] [G acc: 0.031]\n",
      "5573 [D loss: (0.586)(R 0.697, F 0.474)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.337] [G acc: 0.094]\n",
      "5574 [D loss: (0.536)(R 0.573, F 0.498)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.627] [G acc: 0.000]\n",
      "5575 [D loss: (0.543)(R 0.605, F 0.482)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.405] [G acc: 0.141]\n",
      "5576 [D loss: (0.507)(R 0.480, F 0.535)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.324] [G acc: 0.125]\n",
      "5577 [D loss: (0.579)(R 0.613, F 0.545)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.266] [G acc: 0.172]\n",
      "5578 [D loss: (0.548)(R 0.478, F 0.619)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.714] [G acc: 0.047]\n",
      "5579 [D loss: (0.539)(R 0.577, F 0.502)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.429] [G acc: 0.109]\n",
      "5580 [D loss: (0.439)(R 0.511, F 0.367)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.653] [G acc: 0.062]\n",
      "5581 [D loss: (0.529)(R 0.442, F 0.615)] [D acc: (0.773)(0.781, 0.766)] [G loss: 1.488] [G acc: 0.062]\n",
      "5582 [D loss: (0.506)(R 0.452, F 0.560)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.545] [G acc: 0.031]\n",
      "5583 [D loss: (0.552)(R 0.647, F 0.457)] [D acc: (0.656)(0.531, 0.781)] [G loss: 1.369] [G acc: 0.125]\n",
      "5584 [D loss: (0.557)(R 0.581, F 0.533)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.587] [G acc: 0.062]\n",
      "5585 [D loss: (0.535)(R 0.522, F 0.548)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.480] [G acc: 0.078]\n",
      "5586 [D loss: (0.530)(R 0.531, F 0.528)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.395] [G acc: 0.094]\n",
      "5587 [D loss: (0.494)(R 0.547, F 0.440)] [D acc: (0.797)(0.672, 0.922)] [G loss: 1.236] [G acc: 0.141]\n",
      "5588 [D loss: (0.522)(R 0.517, F 0.528)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.401] [G acc: 0.156]\n",
      "5589 [D loss: (0.532)(R 0.488, F 0.577)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.497] [G acc: 0.094]\n",
      "5590 [D loss: (0.468)(R 0.457, F 0.480)] [D acc: (0.781)(0.750, 0.812)] [G loss: 1.421] [G acc: 0.125]\n",
      "5591 [D loss: (0.503)(R 0.577, F 0.430)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.515] [G acc: 0.062]\n",
      "5592 [D loss: (0.488)(R 0.519, F 0.457)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.509] [G acc: 0.094]\n",
      "5593 [D loss: (0.526)(R 0.541, F 0.511)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.387] [G acc: 0.078]\n",
      "5594 [D loss: (0.533)(R 0.592, F 0.475)] [D acc: (0.703)(0.594, 0.812)] [G loss: 1.651] [G acc: 0.078]\n",
      "5595 [D loss: (0.511)(R 0.517, F 0.505)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.430] [G acc: 0.094]\n",
      "5596 [D loss: (0.497)(R 0.526, F 0.469)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.499] [G acc: 0.078]\n",
      "5597 [D loss: (0.598)(R 0.494, F 0.701)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.566] [G acc: 0.047]\n",
      "5598 [D loss: (0.589)(R 0.708, F 0.470)] [D acc: (0.672)(0.484, 0.859)] [G loss: 1.465] [G acc: 0.094]\n",
      "5599 [D loss: (0.542)(R 0.583, F 0.501)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.238] [G acc: 0.141]\n",
      "5600 [D loss: (0.527)(R 0.510, F 0.544)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.402] [G acc: 0.078]\n",
      "5601 [D loss: (0.547)(R 0.516, F 0.578)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.346] [G acc: 0.156]\n",
      "5602 [D loss: (0.490)(R 0.485, F 0.496)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.422] [G acc: 0.109]\n",
      "5603 [D loss: (0.534)(R 0.542, F 0.526)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.416] [G acc: 0.125]\n",
      "5604 [D loss: (0.532)(R 0.599, F 0.465)] [D acc: (0.695)(0.609, 0.781)] [G loss: 1.364] [G acc: 0.094]\n",
      "5605 [D loss: (0.554)(R 0.576, F 0.531)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.399] [G acc: 0.125]\n",
      "5606 [D loss: (0.457)(R 0.471, F 0.444)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.388] [G acc: 0.125]\n",
      "5607 [D loss: (0.487)(R 0.518, F 0.456)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.459] [G acc: 0.094]\n",
      "5608 [D loss: (0.531)(R 0.616, F 0.446)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.228] [G acc: 0.141]\n",
      "5609 [D loss: (0.498)(R 0.479, F 0.517)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.668] [G acc: 0.094]\n",
      "5610 [D loss: (0.468)(R 0.502, F 0.435)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.387] [G acc: 0.109]\n",
      "5611 [D loss: (0.610)(R 0.540, F 0.680)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.559] [G acc: 0.078]\n",
      "5612 [D loss: (0.479)(R 0.511, F 0.447)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.564] [G acc: 0.094]\n",
      "5613 [D loss: (0.615)(R 0.652, F 0.578)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.428] [G acc: 0.078]\n",
      "5614 [D loss: (0.485)(R 0.540, F 0.430)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.508] [G acc: 0.094]\n",
      "5615 [D loss: (0.486)(R 0.443, F 0.530)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.563] [G acc: 0.047]\n",
      "5616 [D loss: (0.572)(R 0.522, F 0.622)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.386] [G acc: 0.125]\n",
      "5617 [D loss: (0.635)(R 0.688, F 0.582)] [D acc: (0.719)(0.594, 0.844)] [G loss: 1.471] [G acc: 0.047]\n",
      "5618 [D loss: (0.532)(R 0.555, F 0.509)] [D acc: (0.719)(0.656, 0.781)] [G loss: 1.528] [G acc: 0.078]\n",
      "5619 [D loss: (0.598)(R 0.587, F 0.609)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.432] [G acc: 0.078]\n",
      "5620 [D loss: (0.530)(R 0.624, F 0.435)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.374] [G acc: 0.125]\n",
      "5621 [D loss: (0.478)(R 0.473, F 0.482)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.392] [G acc: 0.109]\n",
      "5622 [D loss: (0.563)(R 0.558, F 0.568)] [D acc: (0.680)(0.641, 0.719)] [G loss: 1.161] [G acc: 0.109]\n",
      "5623 [D loss: (0.472)(R 0.528, F 0.417)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.430] [G acc: 0.094]\n",
      "5624 [D loss: (0.524)(R 0.480, F 0.567)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.405] [G acc: 0.125]\n",
      "5625 [D loss: (0.498)(R 0.498, F 0.497)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.416] [G acc: 0.125]\n",
      "5626 [D loss: (0.443)(R 0.441, F 0.446)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.416] [G acc: 0.141]\n",
      "5627 [D loss: (0.507)(R 0.458, F 0.555)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.552] [G acc: 0.062]\n",
      "5628 [D loss: (0.486)(R 0.567, F 0.404)] [D acc: (0.766)(0.641, 0.891)] [G loss: 1.511] [G acc: 0.078]\n",
      "5629 [D loss: (0.476)(R 0.544, F 0.408)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.549] [G acc: 0.062]\n",
      "5630 [D loss: (0.420)(R 0.443, F 0.397)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.369] [G acc: 0.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5631 [D loss: (0.499)(R 0.562, F 0.436)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.509] [G acc: 0.047]\n",
      "5632 [D loss: (0.480)(R 0.549, F 0.412)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.522] [G acc: 0.203]\n",
      "5633 [D loss: (0.460)(R 0.413, F 0.508)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.493] [G acc: 0.062]\n",
      "5634 [D loss: (0.571)(R 0.616, F 0.525)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.516] [G acc: 0.094]\n",
      "5635 [D loss: (0.515)(R 0.450, F 0.581)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.587] [G acc: 0.094]\n",
      "5636 [D loss: (0.613)(R 0.554, F 0.672)] [D acc: (0.688)(0.672, 0.703)] [G loss: 1.654] [G acc: 0.078]\n",
      "5637 [D loss: (0.491)(R 0.484, F 0.498)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.736] [G acc: 0.047]\n",
      "5638 [D loss: (0.595)(R 0.749, F 0.441)] [D acc: (0.695)(0.531, 0.859)] [G loss: 1.568] [G acc: 0.047]\n",
      "5639 [D loss: (0.555)(R 0.595, F 0.515)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.589] [G acc: 0.031]\n",
      "5640 [D loss: (0.459)(R 0.449, F 0.470)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.516] [G acc: 0.094]\n",
      "5641 [D loss: (0.471)(R 0.525, F 0.418)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.466] [G acc: 0.125]\n",
      "5642 [D loss: (0.566)(R 0.475, F 0.656)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.587] [G acc: 0.047]\n",
      "5643 [D loss: (0.623)(R 0.791, F 0.455)] [D acc: (0.672)(0.516, 0.828)] [G loss: 1.385] [G acc: 0.078]\n",
      "5644 [D loss: (0.478)(R 0.432, F 0.524)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.339] [G acc: 0.078]\n",
      "5645 [D loss: (0.475)(R 0.481, F 0.470)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.268] [G acc: 0.156]\n",
      "5646 [D loss: (0.485)(R 0.489, F 0.481)] [D acc: (0.781)(0.703, 0.859)] [G loss: 1.412] [G acc: 0.094]\n",
      "5647 [D loss: (0.607)(R 0.512, F 0.701)] [D acc: (0.672)(0.688, 0.656)] [G loss: 1.531] [G acc: 0.047]\n",
      "5648 [D loss: (0.592)(R 0.667, F 0.518)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.438] [G acc: 0.078]\n",
      "5649 [D loss: (0.579)(R 0.662, F 0.496)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.461] [G acc: 0.047]\n",
      "5650 [D loss: (0.570)(R 0.663, F 0.477)] [D acc: (0.711)(0.547, 0.875)] [G loss: 1.548] [G acc: 0.047]\n",
      "5651 [D loss: (0.468)(R 0.526, F 0.409)] [D acc: (0.773)(0.641, 0.906)] [G loss: 1.453] [G acc: 0.047]\n",
      "5652 [D loss: (0.487)(R 0.509, F 0.465)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.420] [G acc: 0.094]\n",
      "5653 [D loss: (0.553)(R 0.707, F 0.398)] [D acc: (0.742)(0.578, 0.906)] [G loss: 1.432] [G acc: 0.141]\n",
      "5654 [D loss: (0.515)(R 0.432, F 0.598)] [D acc: (0.742)(0.797, 0.688)] [G loss: 1.535] [G acc: 0.031]\n",
      "5655 [D loss: (0.567)(R 0.518, F 0.616)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.458] [G acc: 0.109]\n",
      "5656 [D loss: (0.582)(R 0.649, F 0.514)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.617] [G acc: 0.031]\n",
      "5657 [D loss: (0.590)(R 0.730, F 0.451)] [D acc: (0.664)(0.500, 0.828)] [G loss: 1.384] [G acc: 0.109]\n",
      "5658 [D loss: (0.558)(R 0.478, F 0.638)] [D acc: (0.680)(0.703, 0.656)] [G loss: 1.436] [G acc: 0.078]\n",
      "5659 [D loss: (0.487)(R 0.548, F 0.426)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.343] [G acc: 0.094]\n",
      "5660 [D loss: (0.503)(R 0.522, F 0.484)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.459] [G acc: 0.078]\n",
      "5661 [D loss: (0.551)(R 0.649, F 0.453)] [D acc: (0.703)(0.547, 0.859)] [G loss: 1.353] [G acc: 0.125]\n",
      "5662 [D loss: (0.491)(R 0.443, F 0.538)] [D acc: (0.742)(0.750, 0.734)] [G loss: 1.304] [G acc: 0.172]\n",
      "5663 [D loss: (0.538)(R 0.415, F 0.662)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.473] [G acc: 0.094]\n",
      "5664 [D loss: (0.392)(R 0.427, F 0.357)] [D acc: (0.852)(0.766, 0.938)] [G loss: 1.488] [G acc: 0.078]\n",
      "5665 [D loss: (0.477)(R 0.458, F 0.495)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.441] [G acc: 0.062]\n",
      "5666 [D loss: (0.487)(R 0.469, F 0.504)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.389] [G acc: 0.109]\n",
      "5667 [D loss: (0.569)(R 0.491, F 0.647)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.478] [G acc: 0.047]\n",
      "5668 [D loss: (0.500)(R 0.491, F 0.508)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.581] [G acc: 0.047]\n",
      "5669 [D loss: (0.521)(R 0.621, F 0.421)] [D acc: (0.750)(0.609, 0.891)] [G loss: 1.548] [G acc: 0.094]\n",
      "5670 [D loss: (0.507)(R 0.622, F 0.391)] [D acc: (0.766)(0.625, 0.906)] [G loss: 1.461] [G acc: 0.078]\n",
      "5671 [D loss: (0.592)(R 0.559, F 0.625)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.436] [G acc: 0.094]\n",
      "5672 [D loss: (0.522)(R 0.538, F 0.506)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.419] [G acc: 0.125]\n",
      "5673 [D loss: (0.494)(R 0.472, F 0.516)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.545] [G acc: 0.062]\n",
      "5674 [D loss: (0.543)(R 0.598, F 0.489)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.318] [G acc: 0.125]\n",
      "5675 [D loss: (0.514)(R 0.587, F 0.440)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.417] [G acc: 0.078]\n",
      "5676 [D loss: (0.481)(R 0.540, F 0.422)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.471] [G acc: 0.109]\n",
      "5677 [D loss: (0.504)(R 0.504, F 0.503)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.304] [G acc: 0.172]\n",
      "5678 [D loss: (0.551)(R 0.563, F 0.538)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.504] [G acc: 0.062]\n",
      "5679 [D loss: (0.513)(R 0.445, F 0.581)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.585] [G acc: 0.094]\n",
      "5680 [D loss: (0.573)(R 0.618, F 0.528)] [D acc: (0.664)(0.578, 0.750)] [G loss: 1.294] [G acc: 0.203]\n",
      "5681 [D loss: (0.550)(R 0.629, F 0.471)] [D acc: (0.672)(0.578, 0.766)] [G loss: 1.453] [G acc: 0.062]\n",
      "5682 [D loss: (0.482)(R 0.469, F 0.495)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.442] [G acc: 0.078]\n",
      "5683 [D loss: (0.536)(R 0.484, F 0.588)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.422] [G acc: 0.062]\n",
      "5684 [D loss: (0.454)(R 0.463, F 0.446)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.332] [G acc: 0.109]\n",
      "5685 [D loss: (0.535)(R 0.660, F 0.411)] [D acc: (0.727)(0.578, 0.875)] [G loss: 1.347] [G acc: 0.188]\n",
      "5686 [D loss: (0.625)(R 0.292, F 0.958)] [D acc: (0.758)(0.875, 0.641)] [G loss: 1.805] [G acc: 0.016]\n",
      "5687 [D loss: (0.506)(R 0.607, F 0.405)] [D acc: (0.750)(0.594, 0.906)] [G loss: 1.343] [G acc: 0.094]\n",
      "5688 [D loss: (0.502)(R 0.601, F 0.402)] [D acc: (0.805)(0.703, 0.906)] [G loss: 1.376] [G acc: 0.109]\n",
      "5689 [D loss: (0.495)(R 0.443, F 0.546)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.620] [G acc: 0.094]\n",
      "5690 [D loss: (0.610)(R 0.672, F 0.549)] [D acc: (0.680)(0.578, 0.781)] [G loss: 1.528] [G acc: 0.094]\n",
      "5691 [D loss: (0.472)(R 0.562, F 0.382)] [D acc: (0.797)(0.703, 0.891)] [G loss: 1.343] [G acc: 0.125]\n",
      "5692 [D loss: (0.545)(R 0.473, F 0.617)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.636] [G acc: 0.094]\n",
      "5693 [D loss: (0.484)(R 0.505, F 0.462)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.581] [G acc: 0.016]\n",
      "5694 [D loss: (0.528)(R 0.583, F 0.472)] [D acc: (0.773)(0.641, 0.906)] [G loss: 1.369] [G acc: 0.109]\n",
      "5695 [D loss: (0.418)(R 0.440, F 0.397)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.440] [G acc: 0.078]\n",
      "5696 [D loss: (0.420)(R 0.375, F 0.464)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.671] [G acc: 0.078]\n",
      "5697 [D loss: (0.520)(R 0.521, F 0.518)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.598] [G acc: 0.078]\n",
      "5698 [D loss: (0.487)(R 0.460, F 0.514)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.634] [G acc: 0.078]\n",
      "5699 [D loss: (0.586)(R 0.628, F 0.544)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.663] [G acc: 0.047]\n",
      "5700 [D loss: (0.538)(R 0.588, F 0.488)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.625] [G acc: 0.047]\n",
      "5701 [D loss: (0.490)(R 0.522, F 0.459)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.388] [G acc: 0.094]\n",
      "5702 [D loss: (0.458)(R 0.473, F 0.443)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.486] [G acc: 0.188]\n",
      "5703 [D loss: (0.548)(R 0.544, F 0.551)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.420] [G acc: 0.109]\n",
      "5704 [D loss: (0.443)(R 0.456, F 0.429)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.598] [G acc: 0.062]\n",
      "5705 [D loss: (0.458)(R 0.535, F 0.380)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.402] [G acc: 0.188]\n",
      "5706 [D loss: (0.448)(R 0.406, F 0.490)] [D acc: (0.797)(0.812, 0.781)] [G loss: 1.420] [G acc: 0.141]\n",
      "5707 [D loss: (0.581)(R 0.516, F 0.647)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.534] [G acc: 0.094]\n",
      "5708 [D loss: (0.540)(R 0.657, F 0.423)] [D acc: (0.719)(0.578, 0.859)] [G loss: 1.516] [G acc: 0.094]\n",
      "5709 [D loss: (0.462)(R 0.536, F 0.388)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.445] [G acc: 0.125]\n",
      "5710 [D loss: (0.429)(R 0.415, F 0.442)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.741] [G acc: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5711 [D loss: (0.466)(R 0.499, F 0.433)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.576] [G acc: 0.031]\n",
      "5712 [D loss: (0.527)(R 0.512, F 0.541)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.510] [G acc: 0.094]\n",
      "5713 [D loss: (0.553)(R 0.649, F 0.457)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.276] [G acc: 0.188]\n",
      "5714 [D loss: (0.670)(R 0.670, F 0.670)] [D acc: (0.664)(0.609, 0.719)] [G loss: 1.496] [G acc: 0.094]\n",
      "5715 [D loss: (0.468)(R 0.525, F 0.411)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.490] [G acc: 0.125]\n",
      "5716 [D loss: (0.437)(R 0.418, F 0.456)] [D acc: (0.812)(0.766, 0.859)] [G loss: 1.379] [G acc: 0.109]\n",
      "5717 [D loss: (0.533)(R 0.438, F 0.628)] [D acc: (0.773)(0.734, 0.812)] [G loss: 1.483] [G acc: 0.094]\n",
      "5718 [D loss: (0.474)(R 0.508, F 0.441)] [D acc: (0.805)(0.719, 0.891)] [G loss: 1.464] [G acc: 0.094]\n",
      "5719 [D loss: (0.570)(R 0.685, F 0.455)] [D acc: (0.688)(0.531, 0.844)] [G loss: 1.430] [G acc: 0.094]\n",
      "5720 [D loss: (0.578)(R 0.670, F 0.486)] [D acc: (0.664)(0.531, 0.797)] [G loss: 1.516] [G acc: 0.078]\n",
      "5721 [D loss: (0.511)(R 0.524, F 0.498)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.587] [G acc: 0.078]\n",
      "5722 [D loss: (0.475)(R 0.497, F 0.453)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.522] [G acc: 0.094]\n",
      "5723 [D loss: (0.452)(R 0.456, F 0.448)] [D acc: (0.773)(0.750, 0.797)] [G loss: 1.700] [G acc: 0.094]\n",
      "5724 [D loss: (0.533)(R 0.562, F 0.503)] [D acc: (0.695)(0.625, 0.766)] [G loss: 1.399] [G acc: 0.094]\n",
      "5725 [D loss: (0.555)(R 0.601, F 0.510)] [D acc: (0.711)(0.625, 0.797)] [G loss: 1.672] [G acc: 0.047]\n",
      "5726 [D loss: (0.494)(R 0.573, F 0.414)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.550] [G acc: 0.078]\n",
      "5727 [D loss: (0.788)(R 0.642, F 0.935)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.624] [G acc: 0.062]\n",
      "5728 [D loss: (0.539)(R 0.683, F 0.394)] [D acc: (0.664)(0.469, 0.859)] [G loss: 1.417] [G acc: 0.109]\n",
      "5729 [D loss: (0.441)(R 0.459, F 0.423)] [D acc: (0.836)(0.781, 0.891)] [G loss: 1.268] [G acc: 0.125]\n",
      "5730 [D loss: (0.438)(R 0.426, F 0.449)] [D acc: (0.820)(0.766, 0.875)] [G loss: 1.482] [G acc: 0.094]\n",
      "5731 [D loss: (0.566)(R 0.605, F 0.528)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.455] [G acc: 0.125]\n",
      "5732 [D loss: (0.523)(R 0.584, F 0.463)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.360] [G acc: 0.094]\n",
      "5733 [D loss: (0.530)(R 0.591, F 0.469)] [D acc: (0.703)(0.609, 0.797)] [G loss: 1.360] [G acc: 0.172]\n",
      "5734 [D loss: (0.398)(R 0.348, F 0.447)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.490] [G acc: 0.000]\n",
      "5735 [D loss: (0.469)(R 0.398, F 0.541)] [D acc: (0.789)(0.781, 0.797)] [G loss: 1.766] [G acc: 0.047]\n",
      "5736 [D loss: (0.497)(R 0.575, F 0.420)] [D acc: (0.797)(0.656, 0.938)] [G loss: 1.621] [G acc: 0.109]\n",
      "5737 [D loss: (0.547)(R 0.498, F 0.596)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.506] [G acc: 0.109]\n",
      "5738 [D loss: (0.433)(R 0.425, F 0.440)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.529] [G acc: 0.062]\n",
      "5739 [D loss: (0.550)(R 0.539, F 0.561)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.491] [G acc: 0.141]\n",
      "5740 [D loss: (0.427)(R 0.416, F 0.437)] [D acc: (0.797)(0.797, 0.797)] [G loss: 1.518] [G acc: 0.141]\n",
      "5741 [D loss: (0.523)(R 0.594, F 0.453)] [D acc: (0.766)(0.672, 0.859)] [G loss: 1.277] [G acc: 0.156]\n",
      "5742 [D loss: (0.416)(R 0.454, F 0.378)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.393] [G acc: 0.109]\n",
      "5743 [D loss: (0.470)(R 0.536, F 0.403)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.336] [G acc: 0.203]\n",
      "5744 [D loss: (0.565)(R 0.520, F 0.610)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.667] [G acc: 0.125]\n",
      "5745 [D loss: (0.447)(R 0.465, F 0.429)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.652] [G acc: 0.078]\n",
      "5746 [D loss: (0.439)(R 0.381, F 0.498)] [D acc: (0.836)(0.812, 0.859)] [G loss: 1.530] [G acc: 0.141]\n",
      "5747 [D loss: (0.559)(R 0.620, F 0.497)] [D acc: (0.695)(0.594, 0.797)] [G loss: 1.501] [G acc: 0.141]\n",
      "5748 [D loss: (0.649)(R 0.490, F 0.808)] [D acc: (0.688)(0.688, 0.688)] [G loss: 1.589] [G acc: 0.078]\n",
      "5749 [D loss: (0.536)(R 0.660, F 0.413)] [D acc: (0.719)(0.547, 0.891)] [G loss: 1.558] [G acc: 0.078]\n",
      "5750 [D loss: (0.514)(R 0.559, F 0.468)] [D acc: (0.719)(0.641, 0.797)] [G loss: 1.361] [G acc: 0.078]\n",
      "5751 [D loss: (0.510)(R 0.482, F 0.538)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.600] [G acc: 0.109]\n",
      "5752 [D loss: (0.473)(R 0.509, F 0.437)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.399] [G acc: 0.078]\n",
      "5753 [D loss: (0.419)(R 0.441, F 0.398)] [D acc: (0.828)(0.766, 0.891)] [G loss: 1.570] [G acc: 0.094]\n",
      "5754 [D loss: (0.485)(R 0.487, F 0.483)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.638] [G acc: 0.094]\n",
      "5755 [D loss: (0.426)(R 0.439, F 0.413)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.542] [G acc: 0.078]\n",
      "5756 [D loss: (0.585)(R 0.542, F 0.627)] [D acc: (0.734)(0.719, 0.750)] [G loss: 1.652] [G acc: 0.047]\n",
      "5757 [D loss: (0.457)(R 0.477, F 0.437)] [D acc: (0.836)(0.734, 0.938)] [G loss: 1.459] [G acc: 0.125]\n",
      "5758 [D loss: (0.478)(R 0.513, F 0.442)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.444] [G acc: 0.125]\n",
      "5759 [D loss: (0.450)(R 0.482, F 0.417)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.579] [G acc: 0.078]\n",
      "5760 [D loss: (0.523)(R 0.537, F 0.510)] [D acc: (0.727)(0.703, 0.750)] [G loss: 1.562] [G acc: 0.062]\n",
      "5761 [D loss: (0.541)(R 0.558, F 0.524)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.504] [G acc: 0.062]\n",
      "5762 [D loss: (0.529)(R 0.476, F 0.582)] [D acc: (0.688)(0.703, 0.672)] [G loss: 1.599] [G acc: 0.047]\n",
      "5763 [D loss: (0.609)(R 0.650, F 0.568)] [D acc: (0.664)(0.594, 0.734)] [G loss: 1.525] [G acc: 0.109]\n",
      "5764 [D loss: (0.552)(R 0.614, F 0.490)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.375] [G acc: 0.062]\n",
      "5765 [D loss: (0.512)(R 0.620, F 0.404)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.423] [G acc: 0.172]\n",
      "5766 [D loss: (0.585)(R 0.574, F 0.597)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.489] [G acc: 0.031]\n",
      "5767 [D loss: (0.424)(R 0.459, F 0.389)] [D acc: (0.797)(0.703, 0.891)] [G loss: 1.469] [G acc: 0.094]\n",
      "5768 [D loss: (0.515)(R 0.489, F 0.541)] [D acc: (0.695)(0.656, 0.734)] [G loss: 1.481] [G acc: 0.031]\n",
      "5769 [D loss: (0.604)(R 0.740, F 0.468)] [D acc: (0.727)(0.562, 0.891)] [G loss: 1.531] [G acc: 0.031]\n",
      "5770 [D loss: (0.392)(R 0.376, F 0.408)] [D acc: (0.836)(0.781, 0.891)] [G loss: 1.416] [G acc: 0.078]\n",
      "5771 [D loss: (0.388)(R 0.421, F 0.355)] [D acc: (0.812)(0.719, 0.906)] [G loss: 1.286] [G acc: 0.125]\n",
      "5772 [D loss: (0.511)(R 0.399, F 0.622)] [D acc: (0.797)(0.812, 0.781)] [G loss: 1.561] [G acc: 0.078]\n",
      "5773 [D loss: (0.499)(R 0.491, F 0.507)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.523] [G acc: 0.062]\n",
      "5774 [D loss: (0.559)(R 0.660, F 0.459)] [D acc: (0.688)(0.609, 0.766)] [G loss: 1.484] [G acc: 0.062]\n",
      "5775 [D loss: (0.432)(R 0.454, F 0.410)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.595] [G acc: 0.109]\n",
      "5776 [D loss: (0.532)(R 0.581, F 0.482)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.467] [G acc: 0.109]\n",
      "5777 [D loss: (0.488)(R 0.415, F 0.560)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.384] [G acc: 0.156]\n",
      "5778 [D loss: (0.478)(R 0.471, F 0.486)] [D acc: (0.727)(0.656, 0.797)] [G loss: 1.425] [G acc: 0.031]\n",
      "5779 [D loss: (0.458)(R 0.447, F 0.470)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.428] [G acc: 0.094]\n",
      "5780 [D loss: (0.552)(R 0.547, F 0.556)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.653] [G acc: 0.016]\n",
      "5781 [D loss: (0.476)(R 0.482, F 0.470)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.533] [G acc: 0.078]\n",
      "5782 [D loss: (0.559)(R 0.597, F 0.522)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.496] [G acc: 0.094]\n",
      "5783 [D loss: (0.568)(R 0.550, F 0.585)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.751] [G acc: 0.062]\n",
      "5784 [D loss: (0.480)(R 0.584, F 0.376)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.292] [G acc: 0.094]\n",
      "5785 [D loss: (0.530)(R 0.584, F 0.476)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.588] [G acc: 0.125]\n",
      "5786 [D loss: (0.531)(R 0.562, F 0.500)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.433] [G acc: 0.109]\n",
      "5787 [D loss: (0.461)(R 0.563, F 0.359)] [D acc: (0.805)(0.688, 0.922)] [G loss: 1.407] [G acc: 0.141]\n",
      "5788 [D loss: (0.448)(R 0.481, F 0.415)] [D acc: (0.820)(0.719, 0.922)] [G loss: 1.567] [G acc: 0.078]\n",
      "5789 [D loss: (0.538)(R 0.481, F 0.595)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.498] [G acc: 0.125]\n",
      "5790 [D loss: (0.460)(R 0.546, F 0.374)] [D acc: (0.781)(0.641, 0.922)] [G loss: 1.584] [G acc: 0.031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5791 [D loss: (0.640)(R 0.724, F 0.555)] [D acc: (0.648)(0.562, 0.734)] [G loss: 1.406] [G acc: 0.125]\n",
      "5792 [D loss: (0.570)(R 0.550, F 0.589)] [D acc: (0.711)(0.672, 0.750)] [G loss: 1.456] [G acc: 0.094]\n",
      "5793 [D loss: (0.502)(R 0.584, F 0.420)] [D acc: (0.758)(0.609, 0.906)] [G loss: 1.438] [G acc: 0.094]\n",
      "5794 [D loss: (0.511)(R 0.509, F 0.514)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.486] [G acc: 0.062]\n",
      "5795 [D loss: (0.486)(R 0.602, F 0.369)] [D acc: (0.742)(0.625, 0.859)] [G loss: 1.440] [G acc: 0.094]\n",
      "5796 [D loss: (0.435)(R 0.452, F 0.417)] [D acc: (0.828)(0.766, 0.891)] [G loss: 1.443] [G acc: 0.125]\n",
      "5797 [D loss: (0.440)(R 0.412, F 0.468)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.294] [G acc: 0.109]\n",
      "5798 [D loss: (0.522)(R 0.340, F 0.704)] [D acc: (0.766)(0.797, 0.734)] [G loss: 1.491] [G acc: 0.031]\n",
      "5799 [D loss: (0.472)(R 0.525, F 0.420)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.529] [G acc: 0.078]\n",
      "5800 [D loss: (0.565)(R 0.474, F 0.657)] [D acc: (0.742)(0.766, 0.719)] [G loss: 1.452] [G acc: 0.078]\n",
      "5801 [D loss: (0.464)(R 0.501, F 0.427)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.589] [G acc: 0.125]\n",
      "5802 [D loss: (0.566)(R 0.580, F 0.553)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.520] [G acc: 0.078]\n",
      "5803 [D loss: (0.531)(R 0.588, F 0.474)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.531] [G acc: 0.109]\n",
      "5804 [D loss: (0.423)(R 0.365, F 0.481)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.645] [G acc: 0.047]\n",
      "5805 [D loss: (0.477)(R 0.578, F 0.375)] [D acc: (0.789)(0.672, 0.906)] [G loss: 1.617] [G acc: 0.062]\n",
      "5806 [D loss: (0.598)(R 0.561, F 0.636)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.479] [G acc: 0.094]\n",
      "5807 [D loss: (0.518)(R 0.560, F 0.477)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.479] [G acc: 0.094]\n",
      "5808 [D loss: (0.496)(R 0.621, F 0.372)] [D acc: (0.719)(0.562, 0.875)] [G loss: 1.556] [G acc: 0.078]\n",
      "5809 [D loss: (0.460)(R 0.505, F 0.414)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.509] [G acc: 0.078]\n",
      "5810 [D loss: (0.575)(R 0.610, F 0.541)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.475] [G acc: 0.109]\n",
      "5811 [D loss: (0.446)(R 0.392, F 0.500)] [D acc: (0.789)(0.781, 0.797)] [G loss: 1.498] [G acc: 0.062]\n",
      "5812 [D loss: (0.454)(R 0.448, F 0.459)] [D acc: (0.820)(0.766, 0.875)] [G loss: 1.429] [G acc: 0.156]\n",
      "5813 [D loss: (0.483)(R 0.641, F 0.325)] [D acc: (0.773)(0.625, 0.922)] [G loss: 1.476] [G acc: 0.078]\n",
      "5814 [D loss: (0.554)(R 0.436, F 0.671)] [D acc: (0.734)(0.688, 0.781)] [G loss: 1.509] [G acc: 0.016]\n",
      "5815 [D loss: (0.543)(R 0.581, F 0.505)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.622] [G acc: 0.031]\n",
      "5816 [D loss: (0.549)(R 0.612, F 0.485)] [D acc: (0.711)(0.656, 0.766)] [G loss: 1.378] [G acc: 0.141]\n",
      "5817 [D loss: (0.547)(R 0.512, F 0.582)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.543] [G acc: 0.094]\n",
      "5818 [D loss: (0.556)(R 0.486, F 0.627)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.432] [G acc: 0.094]\n",
      "5819 [D loss: (0.520)(R 0.659, F 0.381)] [D acc: (0.719)(0.609, 0.828)] [G loss: 1.528] [G acc: 0.094]\n",
      "5820 [D loss: (0.554)(R 0.566, F 0.542)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.310] [G acc: 0.141]\n",
      "5821 [D loss: (0.418)(R 0.327, F 0.510)] [D acc: (0.805)(0.797, 0.812)] [G loss: 1.482] [G acc: 0.078]\n",
      "5822 [D loss: (0.496)(R 0.608, F 0.383)] [D acc: (0.734)(0.578, 0.891)] [G loss: 1.557] [G acc: 0.078]\n",
      "5823 [D loss: (0.509)(R 0.498, F 0.519)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.746] [G acc: 0.078]\n",
      "5824 [D loss: (0.608)(R 0.539, F 0.676)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.680] [G acc: 0.109]\n",
      "5825 [D loss: (0.426)(R 0.487, F 0.365)] [D acc: (0.789)(0.688, 0.891)] [G loss: 1.427] [G acc: 0.094]\n",
      "5826 [D loss: (0.609)(R 0.584, F 0.634)] [D acc: (0.680)(0.625, 0.734)] [G loss: 1.507] [G acc: 0.156]\n",
      "5827 [D loss: (0.523)(R 0.579, F 0.467)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.406] [G acc: 0.172]\n",
      "5828 [D loss: (0.458)(R 0.490, F 0.425)] [D acc: (0.820)(0.719, 0.922)] [G loss: 1.458] [G acc: 0.031]\n",
      "5829 [D loss: (0.485)(R 0.503, F 0.468)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.553] [G acc: 0.141]\n",
      "5830 [D loss: (0.451)(R 0.418, F 0.483)] [D acc: (0.789)(0.766, 0.812)] [G loss: 1.377] [G acc: 0.141]\n",
      "5831 [D loss: (0.498)(R 0.486, F 0.510)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.723] [G acc: 0.016]\n",
      "5832 [D loss: (0.462)(R 0.526, F 0.398)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.652] [G acc: 0.078]\n",
      "5833 [D loss: (0.558)(R 0.590, F 0.526)] [D acc: (0.688)(0.625, 0.750)] [G loss: 1.511] [G acc: 0.078]\n",
      "5834 [D loss: (0.527)(R 0.580, F 0.474)] [D acc: (0.734)(0.641, 0.828)] [G loss: 1.265] [G acc: 0.188]\n",
      "5835 [D loss: (0.467)(R 0.338, F 0.596)] [D acc: (0.773)(0.828, 0.719)] [G loss: 1.680] [G acc: 0.062]\n",
      "5836 [D loss: (0.535)(R 0.565, F 0.505)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.541] [G acc: 0.062]\n",
      "5837 [D loss: (0.470)(R 0.481, F 0.459)] [D acc: (0.789)(0.703, 0.875)] [G loss: 1.602] [G acc: 0.078]\n",
      "5838 [D loss: (0.557)(R 0.615, F 0.500)] [D acc: (0.672)(0.547, 0.797)] [G loss: 1.636] [G acc: 0.078]\n",
      "5839 [D loss: (0.550)(R 0.684, F 0.416)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.522] [G acc: 0.047]\n",
      "5840 [D loss: (0.533)(R 0.498, F 0.568)] [D acc: (0.742)(0.734, 0.750)] [G loss: 1.433] [G acc: 0.031]\n",
      "5841 [D loss: (0.456)(R 0.435, F 0.477)] [D acc: (0.805)(0.766, 0.844)] [G loss: 1.469] [G acc: 0.078]\n",
      "5842 [D loss: (0.512)(R 0.471, F 0.552)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.449] [G acc: 0.078]\n",
      "5843 [D loss: (0.403)(R 0.406, F 0.400)] [D acc: (0.836)(0.781, 0.891)] [G loss: 1.427] [G acc: 0.078]\n",
      "5844 [D loss: (0.498)(R 0.397, F 0.599)] [D acc: (0.820)(0.797, 0.844)] [G loss: 1.579] [G acc: 0.078]\n",
      "5845 [D loss: (0.597)(R 0.529, F 0.665)] [D acc: (0.711)(0.688, 0.734)] [G loss: 1.615] [G acc: 0.047]\n",
      "5846 [D loss: (0.381)(R 0.407, F 0.354)] [D acc: (0.820)(0.766, 0.875)] [G loss: 1.449] [G acc: 0.109]\n",
      "5847 [D loss: (0.564)(R 0.489, F 0.640)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.517] [G acc: 0.109]\n",
      "5848 [D loss: (0.532)(R 0.643, F 0.420)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.495] [G acc: 0.109]\n",
      "5849 [D loss: (0.550)(R 0.615, F 0.485)] [D acc: (0.758)(0.641, 0.875)] [G loss: 1.487] [G acc: 0.047]\n",
      "5850 [D loss: (0.434)(R 0.447, F 0.422)] [D acc: (0.820)(0.766, 0.875)] [G loss: 1.732] [G acc: 0.016]\n",
      "5851 [D loss: (0.512)(R 0.526, F 0.499)] [D acc: (0.789)(0.656, 0.922)] [G loss: 1.530] [G acc: 0.062]\n",
      "5852 [D loss: (0.473)(R 0.501, F 0.446)] [D acc: (0.789)(0.719, 0.859)] [G loss: 1.493] [G acc: 0.125]\n",
      "5853 [D loss: (0.519)(R 0.440, F 0.598)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.604] [G acc: 0.094]\n",
      "5854 [D loss: (0.520)(R 0.519, F 0.521)] [D acc: (0.680)(0.672, 0.688)] [G loss: 1.585] [G acc: 0.031]\n",
      "5855 [D loss: (0.530)(R 0.529, F 0.530)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.548] [G acc: 0.078]\n",
      "5856 [D loss: (0.567)(R 0.644, F 0.490)] [D acc: (0.695)(0.562, 0.828)] [G loss: 1.487] [G acc: 0.016]\n",
      "5857 [D loss: (0.460)(R 0.411, F 0.509)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.613] [G acc: 0.094]\n",
      "5858 [D loss: (0.510)(R 0.584, F 0.436)] [D acc: (0.727)(0.625, 0.828)] [G loss: 1.508] [G acc: 0.125]\n",
      "5859 [D loss: (0.611)(R 0.697, F 0.524)] [D acc: (0.633)(0.531, 0.734)] [G loss: 1.309] [G acc: 0.156]\n",
      "5860 [D loss: (0.498)(R 0.500, F 0.496)] [D acc: (0.797)(0.750, 0.844)] [G loss: 1.436] [G acc: 0.141]\n",
      "5861 [D loss: (0.543)(R 0.612, F 0.474)] [D acc: (0.773)(0.672, 0.875)] [G loss: 1.418] [G acc: 0.109]\n",
      "5862 [D loss: (0.521)(R 0.563, F 0.480)] [D acc: (0.773)(0.688, 0.859)] [G loss: 1.467] [G acc: 0.062]\n",
      "5863 [D loss: (0.610)(R 0.570, F 0.650)] [D acc: (0.672)(0.656, 0.688)] [G loss: 1.438] [G acc: 0.094]\n",
      "5864 [D loss: (0.584)(R 0.730, F 0.438)] [D acc: (0.688)(0.484, 0.891)] [G loss: 1.289] [G acc: 0.125]\n",
      "5865 [D loss: (0.450)(R 0.421, F 0.478)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.465] [G acc: 0.109]\n",
      "5866 [D loss: (0.553)(R 0.525, F 0.580)] [D acc: (0.695)(0.688, 0.703)] [G loss: 1.453] [G acc: 0.062]\n",
      "5867 [D loss: (0.525)(R 0.589, F 0.461)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.514] [G acc: 0.109]\n",
      "5868 [D loss: (0.599)(R 0.627, F 0.572)] [D acc: (0.727)(0.641, 0.812)] [G loss: 1.488] [G acc: 0.109]\n",
      "5869 [D loss: (0.475)(R 0.579, F 0.370)] [D acc: (0.797)(0.656, 0.938)] [G loss: 1.461] [G acc: 0.109]\n",
      "5870 [D loss: (0.452)(R 0.375, F 0.529)] [D acc: (0.812)(0.797, 0.828)] [G loss: 1.547] [G acc: 0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5871 [D loss: (0.511)(R 0.504, F 0.518)] [D acc: (0.758)(0.703, 0.812)] [G loss: 1.458] [G acc: 0.047]\n",
      "5872 [D loss: (0.595)(R 0.643, F 0.547)] [D acc: (0.688)(0.594, 0.781)] [G loss: 1.602] [G acc: 0.047]\n",
      "5873 [D loss: (0.532)(R 0.660, F 0.404)] [D acc: (0.734)(0.594, 0.875)] [G loss: 1.442] [G acc: 0.078]\n",
      "5874 [D loss: (0.505)(R 0.519, F 0.491)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.570] [G acc: 0.094]\n",
      "5875 [D loss: (0.579)(R 0.650, F 0.508)] [D acc: (0.711)(0.562, 0.859)] [G loss: 1.563] [G acc: 0.109]\n",
      "5876 [D loss: (0.552)(R 0.498, F 0.606)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.565] [G acc: 0.047]\n",
      "5877 [D loss: (0.514)(R 0.550, F 0.479)] [D acc: (0.719)(0.625, 0.812)] [G loss: 1.361] [G acc: 0.078]\n",
      "5878 [D loss: (0.422)(R 0.482, F 0.362)] [D acc: (0.797)(0.719, 0.875)] [G loss: 1.562] [G acc: 0.016]\n",
      "5879 [D loss: (0.475)(R 0.462, F 0.489)] [D acc: (0.781)(0.734, 0.828)] [G loss: 1.586] [G acc: 0.109]\n",
      "5880 [D loss: (0.595)(R 0.726, F 0.464)] [D acc: (0.641)(0.484, 0.797)] [G loss: 1.594] [G acc: 0.062]\n",
      "5881 [D loss: (0.654)(R 0.645, F 0.663)] [D acc: (0.672)(0.594, 0.750)] [G loss: 1.297] [G acc: 0.172]\n",
      "5882 [D loss: (0.512)(R 0.589, F 0.434)] [D acc: (0.742)(0.656, 0.828)] [G loss: 1.372] [G acc: 0.141]\n",
      "5883 [D loss: (0.553)(R 0.518, F 0.587)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.399] [G acc: 0.062]\n",
      "5884 [D loss: (0.434)(R 0.434, F 0.434)] [D acc: (0.805)(0.750, 0.859)] [G loss: 1.469] [G acc: 0.094]\n",
      "5885 [D loss: (0.602)(R 0.676, F 0.528)] [D acc: (0.703)(0.641, 0.766)] [G loss: 1.351] [G acc: 0.094]\n",
      "5886 [D loss: (0.515)(R 0.483, F 0.547)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.607] [G acc: 0.078]\n",
      "5887 [D loss: (0.500)(R 0.537, F 0.464)] [D acc: (0.742)(0.672, 0.812)] [G loss: 1.476] [G acc: 0.109]\n",
      "5888 [D loss: (0.561)(R 0.542, F 0.579)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.508] [G acc: 0.125]\n",
      "5889 [D loss: (0.521)(R 0.580, F 0.462)] [D acc: (0.750)(0.625, 0.875)] [G loss: 1.386] [G acc: 0.141]\n",
      "5890 [D loss: (0.591)(R 0.495, F 0.686)] [D acc: (0.703)(0.703, 0.703)] [G loss: 1.507] [G acc: 0.078]\n",
      "5891 [D loss: (0.558)(R 0.689, F 0.427)] [D acc: (0.688)(0.547, 0.828)] [G loss: 1.362] [G acc: 0.078]\n",
      "5892 [D loss: (0.484)(R 0.463, F 0.506)] [D acc: (0.766)(0.750, 0.781)] [G loss: 1.361] [G acc: 0.125]\n",
      "5893 [D loss: (0.571)(R 0.604, F 0.537)] [D acc: (0.672)(0.609, 0.734)] [G loss: 1.393] [G acc: 0.047]\n",
      "5894 [D loss: (0.520)(R 0.515, F 0.526)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.494] [G acc: 0.047]\n",
      "5895 [D loss: (0.448)(R 0.474, F 0.421)] [D acc: (0.812)(0.750, 0.875)] [G loss: 1.501] [G acc: 0.078]\n",
      "5896 [D loss: (0.514)(R 0.548, F 0.480)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.274] [G acc: 0.094]\n",
      "5897 [D loss: (0.538)(R 0.578, F 0.498)] [D acc: (0.773)(0.719, 0.828)] [G loss: 1.434] [G acc: 0.047]\n",
      "5898 [D loss: (0.529)(R 0.594, F 0.464)] [D acc: (0.711)(0.594, 0.828)] [G loss: 1.314] [G acc: 0.094]\n",
      "5899 [D loss: (0.543)(R 0.576, F 0.511)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.361] [G acc: 0.156]\n",
      "5900 [D loss: (0.415)(R 0.405, F 0.425)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.412] [G acc: 0.078]\n",
      "5901 [D loss: (0.630)(R 0.541, F 0.718)] [D acc: (0.680)(0.688, 0.672)] [G loss: 1.614] [G acc: 0.047]\n",
      "5902 [D loss: (0.560)(R 0.661, F 0.459)] [D acc: (0.695)(0.547, 0.844)] [G loss: 1.456] [G acc: 0.078]\n",
      "5903 [D loss: (0.440)(R 0.477, F 0.403)] [D acc: (0.836)(0.766, 0.906)] [G loss: 1.363] [G acc: 0.094]\n",
      "5904 [D loss: (0.474)(R 0.513, F 0.435)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.382] [G acc: 0.078]\n",
      "5905 [D loss: (0.447)(R 0.444, F 0.451)] [D acc: (0.812)(0.781, 0.844)] [G loss: 1.432] [G acc: 0.109]\n",
      "5906 [D loss: (0.554)(R 0.493, F 0.615)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.397] [G acc: 0.109]\n",
      "5907 [D loss: (0.514)(R 0.518, F 0.509)] [D acc: (0.789)(0.734, 0.844)] [G loss: 1.473] [G acc: 0.109]\n",
      "5908 [D loss: (0.497)(R 0.554, F 0.439)] [D acc: (0.750)(0.641, 0.859)] [G loss: 1.396] [G acc: 0.109]\n",
      "5909 [D loss: (0.606)(R 0.424, F 0.788)] [D acc: (0.750)(0.750, 0.750)] [G loss: 1.447] [G acc: 0.094]\n",
      "5910 [D loss: (0.525)(R 0.601, F 0.449)] [D acc: (0.742)(0.578, 0.906)] [G loss: 1.609] [G acc: 0.016]\n",
      "5911 [D loss: (0.507)(R 0.586, F 0.429)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.355] [G acc: 0.062]\n",
      "5912 [D loss: (0.517)(R 0.464, F 0.570)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.382] [G acc: 0.172]\n",
      "5913 [D loss: (0.506)(R 0.590, F 0.421)] [D acc: (0.734)(0.609, 0.859)] [G loss: 1.543] [G acc: 0.094]\n",
      "5914 [D loss: (0.650)(R 0.471, F 0.828)] [D acc: (0.711)(0.719, 0.703)] [G loss: 1.414] [G acc: 0.047]\n",
      "5915 [D loss: (0.601)(R 0.706, F 0.496)] [D acc: (0.680)(0.562, 0.797)] [G loss: 1.529] [G acc: 0.078]\n",
      "5916 [D loss: (0.588)(R 0.696, F 0.480)] [D acc: (0.727)(0.578, 0.875)] [G loss: 1.464] [G acc: 0.062]\n",
      "5917 [D loss: (0.530)(R 0.541, F 0.520)] [D acc: (0.695)(0.641, 0.750)] [G loss: 1.250] [G acc: 0.125]\n",
      "5918 [D loss: (0.459)(R 0.492, F 0.426)] [D acc: (0.805)(0.734, 0.875)] [G loss: 1.380] [G acc: 0.141]\n",
      "5919 [D loss: (0.469)(R 0.475, F 0.463)] [D acc: (0.789)(0.750, 0.828)] [G loss: 1.363] [G acc: 0.125]\n",
      "5920 [D loss: (0.540)(R 0.507, F 0.572)] [D acc: (0.727)(0.688, 0.766)] [G loss: 1.575] [G acc: 0.031]\n",
      "5921 [D loss: (0.501)(R 0.511, F 0.490)] [D acc: (0.812)(0.719, 0.906)] [G loss: 1.449] [G acc: 0.062]\n",
      "5922 [D loss: (0.541)(R 0.586, F 0.496)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.532] [G acc: 0.047]\n",
      "5923 [D loss: (0.509)(R 0.548, F 0.470)] [D acc: (0.711)(0.641, 0.781)] [G loss: 1.315] [G acc: 0.109]\n",
      "5924 [D loss: (0.560)(R 0.555, F 0.564)] [D acc: (0.742)(0.703, 0.781)] [G loss: 1.388] [G acc: 0.156]\n",
      "5925 [D loss: (0.464)(R 0.510, F 0.417)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.450] [G acc: 0.141]\n",
      "5926 [D loss: (0.472)(R 0.387, F 0.556)] [D acc: (0.781)(0.781, 0.781)] [G loss: 1.453] [G acc: 0.109]\n",
      "5927 [D loss: (0.504)(R 0.508, F 0.501)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.430] [G acc: 0.109]\n",
      "5928 [D loss: (0.455)(R 0.460, F 0.451)] [D acc: (0.766)(0.719, 0.812)] [G loss: 1.558] [G acc: 0.094]\n",
      "5929 [D loss: (0.483)(R 0.502, F 0.465)] [D acc: (0.750)(0.688, 0.812)] [G loss: 1.526] [G acc: 0.078]\n",
      "5930 [D loss: (0.560)(R 0.492, F 0.627)] [D acc: (0.703)(0.734, 0.672)] [G loss: 1.590] [G acc: 0.078]\n",
      "5931 [D loss: (0.450)(R 0.521, F 0.379)] [D acc: (0.797)(0.656, 0.938)] [G loss: 1.425] [G acc: 0.125]\n",
      "5932 [D loss: (0.506)(R 0.390, F 0.621)] [D acc: (0.766)(0.781, 0.750)] [G loss: 1.603] [G acc: 0.047]\n",
      "5933 [D loss: (0.588)(R 0.633, F 0.542)] [D acc: (0.711)(0.578, 0.844)] [G loss: 1.404] [G acc: 0.141]\n",
      "5934 [D loss: (0.453)(R 0.516, F 0.391)] [D acc: (0.805)(0.672, 0.938)] [G loss: 1.353] [G acc: 0.109]\n",
      "5935 [D loss: (0.556)(R 0.518, F 0.594)] [D acc: (0.719)(0.688, 0.750)] [G loss: 1.673] [G acc: 0.047]\n",
      "5936 [D loss: (0.479)(R 0.468, F 0.491)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.662] [G acc: 0.047]\n",
      "5937 [D loss: (0.486)(R 0.489, F 0.484)] [D acc: (0.727)(0.672, 0.781)] [G loss: 1.476] [G acc: 0.172]\n",
      "5938 [D loss: (0.551)(R 0.549, F 0.554)] [D acc: (0.758)(0.734, 0.781)] [G loss: 1.444] [G acc: 0.094]\n",
      "5939 [D loss: (0.455)(R 0.424, F 0.485)] [D acc: (0.797)(0.781, 0.812)] [G loss: 1.646] [G acc: 0.062]\n",
      "5940 [D loss: (0.489)(R 0.486, F 0.492)] [D acc: (0.805)(0.750, 0.859)] [G loss: 1.644] [G acc: 0.094]\n",
      "5941 [D loss: (0.471)(R 0.527, F 0.414)] [D acc: (0.797)(0.672, 0.922)] [G loss: 1.467] [G acc: 0.109]\n",
      "5942 [D loss: (0.574)(R 0.514, F 0.635)] [D acc: (0.773)(0.766, 0.781)] [G loss: 1.400] [G acc: 0.125]\n",
      "5943 [D loss: (0.664)(R 0.524, F 0.804)] [D acc: (0.719)(0.703, 0.734)] [G loss: 1.568] [G acc: 0.094]\n",
      "5944 [D loss: (0.524)(R 0.708, F 0.341)] [D acc: (0.773)(0.562, 0.984)] [G loss: 1.509] [G acc: 0.078]\n",
      "5945 [D loss: (0.518)(R 0.527, F 0.510)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.477] [G acc: 0.109]\n",
      "5946 [D loss: (0.561)(R 0.589, F 0.534)] [D acc: (0.750)(0.656, 0.844)] [G loss: 1.541] [G acc: 0.094]\n",
      "5947 [D loss: (0.397)(R 0.371, F 0.423)] [D acc: (0.844)(0.859, 0.828)] [G loss: 1.673] [G acc: 0.031]\n",
      "5948 [D loss: (0.518)(R 0.607, F 0.429)] [D acc: (0.742)(0.578, 0.906)] [G loss: 1.562] [G acc: 0.109]\n",
      "5949 [D loss: (0.526)(R 0.502, F 0.551)] [D acc: (0.727)(0.719, 0.734)] [G loss: 1.622] [G acc: 0.109]\n",
      "5950 [D loss: (0.533)(R 0.577, F 0.489)] [D acc: (0.742)(0.688, 0.797)] [G loss: 1.479] [G acc: 0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5951 [D loss: (0.501)(R 0.486, F 0.516)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.428] [G acc: 0.094]\n",
      "5952 [D loss: (0.428)(R 0.422, F 0.433)] [D acc: (0.820)(0.797, 0.844)] [G loss: 1.674] [G acc: 0.047]\n",
      "5953 [D loss: (0.419)(R 0.484, F 0.354)] [D acc: (0.820)(0.719, 0.922)] [G loss: 1.624] [G acc: 0.031]\n",
      "5954 [D loss: (0.454)(R 0.450, F 0.458)] [D acc: (0.781)(0.719, 0.844)] [G loss: 1.583] [G acc: 0.078]\n",
      "5955 [D loss: (0.529)(R 0.549, F 0.510)] [D acc: (0.750)(0.703, 0.797)] [G loss: 1.511] [G acc: 0.141]\n",
      "5956 [D loss: (0.471)(R 0.477, F 0.465)] [D acc: (0.766)(0.688, 0.844)] [G loss: 1.636] [G acc: 0.031]\n",
      "5957 [D loss: (0.443)(R 0.397, F 0.488)] [D acc: (0.781)(0.766, 0.797)] [G loss: 1.459] [G acc: 0.141]\n",
      "5958 [D loss: (0.518)(R 0.441, F 0.596)] [D acc: (0.750)(0.719, 0.781)] [G loss: 1.644] [G acc: 0.109]\n",
      "5959 [D loss: (0.494)(R 0.577, F 0.410)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.500] [G acc: 0.109]\n",
      "5960 [D loss: (0.456)(R 0.500, F 0.412)] [D acc: (0.734)(0.656, 0.812)] [G loss: 1.433] [G acc: 0.172]\n",
      "5961 [D loss: (0.546)(R 0.495, F 0.597)] [D acc: (0.734)(0.703, 0.766)] [G loss: 1.553] [G acc: 0.078]\n",
      "5962 [D loss: (0.510)(R 0.541, F 0.478)] [D acc: (0.758)(0.719, 0.797)] [G loss: 1.674] [G acc: 0.062]\n",
      "5963 [D loss: (0.572)(R 0.653, F 0.491)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.522] [G acc: 0.078]\n",
      "5964 [D loss: (0.522)(R 0.514, F 0.529)] [D acc: (0.766)(0.734, 0.797)] [G loss: 1.333] [G acc: 0.141]\n",
      "5965 [D loss: (0.448)(R 0.387, F 0.510)] [D acc: (0.797)(0.797, 0.797)] [G loss: 1.555] [G acc: 0.078]\n",
      "5966 [D loss: (0.506)(R 0.505, F 0.506)] [D acc: (0.742)(0.719, 0.766)] [G loss: 1.472] [G acc: 0.188]\n",
      "5967 [D loss: (0.405)(R 0.303, F 0.508)] [D acc: (0.820)(0.844, 0.797)] [G loss: 1.629] [G acc: 0.094]\n",
      "5968 [D loss: (0.576)(R 0.542, F 0.611)] [D acc: (0.711)(0.703, 0.719)] [G loss: 1.739] [G acc: 0.031]\n",
      "5969 [D loss: (0.507)(R 0.592, F 0.423)] [D acc: (0.742)(0.609, 0.875)] [G loss: 1.644] [G acc: 0.062]\n",
      "5970 [D loss: (0.631)(R 0.613, F 0.648)] [D acc: (0.688)(0.641, 0.734)] [G loss: 1.676] [G acc: 0.078]\n",
      "5971 [D loss: (0.500)(R 0.611, F 0.389)] [D acc: (0.711)(0.531, 0.891)] [G loss: 1.683] [G acc: 0.031]\n",
      "5972 [D loss: (0.428)(R 0.425, F 0.431)] [D acc: (0.797)(0.781, 0.812)] [G loss: 1.683] [G acc: 0.062]\n",
      "5973 [D loss: (0.512)(R 0.573, F 0.451)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.656] [G acc: 0.078]\n",
      "5974 [D loss: (0.580)(R 0.719, F 0.440)] [D acc: (0.727)(0.609, 0.844)] [G loss: 1.362] [G acc: 0.172]\n",
      "5975 [D loss: (0.538)(R 0.509, F 0.567)] [D acc: (0.703)(0.719, 0.688)] [G loss: 1.489] [G acc: 0.109]\n",
      "5976 [D loss: (0.476)(R 0.570, F 0.382)] [D acc: (0.789)(0.672, 0.906)] [G loss: 1.592] [G acc: 0.031]\n",
      "5977 [D loss: (0.485)(R 0.429, F 0.540)] [D acc: (0.758)(0.766, 0.750)] [G loss: 1.480] [G acc: 0.094]\n",
      "5978 [D loss: (0.517)(R 0.544, F 0.490)] [D acc: (0.734)(0.672, 0.797)] [G loss: 1.528] [G acc: 0.062]\n",
      "5979 [D loss: (0.561)(R 0.656, F 0.465)] [D acc: (0.680)(0.609, 0.750)] [G loss: 1.464] [G acc: 0.078]\n",
      "5980 [D loss: (0.469)(R 0.509, F 0.430)] [D acc: (0.797)(0.734, 0.859)] [G loss: 1.584] [G acc: 0.062]\n",
      "5981 [D loss: (0.513)(R 0.481, F 0.545)] [D acc: (0.719)(0.672, 0.766)] [G loss: 1.510] [G acc: 0.094]\n",
      "5982 [D loss: (0.495)(R 0.575, F 0.415)] [D acc: (0.734)(0.625, 0.844)] [G loss: 1.469] [G acc: 0.109]\n",
      "5983 [D loss: (0.525)(R 0.504, F 0.547)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.502] [G acc: 0.109]\n",
      "5984 [D loss: (0.452)(R 0.478, F 0.427)] [D acc: (0.758)(0.688, 0.828)] [G loss: 1.471] [G acc: 0.125]\n",
      "5985 [D loss: (0.551)(R 0.629, F 0.473)] [D acc: (0.766)(0.656, 0.875)] [G loss: 1.390] [G acc: 0.094]\n",
      "5986 [D loss: (0.569)(R 0.511, F 0.627)] [D acc: (0.695)(0.703, 0.688)] [G loss: 1.601] [G acc: 0.047]\n",
      "5987 [D loss: (0.538)(R 0.671, F 0.405)] [D acc: (0.734)(0.578, 0.891)] [G loss: 1.389] [G acc: 0.109]\n",
      "5988 [D loss: (0.539)(R 0.529, F 0.550)] [D acc: (0.688)(0.656, 0.719)] [G loss: 1.338] [G acc: 0.125]\n",
      "5989 [D loss: (0.594)(R 0.595, F 0.594)] [D acc: (0.703)(0.578, 0.828)] [G loss: 1.388] [G acc: 0.141]\n",
      "5990 [D loss: (0.466)(R 0.484, F 0.447)] [D acc: (0.773)(0.703, 0.844)] [G loss: 1.316] [G acc: 0.203]\n",
      "5991 [D loss: (0.596)(R 0.622, F 0.570)] [D acc: (0.656)(0.578, 0.734)] [G loss: 1.423] [G acc: 0.094]\n",
      "5992 [D loss: (0.493)(R 0.483, F 0.502)] [D acc: (0.820)(0.734, 0.906)] [G loss: 1.557] [G acc: 0.078]\n",
      "5993 [D loss: (0.492)(R 0.524, F 0.460)] [D acc: (0.766)(0.703, 0.828)] [G loss: 1.436] [G acc: 0.125]\n",
      "5994 [D loss: (0.504)(R 0.539, F 0.468)] [D acc: (0.750)(0.672, 0.828)] [G loss: 1.558] [G acc: 0.047]\n",
      "5995 [D loss: (0.464)(R 0.397, F 0.531)] [D acc: (0.820)(0.781, 0.859)] [G loss: 1.580] [G acc: 0.047]\n",
      "5996 [D loss: (0.554)(R 0.602, F 0.506)] [D acc: (0.703)(0.625, 0.781)] [G loss: 1.404] [G acc: 0.062]\n",
      "5997 [D loss: (0.509)(R 0.567, F 0.451)] [D acc: (0.758)(0.656, 0.859)] [G loss: 1.435] [G acc: 0.109]\n",
      "5998 [D loss: (0.569)(R 0.416, F 0.721)] [D acc: (0.719)(0.781, 0.656)] [G loss: 1.422] [G acc: 0.094]\n",
      "5999 [D loss: (0.493)(R 0.584, F 0.403)] [D acc: (0.781)(0.672, 0.891)] [G loss: 1.373] [G acc: 0.109]\n"
     ]
    }
   ],
   "source": [
    "gan.train(     \n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[0] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "plt.ylim(0, 2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[3] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "plt.plot([x[4] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[5] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[1] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('accuracy', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 에포크 20\n",
    "![20](run/gan/0001_camel/images/sample_20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 에포크 200\n",
    "![200](run/gan/0001_camel/images/sample_200.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 에포크 400\n",
    "![400](run/gan/0001_camel/images/sample_400.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 에포크 1000\n",
    "![1000](run/gan/0001_camel/images/sample_1000.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 에포크 2000\n",
    "![2000](run/gan/0001_camel/images/sample_2000.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
